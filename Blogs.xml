<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Booles&apos; Rings -- Blogs</title>
    <link>http://boolesrings.org/</link>
    <updated>2019-10-12T18:45:35Z</updated>
    <author>
        <name>Booles&apos; Rings</name>
        <email>info@boolesrings.org</email>
        <uri>http://boolesrings.org</uri>
    </author>
    <link rel="alternate" href="http://boolesrings.org/"/>
    <subtitle>Researchers. Connecting.</subtitle>
    <logo>http://boolesrings.org/favicon.gif</logo>
    <rights>No copyright asserted over individual posts; see original posts for copyright and/or licensing.</rights>
    <generator>Feed for Node.js</generator>
    <entry>
        <title type="html"><![CDATA[On conjugacy problems for graphs and trees]]></title>
        <id>http://scoskey.org/presentation/on-conjugacy-problems-for-graphs-and-trees/</id>
        <link href="http://scoskey.org/presentation/on-conjugacy-problems-for-graphs-and-trees/">
        </link>
        <updated>2019-10-11T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Boise Set Theory and Logic Seminar, October 2019<!--more--></p>

<p>Abstract: Given a graph or tree G, the conjugacy problem for G is the conjugacy equivalence relation on the group Aut(G) of automorphisms of G. In this talk we will introduce the basic framework for studying the complexity of the conjugacy problem for G, and then use it to examine a series of examples of graphs and trees G. In particular we will demonstrate that a variety of complexities can occur, from trivial (smooth), up to maximally complex (Borel complete), and in between.</p>]]></summary>
        <author>
            <name>Samuel Coskey</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[(with Y. Hayut) Perfect Subtree Property for Weakly Compact Cardinals]]></title>
        <id>https://muellersandra.github.io/publication/2019/10/11/PaperPSPweaklycompact.html</id>
        <link href="https://muellersandra.github.io/publication/2019/10/11/PaperPSPweaklycompact.html">
        </link>
        <updated>2019-10-10T22:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Submitted. <a href="http://www.logic.univie.ac.at/~smueller/HayutMuellerPSPwc.pdf">PDF.</a> 
<a data-toggle="collapse" href="javascript:toggle('bibHM19');" class="title">Bibtex.</a></p>

<div style="display:none" id="bibHM19">
<pre class="collapse"> @ARTICLE{HM19,
   AUTHOR= {Y. Hayut and S. Müller},
   TITLE= {Perfect Subtree Property for Weakly Compact Cardinals},
   Note={Submitted} }</pre>
</div>

<!--more-->

<p>In this paper we investigate the consistency strength of the statement: $\kappa$ is weakly compact and there is no tree on $\kappa$ with exactly $\kappa^{+}$ many branches. We show that this property fails strongly (there is a sealed tree) if there is no inner model with a Woodin cardinal. On the other hand, we show that this property as well as the related Perfect Subtree Property for $\kappa$, implies the consistency of $\operatorname{AD}_{\mathbb{R}}$.</p>]]></summary>
        <author>
            <name>Sandra Müller</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ground model definability in ${\rm ZF}$]]></title>
        <id>https://victoriagitman.github.io/talks/2019/10/10/ground-model-definability-in-zf.html</id>
        <link href="https://victoriagitman.github.io/talks/2019/10/10/ground-model-definability-in-zf.html">
        </link>
        <updated>2019-10-10T04:00:00Z</updated>
        <summary type="html"><![CDATA[<p>This is a talk at the <a href="http://jointmathematicsmeetings.org/jmm">Joint Mathematics Meeting</a>, special session on 'Choiceless Set Theory and related areas', University of Denver, January 15-16, 2020.<br><strong><a href="">Slides</a></strong><!--more--></p>
<p>
Laver, and independently Woodin, showed that a ground model is always definable (with a ground model parameter) in its set-forcing extensions <a href="#laver:groundmodel">[1]</a>, <a href="#woodin:groundmodel">[2]</a>. More so, the definition is uniform for all ${\rm ZFC}$-universes: there is a single formula $\varphi(x,y)$ such that whenever $V\models{\rm ZFC}$ and $V[G]$ is a set-forcing extension of $V$ by a poset $\mathbb P\in V$ of size $|\mathbb P|^V=\gamma$, then $V$ is defined in $V[G]$ by $\varphi(x,P^V(\delta))$ with $\delta=(\gamma^+)^V(=(\gamma^+)^{V[G]})$. Let's explain what the formula $\varphi(x,P^V(\delta))$ says. Let ${\rm Z}^*$ be a certain finite fragment of ${\rm ZFC}$. We will say that a transitive model $M\in V[G]$ is <em>good</em> if $M\models {\rm Z}^*$, $P^M(\delta)=P^V(\delta)$ and $(\delta^+)^M=(\delta^+)^{V[G]}$. The formula $\varphi(x,P^V(\delta))$ then holds of a set $x$ if $x$ is an element of a good model $M$ of height $\lambda\gg\delta$ such that $V[G]_\lambda\models {\rm Z}^*$ and the pair $M\subseteq V[G]_\lambda$ has the $\delta$-cover and $\delta$-approximation properties (we will explain what those are in a moment). Here is the reason the formula works. Any forcing extension by a poset of size less than a regular cardinal $\delta$ has the property that there are unboundedly many ordinals $\lambda$ such that both $V_\lambda$ and $V[G]_\lambda$ satisfy ${\rm Z}^*$ and the pair $V_\lambda\subseteq V[G]_\lambda$ has the $\delta$-cover and $\delta$-approximation properties. Also, if there is a good model $M$ of height $\lambda$ with $P^M(\delta)=P^V(\delta)$ and $(\delta^+)^M=(\delta^+)^{V[G]}$ such that that pair $M\subseteq V[G]_\delta\models {\rm Z}^*$ has the the $\delta$-cover and $\delta$-approximation properties, then the model is unique. Hence such a model $M$ of height $\lambda$ can only be $V_\lambda$.</p>
<p>
The notions of $\delta$-cover and $\delta$-approximation properties are due to Hamkins <a href="#hamkins:coverandapproximations">[3]</a>. Suppose that $V\subseteq W$ are transitive models of (some fragment of) ${\rm ZFC}$ and $\delta$ is a cardinal in $W$.
<ol>
<li>
The pair $V\subseteq W$ satisfies the <em>$\delta$-cover property</em> if for every $A\in W$ with $A\subseteq V$ and $|A|^W<\delta$, there is $B\in V$ with $A\subseteq B$ and $|B|^V<\delta$.</li>
<li>The pair $V\subseteq W$ satisfies the <em>$\delta$-approximation property</em> if whenever $A\in W$ with $A\subseteq V$ and $A\cap a\in V$ for every $a$ of size less than $\delta$ in $V$, then $A\in V$.</li>
</ol>
</p>
<p>
Because the existence of cardinalities is fundamental to the definition of the cover and approximation properties, these notions appear to rely  essentially on the axiom of choice. Therefore proofs of ground model definability based on these properties cannot be easily modified to work in the absence of choice. It is not known yet whether ground definability holds in ${\rm ZF}$. There are partial positive results and no known counterexamples.</p>

<p>With Tom Johnstone, we adapted the approximation and cover properties arguments to show that for a cardinal $\delta$, uniform ground model definability holds in models of ${\rm ZF}+{\rm DC}_\delta$ for posets admitting a gap at $\delta$.</p>
<p>
<strong>Theorem</strong>: There is a single formula $\varphi(x,y)$ such that whenever $V\models{\rm ZF}+{\rm DC}_\delta$ and $V[G]$ is a set-forcing extension of $V$ by a poset $\mathbb P$ admitting a gap at $\delta$ in $V$, then $V$ is defined in $V[G]$ by $\varphi(x,P^V(\delta))$.
</p><p>
A poset is said to <em>admit a gap at $\delta$</em> if it has the form $\mathbb R*\dot{\mathbb Q}$ where $\mathbb R$ is a non-trivial forcing of size less than $\delta$ and it is forced by $\mathbb R$ that is $\dot{\mathbb Q}$ is $\leq\delta$-strategically closed. The $\delta$-dependent choice principle ${\rm DC}_\delta$, introduced by Lévy, allows us to make $\delta$-many dependent choices along any relation without terminal nodes. It asserts that for any non-empty set $S$ and any binary relation  $R$, if for each sequence $s\in S^{\lt\delta}$ there is a $y\in S$ such that $s$ is $R$ related $y$, then there is a function $f:\delta\to S$ such that $f\upharpoonright\alpha \,R\, f(\alpha)$ for all $\alpha<\delta$. The principle ${\rm DC}_\delta$ is robust for forcing with posets admitting a gap at $\delta$ because they preserve it to the forcing extension (see <a href="#gitmanjohnstone:groundmodels">[4]</a>).</p>
<p>
A very different recent partial result on ${\rm ZF}$-ground model definability is due to Usuba <a href="#Usuba:ZFGroundModelDefinability">[5]</a>. Usuba showed that if a ${\rm ZF}$-universe has a proper class of Löwenheim-Skolem cardinals, a notion which he introduces, then uniform ground model definability holds for it.</p><p>
<strong>Theorem</strong>: There is a single formula $\varphi(x,y)$ such that whenever $V$ is a model of ${\rm ZF}$ with a proper class of Löwenheim-Skolem cardinals and $V[G]$ is a set-forcing extension of $V$ by a poset $\mathbb P\in V_\kappa$ for a Lowenheim-Skolem cardinal $\kappa$, then $V$ is defined in the extension $V[G]$ by $\varphi(x,V_\kappa)$.</p><p>

Usuba's proof is another modification of the arguments using cover and approximation, where he replaces the notion of cardinality by a rough measure on sets, defining for a set $x$ that the measure $|\!|x|\!|$ is the least ordinal $\alpha$ such that there is a surjection from $V_\alpha$ onto $x$.
</p><p>
An uncountable cardinal $\kappa$ is a <em>Löwenheim-Skolem</em> (${\rm LS}$) <em>cardinal</em> if for every $\gamma<\kappa\leq\alpha$ and $x\in V_\alpha$, there is $\beta>\alpha$ and an elementary $X\prec V_\beta$ such that
<ol>
<li>$V_\gamma\subseteq X$,</li>
<li>$x\in X$,</li>
<li>the transitive collapse of $X$ belongs to $V_\kappa$,</li>
<li>$(X\cap V_\alpha)^{V_\gamma}\subseteq X$.</li>
</ol>
In a model of ${\rm ZFC}$, the ${\rm LS}$ cardinals are precisely the $\beth$-fixed point cardinals, and so in particular there are proper class many ${\rm LS}$ cardinals. Let us say, following Woodin, that an uncountable cardinal $\kappa$ is <em>supercompact</em> in a model of ${\rm ZF}$ if for every $\alpha\geq\kappa$, there is $\beta\geq\alpha$, a transitive set $N$ and an elementary embedding $j:V_\beta\to N$ such that the critical point of $j$ is $\kappa$, $\alpha < j(\kappa)$, and $N^{V_\alpha}\subseteq N$. It is not difficult to see that every supercompact cardinal is an ${\rm LS}$ cardinal. So, for example, models of ${\rm ZF}$ with a proper class of supercompact cardinals satisfy uniform ground model definability. </p>
<p>
The existence of ${\rm LS}$ cardinals is absolute throughout the generic multiverse <a href="#Usuba:ZFGroundModelDefinability">[5]</a>. It follows that if we can force choice over a ${\rm ZF}$-universe, then since its forcing extension has a proper class of ${\rm LS}$ cardinals, it must have a proper class of ${\rm LS}$ cardinals as well. Thus, in particular, ground model definability holds for any ${\rm ZF}$-universe, such as $L(\mathbb R)$, over which we can force the axiom of choice.</p>
<p>
At the same time, it is known that there are ${\rm ZF}$ universes without any ${\rm LS}$-cardinals. Let's explain how. Usuba showed that if $\kappa$ is an ${\rm LS}$-cardinal, then the club filter on $\kappa^+$ must be $\kappa$-complete <a href="#Usuba:ZFGroundModelDefinability">[5]</a>. Asaf Karagila showed that every model $V$ of ${\rm ZFC}$ has an extension to a model of ${\rm ZF}$ with the same cofinalities in which the club filter is not $\sigma$-complete on every regular cardinal $\kappa$ <a href="#karagila:Fodor">[6]</a>. This model cannot have any ${\rm LS}$ cardinals because if $\kappa$ in it was an ${\rm LS}$-cardinal, then $\kappa^+$ would be a regular cardinal (since cofinalities from $V$ are preserved) with a $\kappa$-complete club filter.</p>
<p>
One important consequence of uniform ground model definability is that it makes it possible to define in a first-order way the collection of all grounds of a ${\rm ZFC}$-universe. A priori this is a collection of classes, a second-order notion, but using ground model definability we can write down a first-order formula $\psi(x,y)$ such that for every set $a$, the class $W_a=\{x\mid \psi(x,a)\}$ is a ground of $V$ and for every $W$ ground of $V$, there is a set $a$ such that $W=W_a$. The first-order definability of the collection of grounds makes it possible to study their structure in ${\rm ZFC}$. This has led to the very fruitful subject of set-theoretic geology, initiated by Fuchs, Hamkins, and Reitz, which explores the structure of grounds of a set-theoretic universe. Ground model definability for ${\rm ZF}$ would allow us to extend the same analysis to ${\rm ZF}$-universes, and Usuba's theorem has now made such an analysis possible for a large collection of models, namely those with a proper class of ${\rm LS}$ cardinals. 

We will have to wait to find out whether ground definability holds fully in ${\rm ZF}$.

<h2>References</h2>
<ol class="bibliography"><li><span id="laver:groundmodel">R. Laver, “Certain very large cardinals are not created in small forcing
              extensions,” <i>Ann. Pure Appl. Logic</i>, vol. 149, no. 1-3, pp. 1–6, 2007. Available at: http://dx.doi.org/10.1016/j.apal.2007.07.002</span></li>
<li><span id="woodin:groundmodel">H. Woodin, “Recent developments on Cantor’s Continuum Hypothesis,” in <i>Proceedings of the continuum in Philosophy and Mathematics</i>, 2004. </span></li>
<li><span id="hamkins:coverandapproximations">J. D. Hamkins, “Extensions with the approximation and cover properties have no
              new large cardinals,” <i>Fund. Math.</i>, vol. 180, no. 3, pp. 257–277, 2003. Available at: http://dx.doi.org/10.4064/fm180-3-4</span></li>
<li><span id="gitmanjohnstone:groundmodels">V. Gitman and T. A. Johnstone, “On ground model definability,” in <i>Infinity, Computability, and Metamathematics: Festschrift in honour of the 60th birthdays of Peter Koepke and Philip Welch</i>, London, GB: College publications, 2014. </span></li>
<li><span id="Usuba:ZFGroundModelDefinability">T. Usuba, “Choiceless Löwenheim-Skolem property and uniform definability of grounds,” <i>Manuscript</i>. </span></li>
<li><span id="karagila:Fodor">A. Karagila, “Fodor’s lemma can fail everywhere,” <i>Acta Math. Hungar.</i>, vol. 154, no. 1, pp. 231–242, 2018. Available at: https://doi.org/10.1007/s10474-017-0768-5</span></li></ol>]]></summary>
        <author>
            <name>Victoria Gitman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Structural properties of the stable core]]></title>
        <id>https://victoriagitman.github.io/publications/2019/10/10/structural-properties-of-the-stable-core.html</id>
        <link href="https://victoriagitman.github.io/publications/2019/10/10/structural-properties-of-the-stable-core.html">
        </link>
        <updated>2019-10-10T04:00:00Z</updated>
        <summary type="html"><![CDATA[<p><span id="FriedmanGitmanMuller:StableCore">S.-D. Friedman, V. Gitman, and S. Müller, “Some properties of the Stable Core,” <i>Manuscript</i>. </span></p>

<p>The first author introduced the inner model <em>stable core</em> while investigating under what
circumstances the universe $V$ is a class forcing extension of the
inner model ${\rm HOD}$, the collection of all hereditarily ordinal
definable sets (missing reference). He showed in (missing reference) that there is a robust $\Delta_2$-definable
class $S$ contained in ${\rm HOD}$ such that $V$ is a class-forcing extension of the structure $\langle L[S],\in, S\rangle$, which he called the stable core, by an ${\rm Ord}$-cc class partial order $\mathbb P$ definable from $S$. Indeed, for any inner model $M$, $V$ is a $\mathbb P$-forcing extension of $\langle M[S],\in,S\rangle$, so that in particular, since ${\rm HOD}[S]={\rm HOD}$, $V$ is a $\mathbb P$-forcing extension of $\langle {\rm HOD},\in,S\rangle$.</p>

<p>Let's explain the result in more detail for the stable core $L[S]$, noting that exactly the same analysis applies to ${\rm HOD}$. The partial order $\mathbb P$ is definable in $\langle L[S],\in,S\rangle$ and there is a generic filter $G$, meeting all dense sub-classes of $\mathbb P$ definable in $\langle L[S],\in,S\rangle$,
such that $V=L[S][G]$. All standard forcing theorems hold for $\mathbb P$ since it has the ${\rm Ord}$-cc. Thus, we get that the forcing relation for $\mathbb P$ is definable in $\langle L[S],\in,S\rangle$ and the forcing extension $\langle V,\in,G\rangle\models{\rm ZFC}$. However, this particular generic filter $G$ is not definable in $V$. To obtain $G$, we first force with an auxiliary forcing $\mathbb Q$ to add a particular class $F$, without adding sets, such that $V=L[F]$. We then show that $G$ is definable from $F$ and $F$ is in turn definable in the structure $\langle L[S][G], \in, S,G\rangle$, so that $L[S][G]=V$. This gives a formulation of the result as a ${\rm ZFC}$-theorem because we can say (using the definitions of $\mathbb P$ and $\mathbb Q$) that it is forced by $\mathbb Q$ that $V=L[F]$, where $F$ is $V$-generic for $\mathbb Q$, and (the definition of) $G$ is $\langle L[S],\in,S\rangle$-generic, and finally that $F$ is definable in $\langle L[S][G],\in,S,G\rangle$. Of course, a careful formulation would say that the result holds for all sufficiently large natural numbers $n$, where $n$ bounds the complexity of the formulas used.</p>
<p>
Without the niceness requirement on $\mathbb P$ that it has the ${\rm Ord}$-cc, there is a much easier construction of a class forcing notion $\mathbb P$, suggested by Woodin, such that $V$ is a class forcing extension of $\langle {\rm HOD},\in, \mathbb P\rangle$. At the same time, some additional predicate must be added to ${\rm HOD}$ in
order to realize all of $V$ as a class-forcing extension because, as
Hamkins and Reitz observed in
<a href="#HamkinsReitz:The-set-theoretic-universe-is-not-necessarily-a-forcing-extension-of-HOD">[1]</a>,
it is consistent that $V$ is not a class-forcing extension of ${\rm HOD}$. To construct such a counterexample, we suppose that $\kappa$ is inaccessible in $L$ and force over the Kelley-Morse model $\mathcal L=\langle L_\kappa,\in, L_{\kappa+1}\rangle$ to code the truth predicate of $L_\kappa$ (which is an element of $L_{\kappa+1}$) into the continuum pattern below $\kappa$. The first-order part $L_\kappa[G]$ of this extension cannot be a forcing extension of ${\rm HOD}^{L_\kappa[G]}=L_\kappa$ (by the weak homogeneity of the coding forcing), because the truth predicate of $L_\kappa$ is definable there and this can be recovered via the forcing relation.</p>
<p>
While the definition of the partial order $\mathbb P$ is fairly involved, the
<em>stability predicate</em> $S$ simply codes the elementarity relations
between sufficiently nice initial segments $H_\alpha$ (the collection of all sets with transitive closure of size less than $\alpha$) of $V$. Given a
natural number $n\geq 1$, call a cardinal $\alpha$ $n$-<em>good</em> if
it is a strong limit cardinal and $H_\alpha$ satisfies
$\Sigma_n$-collection. The predicate $S$ consists of
triples $(n,\alpha,\beta)$ such that $n\geq 1$, $\alpha$ and $\beta$
are $n$-good cardinals and $H_\alpha\prec_{\Sigma_n}H_\beta$. We will denote by $S_n$ the $n$-th slice of the stability predicate $S$, namely $S_n=\{(\alpha,\beta)\mid (n,\alpha,\beta)\in S\}$.</p>

<p>
Clearly the stable core $L[S]\subseteq{\rm HOD}$, and the first author showed in (missing reference) that
it is consistent that $L[S]$ is smaller than ${\rm HOD}$. The stable core has several nice properties which fail for ${\rm HOD}$ such as that it is partially forcing absolute and, assuming ${\rm GCH}$, is preserved by forcing to code the universe into a real (missing reference)</p>

<p>
In order to
motivate the many questions which arise about the stable core let us
briefly discuss the set-theoretic goals of studying inner models.</p>

<p>The study of canonical inner models has proved to be one of the most
fruitful directions of modern set-theoretic research. The canonical
inner models, of which Gödel's constructible universe $L$ was the first
example, are built bottom-up by a canonical procedure. The resulting
fine structure of the models leads to regularity properties, such as
the ${\rm GCH}$ and $\square$, and sometimes even absoluteness
properties. But all known canonical inner models are incompatible with
sufficiently large large cardinals, and indeed each such inner model
is very far from the universe in the presence of sufficiently large
large cardinals in the sense, for example, that covering fails and the
large cardinals are not downward absolute.</p>
<p>
The inner model ${\rm HOD}$ was introduced by Gödel, who showed that in a
universe of ${\rm ZF}$ it is always a model of ${\rm ZFC}$. But unlike the
constructible universe which also shares this property, ${\rm HOD}$ has
turned out to be highly non-canonical. While $L$ cannot be modified by
forcing, ${\rm HOD}$ can be easily changed by forcing because we can use
forcing to code information into ${\rm HOD}$. For instance, any subset of
the ordinals from $V$ can be made ordinal definable in a set-forcing extension
by coding its characteristic function into the continuum pattern, so
that it becomes an element of the ${\rm HOD}$ of the extension. Indeed, by
coding all of $V$ into the continuum pattern of a class-forcing
extension, Roguski showed that every universe $V$ is the ${\rm HOD}$ of one
of its class-forcing extensions <a href="#Roguski:HOD">[2]</a>. Thus, any
consistent set-theoretic property, including all known large cardinals, consistently holds in ${\rm HOD}$. At the same time, the
${\rm HOD}$ of a given universe can be very far from it. It is consistent
that every measurable cardinal is not even weakly compact in ${\rm HOD}$
and that a universe can have a supercompact cardinal which is not even
weakly compact in ${\rm HOD}$
<a href="#ChengFriedmanHamkins:LargeCardinalsNeedNotBeLargeInHOD">[3]</a>. It is
also consistent that ${\rm HOD}$ is wrong about all successor cardinals
<a href="#CummingsFriedmanGolshani:CollapsingCardinalsHOD">[4]</a>.</p>
<p>
Does the stable core behave more like the canonical inner models or
more like ${\rm HOD}$? Is there a fine structural version of the stable
core, does it satisfy regularity properties such as the ${\rm GCH}$? Is
there a bound on the large cardinals that are compatible with the stable core? Or, on the other hand, are the large cardinals
downward absolute to the stable core? Can we code information into the
stable core using forcing?</p><p>

In this article, we show the following results about the structure of
the stable core, which answer some of the aforementioned questions as
well as motivate further questions about the structure of the stable
core in the presence of sufficiently large large cardinals.</p>
<p>
Measurable cardinals are consistent with the stable core.</p><p>
<strong>Theorem</strong>:
<ol>
<li> The stable core of $L[\mu]$, the canonical model for one measurable
  cardinal, is $L[\mu]$. In particular, the stable core can have a measurable cardinal.</li>
<li> If $\vec U=\langle U_\alpha\mid\alpha\in{\rm Ord}\rangle$ is a discrete collection of normal measures, then the stable core of $L[\vec U]$ is $L[\vec U]$. In particular, the stable core can have a discrete proper class of measurable cardinals.
</li>
</ol></p>
<p>
We can code information into the stable core over $L$ or $L[\mu]$
using forcing.</p><p>
<strong>Theorem</strong>:
  Suppose $\mathbb P\in L$ is a forcing notion and $G\subseteq \mathbb P$ is
  $L$-generic. Then there is a further forcing extension $L[G][H]$
  such that $G\in L[S^{L[G][H]}]$ (the universe of the stable core). An analogous result holds for
  $L[\mu]$.</p>
<p>
An extension of the coding results shows that the ${\rm GCH}$ can fail
badly in the stable core.</p>
<p>
<strong>Theorem</strong>:
<ol>
<li>There is a class-forcing extension of $L$ such that in its stable core the ${\rm GCH}$
  fails at every regular cardinal.</li>
<li> There is a class-forcing extension of $L[\mu]$ such that in its stable core there is
  a measurable cardinal and the ${\rm GCH}$ fails on a tail of regular
  cardinals.</li>
</ol>
</p>
<p>
Measurable cardinals need not be downward absolute to the stable core.</p>
<p><strong>Theorem</strong>:
  There is a forcing extension of $L[\mu]$ in which the measurable
  cardinal $\kappa$ of $L[\mu]$ remains measurable, but it is not even
  weakly compact in the stable core.</p>
<p>

Although we don't know whether the stable core can have a measurable limit of measurables, the stable core has inner models with measurable limits of measurables, and much more. Say that a cardinal $\kappa$ is $1$-<em>measurable</em>
if it is measurable, and, for $n < \omega$, $(n+1)$-<em>measurable</em> if it
is measurable and a limit of $n$-measurable cardinals. Write $m_0^\#$ for $0^\#$ and $m_n^\#$ for the minimal mouse which is a sharp for a proper class of $n$-measurable cardinals, namely, an active mouse $\mathcal M$ such that the critical point of the top extender is a limit of $n$-measurable cardinals in $\mathcal M$. Here we mean <em>mouse</em> in the sense of <a href="#Mitchell:BeginningInnerModelTheory">[5]</a> (Sections 1 and 2), i.e., a mouse has only total measures on its sequence. The mouse $m_n^{\#}$ can also be construed as a fine structural
mouse with both total and partial extenders (see <a href="#Zeman:InnerModelsLargeCardinals">[6]</a>, Section 4).</p>
<p><strong>Theorem</strong>:
  For all $n<\omega$, if $m_{n+1}^\#$ exists, then $m_n^\#$ is in the
  stable core.
</p>
<p>
Moreover, we obtain the following characterization of natural inner
models of the stable core.
</p>
<p>
<strong>Theorem</strong>:
  Let $n < \omega$ and suppose that $m_n^\#$ exists. Then whenever
  $$C_1\supseteq C_2\supseteq\ldots\supseteq C_n$$ are class clubs of
  uncountable cardinals such that for every $1 < i\leq n$ and every
  $\gamma \in C_i$,
\[\langle H_\gamma,\in, C_1,\ldots,C_{i-1}\rangle\prec_{\Sigma_1} \langle V,\in,
  C_1,\ldots,C_{i-1}\rangle,\] then $L[C_1,\ldots,C_n]$ is a hyperclass-forcing extension of a (truncated) iterate of $m_n^\#$.
</p>


<h2>References</h2>
<ol class="bibliography"><li><span id="HamkinsReitz:The-set-theoretic-universe-is-not-necessarily-a-forcing-extension-of-HOD">J. D. Hamkins and J. Reitz, “The set-theoretic universe $V$ is not necessarily a class-forcing extension of HOD,” <i>ArXiv e-prints</i>, Sep. 2017. Available at: http://jdh.hamkins.org/the-universe-need-not-be-a-class-forcing-extension-of-hod</span></li>
<li><span id="Roguski:HOD">S. Roguski, “Cardinals and iterations of ${\rm HOD}$,” <i>Colloq. Math.</i>, vol. 58, no. 2, pp. 159–161, 1990. Available at: https://doi.org/10.4064/cm-58-2-159-161</span></li>
<li><span id="ChengFriedmanHamkins:LargeCardinalsNeedNotBeLargeInHOD">Y. Cheng, S.-D. Friedman, and J. D. Hamkins, “Large cardinals need not be large in HOD,” <i>Ann. Pure Appl. Logic</i>, vol. 166, no. 11, pp. 1186–1198, 2015. Available at: https://doi.org/10.1016/j.apal.2015.07.004</span></li>
<li><span id="CummingsFriedmanGolshani:CollapsingCardinalsHOD">J. Cummings, S. D. Friedman, and M. Golshani, “Collapsing the cardinals of HOD,” <i>J. Math. Log.</i>, vol. 15, no. 2, pp. 1550007, 32, 2015. Available at: https://doi.org/10.1142/S0219061315500075</span></li>
<li><span id="Mitchell:BeginningInnerModelTheory">W. J. Mitchell, “Beginning inner model theory,” in <i>Handbook of set theory. Vols. 1, 2, 3</i>, Springer, Dordrecht, 2010, pp. 1449–1495. Available at: https://doi.org/10.1007/978-1-4020-5764-9_18</span></li>
<li><span id="Zeman:InnerModelsLargeCardinals">M. Zeman, <i>Inner Models and Large Cardinals</i>. Walter de Gruyter, 2002. Available at: https://books.google.at/books?id=V0bLReBbRDEC</span></li></ol>]]></summary>
        <author>
            <name>Victoria Gitman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[(with S.-D. Friedman and V. Gitman) Structural Properties of the Stable Core]]></title>
        <id>https://muellersandra.github.io/publication/2019/10/05/PaperStableCore.html</id>
        <link href="https://muellersandra.github.io/publication/2019/10/05/PaperStableCore.html">
        </link>
        <updated>2019-10-04T22:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Submitted. <a href="https://arxiv.org/pdf/1910.02265.pdf">PDF.</a> <a href="https://arxiv.org/abs/1910.02265">arXiv.</a>
<a data-toggle="collapse" href="javascript:toggle('bibFGM19');" class="title">Bibtex.</a></p>

<div style="display:none" id="bibFGM19">
<pre class="collapse"> @ARTICLE{FGM19,
   AUTHOR= {S.-D. Friedman and V. Gitman},
   TITLE= {Structural Properties of the Stable Core},
   Note={Submitted},
   EPRINT ={1910.02265}}</pre>
</div>

<!--more-->

<p>The stable core, an inner model of the form $\langle L[S],\in, S\rangle$ for a simply definable predicate $S$, was introduced by the first author in [Fri12], where he showed that $V$ is a class forcing extension of its stable core. We study the structural properties of the stable core and its interactions with large cardinals. We show that the $\operatorname{GCH}$ can fail at all regular cardinals in the stable core, that the stable core can have a discrete proper class of measurable cardinals, but that measurable cardinals need not be downward absolute to the stable core. Moreover, we show that, if large cardinals exist in $V$, then the stable core has inner models with a proper class of measurable limits of measurables, with a proper class of measurable limits of measurable limits of measurables, and so forth. We show this by providing a characterization of natural inner models $L[C_1, \dots, C_n]$ for specially nested class clubs $C_1, \dots, C_n$, like those arising in the stable core, generalizing recent results of Welch [Wel19].</p>]]></summary>
        <author>
            <name>Sandra Müller</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The 15th International Workshop on Set Theory in Luminy, September 2019]]></title>
        <id>http://blog.assafrinot.com/?p=4602</id>
        <link href="http://blog.assafrinot.com/?p=4602">
        </link>
        <updated>2019-09-28T15:02:37Z</updated>
        <summary type="html"><![CDATA[<div class="thanks_button_div" 
                  style="margin-bottom: 30px;"><div id="thanksButtonDiv_4602_2" style="background-image:url(http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/thanks_compact_brown1.png); background-repeat:no-repeat; float: left; display: inline;"
                onmouseover="javascript:thankYouChangeButtonImage('thanksButtonDiv_4602_2', true);" 
                onmouseout="javascript:thankYouChangeButtonImage('thanksButtonDiv_4602_2', false);"
                onclick="javascript:thankYouChangeButtonImage('thanksButtonDiv_4602_2', false);" >
                <input type="button" onclick="thankYouButtonClick(4602, 'You left &ldquo;Thanks&rdquo; already for this post')" value="Like 4"
                  class="thanks_button thanks_compact thanks_brown"
                  style="  font-family: Verdana, Arial, Sans-Serif; font-size: 14px; font-weight: normal;; color:#ffffff;"
                  id="thanksButton_4602_2" title="Click to leave &ldquo;Thanks&rdquo; for this post"/>
             </div><div id="ajax_loader_4602_2" style="display:inline;visibility: hidden;"><img alt="ajax loader" src="http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/ajax-loader.gif" /></div></div><p>I gave an invited talk at the <a href="https://conferences.cirm-math.fr/2052.html">15th International Workshop on Set Theory in Luminy</a> in Marseille, September 2019.</p>
<p><strong>Talk Title: </strong>Chain conditions, unbounded colorings and the C-sequence spectrum.</p>
<p><strong>Abstract: </strong>The productivity of the $\kappa$-chain condition, where $\kappa$ is a regular, uncountable cardinal, has been the focus of a great deal of set-theoretic research.</p>
<p>In the 1970&#8217;s, consistent examples of $\kappa$-cc posets whose squares are not $\kappa$-cc were constructed by Laver, Galvin, Roitman and Fleissner. Later, ZFC examples were constructed by Todorcevic, Shelah, and others. The most difficult case, that in which $\kappa = \aleph_2$, was resolved by Shelah in 1997.</p>
<p>In the first part of this talk, we shall present analogous results regarding the infinite productivity of chain conditions stronger than $\kappa$-cc. In particular, for any successor cardinal $\kappa$, we produce a ZFC example of a poset with precaliber $\kappa$ whose $\omega^{\mathrm{th}}$ power is not $\kappa$-cc. To do so, we introduce and study the principle $\textrm{U}(\kappa,\mu,\theta,\chi)$ asserting the existence of a coloring $c:[\kappa]^2\rightarrow\theta$ satisfying a strong unboundedness condition.</p>
<p>In the second part of this talk, we shall introduce and study a new cardinal invariant $\chi(\kappa)$ for a regular uncountable cardinal $\kappa$. For inaccessible $\kappa$, $\chi(\kappa)$ may be seen as a measure of how far away $\kappa$ is from being weakly compact. We shall prove that if $\chi(\kappa)&gt;1$, then $\chi(\kappa)=\max(\mathrm{Cspec}(\kappa))$, where:</p>
<p>1. $\textrm{Cspec}(\kappa) := \{\chi(\vec{C}) \mid \vec{C}$ is a $C$-sequence over $\kappa\} \setminus \omega$, and</p>
<p>2. $\chi(\vec{C})$ is the least cardinal $\chi \leq \kappa$ such that there exist $\Delta \in [\kappa]^\kappa$ and $b:\kappa\rightarrow[\kappa]^\chi$ with $\Delta\cap\alpha\subseteq\bigcup_{\beta\in b(\alpha)}C_\beta$ for every $\alpha&lt;\kappa$.</p>
<p>We shall also prove that if $\chi(\kappa)=1$, then $\kappa$ is greatly Mahlo, prove the consistency (modulo the existence of a supercompact) of $\chi(\aleph_{\omega+1})=\aleph_0$, and carry a systematic study of the effect of square principles on the $C$-sequence spectrum.</p>
<p>In the last part of this talk, we shall unveil an unexpected connection between the two principles discussed in the previous parts, proving that, for infinite regular cardinals $\theta&lt;\kappa$, $\theta\in\mathrm{Cspec}(\kappa)$ iff there is a closed witness to $\mathrm{U}(\kappa,\kappa,\theta,\theta)$.</p>
<p>This is joint work with <a href="http://blog.assafrinot.com/?persons=chris-lambie-hanson">Chris Lambie-Hanson</a>.</p>
<p><strong>Downloads:</strong></p>
<p><p><table class=paperruler"><tr><td><a onclick="thankYouButtonClick(4602, '')" href="http://www.assafrinot.com/files/rinot_luminy2019.pdf" class="billet_slides"></a><a href="http://www.assafrinot.com/paper/34" class="billet_further"></a><a href="http://www.assafrinot.com/talk/luminy2019" class="billet_perm"></a></td></tr></table></p><span id="more-4602"></span></p>]]></summary>
        <author>
            <name>Assaf Rinot</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The $\Sigma_1$-definable universal finite sequence]]></title>
        <id>http://jdh.hamkins.org/the-sigma_1-definable-universal-finite-sequence/</id>
        <link href="http://jdh.hamkins.org/the-sigma_1-definable-universal-finite-sequence/">
        </link>
        <updated>2019-09-25T16:38:13Z</updated>
        <summary type="html"><![CDATA[J. D. Hamkins and K. J. Williams, &#8220;The $\Sigma_1$-definable universal finite sequence,&#8221; ArXiv e-prints, 2019. (undeer review) &#160; Citation ar&#967;iv @ARTICLE{HamkinsWilliams:The-universal-finite-sequence, author = {Joel David Hamkins and Kameryn J. Williams}, title = {The $\Sigma_1$-definable universal finite sequence}, journal = {ArXiv &#8230; <a href="http://jdh.hamkins.org/the-sigma_1-definable-universal-finite-sequence/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[I know that you know that I know that you know…. Oxford, October 2019]]></title>
        <id>http://jdh.hamkins.org/i-know-that-you-know-that-i-know-that-you-know-oxford-october-2019/</id>
        <link href="http://jdh.hamkins.org/i-know-that-you-know-that-i-know-that-you-know-oxford-october-2019/">
        </link>
        <updated>2019-09-25T14:49:54Z</updated>
        <summary type="html"><![CDATA[This will be a fun start-of-term Philosophy Undergraduate Welcome Lecture for philosophy students at Oxford in the Mathematics &#38; Philosophy, Physics &#38; Philosophy, Computer Science &#38; Philosophy, and Philosophy &#38; Linguistics degrees. New students are especially encouraged, but everyone is &#8230; <a href="http://jdh.hamkins.org/i-know-that-you-know-that-i-know-that-you-know-oxford-october-2019/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Weeknote 2019/38]]></title>
        <id>https://www.peterkrautzberger.org/0212/</id>
        <link href="https://www.peterkrautzberger.org/0212/">
        </link>
        <updated>2019-09-21T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Let's see if I can <a href="https://www.peterkrautzberger.org/0211">keep this up</a>. I have a feeling these posts could be a collection of all the small bits and pieces that do not warrant a blog post.</p>
<h2>Work</h2>
<p>Work was full of organizational stuff - everything from reorganizing git repos to organizing people t which seems odd since I was fairly addicted to it as a kid/ya o organizing reporting data. So in many ways uneventful but for me usually a form of complementary exercise which gives me a productivity boost once all the end-of-quarter shenanigans are over.</p>
<h2>Media</h2>
<p>I've been thinking about my media usage recently, in particular the role of podcasts and video hosting platforms (ok, mostly youtube at the moment).</p>
<p>For the past two decades, the internet gradually eliminated any need (of mine) for TV consumption. Besides the obvious (there's a ton of media with a single subscription to a streaming service, a ton more with multiple subscriptions, and virtually all media in gray areas), I was pondering &quot;TV programming&quot; recently. It's something that many friends still describe as pleasing (switch on the TV and just watch something) and I would usually argue against it. But recently I noticed how similar subscriptions to YouTube channels work. This is especially impressive with more original work such as <a href="https://de.wikipedia.org/wiki/Druck_(Webserie)">Druck</a>, the German version of <a href="https://de.wikipedia.org/wiki/Skam_(Fernsehserie)">Skam</a>, which timestamps its episodes and releases them on matching times of day. Reading about their approach (and watching a season, which was quite interesting in itself and as a parent) made me realize how I use my YouTube subscriptions like TV programming. It's ephemeral, passing me by, tuning in, maybe hopping to the next one. And yet it's way better than even tivo-era TV as it gives both the ephemeral and the archival.</p>
<p>Similarly, podcasts (and again to some degree YouTube) have done much of the same for my radio consumption. Serious news stations like Deutschlandfunk, BBC 4, and various forms of NPR have been in my life since forever, and yet their consumption has been reduced to morning news and otherwise podcasts. In addition, podcasting covers anything from web industry to fiction, from comedy to whatever <a href="https://blog.richter.fm/category/podcast/derweisheit">Der Weisheit</a> is (basically 4 friends chatting). I struggled to find interesting music podcasts (as in: playing contemporary popular music) for a while but I eventually found a few I liked; YouTube music channels do the rest.</p>
<p>Anyhoo, just a reminder that this internet is wonderful, I guess.</p>
<h2>Links</h2>
<p>I thought one way to use this format might be to just browse through Mastodon and see what I find (boosted or, gasp, original content). So here we go.</p>
<p>Christian posted lovely 3D printable Lᵖ norm balls thing:</p>
<iframe src="https://mathstodon.xyz/@christianp/102807944228401858/embed" class="mastodon-embed" style="max-width: 100%; border: 0" width="400" allowfullscreen="allowfullscreen"></iframe>
<iframe src="https://mathstodon.xyz/@christianp/102807949209412600/embed" class="mastodon-embed" style="max-width: 100%; border: 0" width="400" allowfullscreen="allowfullscreen"></iframe>
<p>David Eppstein linked to a glorious collection of Turing Complete things.</p>
<iframe src="https://mathstodon.xyz/@11011110/102789724968251958/embed" class="mastodon-embed" style="max-width: 100%; border: 0" width="400" allowfullscreen="allowfullscreen"></iframe>
<script src="https://mathstodon.xyz/embed.js" async="async"></script>
<h2>Life</h2>
<p>We finally went to <a href="https://fridaysforfuture.de/allefuersklima/">fridays for future</a> this week; the fucking least we can all do is to show up whenever we can and always support them.</p>
<p>Oh, my keyboard; I wanted to get onto that, didn't I.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lectures on the philosophy of mathematics, Oxford, Michaelmas term 2019]]></title>
        <id>http://jdh.hamkins.org/lectures-on-the-philosophy-of-mathematics-oxford-michaelmas-2019/</id>
        <link href="http://jdh.hamkins.org/lectures-on-the-philosophy-of-mathematics-oxford-michaelmas-2019/">
        </link>
        <updated>2019-09-20T17:42:03Z</updated>
        <summary type="html"><![CDATA[This will be a series of self-contained lectures on the philosophy of mathematics, given at Oxford University in Michaelmas term 2019. We will be meeting in the Radcliffe Humanities Lecture Room at the Faculty of Philosophy every Friday 12-1 during &#8230; <a href="http://jdh.hamkins.org/lectures-on-the-philosophy-of-mathematics-oxford-michaelmas-2019/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Methods in Higher Forcing Axioms: The inevitable conclusion]]></title>
        <id>http://karagila.org/2019/mehifox-conclusions/</id>
        <link href="http://karagila.org/2019/mehifox-conclusions/">
        </link>
        <updated>2019-09-17T16:42:31Z</updated>
        <summary type="html"><![CDATA[<p>The meeting in Norwich is over. Here are my thoughts.</p>

<p>It felt haphazard, without a concrete plan. And that was great. In the first day, Tadatoshi Miyamoto and David (Asperó) presented two problems in the morning and in the early afternoon. We then had a discussion about them, and it was just a general discussion, that went very well. <a href="http://karagila.org/2019/mehifox-conclusions/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Weeknote 2019/37]]></title>
        <id>https://www.peterkrautzberger.org/0211/</id>
        <link href="https://www.peterkrautzberger.org/0211/">
        </link>
        <updated>2019-09-14T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I've fallen silent this year. There were a lot of reasons for that. Mostly bad things, but many good things, too. I want to try to find a way back to writing, especially given this blog's 10<sup>th</sup> anniversary coming up in December. I've never been very personal on this personal site of mine; or perhaps more precisely I may not have appeared to be so, that is, I've not been writing the stuff most people think of when they say &quot;personal website&quot;. I'm thinking maybe I'll give it a try.</p>
<p>Anyway. I really like this idea of a weeknote which I first saw at <a href="https://daverupert.com/">Dave Rupert's</a> and then at <a href="https://www.baldurbjarnason.com/">Baldur Bjarnason's</a>. Let's give it a try and see how it feels.</p>
<h2>Work</h2>
<p>Work has been mixed this week. A big chunk of in-depth work was finalizing (what feels like a countless number of) tests for a very old piece of code that never had any tests. As this code had grown into a little bit of a monster, I now feel much more in control of it and ready to rewrite/port it. I also got into the GitHub Actions beta this week which looks nice and should help automate a bunch of stuff that's being done by a much less natural GitHub app (client permitting, anyway).</p>
<p>Oh, and I had some interesting work helping some (print) designers wrap their heads around some web thing. That was a ton of fun and maybe it will turn into more, we'll see.</p>
<h2>Reading</h2>
<p>I've been having a fit of escapism and churning through Harry Dresden novels at a high pace; as re-readings go, these are still quite good. I still don't like some things but I do still like how he grew the universe, something so many fantasy series fail at. This year really has been a year of re-reading incidentally; there are worse things.</p>
<h2>Life</h2>
<p>I had the yearly meeting of our daycare (which is set up as an association run by the parents). I'm the data privacy person for another year which has really been quite interesting (thanks, GDPR); after focusing on the digital side (where I'm more comfortable), it's time to focus on the physical side, where I look forward to learning a few new things. Otherwise, I was amazed how little drama we had; in the end, we seem to be good people, wanting to make things better.</p>
<p><a href="https://scoskey.org/">Sam</a> and I are back to regular meetings after a long summer which is just plain good. Besides good times, we are working on upgrades to <a href="http://mathblogging.org/">mathblogging.org</a> and <a href="http://boolesrings.org/">boolesrings.org</a>.</p>
<p>I also think it may be time to finally fix my laptop's keyboard. First the left ctrl key went (which was fun to relearn with the right ctrl key), then the tick and some numbers started to become iffy (which gets annoying) but with the letter E starting to act up I'm really coming to the end of the line. I don't know why I keep dragging it out. Let's see if I have an update in the next note, shall we?</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Carnival of Math No. 173]]></title>
        <id>https://www.peterkrautzberger.org/0210/</id>
        <link href="https://www.peterkrautzberger.org/0210/">
        </link>
        <updated>2019-09-12T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>This year I <a href="https://www.peterkrautzberger.org/0194/">once again</a> have the pleasure to host the now <strong>173th Carnival of Mathematics</strong>, the moveable feast of mathematical blogging shepherded by <a href="http://aperiodical.com/carnival-of-mathematics/">The Aperiodical</a>, the best math blogging collective on this little blue ball in space. Be sure to <a href="https://leeyieng.wordpress.com/2019/08/04/carnival-of-mathematics-172/">visit the previous Carnival (No. 172) at Cassandra Lee Yieng's blog</a> and keep an eye on <a href="https://aperiodical.com/carnival-of-mathematics/">all Carnivals</a>.</p>
<p>As tradition will have it, we begin our show by taking a closer look at our number.</p>
<p><strong>173</strong> is not just a prime, the sum of two squares of primes (2²+13²) <em>and</em> the sum of three primes (53+59+61). No, it is also a <a href="https://en.wikipedia.org/wiki/Balanced_prime">balanced prime</a> (same gap to previous and following prime) and the 13<sup>th</sup>(!) <a href="https://en.wikipedia.org/wiki/Sophie_Germain_prime">Sopie Germain prime</a> (since 2×173+1=347 is also prime).</p>
<figure>
<img width="256" style="margin: 0 auto;" alt="Sophie Germain" src="https://upload.wikimedia.org/wikipedia/commons/8/8b/Germain.jpeg">
<figcaption>Portrait of <a href="https://en.wikipedia.org/wiki/Sophie_Germain">Sophie Germain</a> (April 1, 1776 - June 27, 1831), <a href="https://commons.wikimedia.org/wiki/File:Germain.jpeg">[Public domain], via Wikimedia Commons</a></figcaption>
</figure>
<p>Alas, 173 is also an <a href="https://en.wikipedia.org/wiki/Odious_number">odious number</a>, which may sound rather bad but just means it has an odd number of 1's in binary (10101101).</p>
<p>Now that you've warmed up, let us once again enter the decidely wonderful, balanced madness of the mathematical blogging carnival.</p>
<hr>
<p>Likely most people (or at least the most people) will already have seen the NYT's Kenneth Chang looking into <a href="https://www.nytimes.com/2019/08/06/science/math-equation-pemdas.html">Why Mathematicians hate that viral equation</a>; but really who needs 8÷2(2+2) when you can so easily have drama with the Oxford Comma.</p>
<p>In any case, make sure you head over to Over at the Art of Research where Vi Hart shared <a href="https://theartofresearch.org/computation-for-hands-systems-for-humans/">Computation for Hands, Systems for Humans</a>, taking you on the magic carpet ride that's Vi's hands &quot;craving computation&quot;, combining hardware, software, systems thinking, VR and a ton of other ideas.</p>
<p>Before you continue to Ari Rubinsztejn explains <a href="https://gereshes.com/2019/05/27/why-tracking-space-debris-is-so-hard/">Why Tracking Space Debris is so Hard</a> (thanks, nonlinear dynamics!), step under the cover of the Undercover economist Tim Harford who wrote on <a href="http://timharford.com/2019/08/the-strange-power-of-the-idea-of-average/">the strange power of the idea of average</a>, both good and bad.</p>
<p>Of course any mathematically topic is worth a deep dive into, so head into the magical depths of the Math Vault for an extensive article on <a href="https://mathvault.ca/long-division/">Long Division and Its Variants (for Integers)</a> Once you're ready, jump out and get yourself back into Cantor's Paradise where Jørgen Veisdal will let you in on <a href="https://medium.com/cantors-paradise/the-mathematics-of-elo-ratings-b6bfc9ca1dba">the mathematics of Elo ratings</a>, a glimpse at the history of the famous ranking system.</p>
<p>Before you lose your king or queen, let Richard Elwes ask you a question befit Carol's Red Queen: <a href="https://richardelwes.co.uk/2019/09/06/how-many-sides-does-a-circle-have/">How Many Sides Does A Circle Have?</a> and be sure to follow him off on a tanget or two. If all those tangents twirled you around too much, switch to a classical, sold blog post by the amazing John Cook who will help you <a href="https://www.johndcook.com/blog/2019/08/27/heaps-law/">estimate vocabulary size with Heaps’ law</a> just in case you need to verify a post-humously discovered manuscript by Jane Austen.</p>
<p>To ease your way out of those particular mazes, take a sip and mingle over at <a href="https://ima.org.uk/12133/editorial-august-2019/">this month's IMA editorial</a>, if only to catch up on the Queen’s Birthday Honours List for 2019. And if you are one of those people who frequent the always dramatic birdsite, here are a two math-focused threads for you:</p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Oh no, I&#39;ve deliberately obscured large portions of this ruler and I need to make sure these vegetables are whole numbers of inches long or my toddler will eat me instead: a <a href="https://twitter.com/hashtag/RealWorldMaths?src=hash&amp;ref_src=twsrc%5Etfw">#RealWorldMaths</a> thread <a href="https://t.co/GWuZMry6Ti">pic.twitter.com/GWuZMry6Ti</a></p>&mdash; Christian Lawson-Perfect (@christianp) <a href="https://twitter.com/christianp/status/1169651584416079872?ref_src=twsrc%5Etfw">September 5, 2019</a></blockquote>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Unpopular take: As someone with a Master&#39;s degree in statistics and who teaches data science, I&#39;m very much over the &quot;data scientists are incompetent fools who just throw data in and get results from a computer with no critical thinking&quot; takes. 1/</p>&mdash; Matt Brems (@matthewbrems) <a href="https://twitter.com/matthewbrems/status/1163224585644511233?ref_src=twsrc%5Etfw">August 18, 2019</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p><a href="https://twitter.com/mathyawp/status/1162462128441139201?s=19">Also via twitter</a>, Francis Su shared his handout with <a href="https://www.math.hmc.edu/~su/math131/good-math-writing.pdf">Guildelines for good mathematical writing (PDF)</a> which he says you should feel free to share with your students.</p>
<p>To wrap things up, take a carousel of math blogging perfection at Math Off The Grid where Benjamin Leis's post on <a href="https://blog.mathoffthegrid.com/2019/08/cardanos-method.html">Cardano's Method</a> starts from a new video from Mathologer (below), picks up <a href="https://twitter.com/MrHonner/status/1165417359764533248?ref_src=twsrc%5Etfw">a tweet by Patrick Honner</a> throws in <a href="https://artofproblemsolving.com/news/aftermath/aftermath-running-a-school-for-math-lovers-with-sam-vandervelde">a podcast with Sam Vandervelde</a> and tops it off with a pointer to <a href="https://en.wikipedia.org/wiki/Marden%27s_theorem">Marden's Theorem</a> to drag you into the carnival that is Wikipedia's mathematics articles.</p>
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class="embed-container"><iframe src="https://www.youtube.com/embed/QILiHiTD3uc" frameborder="0" allowfullscreen=""></iframe></div>
<hr>
<p>That’s it for the beautiful month of September. Thanks to everyone who submitted a post! After almost 9 years of running</p>
<p>Be sure to stop by next month’s Carnival. You should <a href="http://aperiodical.com/carnival-of-mathematics/">submit your favorite blog posts/videos/content</a> from the month of September. If you’d like to host an upcoming show, please get in touch with <a href="mailto:katie@aperiodical.com">Katie</a>.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Being a refugee]]></title>
        <id>https://sixsmith2017.wordpress.com/2019/09/11/being-a-refugee/</id>
        <link href="https://sixsmith2017.wordpress.com/2019/09/11/being-a-refugee/">
        </link>
        <updated>2019-09-11T09:19:47Z</updated>
        <summary type="html"><![CDATA[<p>This is kind of an addendum to Anne&#8217;s post <a href="https://annesixsmith.wordpress.com/2019/09/03/the-new-country">https://annesixsmith.wordpress.com/2019/09/03/the-new-country</a>. Hers is better, of course.</p>
<p>This summer we were moved to a new country. Its hard to put an exact time or date on it. Let&#8217;s say it was the evening Anne had really bad indigestion and we didn&#8217;t have any Rennies, so secretly I cycled up to Sainsbury&#8217;s and was back in 20 minutes to surprise her. We laughed. It was funny. But that&#8217;s when we were moved, without realising it.</p>
<p>We looked around for some weeks, without appreciating what had happened. You peer through the mist and think you recognise familiar landmarks. Familiar features. Probably its just a short walk home. Or worst case a short bus ride. Nothing too bothersome. Nothing dramatic. This is just a visit, and we&#8217;ll be home by Christmas.</p>
<p>But no. It turns out we&#8217;ve changed country, and there is no way back. We&#8217;re refugees here. Trying to make the best of it, trying to make something work out. There are lots of people happy to help, and they&#8217;ve sorted us out with stuff, and that&#8217;s great. It turns out there are a couple of old friends also here, who have already settled in.</p>
<p>We&#8217;re beginning to find our way round, though there are only a few road signs so its easy to get lost. The weather is very changeable; you&#8217;re out in the sun and feeling good and suddenly the rain starts and its cold and miserable. It can be very cold. I&#8217;ve not found a weather forecasting app.</p>
<p>Sometimes we wander down to the beach and look out at the ocean. Somewhere over there is the old country, where life was very different. Its hard not to think about that life, and wonder. But its not really helpful. Its best to wander back up the beach, wander back into the new country, wander back to our new life as refugees. We&#8217;re going to make this work.</p>
<p>(I probably talk in cliches, and just murdered a perfectly good metaphor. But this will have to do.)</p>
<p>&nbsp;</p>
<p>&nbsp;</p>]]></summary>
        <author>
            <name>Dave Sixsmith – I am a mathematician, not a calculator</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Methods in Higher Forcing Axioms]]></title>
        <id>http://karagila.org/2019/mehifox/</id>
        <link href="http://karagila.org/2019/mehifox/">
        </link>
        <updated>2019-09-09T15:12:31Z</updated>
        <summary type="html"><![CDATA[<p>Methods in Higher Forcing Axioms (or MEHIFOX, for short) is an experimental workshop hosted in Norwich by David Asperó and myself. You can find the website, <a href="../../mehifox">right here</a>. This workshop is sponsored by the London Mathematical Society, and the School of Mathematics in UEA.</p>

<p>The idea is to have a workshop, where we actually work. This is contrary to the normal use of &quot;workshop&quot; (in set theory, at least, but I believe in most mathematical areas) which means a very small conference where almost all the participants are also speaking. <a href="http://karagila.org/2019/mehifox/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Jumps of equivalence relations and scattered linear orders]]></title>
        <id>http://scoskey.org/presentation/jumps-of-equivalence-relations-and-scattered-linear-orders/</id>
        <link href="http://scoskey.org/presentation/jumps-of-equivalence-relations-and-scattered-linear-orders/">
        </link>
        <updated>2019-09-09T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>CUNY Set Theory Seminar, September 2019<!--more--></p>

<p>Abstract: This is joint work with John Clemens. We will begin this talk by discussing the problem of classifying the countable scattered linear orders. Here a linear order is called scattered if the rational order doesn’t embed into it. The class of such orders admits a ranking function valued in the ordinals; we will study the corresponding classification problem for each fixed rank. We will show that each increase in rank results in a “jump” in the complexity of the classification problem. In the second part of the talk we will define a family of jump operators on equivalence relations, each associated with a fixed countable group. The jump in the case of scattered linear orders is that associated with the group Z of integers. We will discuss the basic theory of these jump operators. Finally, we will discuss the question of when such a jump operator is proper, in the sense that the jump of E is strictly above E in the Borel reducibility order.</p>]]></summary>
        <author>
            <name>Samuel Coskey</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Groups and Geometries 2019]]></title>
        <id>https://nickpgill.github.io/groups-and-geometries-2019</id>
        <link href="https://nickpgill.github.io/groups-and-geometries-2019">
        </link>
        <updated>2019-09-06T00:00:00Z</updated>
        <summary type="html"><![CDATA[<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p>I just got back from a conference at <a href="http://www.birs.ca">Banff International Research Station</a> on “Groups and Geometries”. Many thanks to Martin Liebeck, Inna Capdebosq and Bernhard Muehlherr for organising a brilliant week.</p>

<p>I gave a talk at the conference entitled “The relational complexity of a finite primitive permutation group”, which you can view by clicking <a href="http://www.birs.ca/events/2019/5-day-workshops/19w5046/videos/embed/201908261531-Gill.mp4">here</a>. The abstract of the talk was the following:</p>

<blockquote>
  <p>Motivated by questions in model theory, Greg Cherlin introduced the idea of “relational
 complexity”, a statistic connected to finite permutation groups. He also stated a conjecture
classifying those permutation groups with minimal relational complexity. We report on recent 
progress towards a proof of this conjecture. We also make some remarks about permutation
groups with large relational complexity, and we explain how this statistic relates to others in the literature, notably base-size.</p>

  <p>This work is joint with Pablo Spiga, Martin Liebeck, Francesca Dalla Volta, Francis Hunt and Bianca Lodà.”</p>
</blockquote>

<p><strong>Erratum</strong>: at minute 39 of the talk I mis-stated a theorem. The correct statement is as follows:</p>

<p><strong>Theorem</strong> (Gill, Lodà, Spiga) There exists a constant $c$ such that if $G$ acts primitively on a set $X$ of size $t$, then either</p>
<ol>
  <li>$H(G,X) &lt; c {\rm log} t$</li>
  <li>$G$ is a subgroup of $S_m \wr S_r$ containing $(A_m)^r$, where the action of $S_m$ is on $k$-element subsets of ${1, …, m}$ and the wreath product has the product action of degree $t={m \choose k}^r$.</li>
</ol>]]></summary>
        <author>
            <name>Nick Gill</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sigma-Prikry I: The Axioms]]></title>
        <id>http://blog.assafrinot.com/?p=4596</id>
        <link href="http://blog.assafrinot.com/?p=4596">
        </link>
        <updated>2019-09-02T14:34:33Z</updated>
        <summary type="html"><![CDATA[<div class="thanks_button_div" 
                  style="margin-bottom: 30px;"><div id="thanksButtonDiv_4596_2" style="background-image:url(http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/thanks_compact_brown1.png); background-repeat:no-repeat; float: left; display: inline;"
                onmouseover="javascript:thankYouChangeButtonImage('thanksButtonDiv_4596_2', true);" 
                onmouseout="javascript:thankYouChangeButtonImage('thanksButtonDiv_4596_2', false);"
                onclick="javascript:thankYouChangeButtonImage('thanksButtonDiv_4596_2', false);" >
                <input type="button" onclick="thankYouButtonClick(4596, 'You left &ldquo;Thanks&rdquo; already for this post')" value="Like 16"
                  class="thanks_button thanks_compact thanks_brown"
                  style="  font-family: Verdana, Arial, Sans-Serif; font-size: 14px; font-weight: normal;; color:#ffffff;"
                  id="thanksButton_4596_2" title="Click to leave &ldquo;Thanks&rdquo; for this post"/>
             </div><div id="ajax_loader_4596_2" style="display:inline;visibility: hidden;"><img alt="ajax loader" src="http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/ajax-loader.gif" /></div></div><p>Joint work with <a href="http://www.ub.edu/dept_matinfo/professors/poveda-alejandro/">Alejandro Poveda</a> and <a href="http://homepages.math.uic.edu/~sinapova/">Dima Sinapova</a>.</p>
<p><strong>Abstract. </strong>We introduce a class of notions of forcing which we call $\Sigma$-Prikry, and show that many of the known Prikry-type notions of forcing that centers around singular cardinals of countable cofinality are $\Sigma$-Prikry. We show that given a $\Sigma$-Prikry poset $\mathbb P$ and a name for a non-reflecting stationary set $T$, there exists a corresponding $\Sigma$-Prikry poset that projects to $\mathbb P$ and kills the stationarity of $T$. Then, in a sequel to this paper, we develop an iteration scheme for $\Sigma$-Prikry posets. Putting the two works together, we obtain a proof of the following.</p>
<p><em><strong>Theorem. </strong></em>Suppose $\kappa$ is the limit of a countable increasing sequence of supercompact cardinals. For every cardinal $\lambda=\lambda^{&lt;\lambda}$ greater than $\kappa^+$, there exists a cofinality-preserving forcing extension in which $\kappa$ remains a strong limit, every finite collection of stationary subsets of $\kappa^+$ reflects simultaneously, and $2^\kappa=\lambda$.</p>
<p><strong>Downloads:</strong></p>
<p><table class=paperruler"><tr><td><a onclick="thankYouButtonClick(4596, '')"  href="http://www.assafrinot.com/files/paper41.pdf" class="billet_author"></a><img src="/design/002_arxiv_dis.png"   class="opacity_icons"  height=90 width=64 border=1  alt="[No arXiv entry]" title="No arXiv entry"  /><img src="/design/003_publish_dis.png"   class="opacity_icons"  height=90 width=64 border=1  alt="[No published version]" title="Published version not available"  /><img src="/design/004_review_dis.png"  class="opacity_icons" height=90 width=64 border=1  alt="[No entry on mathscinet]" title="No entry on mathscinet"  /><img src="/design/005_slides_dis.png"    class="opacity_icons"  height=90 width=64 border=1  alt="[No related presentations]" title="No related presentations"  /><a href="http://www.assafrinot.com/paper/42" class="billet_further"></a><a href="http://papers.assafrinot.com/list.php?bib=preprints.bib&key=paper41" class="billet_bibtex"></a><a href="http://www.assafrinot.com/paper/41" class="billet_perm"></a></td></tr></table></p>
<p>&nbsp;</p>
<p><span id="more-4596"></span></p>]]></summary>
        <author>
            <name>Assaf Rinot</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[(with O. Ben-Neria) Infinite decreasing chains in the Mitchell order]]></title>
        <id>https://muellersandra.github.io/publication/2019/08/28/PaperInfiniteDecreasingChainsMO.html</id>
        <link href="https://muellersandra.github.io/publication/2019/08/28/PaperInfiniteDecreasingChainsMO.html">
        </link>
        <updated>2019-08-27T22:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Submitted. <a href="https://arxiv.org/pdf/1908.10224.pdf">PDF.</a> <a href="https://arxiv.org/abs/1908.10224">arXiv.</a>
<a data-toggle="collapse" href="javascript:toggle('bibBNM19');" class="title">Bibtex.</a></p>

<div style="display:none" id="bibBNM19">
<pre class="collapse"> @ARTICLE{BNM19,
   AUTHOR= {O. Ben-Neria and S. Müller},
   TITLE= {Infinite decreasing chains in the Mitchell order},
   Note={Submitted},
   EPRINT ={1908.10224}}</pre>
</div>

<!--more-->

<p>It is known that the behavior of the Mitchell order substantially changes at the level of rank-to-rank extenders, as it ceases to be well-founded. While the possible partial order structure of the Mitchell order below rank-to-rank extenders is considered to be well understood, little is known about the structure in the ill-founded case. The purpose of the paper is to make a first step in understanding this case, by studying the extent to which the Mitchell order can be ill-founded. Our main results are (i) in the presence of a rank-to-rank extender there is a transitive Mitchell order decreasing sequence of extenders of any countable length, and (ii) there is no such sequence of length $\omega_1$.</p>]]></summary>
        <author>
            <name>Sandra Müller</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CUNY Logic Workshop - TBA]]></title>
        <id>https://muellersandra.github.io/upcomingtalk/talk/invsemtalk/2019/08/28/TalkCUNYLogicWorkshop.html</id>
        <link href="https://muellersandra.github.io/upcomingtalk/talk/invsemtalk/2019/08/28/TalkCUNYLogicWorkshop.html">
        </link>
        <updated>2019-08-27T22:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I am invited to give a talk in the <a href="https://nylogic.github.io/logic-workshop">CUNY Logic Workshop</a> on Nov 15, 2019. Title and
abstract for the talk will be announced in due course.</p>]]></summary>
        <author>
            <name>Sandra Müller</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[7 Easy Hacks to Improve Your Math Skills]]></title>
        <id>http://karagila.org/2019/quick-hacks/</id>
        <link href="http://karagila.org/2019/quick-hacks/">
        </link>
        <updated>2019-08-22T18:55:31Z</updated>
        <summary type="html"><![CDATA[<p>Everybody wants to improve their mathematical skills! And quickly, too! Since it's so hard to do just that, I've written down some quick and dirty hacks for quickly improving your mathematical skills!</p>

<h3>1. Get a graduate-level degree in mathematics!</h3>

<p>Getting a PhD in mathematics is not really about getting the PhD itself. It's more about getting much better at learning mathematics. So if you get a PhD in mathematics it will help you better your ability to study more mathematics and improve your skills. <a href="http://karagila.org/2019/quick-hacks/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to organize an equitable pre-CUMC conference for students]]></title>
        <id>https://mikepawliuk.ca/2019/07/23/how-to-organize-an-equitable-pre-cumc-conference-for-students/</id>
        <link href="https://mikepawliuk.ca/2019/07/23/how-to-organize-an-equitable-pre-cumc-conference-for-students/">
        </link>
        <updated>2019-07-23T19:10:31Z</updated>
        <summary type="html"><![CDATA[<p>Every summer, Canadian undergraduate students in mathematics meet at the <a href="https://cumc.math.ca/2019/home">Canadian Undergraduate Mathematics Conference (CUMC)</a>. Hundreds of students attend, and it gives them a chance to meet other people excited by mathematics. Students are also encouraged to give a short presentation on a math topic that interests them.</p>
<p>I attended the 2007 CUMC at <a href="http://www.sfu.ca/math.html">Simon Fraser university</a> and the 2008 CUMC at the <a href="https://www.math.toronto.edu/cms/">University of Toronto</a> (where I would go on to complete my PhD and then eventually work at).</p>
<p>In the summer of 2018, while I was a Post Doc at the <a href="https://math.ucalgary.ca/">University of Calgary</a>, we hosted a &#8220;mini pre-CUMC conference&#8221; for undergrads to give their presentations ahead of time. It was so successful that I ran an expanded version of this at the University of Toronto for CUMC 2019.</p>
<p>I think these events and workshops are important for all students, but in particular it helps break down barriers to entry for marginalized students. With that in mind, I&#8217;m sharing my resources, thoughts and experiences about our pre-CUMC conference with the hope that other universities and colleges in Canada will benefit.</p>
<p><img data-attachment-id="1876" data-permalink="https://mikepawliuk.ca/2019/07/23/how-to-organize-an-equitable-pre-cumc-conference-for-students/exercise-86200_640/" data-orig-file="https://mikepawliuk.files.wordpress.com/2019/07/exercise-86200_640.jpg" data-orig-size="640,426" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="exercise-86200_640" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2019/07/exercise-86200_640.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2019/07/exercise-86200_640.jpg?w=640" class=" size-full wp-image-1876 aligncenter" src="https://mikepawliuk.files.wordpress.com/2019/07/exercise-86200_640.jpg?w=660" alt="exercise-86200_640" srcset="https://mikepawliuk.files.wordpress.com/2019/07/exercise-86200_640.jpg 640w, https://mikepawliuk.files.wordpress.com/2019/07/exercise-86200_640.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2019/07/exercise-86200_640.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p><span id="more-1858"></span></p>
<h2>Events</h2>
<p class="biz-page-title embossed-text-white">We had four main events to support students before the CUMC. All of the events were open to students from all three U of T campuses (and we even had a participant from the <a href="https://uoit.ca/">University of Ontario Institute of Technology</a> in Oshawa).</p>
<h3>1: Workshopping appropriate topics &#8211; (two months before CUMC)</h3>
<p>About two months before the conference, the Undergraduate Math union at the University of Toronto announced that they would help some students with funding for the CUMC. Since the funding required a proposal of the talk that would be given, I volunteered to help anyone (especially beginners) who had questions or wanted advice.</p>
<figure data-shortcode="caption" id="attachment_1862" aria-describedby="caption-attachment-1862" style="width: 700px" class="wp-caption alignnone"><img data-attachment-id="1862" data-permalink="https://mikepawliuk.ca/2019/07/23/how-to-organize-an-equitable-pre-cumc-conference-for-students/fb_pre_cumc/" data-orig-file="https://mikepawliuk.files.wordpress.com/2019/07/fb_pre_cumc.png" data-orig-size="700,243" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="FB_pre_cumc" data-image-description="&lt;p&gt;Screenshot of Facebook post by me encouraging students to participate in the CUMC.&lt;/p&gt;
" data-medium-file="https://mikepawliuk.files.wordpress.com/2019/07/fb_pre_cumc.png?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2019/07/fb_pre_cumc.png?w=660" class="alignnone size-full wp-image-1862" src="https://mikepawliuk.files.wordpress.com/2019/07/fb_pre_cumc.png?w=660" alt="If anyone is looking for feedback or advice about their presentation, please feel free to email me m.pawliuk@utoronto.ca . Especially if you've never done this before, or maybe you feel intimidated by presenting, or don't know what to expect. This conference is perfect for first-timers. I'm currently faculty at UTM, I presented at the CUMC in 2008 and 2009, and I've helped send many undergrads to the CUMC." srcset="https://mikepawliuk.files.wordpress.com/2019/07/fb_pre_cumc.png?w=660 660w, https://mikepawliuk.files.wordpress.com/2019/07/fb_pre_cumc.png?w=150 150w, https://mikepawliuk.files.wordpress.com/2019/07/fb_pre_cumc.png?w=300 300w, https://mikepawliuk.files.wordpress.com/2019/07/fb_pre_cumc.png 700w" sizes="(max-width: 660px) 100vw, 660px"   /><figcaption id="caption-attachment-1862" class="wp-caption-text">Actually, I attended the 2007 and 2008 conferences. Oops!</figcaption></figure>
<p>Four students took me up on the offer.</p>
<p>It&#8217;s important to make sure that support and funding is accessible to those who need it, and that we remove any obstacles to participation. Students have many anxieties about presenting math outside their comfort zone, and those of us with experience can help by answering questions and setting people up for success.</p>
<p><img data-attachment-id="1872" data-permalink="https://mikepawliuk.ca/2019/07/23/how-to-organize-an-equitable-pre-cumc-conference-for-students/sport-2264825_640/" data-orig-file="https://mikepawliuk.files.wordpress.com/2019/07/sport-2264825_640.jpg" data-orig-size="640,426" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;6.3&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 6D&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;50&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.008&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sport-2264825_640" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2019/07/sport-2264825_640.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2019/07/sport-2264825_640.jpg?w=640" class=" size-full wp-image-1872 aligncenter" src="https://mikepawliuk.files.wordpress.com/2019/07/sport-2264825_640.jpg?w=660" alt="sport-2264825_640" srcset="https://mikepawliuk.files.wordpress.com/2019/07/sport-2264825_640.jpg 640w, https://mikepawliuk.files.wordpress.com/2019/07/sport-2264825_640.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2019/07/sport-2264825_640.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<h3>2: Panel + Workshop with past participants &#8211; (two weeks before CUMC)</h3>
<p>Despite being a trained improvisor, and a reasonably outgoing person, I&#8217;ve always had challenges networking at conferences. We held a one-hour panel followed by a one-hour workshop to help students with networking and the challenges of attending a conference.</p>
<p>Here is the <a href="https://gist.github.com/mpawliuk/c98f869011ec6eb7250ad1e978779cef">list of activities together with the learning objectives for each hour</a>.</p>
<p>The panel was made up of undergrads with previous experience at math conferences. The math union helped recruit four panelists from the University of Toronto, and I got testimonials from two former students from the University of Calgary. One of the testimonials was a written document, and one was a 3 minute video.</p>
<p>The format of the panel worked quite nicely. We used <a href="https://www.mentimeter.com/">Mentimeter</a> to gather anonymous questions from the audience (through their devices).</p>
<figure data-shortcode="caption" id="attachment_1866" aria-describedby="caption-attachment-1866" style="width: 2137px" class="wp-caption alignnone"><img data-attachment-id="1866" data-permalink="https://mikepawliuk.ca/2019/07/23/how-to-organize-an-equitable-pre-cumc-conference-for-students/menti_cumc/" data-orig-file="https://mikepawliuk.files.wordpress.com/2019/07/menti_cumc.png" data-orig-size="2137,621" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Menti_CUMC" data-image-description="&lt;p&gt;A screenshot of the list of questions the students asked.&lt;/p&gt;
" data-medium-file="https://mikepawliuk.files.wordpress.com/2019/07/menti_cumc.png?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2019/07/menti_cumc.png?w=660" class="alignnone size-full wp-image-1866" src="https://mikepawliuk.files.wordpress.com/2019/07/menti_cumc.png?w=660" alt="Menti_CUMC" srcset="https://mikepawliuk.files.wordpress.com/2019/07/menti_cumc.png?w=660 660w, https://mikepawliuk.files.wordpress.com/2019/07/menti_cumc.png?w=1320 1320w, https://mikepawliuk.files.wordpress.com/2019/07/menti_cumc.png?w=150 150w, https://mikepawliuk.files.wordpress.com/2019/07/menti_cumc.png?w=300 300w, https://mikepawliuk.files.wordpress.com/2019/07/menti_cumc.png?w=768 768w, https://mikepawliuk.files.wordpress.com/2019/07/menti_cumc.png?w=1024 1024w" sizes="(max-width: 660px) 100vw, 660px"   /><figcaption id="caption-attachment-1866" class="wp-caption-text">In total we had 13 questions (some not shown).</figcaption></figure>
<p>Each panelist chose one of the questions to answer, then in order each other panelist could give their take on it. We went through two full rounds of this (so we got to discuss 8 questions). This allowed the panelists to speak on topics they felt they had the most expertise in, and allowed all of the panelists equal time. After the two rounds we did a final &#8220;lightning round&#8221; for any outstanding questions the audience had that didn&#8217;t get answered.</p>
<p>Cross-cohort bonds are important for students new to math. It demystifies the experience, and makes the &#8220;rules&#8221; explicit rather than implicit. Senior students develop their mentorship and leadership. Plus, it was fun and social, and people made new friends. Universities can be isolating places!</p>
<p>The workshop had lots of social interaction and discussion built into it. In particular we allowed students to practice introducing themselves to (math) strangers in a way that imitated what a real conference would be like. This gave them a low(er) stakes way to practice their social interactions. The sharing afterwards was especially valuable.</p>
<p><img data-attachment-id="1874" data-permalink="https://mikepawliuk.ca/2019/07/23/how-to-organize-an-equitable-pre-cumc-conference-for-students/zumba-4333580_640/" data-orig-file="https://mikepawliuk.files.wordpress.com/2019/07/zumba-4333580_640.jpg" data-orig-size="640,425" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D700&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;80&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.0004&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zumba-4333580_640" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2019/07/zumba-4333580_640.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2019/07/zumba-4333580_640.jpg?w=640" class=" size-full wp-image-1874 aligncenter" src="https://mikepawliuk.files.wordpress.com/2019/07/zumba-4333580_640.jpg?w=660" alt="zumba-4333580_640" srcset="https://mikepawliuk.files.wordpress.com/2019/07/zumba-4333580_640.jpg 640w, https://mikepawliuk.files.wordpress.com/2019/07/zumba-4333580_640.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2019/07/zumba-4333580_640.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p>&nbsp;</p>
<h3>3: Practice talks &#8211; (one week before CUMC)</h3>
<p>The math union organized time and space for students to give practice talks ahead of our mock conference. In the words of the organizer:</p>
<blockquote><p><span dir="ltr"><span class="_3l3x">&#8220;[These are] raw practice talks, we&#8217;re doing it in small groups and you&#8217;ll get a chance to run through your talk several times and get feedback. [At the mock conference], you get a chance to present a &#8220;good copy&#8221; of your talk to a more open audience in a mock conference setting.&#8221;</span></span></p></blockquote>
<p>These had six or so participants, and gave students a low stakes way to experiment with their presentations.</p>
<p><img data-attachment-id="1873" data-permalink="https://mikepawliuk.ca/2019/07/23/how-to-organize-an-equitable-pre-cumc-conference-for-students/running-2375066_640/" data-orig-file="https://mikepawliuk.files.wordpress.com/2019/07/running-2375066_640.jpg" data-orig-size="640,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;5.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SP590UZ&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;31.67&quot;,&quot;iso&quot;:&quot;64&quot;,&quot;shutter_speed&quot;:&quot;0.004&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="running-2375066_640" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2019/07/running-2375066_640.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2019/07/running-2375066_640.jpg?w=640" class=" size-full wp-image-1873 aligncenter" src="https://mikepawliuk.files.wordpress.com/2019/07/running-2375066_640.jpg?w=660" alt="running-2375066_640" srcset="https://mikepawliuk.files.wordpress.com/2019/07/running-2375066_640.jpg 640w, https://mikepawliuk.files.wordpress.com/2019/07/running-2375066_640.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2019/07/running-2375066_640.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<h3>4: Mock conference &#8211; (Friday before CUMC)</h3>
<p>The culmination of these events was the mock conference held the Friday before the CUMC. We had 8 presentations and needed two rooms.</p>
<p>Here are <a title="Feedback_Rubric" href="https://mikepawliuk.files.wordpress.com/2019/07/feedback_rubric.pdf">the feedback forms</a> I made for the event, and the <a href="https://gist.github.com/mpawliuk/68c75de95fad5724ad93e9b78bfecf0a">TeX source files</a>. Both of these are open access; please use them! Each audience member filled out an anonymous feedback form for each presenter. The feedback forms are structured to help the presenter find the strongest parts of their presentation. There&#8217;s also blank section at the bottom in which we encouraged each presenter to ask the audience for targeted feedback. For example, one presenter asked about the technical intensity of their talk.</p>
<p>It&#8217;s important to give presenters agency in their own feedback. Presenting in front of peers makes you vulnerable to criticism. Giving the presenter choices allows them to determine <em>for themselves</em> how vulnerable they would like to be.</p>
<h2>Takeaways and Future Goals</h2>
<p>Overall, I was very happy with how the events went, and students seemed to share in this impression. They were well attended, and the mock conference even drew in some faculty and other members of the math department.</p>
<p><img data-attachment-id="1875" data-permalink="https://mikepawliuk.ca/2019/07/23/how-to-organize-an-equitable-pre-cumc-conference-for-students/mountain-3850166_640/" data-orig-file="https://mikepawliuk.files.wordpress.com/2019/07/mountain-3850166_640.jpg" data-orig-size="640,425" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;5.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D3200&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;55&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.000625&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mountain-3850166_640" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2019/07/mountain-3850166_640.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2019/07/mountain-3850166_640.jpg?w=640" class=" size-full wp-image-1875 aligncenter" src="https://mikepawliuk.files.wordpress.com/2019/07/mountain-3850166_640.jpg?w=660" alt="mountain-3850166_640" srcset="https://mikepawliuk.files.wordpress.com/2019/07/mountain-3850166_640.jpg 640w, https://mikepawliuk.files.wordpress.com/2019/07/mountain-3850166_640.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2019/07/mountain-3850166_640.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p>I will definitely run this event in future years. Some goals for next time:</p>
<ol>
<li><strong>Start earlier next year</strong>! This is my biggest goal. I want to make sure that anyone who wants to participate can, and that means getting details firmer up sooner than I did this year.</li>
<li><strong>Increase participation from the satellite campuses (Scarborough and UTM)</strong>. We had faculty and students from UTM participate, but that was a bit easier because that&#8217;s my home faculty. This can be set up by me getting to know the department at Scarborough better in the coming year.</li>
<li><strong>Connect with other universities across Canada</strong>. I would love to run workshops in conjunction with other universities in Canada. This would align with the goals of the workshop because it would require participants to introduce themselves to math strangers. Writing this post, and making the feedback forms available and open access is a step towards achieving this goal.</li>
</ol>
<p>If you&#8217;re interested in running one of these workshops or mock-conferences and would like to connect with us, please <a href="https://mikepawliuk.ca/contact/">let me know</a>.</p>
<p>What&#8217;s your <em>one simple trick</em><span class="st"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/2122.png" alt="™" class="wp-smiley" style="height: 1em; max-height: 1em;" /></span> for networking at conferences? What does your university do to help students prepare for conferences? What could I be doing to improve equity and accessibility to these events?</p>
<p><strong>Special thanks</strong> to Alex Karapetyan (and the math union), Parker Glynn-Adey, Lyra Qian, Jordyn Dyck, and Kristine Bauer for your help in making these events happen.</p>
<p>All photos <a href="https://pixabay.com/service/faq/">used with permission</a> from <a href="https://pixabay.com/">Pixabay</a>.</p>
<p>&nbsp;</p>]]></summary>
        <author>
            <name>Mike Pawliuk – Mathematics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New notes online!]]></title>
        <id>http://karagila.org/2019/new-notes/</id>
        <link href="http://karagila.org/2019/new-notes/">
        </link>
        <updated>2019-07-22T16:40:12Z</updated>
        <summary type="html"><![CDATA[<p>I have posted two new lecture notes online. The one is from a course in functional analysis I took in the autumn of 2015/16 with Prof. Matania Ben-Artzi, and the second is from the course I taught in axiomatic set theory in the autumn of 2016/17.</p>

<p>Just as a general caveat for the set theory notes, since all the students in the course were also my students in the basic set theory course that I taught with Azriel Levy (yes, that Azriel Levy, and yes it was quite an awesome experience) and there I managed to cover some fairly nontrivial things in that course, these notes might feel as if there are some gaps there, or that I skip here and there over some information. <a href="http://karagila.org/2019/new-notes/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Toy multiverses of set theory]]></title>
        <id>https://victoriagitman.github.io/talks/2019/07/17/toy-multiverses-of-set-theory.html</id>
        <link href="https://victoriagitman.github.io/talks/2019/07/17/toy-multiverses-of-set-theory.html">
        </link>
        <updated>2019-07-17T04:00:00Z</updated>
        <summary type="html"><![CDATA[<p>This is a talk at the <a href="https://workshop2019.forcing-project.com/">Philosophy of Set Theory and Foundations workshop</a>, University of Konstanz, August 1, 2019.<br><strong><a href="">Slides</a></strong><!--more--></p>

<p>In the early 20th century, optimism ran high that a formal development of mathematics through first-order logic within appropriate axiom systems would set up mathematical knowledge as incontrovertible truth. With the introdution of set theory, all mathematics could now be unified within a single field whose fundamental properties were codified by the Zermelo-Fraenkel axioms ${\rm ZFC}$. But already within a few decades, discoveries were made which suggested that the concept of set was prone to relativity. Löwenheim and Skolem showed that if there is a model of ${\rm ZFC}$, then there is a countable model of ${\rm ZFC}$. This countable model would, of course, think that its reals are uncountable, demonstrating the non-absoluteness of countability. Gödel proved the Completeness Theorem, an immediate consequences of which was the existence of nonstandard models of set theory, even with nonstandard natural numbers, demonstrating the non-absoluteness of well-foundedness. Soon afterwards, Gödel's First Incompleteness Theorem showed the general limitations inherent in formal method: no computable theory extending ${\rm ZFC}$ could decide the truth of all set theoretic assertions. In the next few decades came forcing, large cardinals, canonical inner models, and a model theoretic treatment of ${\rm ZFC}$. Set theory ever since has indisputably been the study of a multiverse of universes each instantiating its own concept of set. </p>

<p>Cohen's technique of forcing showed how to extend a given universe of sets to a larger universe satisfying a desired list of properties. Forcing could be used to construct universes in which the continuum was any cardinal of uncountable cofinality (including singular cardinals), indeed the continuum function on the regular cardinals could be made to satisfy any desired pattern (modulo a few necessary restrictions). There could be universes with or without a Suslin line, universes with non-constructible reals, universes whose cardinal characteristics had different values and different relationships.</p>

<p>At the same time, set theorists started exploring the consistency strength hierarchy of large cardinal axioms asserting existence of improbably large infinite objects. Other set theoretic assertions, no matter how unrelated to large cardinals, inevitably fell somewhere inside the hierarchy. Set theorists could now combine forcing with large cardinals to produce universes in which large cardinals were compatible with other desired properties. Many of the larger large cardinals implied that the universe had transitive sub-universes (inner models) into which it would elementarily embed. Such sub-universes, obtained from large cardinals or through other considerations, joined the menagerie of mathematical worlds populating the field.</p>

<p>In yet another direction, motivated by Godel's construction of $L$, set theorists began exploring how to build ever more sophisticated canonical inner models, universes built bottom-up from a recipe specifying what kind of sets should exists. </p>


<p>Finally, a model theoretic treatment of ${\rm ZFC}$ produced some unexpected results. Given two models $M$ and $N$ of ${\rm ZFC}$, let us say that $N$ is an <em>end-extension</em> of $M$ if $M$ is transitive in $N$, let us say that $N$ is a <em>top-extension</em> of $M$ if every element of $N\setminus M$ has higher rank than all ordinals of $M$. Keisler and Morley showed that every countable model of ${\rm ZFC}$ has a proper elementary top-extension (Keisler-Morley Extension Theorem <a href="#keislermorley:topextensions">[1]</a>). Thus, any countable model could be grown in height without changing its theory. Barwise showed that every countable model of ${\rm ZFC}$ has an end-extension to a model of $V=L$ (Barwise Extension Theorem <a href="#Barwise:extensionTheorem">[2]</a>). Thus, sets could become constructible in a larger universe.</p>

<p>What does set theoretic practice tell us about the nature of sets? Is there the one true universe of sets, the mathematical world in which all mathematics lives, but our epistemic limitations have so far prevented us from understanding its structure? Or is there simply no one true universe, and instead the multiverse of universes encountered by set theorists is the true mathematical reality?
</p>

<p>The Universist position in the philosophy of set theory asserts that there is the one true universe of sets. Incompleteness is simply a by-product of formal methods we are forced to use to investigate mathematics, not an indication of some inherent relativity in the nature of sets. After all, in spite of a plethora of nonstandard models of arithmetic, most mathematicians would agree that the natural numbers is the only true model of arithmetic. The Peano Axioms, actually do a rather excellent job of capturing the fundamental properties of natural numbers, they are bound by the incompleteness phenomena but number theorists don't often run into statements independent of them. This certainty with regards to number theory comes from the deep intuition we believe we hold about the nature of natural numbers. The goal of set theory should then be to obtain the same deep intuition about the nature of sets so that ${\rm ZFC}$ can be extended to a theory deciding most of the more significant properties of sets. Woodin for instance believes that such a theory will come from a construction of a sufficiently sophisticated canonical inner model compatible with all known large cardinals.</p>

<p>The Multiversist position in the philosophy of set theory asserts that there is simply no one true universe of sets. All universes of sets discovered by set theorists: forcing extensions, canonical and non-canonical inner models, models with and without large cardinals, have equal ontological status. They all populate the multiverse of mathematical worlds, each instantiating its own equally valid concept of set. The Multiversist position splits along the lines of just how non-absolute should the notion of set be under this view. Can the multiverse contain models of different heights? Are ill-founded models allowed? The Radical Multiversist position, espoused most notably by Hamkins, asserts that all these models belong in the multiverse. Indeed, once you adapt the position that there is no absolute set theoretic background, no background aught to be better than any other and in fact each should be as bad as the next in the following sense. In the Hamkins perspective each universe in the multiverse will be seen to be countable and ill-founded from the perspective of a <em>better</em> universe. In particular, under this view the universist is mistaken even about the nature of the natural numbers. The Hamkins position is captured by his <em>Multiverse Axioms</em>.</p>

<p><strong>Realizability</strong>: If $M$ is a universe and $N$ is a definable class in $M$ such that $M$ believes that $N\models{\rm ZFC}$, then $N$ is a universe. (This includes set models, inner models, will-founded models, etc.)</p>
<p><strong>Forcing Extension</strong>: If $M$ is a universe and $\mathbb P\in M$ is a forcing notion, then there is a universe $M[G]$ where $G\subseteq\mathbb P$ is $M$-generic.</p>
<p><strong>Class Forcing Extension</strong>: If $M$ is a universe  and $\mathbb P$ is a definable ${\rm ZFC}$-preserving forcing notion in $M$, then there is a universe $M[G]$ where $G\subseteq \mathbb P$ is $V$-generic.</p>
<p><strong>Reflection</strong>: If $M$ is a universe, then there is a universe $N$ such that $M\prec V^N_\theta\prec N$ for some rank initial segment $V^N_\theta$ of $N$. (Recall the Keisler-Morley Extension Theorem.)</p>
<p><strong>Countability</strong>: Every universe $M$ is a countable set in another universe $N$.</p>
<p><strong>Well-founded Mirage</strong>: Every universe $M$ is a set in another universe $N$ which thinks that $\mathbb N^M$ is ill-founded.</p>
<p><strong>Reverse Embedding</strong>: If $M$ is a universe and $j:M\to N$ is an elementary embedding definable in $M$, then there is a universe $M^*$ and an elementary embedding $j^*:M^*\to M$ definable in $M^*$ such that $j=j^*(j^*)$. (Every elementary embedding has already been iterated many times.)</p>
<p><strong>Absorbtion into $L$</strong>: Every universe $M$ is a transitive set in another universe $N$ satisfying $V=L$. (This is stronger than the Barwise Extension Theorem.)</p>

<p>A way to investigate the viability of a collection of multiverse axioms, without coming up with a formal background beyond ${\rm ZFC}$, is by considering toy multiverses of ${\rm ZFC}$ models. Assuming that ${\rm ZFC}$ is consistent, a toy multiverse is some set collection of models of ${\rm ZFC}$. Does a given collection of multiverse axioms have a toy multiverse, does it have a <em>natural</em> toy multiverse? With Hamkins, we showed that his Multiverse Axioms, radical as their assertions may seem, have a very natural toy multiverse, namely the collection of all countable computably saturated models <a href="#multiverse:gitmanhamkins">[3]</a>. In fact, every model in any toy multiverse satisfying the Hamkins Multiverse Axioms must be computably saturated because every model of ${\rm ZFC}$ that is an element of a model of ${\rm ZFC}$ with an ill-founded $\omega$ is computably saturated (see the previous <a href="/research/2019/06/04/some-cute-observations-about-computably-saturated-models/">post</a>). </p>

<p>In a recent joint work with Godziszewski, Meadows, and Williams, we consider various weakenings of the Hamkins Multiverse Axioms that have toy multiverses not consisting entirely of computably saturated models. First, we consider the Hamkins Multiverse Axioms with a weak version of well-founded mirage which asserts that every universe in the multiverse is merely ill-founded, not necessarily at $\omega$, from the perspective of a better universe. </p>

<p><strong>Weak well-founded mirage</strong>: Every universe $M$ is a set in another universe which thinks that its membership relation is ill-founded.</p>

<p>Recall that if there is a transitive model of ${\rm ZFC}$, then the <em>Cohen-Shepherdson model $L_\alpha$</em> is the minimum transitive model of ${\rm ZFC}$.</p>

<p><strong>Theorem</strong>: (G., Godziszewki, Meadows, Williams) The collection in $L_\alpha$ of all models $M$ such that $L_\alpha$ thinks that $M$ is a countable model of ${\rm ZFC}$ satisfies:
<ol>
<li>Realizability</li>
<li>Set Forcing and Class Forcing Extension</li>
<li>Countability</li>
<li>Weak Well-founded Mirage</li>
</ol>

<p>Next we consider weakening the axioms to the so-called covering versions, where instead of demanding that a universe be a set inside another universe, we ask that each universe has, a <em>cover</em>, an end-extension that is a set in a better universe.</p>

<p><strong>Covering Countability</strong>: For every universe $M$, there is a universe $N$ and a countable set $A\in N$ with $M\subseteq A$.</p>

<p><strong>Covering Well-founded Mirage</strong>: For every universe $M$, there is a universe $N$ and a model $M^*\in N$ end-extending $M$ such that $N$ thinks that $\mathbb N^{M^*}$ is ill-founded.</p>

<p><strong>Covering Absorbtion into $L$</strong>: For every universe $M$, there is a universe $N\models{\rm ZFC}+V=L$ and a model $M^*\in N$ end-extending $M$.</p>
<p><strong>Theorem</strong>: (G., Godziszewki, Meadows, Williams) There is a toy multiverse, not all of whose models are computably saturated, satisfying:
<ol>
<li>Realizability</li>
<li>Forcing Extension</li>
<li>Class Forcing Extension for ${\rm Ord}$-cc forcing</li>
<li>Covering Countability</li>
<li>Covering Well-founded Mirage</li>
<li>Covering Absorbtion into $L$</li>
</ol></p>
<p>In this post, I purposely didn't tell you what my philosophical position is on all of this. I will leave it up to the reader to guess.</p>
<h2>References</h2>
<ol class="bibliography"><li><span id="keislermorley:topextensions">H. J. Keisler and M. Morley, “Elementary extensions of models of set theory,” <i>Israel J. Math.</i>, vol. 6, pp. 49–65, 1968. </span></li>
<li><span id="Barwise:extensionTheorem">J. Barwise, “Infinitary methods in the model theory of set theory,” in <i>Logic Colloquium ’69 (Proc. Summer School and
              Colloq., Manchester, 1969)</i>, North-Holland, Amsterdam, 1971, pp. 53–66. </span></li>
<li><span id="multiverse:gitmanhamkins">V. Gitman and J. D. Hamkins, “A natural model of the multiverse axioms,” <i>Notre Dame J. Form. Log.</i>, vol. 51, no. 4, pp. 475–484, 2010. Available at: http://dx.doi.org/10.1215/00294527-2010-030</span></li></ol>]]></summary>
        <author>
            <name>Victoria Gitman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computably saturated models of ZFC]]></title>
        <id>https://victoriagitman.github.io/research/2019/07/16/computably-saturated-models-of-zfc.html</id>
        <link href="https://victoriagitman.github.io/research/2019/07/16/computably-saturated-models-of-zfc.html">
        </link>
        <updated>2019-07-16T04:00:00Z</updated>
        <summary type="html"><![CDATA[<p>
Let $\mathcal L$ be any computable first-order language. A type $p(\bar x,\bar y)$ in $\mathcal L$ is said to be <em>computable</em> if the collection of Gödel codes of the formulas in the type $$\{\ulcorner \varphi\urcorner\mid \varphi\in p(\bar x,\bar y)\}$$ is a computable set. A model $M$ of $\mathcal L$ is said to be <em>computably saturated</em> if for every tuple $\bar a\in M$ and every computable type $p(\bar x,\bar y)$, whenever $p(\bar x,\bar a)$ is finitely realizable in $M$, then $p(\bar x,\bar a)$ is realized: there is a tuple $\bar b\in M$ such that for every $\varphi\in p(\bar x,\bar y)$, $M\models\varphi(\bar b,\bar a)$. It is not difficult to see that any model $M$ of cardinality $\kappa$ has a computably saturated elementary extension of cardinality $\kappa$. We build the elementary extension in $\omega$-many steps, at each step realizing all finitely realizable computable types with parameters from the previous stage. Observe that any computably saturated model of ${\rm ZFC}$ must have nonstandard natural numbers because it realizes the computable type $$p(x)=\{x>\underbrace{1+\cdots+1}_{n\text{-times}}\mid n\in\mathbb N\}.$$ Computable saturation was introduced in <a href="#BarwiseSchlipf:recursiveSaturation">[1]</a>.</p>

<p>
Let's call a model of ${\rm ZFC}$ <em>$\omega$-nonstandard</em> if it has nonstandard natural numbers. In the model theory of $\omega$-nonstandard models of ${\rm ZFC}$ (as in the model theory of nonstandard models of ${\rm PA}$) one of the most important notions is the standard system introduced by Friedman in <a href="#friedman:countableModelsOfSetTheory">[2]</a>. The <em>standard system </em> of an $\omega$-nonstandard model of ${\rm ZFC}$ is a collection of subsets of $\mathbb N$ consisting of the traces of sets in $M$ on the natural numbers: $${\rm SSy}(M)=\{A\cap \mathbb N\mid A\in M\}.$$ Standard systems are clearly Boolean algebras. Standard systems are closed under computability: whenever $A$ is in it and $B$ is computable from $A$, then $B$ is in it. To see this, fix $A\in {\rm SSy}(M)$ and let $B$ be computed from $A$ by a program $p$. The set $A=A^*\cap \mathbb N$ for some $A^*\in M$ and we can assume without loss that $A^*\subseteq\mathbb N^M$. The computation of program $P$ with oracle $A^*$ inside $M$ agrees with the actual computation of $p$ with oracle $A$ on the standard part, which is $B$. In particular, it follows that a standard system has all computable sets, and so computable theories such as ${\rm PA}$ and ${\rm ZFC}$ are (coded) in the standard system. Finally, whenever a set $T$ in a standard system codes an infinite binary tree, the standard system must have some infinite branch through $T$. Such a set $T$ must have come from a set $T^*\in M$, which has to look like a binary tree up to some nonstandard level (because otherwise the true natural numbers would be definable in $M$). So we fix some node $c$ on a nonstandard level of $T^*$ and its predecessors in $T^*$ give a branch through $T$. Observe also if $M$ and $N$ are $\omega$-nonstandard models of ${\rm ZFC}$ such that $\mathbb N^M$ is an initial segment of $\mathbb N^N$, then ${\rm SSy}(M)\subseteq {\rm SSy}(N)$. The reason is that if a set $A\in {\rm SSy}(M)$, then there is a nonstandard natural number $a\in M$ such that the characteristic function of $A$ is coded on the standard part of the binary expansion of $a$, and indeed $M$ has such numbers arbitrarily low above the standard $\mathbb N$.</p>

<p>An $\omega$-nonstandard model $M\models{\rm ZFC}$ is said to be <em>${\rm SSy}(M)$-saturated</em> if for every type $p(\bar x,\bar y)$ (coded) in ${\rm SSy}(M)$, whenever there is $\bar a\in M$ such that $p(\bar x,\bar a)$ is finitely realizable, then $p(\bar x,\bar a)$ is realized. Since ${\rm SSy}(M)$ has all the computable sets, ${\rm SSy}(M)$-saturated models are computably saturated. But the converse holds as well. To see this, fix a type $p(\bar x,\bar y)$ in ${\rm SSy}(M)$ and let $A\in M$ such that $A\cap\mathbb N=\{\ulcorner\varphi\urcorner\mid \varphi\in p(\bar x,\bar y)\}$. Suppose that for $\bar a\in M$, $p(\bar x,\bar a)$ is finitely realizable. Consider the computable type $$p^*(\bar x,\bar y,z)=\{\varphi(\bar x,\bar y)\leftrightarrow \ulcorner\varphi\urcorner\in z\mid \varphi\text{ is a formula}\}.$$ Since $p(\bar x,\bar a)$ is finitely realizable, then so is $p^*(\bar x,\bar a,A)$, but the realization of $p^*(\bar x,\bar a,A)$ also realizes $p(\bar x,\bar a)$. Standard system saturation was introduced by Wilmers in an unpublished 1975 thesis.</p>
<p>
We can use standard system saturation to show several key properties of computably saturated models. The standard system of a computably saturated model has all the types of its elements ($\text{tp}^M(\bar a)$ for $\bar a\in M$), and in particular its theory. Suppose $M$ is ${\rm SSy}(M)$-saturated and $\bar a\in M$. We need to show that there is $A\in M$ such that $A\cap \mathbb N=\{\ulcorner\varphi\urcorner\mid M\models\varphi(\bar a)\}$. Consider the computable type $$p(x,\bar y)=\{\varphi(\bar y)\leftrightarrow \ulcorner\varphi\urcorner\in\bar x\mid\varphi\text{ is a formula}\}.$$ Since $M$ has $\Sigma_n$-truth predicates for every true natural number $n$, $p(x,\bar a)$ is finitely realizable in $M$, and thus there is $A\in M$ realizing $p(\bar x,\bar a)$. Once we have that all types are in the standard system, we obtain a remarkable characterization of countable computably saturated models.</p>
<p>
<strong>Theorem</strong>: Countable computably saturated models $M$ and $N$ of ${\rm ZFC}$ are isomorphic if and only if they have the same theory and the same standard system. Indeed, if $\text{tp}^M(\bar a)=\text{tp}^N(\bar b)$, then there is an isomorphism taking $\bar a$ to $\bar b$.</p>
<p>
<strong>Proof</strong>: This is a back-and-forth argument. Let's extend the partial isomorphism taking $\bar a$ to $\bar b$ one more step. Fix $c\in M$. Then $\text{tp}(c,\bar a)\in {\rm SSy}(M)={\rm SSy}(N)$ and $p(x,\bar y)=\{\varphi(x,\bar y)\mid \varphi\in \text{tp}(x,\bar y)\}$ is finitely realizable in $N$. Thus, by standard system saturation, there is $d\in N$ such that $\text{tp}(c,\bar a)=\text{tp}(d,\bar b)$.</p>
<p>
<strong>Corollary</strong>: Countable computably saturated models $M\models{\rm ZFC}$ have many automorphisms. Whenever $a,b\in M$ are such that $\text{tp}(a)=\text{tp}(b)$, then there is an automorphism of $M$ taking $a$ to $b$.</p>
<p>
Computably saturated models of ${\rm ZFC}$ arise naturally as follows. If $M\models{\rm ZFC}$ is an element of an $\omega$-nonstandard model of ${\rm ZFC}$, then $M$ is computably saturated. To see this, fix a computable type $p(\bar x,\bar y)$ and a tuple $\bar a\in M$ such that $p(\bar x,\bar a)$ is finitely realizable. Also fix a set $A\in N$ such that $A\cap \mathbb N$ codes $p(\bar x,\bar y)$. Since $M$ is a set in $N$, $N$ has a truth predicate for $M$, which by absoluteness of satisfaction must be correct for standard formulas. The model $N$ sees, for every true natural number $n$, that $M$ realizes all $\varphi(\bar x,\bar a)$ such that $\ulcorner\varphi\urcorner\in A\cap n$. But then there must be some nonstandard $c\in N$ such that $N$ thinks that $M$ realizes all $\varphi(\bar x,\bar a)$ such that $\ulcorner\varphi\urcorner\in A\cap c$. Any such realization $\bar b$ realizes $p(\bar x,\bar a)$ because $A\cap c$ includes all standard assertions.</p>
<p>
Here are some other remarkable results about computably saturated models of ${\rm ZFC}$.</p>
<p>
<strong>Theorem:</strong>: Every computably saturated model $M\models{\rm ZFC}$ has an elementary rank initial segment $V_\alpha^M\prec M$ <a href="#Ressayre:recursiveSaturation">[3]</a>.</p>

<p><strong>Proof</strong>: Consider the computable type $p(x)$ consisting of assertions $$\forall \ulcorner\varphi\urcorner\in\Sigma_n\,\text{Tr}_{\Sigma_n}(\ulcorner\varphi\urcorner)\leftrightarrow \text{Tr}_{\Delta_0}(\ulcorner x\models\varphi\urcorner)$$ for every $n$ (where $\text{Tr}_{\Sigma_n}$ is a $\Sigma_n$-truth predicate) together with the assertion 
"$x$ is a rank initial segment".</p>
<p>
The following observation was the key to our theorem with Joel Hamkins that the collection of all countable computably saturated models satisfies the Hamkins Multiverse Axioms <a href="#multiverse:gitmanhamkins">[4]</a>. </p>
<p><strong>Theorem:</strong> Every countable computably saturated model of ${\rm ZFC}$ has an isomorphic copy of itself as an element which it thinks is countable and $\omega$-nonstandard.</p>
<p><strong>Proof:</strong> Suppose $N$ is countable and computably saturated. The theory $\mathcal T$ of $N$ is in ${\rm SSy}(N)$ and so we can fix a theory $\mathcal T^*\in N$ such that $\mathcal T^*\cap\mathbb N=\mathcal T$. The model $N$ sees that $\mathcal T^*\cap n$ is consistent for every true natural number $n$ and therefore $N$ has some nonstandard natural number $c$ such that it thinks that $\mathcal T^*\cap c$ is consistent. Thus, $N$ has a model of $\mathcal T^*\cap c$. But then $N$ also thinks that $\mathcal T^*\cap c$ also has an $\omega$-nonstandard model $M$. Since $\mathbb N^N$ is an initial segment of $\mathbb N^M$, the two models have the same standard system and by construction they have the same theory. Therefore $M\cong N$.</p>
<p>
For the final result I want to mention, let's recall that a <em>truth predicate</em> for an $\omega$-nonstandard model $M\models{\rm ZFC}$ is a subset $T\subseteq M$ such that in the structure $\langle M,\in,T\rangle$, $T$ satisfies the Tarskian truth conditions for $\langle M,\in\rangle$. In particular, $T$ must be a truth predicate for standard formulas. A set $T\subseteq M$ is a <em>partial truth predicate</em> if in $\langle M,\in,T\rangle$, there is a nonstandard number $c$ such that $T$ restricted to formulas of length less than $c$ satisfies Tarskian truth conditions.
</p>
<p>
<strong>Theorem</strong>: The following are equivalent for a countable $\omega$-nonstandard $M\models{\rm ZFC}$.
<ol>
<li> $M$ is computably saturated.</li>
<li> $M$ has a partial truth predicate $T$ such that $\langle M,\in,T\rangle$ satisfies ${\rm ZFC}$ in the extended language.</li>
<li> $M$ has a truth predicate.</li>
</ol></p>
<p>
The same result for models of ${\rm PA}$ was shown by Kotlarski, Krajewski, and Lachlan <a href="#KotlarskiKrajewskiLachlan:fullSatisfactionClass">[5]</a>, <a href="#Lachlan:fullSatisfactionClass">[6]</a>. In his dissertation Bartosz Wcisło showed that a truth predicate can be used to define a partial truth predicate preserving ${\rm PA}$ and Michał Godzisgewski observed that with this new result the theorem extends to models of ${\rm ZFC}$. Note that it is impossible to extend condition $(3)$ to say that $\langle M,\in,T\rangle\models{\rm ZFC}$ because any such $M$ would be a model of $\text{Con}({\rm ZFC})$.</p>


<h2>References</h2>
<ol class="bibliography"><li><span id="BarwiseSchlipf:recursiveSaturation">J. Barwise and J. Schlipf, “An introduction to recursively saturated and resplendent
              models,” <i>J. Symbolic Logic</i>, vol. 41, no. 2, pp. 531–536, 1976. Available at: https://doi.org/10.2307/2272253</span></li>
<li><span id="friedman:countableModelsOfSetTheory">H. Friedman, “Countable models of set theories,” in <i>Cambridge Summer School in Mathematical Logic
              (Cambridge, 1971)</i>, Berlin: Springer, 1973, pp. 539–573. Lecture Notes in Math., Vol. 337. </span></li>
<li><span id="Ressayre:recursiveSaturation">J. P. Ressayre, “Introduction aux modèles récursivement saturés,” in <i>Séminaire Général de Logique 1983–1984 (Paris,
              1983–1984)</i>, vol. 27, Univ. Paris VII, Paris, 1986, pp. 53–72. </span></li>
<li><span id="multiverse:gitmanhamkins">V. Gitman and J. D. Hamkins, “A natural model of the multiverse axioms,” <i>Notre Dame J. Form. Log.</i>, vol. 51, no. 4, pp. 475–484, 2010. Available at: http://dx.doi.org/10.1215/00294527-2010-030</span></li>
<li><span id="KotlarskiKrajewskiLachlan:fullSatisfactionClass">H. Kotlarski, S. Krajewski, and A. H. and Lachlan, “Construction of satisfaction classes for non-standard models,” <i>Canad. Math. Bull.</i>, vol. 24, no. 3, pp. 283–293, 1981. </span></li>
<li><span id="Lachlan:fullSatisfactionClass">A. H. Lachlan, “Full satisfaction classes and recursive saturation,” <i>Canad. Math. Bull.</i>, vol. 24, no. 3, pp. 295–297, 1981. Available at: https://doi.org/10.4153/CMB-1981-046-0</span></li></ol>]]></summary>
        <author>
            <name>Victoria Gitman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rutgers MAMLS 2019 - TBA]]></title>
        <id>https://muellersandra.github.io/upcomingtalk/talk/invconftalk/2019/07/15/TalkMAMLS.html</id>
        <link href="https://muellersandra.github.io/upcomingtalk/talk/invconftalk/2019/07/15/TalkMAMLS.html">
        </link>
        <updated>2019-07-14T22:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I am invited to give a talk at the 2019 edition of <a href="http://www.grigorsargis.net/RutgersMamls2019.html">Rutgers MAMLS</a>
taking place Nov 1-3, 2019 at Rutgers University, USA. Title and
abstract for the talk will be announced in due course.</p>]]></summary>
        <author>
            <name>Sandra Müller</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[15th International Luminy Workshop in Set Theory - Lower bounds for the perfect subtree property at weakly compact cardinals]]></title>
        <id>https://muellersandra.github.io/upcomingtalk/talk/invconftalk/2019/07/14/TalkLuminy.html</id>
        <link href="https://muellersandra.github.io/upcomingtalk/talk/invconftalk/2019/07/14/TalkLuminy.html">
        </link>
        <updated>2019-07-13T22:00:00Z</updated>
        <summary type="html"><![CDATA[<p>During the week of September 23 - 27, 2019 I will attend the <a href="https://conferences.cirm-math.fr/2052.html">15th International Luminy Workshop in Set Theory</a> and give a talk.</p>

<p><em>Lower bounds for the perfect subtree property at weakly compact cardinals</em></p>

<p><em>Abstract:</em> By the Cantor-Bendixson theorem, subtrees of the binary tree on $\omega$ satisfy a dichotomy - either the tree has countably many branches or there is a perfect subtree (and in particular, the tree has continuum many branches, regardless of the size of the continuum). We generalize this to arbitrary regular cardinals $\kappa$ and ask whether every $\kappa$-tree with more than $\kappa$ branches has a perfect subtree. From large cardinals, this statement is consistent at a weakly compact cardinal $\kappa$. We show using stacking mice that the existence of a non-domestic mouse (which yields a model with a proper class of Woodin cardinals and strong cardinals) is a lower bound. Moreover, we study variants of this statement involving sealed trees, i.e. trees with the property that their set of branches cannot be changed by certain forcings, and obtain lower bounds for these as well. This is joint work with Yair Hayut.</p>]]></summary>
        <author>
            <name>Sandra Müller</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[(with R. Carroy and A. Medini) Constructing Wadge classes]]></title>
        <id>https://muellersandra.github.io/publication/2019/07/12/PaperConstructingWadgeClasses.html</id>
        <link href="https://muellersandra.github.io/publication/2019/07/12/PaperConstructingWadgeClasses.html">
        </link>
        <updated>2019-07-11T22:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Submitted. <a href="https://arxiv.org/pdf/1907.07612.pdf">PDF.</a> <a href="https://arxiv.org/abs/1907.07612">arXiv.</a>
<a data-toggle="collapse" href="javascript:toggle('bibCMM19');" class="title">Bibtex.</a></p>

<div style="display:none" id="bibCMM19">
<pre class="collapse"> @ARTICLE{CMM19,
   AUTHOR= {R. Carroy, A. Medini and S. Müller},
   TITLE= {Constructing Wadge classes},
   Note={Submitted},
   EPRINT ={1907.07612}}</pre>
</div>

<!--more-->

<p>We show that, assuming the Axiom of Determinacy, every non-selfdual Wadge class can be constructed by starting with those of level $\omega_1$ (that is, the ones that are closed under Borel preimages) and iteratively applying the operations of expansion and separated differences. The proof is essentially due to Louveau, and it yields at the same time a new proof of a theorem of Van Wesep (namely, that every non-selfdual Wadge class can be expressed as the result of a Hausdorff operation applied to the open sets). The exposition is self-contained, except for facts from classical descriptive set theory.</p>]]></summary>
        <author>
            <name>Sandra Müller</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Maximal tori of groups of Lie type]]></title>
        <id>https://nickpgill.github.io/maximal-tori-of-groups-of-Lie-type</id>
        <link href="https://nickpgill.github.io/maximal-tori-of-groups-of-Lie-type">
        </link>
        <updated>2019-07-11T00:00:00Z</updated>
        <summary type="html"><![CDATA[<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p>I’ve been re-reading parts of Carter’s “Finite groups of Lie type” and Malle-Testerman’s “Linear algebraic groups and finite groups of Lie type” with a view to understanding the theory of maximal tori in finite groups of Lie type.</p>

<p>In this post I want to use the theory in those books to write down the orders of the maximal tori of $A_2(q)$, ${^2A_2(q)}$ and $G_2(q)$. I wanted to also do ${^2G_2(q)}$ but, so far, I haven’t managed to write things down properly for the Ree and Suzuki groups, so I’ll exclude these from what follows.</p>

<p>The general set-up is as follows: $G$ is a simple linear algebraic groups, and $F:G\to G$ is a Steinberg endomorphism, i.e. some power $F^m:G\to G$ is a Frobenius endomorphism of $G$. (Some of this theory works more generally – for $G$ connected reductive – and, in particular, this can be important when one studies centralizers inside a simple LAG’s…. But I’m not going there just now.) Now a theorem of Steinberg asserts that $G^F$, the set of fixed-points of $F$, is a finite set [MT, Theorem 21.5] – such a group is an example of a <strong>finite group of Lie type</strong>.</p>

<p>Now the Lang-Steinberg theorem asserts that the map $L:G\to G, \, g\mapsto F(g) g^{-1}$ is surjective [MT, Theorem 21.7]. This theorem then implies that $G$ contains an $F$-stable maximal torus $T$ inside an $F$-stable Borel subgroup $B$. Since $T$ is $F$-stable, $N_G(T)$ is also $F$-stable, and so $F$ naturally acts on the Weyl group $W=N_G(T)/T$ of $G$. Similarly, $F$ acts on the character group $X:=X(T)$ via</p>

<script type="math/tex; mode=display">F(\chi(t)):= \chi(F(t)) \textrm{ for } \chi \in X, t\in T.</script>

<p>We will need the notion of $F$-conjugacy in $W$: if $w_1, w_2\in W$, then $w_1$ is <strong>$F$-conjugate</strong> with $w_2$ if there exists $g\in W$ such that $w_1=F(g)w_2g^{-1}$.</p>

<p>Let $\Phi\subset X$ be the root system of $G$ with positive system $\Phi^+$ with respect to $T$ and $B$. In what follows we write $X_\mathbb{R}:=X\otimes_{\mathbb{Z}}\mathbb{R}$.</p>

<p>Now the first three results of [MT, Section 22.1] imply that</p>
<ul>
  <li>there exists a natural number $\delta$ such that $F^\delta=r.1$ in its action on $X$, where $r$ is some power of $p$;</li>
  <li>there exists a permutation $\rho$ of $\Phi^+$ such that, for each $\alpha\in\Phi^+$, $F(\rho(\alpha)) = q_\alpha \alpha$ where $q_\alpha&gt;1$ is a power of $p$;</li>
  <li>the parameter $q_\alpha$ is constant on root lengths; moreover, either $q_\alpha=q$ or else $(G,p)\in{(B_2,2), (G_2,3), (F_4,2)}$, $\rho$ interchanges long and short roots, and $q_{long}.q_{short}=q^2$ with $q_{short}/q_{long}=p$;</li>
  <li>setting $q=r^{1/\delta}$, we have that $F=q\phi$, where $q$ is the Frobenius endomorphism, and $\phi\in {\rm Aut}(X_\mathbb{R})$ is of order $\delta$ inducing $\rho^{-1}$ on $\Phi^+$;</li>
  <li>$T^F=X/(F-1)/X$.</li>
</ul>

<p>It is important to note that, in principle, $q$ is a fractional power of $p$ (although, in fact, it will be integral except when $G^F$ is Ree or Suzuki). Note, too, that this set-up clearly defines the real number $q$ to be associated to our finite group of Lie type – for certain families (e.g. the unitaries), the value of $q$ follows varying conventions whereas here it is clear cut.</p>

<p>We have set-up all the necessary parameters associated with our group of Lie type. Now let’s study the maximal tori: we follow [MT, Chapter 25]. First off, we note that, since Frobenius endomorphism commute with elements of $W$ in their action on $T$, the notion of $F$-conjugacy is the same as $\phi$-conjugacy (where $F=q\phi$).</p>

<p>The following principles are important:</p>
<ul>
  <li>[MT, Prop. 25.1] The $G^F$-classes of $F$-stable maximal tori of $G$ are in 1-1 correspondence with the $\phi$-conjugacy classes in $W$.</li>
  <li>[MT, Exercise 30.5] The $G^F$-classes of subgroups of the form $T^F$ ($T$ an $F$-stable maximal torus of $G$) are in 1-1 correspondence with the two previous sets. (I’m slightly unsure of this… But it seems correct.)</li>
</ul>

<p>These correspondences follow from the Lang-Steinberg theorem. More precisely the first correspondence is as follows: if $gTg^{-1}$ is $F$-stable, then it corresponds to the element $w:=g^{-1}F(g)T\in N_g(T)/T=W$. We are then able to write $T_w$ for the conjugate $gTg^{-1}$. Note that $T_1$ corresponds to an $F$-stable maximal torus in an $F$-stable Borel subgroup. Now [MT, Prop. 25.3] asserts:</p>
<ul>
  <li>$T_w^F\cong X/(wF-1)X$;</li>
  <li>$|T_w^F|=|\det_{X\otimes \mathbb{R}}(wF-1)|=\det_{X\otimes \mathbb{R}}(q-(w\phi)^{-1})$.</li>
</ul>

<p>Specific calculations now follow. These can be confirmed using Kantor-Seress “Prime power graphs for groups of Lie type”.</p>

<hr />
<h2 id="calculations-for-a_2q">Calculations for $A_2(q)$</h2>

<p>We record the size of the maximal tori for $A_2(q)$. Note that, here and below, the isogeny class does not matter – so, in this case, these calculations are valid for ${\rm PGL}_3(q)$ and ${\rm SL}_3(q)$.</p>

<p><img src="A2.png" alt="" /></p>

<p>We use the fact that the fundamental roots of $A_2$ – labelled $\alpha$ and $\beta$ in the diagram – form a basis for $X\otimes\mathbb{R}$. With respect to this basis we have
<script type="math/tex">% <![CDATA[
q=\left(\begin{matrix} q & 0 \\ 0 & q \end{matrix}\right). %]]]]><![CDATA[></script>
In this case $\phi$ is trivial, so we just need to write down $q-w^{-1}$. The possibilities are as follows:</p>
<ul>
  <li>$w=1$. Then <script type="math/tex">% <![CDATA[
w=\left(\begin{matrix} 1 & 0 \\ 0 & 1\end{matrix}\right) %]]]]><![CDATA[></script> and</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\det(q-w^{-1})=\det\left(\begin{matrix} q-1 & 0 \\ 0 & q-1\end{matrix}\right) =(q-1)^2. %]]]]><![CDATA[></script>

<ul>
  <li>$w=Ref_\alpha$. Then <script type="math/tex">% <![CDATA[
w=\left(\begin{matrix} -1 & 1\\ 0 & 1\end{matrix}\right) %]]]]><![CDATA[></script> and</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\det(q-w^{-1})=\det\left(\begin{matrix} q+1 & -1 \\ 0 & q-1\end{matrix}\right) = q^2-1. %]]]]><![CDATA[></script>

<ul>
  <li>$w=Rot_{\pi/3}$. Then <script type="math/tex">% <![CDATA[
w=\left(\begin{matrix} 0 & -1\\ 1 & -1\end{matrix}\right) %]]]]><![CDATA[></script> and</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\det(q-w^{-1}=\det\left(\begin{matrix} q & 1 \\ -1 & q+1\end{matrix}\right) = q^2+q+1. %]]]]><![CDATA[></script>

<hr />

<h2 id="calculations-for-2a_2q">Calculations for ${^2A_2}(q)$</h2>

<p>We record the size of the maximal tori for ${^2A_2}(q)$. The root system is as before, and we have the same value for $q$, but this time time $\phi$ is non-trivial.</p>

<p>Using the same basis as before – ${\alpha, \beta}$, we can write $\phi$ as <script type="math/tex">% <![CDATA[
\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right) %]]]]><![CDATA[></script>. This is just taking $\phi$ acting on the Dynkin diagram. (Stupid comment: I’ve never cottoned on to the fact, hitherto, that $\phi$ is also an automorphism of the root system. In particular it normalizes the Weyl group which here is $W\cong D_6$. So we get $\langle W, \phi\rangle \cong D_{12}$. This is clearly true in general.)</p>

<p>So now we need to write down $q-(\phi w)^{-1}$. The possibilities for $w$ are as before:</p>
<ul>
  <li>$w=1$. Then <script type="math/tex">% <![CDATA[
w=\left(\begin{matrix} 1 & 0 \\ 0 & 1\end{matrix}\right) %]]]]><![CDATA[></script> and</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\det(q-(\phi w)^{-1})=\det\left(\begin{matrix} q & 1 \\ 1 & q\end{matrix}\right) = q^2-1. %]]]]><![CDATA[></script>

<ul>
  <li>$w=Ref_\alpha$. Then <script type="math/tex">% <![CDATA[
w=\left(\begin{matrix} -1 & 1\\ 0 & 1\end{matrix}\right) %]]]]><![CDATA[></script> and</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\det(q-(\phi w)^{-1})=\det\left(\begin{matrix} q-1 & 1 \\ -1 & q\end{matrix}\right) = q^2-q+1. %]]]]><![CDATA[></script>

<ul>
  <li>$w=Ref_{\alpha+\beta}$. Then <script type="math/tex">% <![CDATA[
w=\left(\begin{matrix} 0 & -1\\ -1 & 0\end{matrix}\right) %]]]]><![CDATA[></script> and</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\det(q-(\phi w)^{-1})=\det\left(\begin{matrix} q+1 & 0 \\ 0 & q+1\end{matrix}\right) = (q+1)^2. %]]]]><![CDATA[></script>

<p>Note that we need to choose different elements $w$ because the $\phi$-conjugacy classes in $W$ are different to the usual conjugacy classes.</p>

<hr />

<h2 id="calculations-for-g_2q">Calculations for $G_2(q)$</h2>

<p>Recall that $G_2(q)$ has order $q^6(q^2-1)(q^2-1)$.</p>

<p><img src="G2.png" alt="" /></p>

<p>As before, we take ${\alpha, \beta}$ as a basis for $X\otimes\mathbb{R}$, and we note that $\phi$ is trivial, and $q$ is as before. We must go through representatives for each of the conjugacy classes of $W=D_{12}$:</p>
<ul>
  <li>$w=1$. Then <script type="math/tex">% <![CDATA[
w=\left(\begin{matrix} 1 & 0 \\ 0 & 1\end{matrix}\right) %]]]]><![CDATA[></script> and</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\det(q-w^{-1})=\det\left(\begin{matrix} q-1 & 0 \\ 0 & q-1\end{matrix}\right) =(q-1)^2. %]]]]><![CDATA[></script>

<ul>
  <li>$w=-1=Rot_{\pi/2}$. Then <script type="math/tex">% <![CDATA[
w=\left(\begin{matrix} -1 & 0\\ 0 & -1\end{matrix}\right) %]]]]><![CDATA[></script> and</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\det(q-w^{-1})=\det\left(\begin{matrix} q+1 & 0 \\ 0 & q+1\end{matrix}\right) = (q+1)^2. %]]]]><![CDATA[></script>

<ul>
  <li>$w=Rot_{\pi/3}$. Then <script type="math/tex">% <![CDATA[
w=\left(\begin{matrix} 1 & -3\\ 1 & -2\end{matrix}\right) %]]]]><![CDATA[></script> and</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\det(q-w^{-1})=\det\left(\begin{matrix} q-1 & -1 \\ 3 & q+2\end{matrix}\right) = q^2+q+1. %]]]]><![CDATA[></script>

<ul>
  <li>$w=Rot_{\pi/6}$. Then <script type="math/tex">% <![CDATA[
w=\left(\begin{matrix} 2 & -3\\ 1 & -1\end{matrix}\right) %]]]]><![CDATA[></script> and</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\det(q-w^{-1})=\det\left(\begin{matrix} q-2 & 3 \\ -1 & q+1\end{matrix}\right) = q^2-q+1. %]]]]><![CDATA[></script>

<ul>
  <li>$w=Ref_{3\alpha+2\beta}$. Then <script type="math/tex">% <![CDATA[
w=\left(\begin{matrix} 1 & -3\\ 0 & -1\end{matrix}\right) %]]]]><![CDATA[></script> and</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\det(q-w^{-1})=\det\left(\begin{matrix} q-1 & 3 \\ 0 & q+1\end{matrix}\right) = q^2-1. %]]]]><![CDATA[></script>

<p>This yields all of the maximal tori that are listed in Kantor-Seress. However note that there are two conjugacy classes of reflections in $D_{12}$ – here they correspond to reflections in long and short roots – and so we obtain another example:</p>

<ul>
  <li>$w=Ref_{\alpha+\beta}$. Then <script type="math/tex">% <![CDATA[
w=\left(\begin{matrix} 2 & -3\\ 1 & -2\end{matrix}\right) %]]]]><![CDATA[></script> and</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\det(q-w^{-1})=\det\left(\begin{matrix} q-2 & 3 \\ -1 & q+2\end{matrix}\right) = q^2-1. %]]]]><![CDATA[></script>

<p>Thus it appears that there are two conjugacy classes of maximal torus of order $q^2-1$ – I guess one occurs as a split torus in a Levi factor ${\rm GL}_2(q)=\langle U_\alpha, U_{-\alpha}\rangle$, while the other occurs in ${\rm GL}_2(q)=\langle U_\beta, U_{-\beta}\rangle$. I reconcile this to Kantor-Seress by noting that they do not necessarily claim to list all conjugacy classes of tori, although in some places they do note that there is more than one conjugacy class of a certain order.</p>]]></summary>
        <author>
            <name>Nick Gill</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[(with J. Aguilera) Projective Games on the Reals]]></title>
        <id>https://muellersandra.github.io/publication/2019/07/08/PaperGamesOnReals.html</id>
        <link href="https://muellersandra.github.io/publication/2019/07/08/PaperGamesOnReals.html">
        </link>
        <updated>2019-07-07T22:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Submitted. <a href="https://arxiv.org/pdf/1907.03583.pdf">PDF.</a> <a href="https://arxiv.org/abs/1907.03583">arXiv.</a>
<a data-toggle="collapse" href="javascript:toggle('bibAM19');" class="title">Bibtex.</a></p>

<div style="display:none" id="bibAM19">
<pre class="collapse"> @ARTICLE{AM19,
   AUTHOR= {J. Aguilera and S. Müller},
   TITLE= {Projective Games on the Reals},
   Note={Submitted},
   EPRINT ={1907.03583}}</pre>
   </div>

<p><!--more--></p>

<p>Let $M^\sharp_n(\mathbb{R})$ denote the minimal active iterable extender model which has $n$ Woodin cardinals and contains all reals, if it exists, in which case we denote by $M_n(\mathbb{R})$ the class-sized model obtained by iterating the topmost measure of $M_n(\mathbb{R})$ class-many times. We characterize the sets of reals which are $\Sigma_1$-definable from $\mathbb{R}$ over $M_n(\mathbb{R})$, under the assumption that projective games on reals are determined:</p>
<ul>
<li>for even $n$, $\Sigma_1^{M_n(\mathbb{R})} = \Game^\mathbb{R}\Pi^1_{n+1}$;</li>
<li>for odd $n$, $\Sigma_1^{M_n(\mathbb{R})} = \Game^\mathbb{R}\Sigma^1_{n+1}$.</li>
</ul>
<p>This generalizes a theorem of Martin and Steel for $L(\mathbb{R})$, i.e., the case $n=0$.
As consequences of the proof, we see that determinacy of all projective games with moves in $\mathbb{R}$ is equivalent to the statement that $M^\sharp_n(\mathbb{R})$ exists for all $n\in\mathbb{N}$, and that determinacy of all projective games of length $\omega^2$ with moves in $\mathbb{N}$ is equivalent to the statement that $M^\sharp_n(\mathbb{R})$ exists and satisfies AD for all $n\in\mathbb{N}$.</p>]]></summary>
        <author>
            <name>Sandra Müller</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modal model theory]]></title>
        <id>http://jdh.hamkins.org/modal-model-theory/</id>
        <link href="http://jdh.hamkins.org/modal-model-theory/">
        </link>
        <updated>2019-07-06T11:18:08Z</updated>
        <summary type="html"><![CDATA[Let me introduce to you the topic of modal model theory, injecting some ideas from modal logic into the traditional subject of model theory in mathematical logic. For example, we may consider the class of all models of some first-order &#8230; <a href="http://jdh.hamkins.org/modal-model-theory/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Inclusion modulo nonstationary]]></title>
        <id>http://blog.assafrinot.com/?p=4582</id>
        <link href="http://blog.assafrinot.com/?p=4582">
        </link>
        <updated>2019-06-20T15:37:16Z</updated>
        <summary type="html"><![CDATA[<div class="thanks_button_div" 
                  style="margin-bottom: 30px;"><div id="thanksButtonDiv_4582_2" style="background-image:url(http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/thanks_compact_brown1.png); background-repeat:no-repeat; float: left; display: inline;"
                onmouseover="javascript:thankYouChangeButtonImage('thanksButtonDiv_4582_2', true);" 
                onmouseout="javascript:thankYouChangeButtonImage('thanksButtonDiv_4582_2', false);"
                onclick="javascript:thankYouChangeButtonImage('thanksButtonDiv_4582_2', false);" >
                <input type="button" onclick="thankYouButtonClick(4582, 'You left &ldquo;Thanks&rdquo; already for this post')" value="Like 26"
                  class="thanks_button thanks_compact thanks_brown"
                  style="  font-family: Verdana, Arial, Sans-Serif; font-size: 14px; font-weight: normal;; color:#ffffff;"
                  id="thanksButton_4582_2" title="Click to leave &ldquo;Thanks&rdquo; for this post"/>
             </div><div id="ajax_loader_4582_2" style="display:inline;visibility: hidden;"><img alt="ajax loader" src="http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/ajax-loader.gif" /></div></div><p>Joint work with <a href="http://u.math.biu.ac.il/~zanettg/">Gabriel Fernandes</a> and <a href="http://u.math.biu.ac.il/~morenom3/">Miguel Moreno</a>.</p>
<p><strong>Abstract. </strong>A classical theorem of Hechler asserts that the structure $\left(\omega^\omega,\le^*\right)$ is universal in the sense that for any $\sigma$-directed poset $\mathbb P$ with no maximal element, there is a ccc forcing extension in which $\left(\omega^\omega,\le^*\right)$ contains a cofinal order-isomorphic copy of $\mathbb P$.</p>
<p>In this paper, we prove a consistency result concerning the universality of the higher analogue $(\kappa^\kappa,\le^S)$.</p>
<p><em><strong>Theorem.</strong></em> Assume GCH. For every regular uncountable cardinal $\kappa$, there is a cofinality-preserving GCH-preserving forcing extension in which for every analytic quasi-order $\mathbb Q$ over $\kappa^\kappa$ and every stationary subset $S$ of $\kappa$, there is a Lipschitz map reducing $\mathbb Q$ to $(\kappa^\kappa,\le^S)$.</p>
<p><strong>Downloads:</strong></p>
<p><table class=paperruler"><tr><td><a onclick="thankYouButtonClick(4582, '')"  href="http://www.assafrinot.com/files/paper39.pdf" class="billet_author"></a><a onclick="thankYouButtonClick(4582, '')" href="http://arxiv.org/abs/1906.10066" class="billet_arxiv"></a><img src="/design/003_publish_dis.png"   class="opacity_icons"  height=90 width=64 border=1  alt="[No published version]" title="Published version not available"  /><img src="/design/004_review_dis.png"  class="opacity_icons" height=90 width=64 border=1  alt="[No entry on mathscinet]" title="No entry on mathscinet"  /><a onclick="thankYouButtonClick(4582, '')" href="http://www.assafrinot.com/talk/toronto50" class="billet_slides"></a><a href="http://www.assafrinot.com/paper/21" class="billet_further"></a><a href="http://papers.assafrinot.com/list.php?bib=preprints.bib&key=paper39" class="billet_bibtex"></a><a href="http://www.assafrinot.com/paper/39" class="billet_perm"></a></td></tr></table></p>
<p>&nbsp;</p>
<p><span id="more-4582"></span></p>]]></summary>
        <author>
            <name>Assaf Rinot</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tuna Altinel]]></title>
        <id>https://nickpgill.github.io/tuna-altinel</id>
        <link href="https://nickpgill.github.io/tuna-altinel">
        </link>
        <updated>2019-06-06T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I was recently alerted to a <a href="https://euro-math-soc.eu/news/19/05/14/ems-statement-arrest-prof-tuna-altinel">European Maths Society statement on the arrest of Professor Tuna Altinel</a>. I reproduce that statement below. The situation sounds bad, and I so I am posting here to alert members of the mathematical community to what is going on. If you wish to show solidarity with Professor Altinel, then you can do so by signing the petition <a href="http://math.univ-lyon1.fr/SoutienTunaAltinel/?lang=en">here</a>.</p>

<h3 id="ems-statement-on-the-arrest-of-prof-tuna-altinel">EMS Statement on the Arrest of Prof Tuna Altinel</h3>

<blockquote>
  <p>Last week the mathematician Tuna Altinel, member of the European Mathematical Society and professor at the Université Lyon 1 in France, was arrested in Turkey after he had his passport extracted by the police. Tuna Altinel was one of the signatories of the peace petition supported by more than 2000 scientists and intellectuals against military actions towards civilians.</p>
</blockquote>

<blockquote>
  <p>The European Mathematical Society condemns this violation of Prof Altinel’s human rights and demands that he is immediately released and allowed to return to France to resume his teaching and research.</p>
</blockquote>]]></summary>
        <author>
            <name>Nick Gill</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Completely ineffable cardinals]]></title>
        <id>https://victoriagitman.github.io/research/2019/06/05/completely-ineffable-cardinals.html</id>
        <link href="https://victoriagitman.github.io/research/2019/06/05/completely-ineffable-cardinals.html">
        </link>
        <updated>2019-06-05T04:00:00Z</updated>
        <summary type="html"><![CDATA[<p>
I have to admit that I always thought completely ineffable cardinals to be a rather boring technical notion. But I recently came across several equivalent characterizations of complete ineffability that are quite surprising and natural. I also think I stumbled upon an interesting consistency strength implication from completely ineffable cardinals.</p>
<p>
Completely ineffable cardinals sit atop the ineffability hierarchy. A cardinal $\kappa$ is <em>ineffable</em> if every coloring $f:[\kappa]^2\to 2$, coloring pairs of ordinals in 2 colors, has a stationary homogeneous subset. A cardinal $\kappa$ is <em>$n$-ineffable</em> if every coloring $f:[\kappa]^n\to 2$ has a stationary homogeneous subset. A cardinal $\kappa$ is <em>totally ineffable</em> if it is $n$-ineffable for every $n$. It is not easy to remember the definition of completely ineffable cardinals. A cardinal $\kappa$ is <em>completely ineffable</em> if there is a collection $\mathcal R$ of stationary subsets of $\kappa$ closed under supersets such that every coloring $f:[A]^2\to 2$ for $A\in\mathcal R$ has a homogeneous subset in $\mathcal R$. So a completely ineffable $\kappa$ has a set of stationary subsets of $\kappa$ that is closed under the operation of obtaining homogeneous sets for colorings. Completely ineffable cardinals are limits of totally ineffable cardinals. They are also totally indescribable. Completely ineffable cardinals lie relatively low in the large cardinal hierarchy. They are much weaker than Ramsey or even $\omega$-Erdos cardinals, in particular, they can exist in $L$.</p>
<p>
I call a transitive model $M\models{\rm ZFC}^-$ (${\rm ZFC}$ with the powerset axiom removed) a <em>weak $\kappa$-model</em> if it has size $\kappa$ and $\kappa\in M$. Many of the smaller large cardinals, those below a measurable cardinal, have characterizations in terms of existence of elementary embeddings of weak $\kappa$-models. For example, $\kappa$ is weakly compact if (it is inaccessible and) every $A\subseteq\kappa$ is an element of a weak $\kappa$-model $M$ for which there is an elementary embedding $j:M\to N$ with critical point $\kappa$ and $N$ transitive. Equivalently, every $A\subseteq\kappa$ is an element of a weak $\kappa$-model $M$ for which there is an $M$-ultrafilter $U$ on $\kappa$ with a well-founded ultrapower. An <em>$M$-ultrafilter</em> on $\kappa$ is an ultrafilter on $P(\kappa)^M$, not necessarily from $M$, that is normal for sequences from $M$. A well-founded ultrapower by an $M$-ultrafilter yields an elementary embedding $j:M\to N$ with critical point $\kappa$ and conversely given an elementary embedding $j:M\to N$ with critical point $\kappa$ and $N$ transitive, we have that $$U=\{A\in M\mid A\subseteq\kappa\text{ and }\kappa\in j(A)\}$$ is an $M$-ultrafilter with a well-founded ultrapower (the ultrapower embeds into $N$).</p>
<p>
Although we can take the ultrapower by an $M$-ultrafilter, we cannot necessarily iterate the ultrapower construction. If $U$ is not in $M$, how do we define $j(U)$? It turns out that you can do this if the $M$-ultrafilter has the additional property of being weakly amenable, that is being partially internal to $M$. An $M$-ultrafilter $U$ on $\kappa$ is <em>weakly amenable</em> if for every $A\in M$ which $M$ thinks has size $\kappa$, $A\cap U\in M$. A well-founded ultrapower $j:M\to N$ by a weakly amenable $M$-ultrafilter $U$ on $\kappa$ has the property that $P(\kappa)^M=P(\kappa)^N$ and if $j:M\to N$ is any embedding with critical point $\kappa$ such that $P(\kappa)^M=P(\kappa)^N$, then the derived $M$-ultrafilter $U$ (defined as above) is weakly amenable. In my dissertation, I introduced the $\alpha$-iterability hierarchy by exploring iterability properties of weakly amenable $M$-ultrafilters. A cardinal $\kappa$ is <em>1-iterable</em> if every $A\subseteq\kappa$ is an element of a weak $\kappa$-model $M$ for which there is a weakly amenable $M$-ultrafilter with a well-founded ultrapower. More generally, a cardinal $\kappa$ is <em>$\alpha$-iterable</em> for $1\leq\alpha\leq\omega_1$ if every $A\subseteq\kappa$ is an element of a weak $\kappa$-model $M$ for which there is a weakly amenable $M$-ultrafilter with $\alpha$-many well-founded iterated ultrapowers (once you have $\omega_1$-many well-founded iterated ultrapowers, then all the rest are well-founded as well).</p>
<p>
The point here is that a $1$-iterable cardinal $\kappa$ is a already a limit of completely ineffable cardinals. To see this, let $M$ be a weak $\kappa$-model with $V_\kappa\in M$ for which there is a weakly amenable $M$-ultrafilter $U$ with a well-founded ultrapower. First, let's argue that for every $A\in U$ and coloring $f:[A]^2\to 2$ in $M$, there is a homogeneous set for $f$ in $U$. Let $h:M\to K$ be the (possibly ill-founded) ultrapower by $U\times U$, which exists by weak amenability. It is still the case that $A\subseteq \kappa\times\kappa$ is in $U\times U$ if and only if $[\text{id}]_{U\times U}\in h(A)$. Say $h(f)([\text{id}]_{U\times U})=1$. Then $$A=\{(\xi_1,\xi_2)\mid f(\xi_1,\xi_2)=1\}\in U\times U.$$ An easy argument shows that whenever $X\in U\times U$, then there is a set $\bar X\in U$ such that for all $\xi_1<\xi_2$ in $\bar X$, $(\xi_1,\xi_2)\in X$. So $U$ has a set $\bar A$ such that whenever $\xi_1<\xi_2$ are in $\bar A$, then $(\xi_1,\xi_2)\in A$, and so $f(\xi_1,\xi_2)=1$, meaning that $\bar A$ is homogeneous for $f$. Now let $j:M\to N$ be the ultrapower by $U$. We will argue that $\kappa$ is completely ineffable in $N$, and hence by elementarity $M$ thinks that $\kappa$ is a limit of completely ineffable cardinals, but it must be correct about it because it has the true $V_\kappa$. We work now inside $N$. Let $\mathcal R_0$ be the collection of all stationary subsets of $\kappa$. Given $R_\xi$, let $R_{\xi+1}$ be the collection of all sets $A$ in $R_\xi$ such that for every coloring $f:[A]^2\to 2$, $R_\xi$ has a homogeneous set for $A$. At limits take intersections. There must be some $\theta$ such that $R_\theta=R_{\theta+1}$ and if $R_\theta$ is not empty, then by construction it will witness that $\kappa$ is completely ineffable. But this is the case because $U\subseteq R_\xi$ for every $\xi$. Note though that a 1-iterable cardinals may not be completely ineffable itself because it is $\Pi^1_2$-describable.</p>
<p>
Next, let's talk about one of the game Ramsey cardinals introduced by Holy and Schlicht in <a href="#HolySchlicht:HierarchyRamseyLikeCardinals">[1]</a>. First, let's modify the definition of a weak $\kappa$-model to allow <em>non-transitive</em> $\in$-models. We need this because we want to consider models of size $\kappa$ elementary in large $H_\theta$ (collection of all sets whose transitive closure has size less than $\theta$). Let's call a weak $\kappa$-model $M$ a <em>$\kappa$-model</em> if it is closed under sequences of length less than $\kappa$. Now fix an inaccessible cardinal $\kappa$ and a regular cardinal $\theta>\kappa$. Consider a two player game of perfect information of length $\omega$ between the challenger and the judge, where at each step $n$ of the game, the challenger plays a $\kappa$-model $M_n\prec H_\theta$ and the judge responds with an $M_n$-ultrafilter $U_n$. Additionally, at each step the challenger needs to make sure that $M_n\subseteq M_{n+1}$ and $M_n,U_n\cap M_n\in M_{n+1}$. The judge wins the game if she is able to play for $\omega$-many steps and otherwise the challenger wins. A cardinal $\kappa$ has the <em>$\omega$-filter property</em> if the challenger doesn't have a winning strategy for any regular $\theta$.</p>
<p>
Finally, let's talk about Paul Corazza's <em>Wholeness Axiom</em> <a href="#corazza:wholenessAxiom">[2]</a>. Kunen's Inconsistency, which says that there cannot be an elementary embedding $j:V\to V$ can be formalized in several ways. The proof shows that in a model of the second-order Kelley-Morse set theory $(V,\in,\mathcal S)$ there cannot be a class $j\in \mathcal S$ which is an elementary embedding of the first-order part $(V,\in)$. We can also consider expanding the language $\{\in\}$ of set theory by a binary predicate $j$ and considering the theory ${\rm ZFC}$ in this expanded language (with separation and replacement applying to formulas with $j$) together with a scheme of assertions that $j$ is a non-trivial elementary embedding. Kunen's result can also be viewed as asserting that such a theory is inconsistent. What fragment of this theory in the language with $j$ can we salvage? Suppose we just assert that $j$ is non-trivial and elementary. This theory is equiconsistent with ${\rm ZFC}$ because if there is a model of ${\rm ZFC}$, then there is a model of ${\rm ZFC}$ that is computably saturated and hence has plenty of not just elementary embeddings, but automorphisms (see <a href="/research/2019/06/04/some-cute-observations-about-computably-saturated-models/">this post</a>).  How about the theory saying that $j$ is elementary and has a critical point (meaning that some ordinal $\kappa$ is moved and every ordinal 
$\alpha<\kappa$ is fixed)? Corazza calls this theory ${\rm BTEE}$ (basic theory of elementary embeddings). So there is a model $M\models{\rm ZFC}$ and an elementary embedding $j:M\to M$ with critical point $\kappa\in M$. It is easy to see that $\kappa$ must be at least inaccessible in $M$. The argument we gave for 1-iterable cardinals shows that $\kappa$ is $n$-ineffable in $M$ for every natural number $n$ of the metatheory because we can use $j$ to derive an $M$-ultrafilter $U$, which must be weakly amenable, and use product ultrafilters $U^n$ to obtain homogeneous sets. If we additionally assume that $\Sigma_0$-separation holds for formulas with $j$, then it follows that $j$ is amenable to $M$ (for every $a\in M$, $j\upharpoonright a\in M$), which implies that $\kappa$ is at least super $n$-huge in $M$ for every $n\in\omega$. That's quite a jump in consistency strength! It is not known whether assuming full separation for $j$ gives a consistency-wise stronger theory although it is known that weaker and stronger separation have different consequences. Stronger separation implies for example that iterate embeddings $j^n$ are definable in $M$ for every natural number $n\in M$, but this is known to fail with just $\Sigma_0$-separation (the issues here arise for nonstandard $n$).</p>
<p>
The following theorem gives several very different characterizations of completely ineffable cardinals.</p>
<p><strong>Theorem</strong>:
The following are equivalent to $\kappa$ being completely ineffable.
<ol>
<li>
(Nielsen and Welch <a href="#NielsenWelch:GamesAndRamseyLikeCardinals">[3]</a>) $\kappa$ has the $\omega$-filter property.</li>
<li>(<a href="#AbramsonHarringtonKleinbergZwicker:FlippingProperties">[4]</a>) In a forcing extension $V[G]$, there is a weakly amenable $V$-ultrafilter and hence a generic elementary embedding $j:V\to N$ with critical point $\kappa$ such that $V_{\kappa+1}^V=V_{\kappa+1}^N$ (it follows that $\kappa^+$ is in the well-founded part of $j$).</li>
<li> For every regular $\theta>\kappa$, every $A\subseteq\kappa$ is an element of a weak $\kappa$-model $M\prec H_\theta$ for which there is a weakly amenable $M$-ultrafilter $U$ (but the ultrapower may fail to be well-founded).</li>
</ol></p>
<p><strong>Proof</strong>:
For equivalence with (1) see <a href="#NielsenWelch:GamesAndRamseyLikeCardinals">[3]</a>. For equivalence with (2), see the the argument in <a href="#AbramsonHarringtonKleinbergZwicker:FlippingProperties">[4]</a> for forcing over countable models and instead force over $V$. (3) follows from (2) by playing the game for $\omega$-many steps to build $U$. Finally suppose (3) and let's argue that $\kappa$ is completely ineffable. The same argument which shows that $\kappa$ is completely ineffable in $N$ for a 1-iterable embedding $j:M\to N$ will show that $\kappa$ is completely ineffable in $M$ and this suffices because $M\prec H_\theta$ is correct about complete ineffability.</p>
<p>
Completely ineffable cardinals now look very similar to 1-iterable cardinals, but the true analogue is actually the $\omega$-Ramsey cardinals, another game Ramsey cardinal notion of Holy and Schlicht from <a href="#HolySchlicht:HierarchyRamseyLikeCardinals">[1]</a>. A cardinal $\kappa$ is <em>$\omega$-Ramsey</em> if the challenger has no winning strategy in the games described as above only with the additional condition that in order for the judge to win, after the $\omega$-many steps, $U=\bigcup_{n<\omega}U_n$ has to have a well-founded ultrapower. Equivalently, for every regular $\theta>\kappa$, every $A\subseteq\kappa$ is an element of a weak $\kappa$-model $M\prec H_\theta$ for which there is a weakly amenable $M$-ultrafilter $U$ with a well-founded ultrapower. $\omega$-Ramsey cardinals are between 1-iterable and 2-iterable cardinals in consistency strength.</p>
<p><strong>Theorem</strong>:
Consistency of a completely ineffable cardinal implies consistency of the theory ${\rm BTEE}$.
</p><strong>Proof</strong>:
Suppose that $\kappa$ is completely ineffable in a model $V\models{\rm ZFC}$ and move to a forcing extension $V[G]$, in which there is a generic embedding $j:V\to N$ by a weakly amenable $V$-ultrafilter $U$. Since $U$ is weakly amenable, we can iterate the ultrapower construction $\omega$-many times, obtaining iterate embeddings $j_{mn}:N_m\to N_n$ with critical point $\kappa_n$. Let $\mathcal N$ be the direct limit of this system. Standard arguments show that the critical sequence $\{\kappa_n\mid n<\omega\}$ are indiscernibles for $\mathcal N$ even for formulas with parameters $\alpha<\kappa$. (Note that $V_{\kappa+1}^{\mathcal N}=V_{\kappa+1}^V$.) Now let $M$ be generated in $\mathcal N$ by $\alpha<\kappa$ and the critical sequence $\kappa_n$ for $n<\omega$. Define $h:M\to M$ to be the elementary embedding generated by the shift of indiscernibles map taking $\kappa_n$ to $\kappa_{n+1}$. In other words, a term $t(\alpha_0,\ldots,\alpha_n,\kappa_0,\ldots,\kappa_m)$, with $\alpha_i<\kappa$, gets mapped to the term $t(\alpha_0,\ldots\alpha_n,\kappa_1,\ldots,\kappa_{n+1})$. Because the $\kappa_n$ are indiscernibles for formulas with parameters $\alpha<\kappa$, $h$ is a well-defined elementary embedding with critical point $\kappa=\kappa_0$.</p>
<p>This squizes the consistency strength of ${\rm BTEE}$ between $n$-ineffable cardinals for every $n$ and completely ineffable cardinals.</p>

<h2>References</h2>
<ol class="bibliography"><li><span id="HolySchlicht:HierarchyRamseyLikeCardinals">P. Holy and P. Schlicht, “A hierarchy of Ramsey-like cardinals.” </span></li>
<li><span id="corazza:wholenessAxiom">P. Corazza, “The spectrum of elementary embeddings $j\:V\to V$,” <i>Ann. Pure Appl. Logic</i>, vol. 139, no. 1-3, pp. 327–399, 2006. Available at: https://doi.org/10.1016/j.apal.2005.06.014</span></li>
<li><span id="NielsenWelch:GamesAndRamseyLikeCardinals">D. S. Nielsen and P. D. Welch, “Games and Ramsey-like cardinals,” <i>Submitted</i>. </span></li>
<li><span id="AbramsonHarringtonKleinbergZwicker:FlippingProperties">F. G. Abramson, L. A. Harrington, E. M. Kleinberg, and W. S. Zwicker, “Flipping properties: a unifying thread in the theory of large
              cardinals,” <i>Ann. Math. Logic</i>, vol. 12, no. 1, pp. 25–58, 1977. Available at: http://dx.doi.org/10.1016/0003-4843(77)90005-5</span></li></ol>]]></summary>
        <author>
            <name>Victoria Gitman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some cute observations about computably saturated models]]></title>
        <id>https://victoriagitman.github.io/research/2019/06/04/some-cute-observations-about-computably-saturated-models.html</id>
        <link href="https://victoriagitman.github.io/research/2019/06/04/some-cute-observations-about-computably-saturated-models.html">
        </link>
        <updated>2019-06-04T04:00:00Z</updated>
        <summary type="html"><![CDATA[<p>
A model of a first-order theory $T$ is said to be <em>computably saturated</em> (old fashioned terminology is: recursively saturated) if it satisfies all its finitely realizable computable types (in finitely many parameters). A type $p(x,\bar y)$ is <em>computable</em> if the set of Gödel codes of the formulas in it is computable. A type $p(x,\bar a)$ is finitely realizable over a model $M$ with parameters $\bar a\in M$ if for every finite set $A$ of formulas from $p(\bar a,x)$, there is some $b\in M$ such that $\varphi(b,\bar a)$ holds in $M$ for every $\varphi(x,\bar y )\in A$.
</p><p>
I am particularly interested in computably saturated models of my two favorite theories Peano Arithmetic ${\rm PA}$ and set theory ${\rm ZFC}$. These models have many remarkable properties. For instance, countable computably saturated models have plenty of automorphisms. If $M\models{\rm PA}$ is a countable computably saturated model and $a\in M$ is not definable, then there is an automorphism which moves $a$. Indeed, given two elements $a$ and $b$ of the same type in $M$, there is an automorphism of $M$ moving $a$ to $b$. Also, if $a'$ is not definable from $a$ in $M$, then there is an automorphism fixing $a$, but moving $a'$. 
</p><p>
As an example, let's argue that if $a$ is not definable, then there there is $b\neq a$ with the same type as $a$. For this we need to recall the notion of a standard system ${\rm SSy}(M)$ of $M$. The standard system is a collection of subsets of the (actual) natural numbers $\mathbb N$ that arise as intersections of $\mathbb N$ with definable (with parameters) sets of $M$: $${\rm SSy}(M)=\{A\subseteq\mathbb N\mid A=B\cap \mathbb N\text{ for some definable }B\subseteq M\}.$$ It is not difficult to see that a computably saturated model $M$ is ${\rm SSy}(M)$-<em>saturated</em> - saturated for every type (coded) in the standard system. Conversely, if $M$ is computably saturated, then ${\rm tp}(a)$, the type of $a$, is in ${\rm SSy}(M)$ for every $a\in M$. Now consider the type $p(x,a)$ consisting of formulas in ${\rm tp}(a)$ together with the assertion $x\neq a$. Clearly $p(x,y)$ is in the standard system, since ${\rm tp}(a)$ is. So it suffices to argue that it is finitely realizable, but this follows trivially from the fact that $a$ is not definable.
</p><p>
All the same machinery works for computably saturated models of ${\rm ZFC}$ In particular, computably saturated models of ${\rm ZFC}$ have lots of automoprhisms.
</p><p>
At a recent <a href="https://jaf2019nyc.com/">JAF meeting</a>, we were chatting about automorphisms of computably saturated models with Roman Kossak and 
Michał Godziszewski, when the following cute question came up. Is it possible to have a countable computably saturated model $M$ of ${\rm ZFC}$ such that every automorphism of its natural numbers $\mathbb N^M$ extends to an automorphism of $M$? Note that $\mathbb N^M$ must be computably saturated because $M$ is, so it has many automorphisms. We thought about it some more with Corey Switzer and finally realized that this is not possible. My guess is that this is all folklore. </p><p>
<strong>Theorem</strong>
Suppose $M\models{\rm ZFC}$ is a countable computably saturated model, then there is an automorphism of $\mathbb N^M$ that does not extend to an automorphism of $M$. </p><p>
<strong>Proof</strong>:
Fix any nonstandard natural number $a\in M$. The model $M$ thinks that there is a least number $a'$ above all numbers definable over $\mathbb N^M$ by formulas of length less than $a$. In particular, it must be the case that $a'$ is not definable from $a$ because $M$ is correct about satisfaction for standard formulas over $\mathbb N^M$ and $a$ was chosen to be nonstandard. Thus, there is an automorphism of $\mathbb N^M$ which fixes $a$ but moves $a'$. But this automorphism cannot extend to $M$ because over $M$ $a'$ is definable from $a$.</p><p>
The above result holds with $\mathbb N^M$ replaced by any computably saturated substructure of $M$ that is a set in $M$ because all the proof used was that $M$ has a satisfaction relation for $\mathbb N^M$.</p><p>

Another random question that came up in the discussion, curtesy of Corey, was whether a non-computably saturated model of ${\rm ZFC}$ can have its natural numbers be computably saturated. The answer is easily seen to be yes.</p>
<p><strong>Theorem</strong>:
There is a model $M\models{\rm ZFC}$ which is not computably saturated, but its natural numbers are computably saturated.
</p><p>
<strong>Proof</strong>:
Suppose $\bar M\models{\rm ZFC}+V={\rm HOD}$ (without getting into technicalities, $V={\rm HOD}$, the assertion that every set is hereditarily ordinal definable, says that $M$ has a definable well-ordering, and hence definable Skolem functions) is computably saturated. So $\mathbb N^{\bar M}$ is computably saturated as well. Now let $M={\rm Scl}(\mathbb N^{\bar M})$ be the Skolem closure in $\bar M$ of the set of its natural numbers. It is not difficult to see that $M$ cannot be computably saturated. Consider the type $p(x,\omega)$ (using the single parameter $\omega\in M$) asserting that $x$ is an ordinal and for every formula $\varphi(y,z)$ asserting that for every $n\in\omega$, if there is a unique $z$ such that $\varphi(n,z)$, then $x>z$. Clearly $p(x,\omega)$ is computable and finitely realizable in $M$, but it is not realized by the definition of $M$.
</p><p>
Roman Kossak claims, but I don't know the argument, that we can even construct such $M$ to be rigid (meaning that it would have no automorphisms), and hence very far from computably saturated. </p>
<p style="color:red;">
Thanks Kameryn Williams for pointing out the following result.</p>
<p style="color:red;">
<strong>Theorem</strong>: Suppose $M\models{\rm ZFC}$ is non-standard. Then $\mathbb N^M$ is computably saturated.</p>
<p style="color:red;">
<strong>Proof</strong>: By a classical theorem of Lachlan, having a full satisfaction class implies computable saturation <a href="#Lachlan:fullSatisfactionClass">[1]</a>.
</p>
<p style="color:red;">
A full satisfaction class is the ${\rm PA}$ terminology for a truth predicate - a subset of the model consisting of Gödel codes of formulas (including non-standard formulas) satisfying Tarskian truth conditions. A truth predicate gives a coherent definition of what is true in the model including a truth interpretation for non-standard formulas. Kotlarski, Krajewski, and Lachlan showed a partial converse that a countable computably saturated model always has a full satisfaction class <a href="#KotlarskiKrajewskiLachlan:fullSatisfactionClass">[2]</a>.
</p>
<p>
An excellent source on everything you need to know about computably saturated models of ${\rm PA}$ is Roman's and Jim Schmerl's book <a href="#kossakschmerl:modelsofpa">[3]</a>. Most results there generalize to computably saturated models of ${\rm ZFC}$, but there is not one good definitive source for results on these models, although people including myself, Joel Hamkins and Michał have written papers about them. See for example, <a href="#HamkinsYang:SatisfactionIsNotAbsolute">[4]</a> and <a href="#multiverse:gitmanhamkins">[5]</a> for interesting constructions with computably saturated models of ${\rm ZFC}$. </p>


<h2>References</h2>
<ol class="bibliography"><li><span id="Lachlan:fullSatisfactionClass">A. H. Lachlan, “Full satisfaction classes and recursive saturation,” <i>Canad. Math. Bull.</i>, vol. 24, no. 3, pp. 295–297, 1981. Available at: https://doi.org/10.4153/CMB-1981-046-0</span></li>
<li><span id="KotlarskiKrajewskiLachlan:fullSatisfactionClass">H. Kotlarski, S. Krajewski, and A. H. and Lachlan, “Construction of satisfaction classes for non-standard models,” <i>Canad. Math. Bull.</i>, vol. 24, no. 3, pp. 283–293, 1981. </span></li>
<li><span id="kossakschmerl:modelsofpa">R. Kossak and J. H. Schmerl, <i>The structure of models of Peano arithmetic</i>, vol. 50. The Clarendon Press, Oxford University Press, Oxford, 2006, p. xiv+311. Available at: http://dx.doi.org.ezproxy.gc.cuny.edu/10.1093/acprof:oso/9780198568278.001.0001</span></li>
<li><span id="HamkinsYang:SatisfactionIsNotAbsolute">J. D. Hamkins and R. Yang, “Satisfaction is not absolute,” <i>to appear in the Review of Symbolic Logic</i>, pp. 1–34, 2014. Available at: http://wp.me/p5M0LV-Gf</span></li>
<li><span id="multiverse:gitmanhamkins">V. Gitman and J. D. Hamkins, “A natural model of the multiverse axioms,” <i>Notre Dame J. Form. Log.</i>, vol. 51, no. 4, pp. 475–484, 2010. Available at: http://dx.doi.org/10.1215/00294527-2010-030</span></li></ol>]]></summary>
        <author>
            <name>Victoria Gitman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alan Turing’s theory of computation, Oxford and Cambridge Club, June 2019]]></title>
        <id>http://jdh.hamkins.org/alan-turings-theory-of-computation-oxford-and-cambridge-club-june-2019/</id>
        <link href="http://jdh.hamkins.org/alan-turings-theory-of-computation-oxford-and-cambridge-club-june-2019/">
        </link>
        <updated>2019-06-02T17:38:58Z</updated>
        <summary type="html"><![CDATA[I shall speak for the Oxford and Cambridge Club, in a joint event hosted by Maths and Science Group and the Military History Group, an evening (6 June 2019) with dinner and talks on the theme of the Enigma and &#8230; <a href="http://jdh.hamkins.org/alan-turings-theory-of-computation-oxford-and-cambridge-club-june-2019/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computational self-reference and the universal algorithm, Queen Mary University of London, June 2019]]></title>
        <id>http://jdh.hamkins.org/computational-self-reference-and-the-universal-algorithm-queen-mary-university-of-london-june-2019/</id>
        <link href="http://jdh.hamkins.org/computational-self-reference-and-the-universal-algorithm-queen-mary-university-of-london-june-2019/">
        </link>
        <updated>2019-06-02T15:43:36Z</updated>
        <summary type="html"><![CDATA[This will be a talk for the Theory Seminar for the theory research group in Theoretical Computer Science at Queen Mary University of London. The talk will be held 4 June 2019 1:00 pm, ITL first floor. Abstract. Curious, often &#8230; <a href="http://jdh.hamkins.org/computational-self-reference-and-the-universal-algorithm-queen-mary-university-of-london-june-2019/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Representing Ordinal Numbers with Arithmetically Interesting Sets of Real Numbers]]></title>
        <id>http://jdh.hamkins.org/representing-ordinal-numbers-with-arithmetically-interesting-sets-of-real-numbers/</id>
        <link href="http://jdh.hamkins.org/representing-ordinal-numbers-with-arithmetically-interesting-sets-of-real-numbers/">
        </link>
        <updated>2019-06-02T14:18:15Z</updated>
        <summary type="html"><![CDATA[[bibtex key="BlairHamkinsOBryant:Representing-ordinal-numbers-with-arithmetically-interesting-sets-of-real-numbers"] <a href="http://jdh.hamkins.org/representing-ordinal-numbers-with-arithmetically-interesting-sets-of-real-numbers/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[50 Years of Set Theory in Toronto, May 2019]]></title>
        <id>http://blog.assafrinot.com/?p=4577</id>
        <link href="http://blog.assafrinot.com/?p=4577">
        </link>
        <updated>2019-05-19T15:47:41Z</updated>
        <summary type="html"><![CDATA[<div class="thanks_button_div" 
                  style="margin-bottom: 30px;"><div id="thanksButtonDiv_4577_2" style="background-image:url(http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/thanks_compact_brown1.png); background-repeat:no-repeat; float: left; display: inline;"
                onmouseover="javascript:thankYouChangeButtonImage('thanksButtonDiv_4577_2', true);" 
                onmouseout="javascript:thankYouChangeButtonImage('thanksButtonDiv_4577_2', false);"
                onclick="javascript:thankYouChangeButtonImage('thanksButtonDiv_4577_2', false);" >
                <input type="button" onclick="thankYouButtonClick(4577, 'You left &ldquo;Thanks&rdquo; already for this post')" value="Like 6"
                  class="thanks_button thanks_compact thanks_brown"
                  style="  font-family: Verdana, Arial, Sans-Serif; font-size: 14px; font-weight: normal;; color:#ffffff;"
                  id="thanksButton_4577_2" title="Click to leave &ldquo;Thanks&rdquo; for this post"/>
             </div><div id="ajax_loader_4577_2" style="display:inline;visibility: hidden;"><img alt="ajax loader" src="http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/ajax-loader.gif" /></div></div><p>I gave an invited talk at the <a href="http://www.fields.utoronto.ca/activities/18-19/set-theory">50 Years of Set Theory in Toronto</a> meeting,<br />
Fields Institute for Research in Mathematical Sciences, May 2019.</p>
<p><strong>Talk Title: </strong>Analytic quasi-orders and two forms of diamond</p>
<p><strong>Abstract:</strong> We study Borel reduction of equivalence relations (more generally: quasi-orders) in the generalized Baire and Cantor spaces, and connect it with the study of two diamond-type principles. One of these principles holds for all ineffable sets, and the other fails on all ineffable sets, but, in L, holds for all stationary non-ineffable sets.</p>
<p>This is joint work with <a href="http://blog.assafrinot.com/?persons=gabriel-fernandes">Gabriel Fernandes</a> and <a href="http://blog.assafrinot.com/?persons=miguel-moreno">Miguel Moreno</a>.</p>
<p><strong>Downloads:</strong></p>
<p><p><table class=paperruler"><tr><td><a onclick="thankYouButtonClick(4577, '')" href="http://www.assafrinot.com/files/rinot_fields2019.pdf" class="billet_slides"></a><a href="http://www.assafrinot.com/paper/39" class="billet_further"></a><a href="http://www.assafrinot.com/talk/toronto50" class="billet_perm"></a></td></tr></table></p><span id="more-4577"></span></p>]]></summary>
        <author>
            <name>Assaf Rinot</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computable reducibility of equivalence relations]]></title>
        <id>http://scoskey.org/masters-thesis/computable-reducibility-of-equivalence-relations/</id>
        <link href="http://scoskey.org/masters-thesis/computable-reducibility-of-equivalence-relations/">
        </link>
        <updated>2019-05-15T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>A master’s thesis by Gianni Krakoff, Spring 2019<!--more--></p>

<p><em>Abstract</em>: Computable reducibility of equivalence relations is a tool to compare the complexity of equivalence relations on natural numbers. Its use is important to those doing Borel equivalence relation theory, computability theory, and computable structure theory. In this thesis, we compare many naturally occurring equivalence relations with respect to computable reducibility. We will then define a jump operator on equivalence relations and study proprieties of this operation and its iteration. We will then apply this new jump operation by studying its effect on the isomorphism relations of well-founded computable trees.</p>]]></summary>
        <author>
            <name>Samuel Coskey</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The hyperreals; do you prefer non-standard analysis over standard analysis?]]></title>
        <id>http://scoskey.org/senior-thesis/hyperreal-numbers/</id>
        <link href="http://scoskey.org/senior-thesis/hyperreal-numbers/">
        </link>
        <updated>2019-05-01T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>A senior thesis by Chloe Munroe, Spring 2019<!--more--></p>

<table>
  <tbody>
    <tr>
      <td><em>Abstract</em>: The hyperreal number system $\ast\mathbb R$ forms an ordered field that contains $\mathbb R$ as a subfield as well as infinitely large and small numbers. A number is defined to be infinitely large if $</td>
      <td>x</td>
      <td>&gt;n$ for all $n = 1, 2, 3, \ldots$ and infinitely small if $</td>
      <td>x</td>
      <td>&lt;1/n$ for all $n = 1, 2, 3\ldots$ This number system is built out of the real number system analogous to Cantor’s construcion of $\mathbb R$ out of $\mathbb Q$. The new entities in $\ast\mathbb R$ and the relationship between the reals and hyperreals provides an appealing alternate approach to real (standard) analysis referred to as nonstandard analysis. This approach is based around that principle that if a property holds for all real numbers then it holds for all hypereal numbers, known as the transfer principle. By only using the fact that $\ast\mathbb R$ is an ordered field that has $\mathbb R$ as a subfield, includes unlimited numbers and satisfies the transfer principle the topics of analysis can be explored.</td>
    </tr>
  </tbody>
</table>]]></summary>
        <author>
            <name>Samuel Coskey</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The nametag problem]]></title>
        <id>http://scoskey.org/senior-thesis/the-nametag-problem/</id>
        <link href="http://scoskey.org/senior-thesis/the-nametag-problem/">
        </link>
        <updated>2019-05-01T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>A senior thesis by Christian Carley, Spring 2019<!--more--></p>

<p><em>Abstract</em>: This paper explores what has been termed, ``The Name Tag Problem’’ (NTP). The problem is framed thusly. A group of $n$ people sit around a table and to each person a name tag has been assigned. How can you assign the nametags so that just one person has the correct name tag assigned, and no matter how many times the table is rotated, still just one person has the correct name tag assigned?</p>]]></summary>
        <author>
            <name>Samuel Coskey</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fractals, what are they?]]></title>
        <id>http://scoskey.org/senior-thesis/fractals-what-are-they/</id>
        <link href="http://scoskey.org/senior-thesis/fractals-what-are-they/">
        </link>
        <updated>2019-05-01T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>A senior thesis by Nicole Reese, Spring 2019<!--more--></p>

<p><em>Abstract</em>: This presentation explores the concept of a fractal, the Hausdorff dimension of a fractal, and fractals generated by iterated function systems.</p>]]></summary>
        <author>
            <name>Samuel Coskey</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The connect-infinity game!]]></title>
        <id>http://jdh.hamkins.org/the-connect-infinity-game/</id>
        <link href="http://jdh.hamkins.org/the-connect-infinity-game/">
        </link>
        <updated>2019-04-30T09:15:41Z</updated>
        <summary type="html"><![CDATA[I saw the following image on Twitter and Reddit, an image suggesting an entire class of infinitary analogues of the game Connect-Four. What fun! Let&#8217;s figure it out! I&#8217;m not sure to whom the image or the idea is due. &#8230; <a href="http://jdh.hamkins.org/the-connect-infinity-game/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A model of second-order arithmetic satisfying ${\rm AC}$ but not ${\rm DC}$]]></title>
        <id>https://victoriagitman.github.io/talks/2019/04/26/a-model-of-second-order-arithmetic-satisfying-ac-but-not-dc.html</id>
        <link href="https://victoriagitman.github.io/talks/2019/04/26/a-model-of-second-order-arithmetic-satisfying-ac-but-not-dc.html">
        </link>
        <updated>2019-04-26T04:00:00Z</updated>
        <summary type="html"><![CDATA[<p>This is a talk at the <a href="https://jaf2019nyc.com/">Journées sur les Arithmétiques Faibles 2019</a> Conference, CUNY Graduate Center, May 28-30, 2019.<br><strong><a href="/files/JafACnotDC.pdf">Slides</a></strong><!--more--></p>
<p>
<strong>Abstract:</strong> Models of second-order arithmetic have two kinds of objects: numbers and sets of numbers, which we think of as the reals. A second-order arithmetic axiom system specifies general existence rules for real numbers. If a result from, say, analysis can be proved in some such system, then we have a bound on the kind of reals that must exist in order for it to hold. Indeed, most classical results in analysis don't just follows from, but are actually equivalent (over a weak base system) to one of a short list of main second-order arithmetic systems.
</p><p>
One of the strongest second-order arithmetic systems is <em>full second-order arithmetic</em> ${\rm Z}_2$ which asserts that every second-order formula (with any number of set quantifiers) defines a set. We can augment ${\rm Z}_2$ with choice principles such as the choice scheme and the dependent choice scheme. The $\Sigma^1_n$-<em>choice scheme</em> asserts for every $\Sigma^1_n$-formula $\varphi(n,X)$ that if for every $n$, there is a set $X$ witnessing $\varphi(n,X)$, then there is a single set $Z$ whose $n$-th slice $Z_n$ is a witness for $\varphi(n,X)$. The $\Sigma^1_n$-<em>dependent choice scheme</em> asserts that every $\Sigma^1_n$-relation $\varphi(X,Y)$ without terminal nodes has an infinite branch: there is a set $Z$ such that $\varphi(Z_n,Z_{n+1})$ holds for all $n$. The system ${\rm Z}_2$ proves the $\Sigma^1_2$-choice scheme and the $\Sigma^1_2$-dependent choice scheme. The independence of $\Pi^1_2$-choice scheme from ${\rm Z}_2$ follows by taking a model of ${\rm Z}_2$ whose sets are the reals of the Feferman-Levy model of ${\rm ZF}$ in which every $\aleph_n^L$ is countable and $\aleph_\omega^L$ is the first uncountable cardinal.
</p><p>
We construct a model of ${\rm ZF}+{\rm AC}_\omega$ whose reals give a model of ${\rm Z}_2$ together with the full choice scheme in which $\Pi^1_2$-dependent choice fails. This result was first proved by Kanovei in 1979 and published in Russian. It was rediscovered by Sy Friedman and myself with a slightly simplified proof.
</p>

<div class="figure">
<img src="/images/jaf2019.jpg" />

</div>]]></summary>
        <author>
            <name>Victoria Gitman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Borel morphisms between cardinal characteristics, parts 1 and 2]]></title>
        <id>http://scoskey.org/presentation/borel-morphisms-between-cardinal-characteristics/</id>
        <link href="http://scoskey.org/presentation/borel-morphisms-between-cardinal-characteristics/">
        </link>
        <updated>2019-04-26T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Boise Set Theory Seminar, April 2019<!--more--></p>

<p>Abstract: A cardinal characteristic is the cardinality of some special subset of the continuum. Vojtas introduced a categorical framework in which to study cardinal characteristics and their relationships. In this talk we introduce the objects and morphisms of this framework. We then consider a variation of this framework where the objects are morphisms are Borel definable.</p>]]></summary>
        <author>
            <name>Samuel Coskey</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Set theory in second-order]]></title>
        <id>https://victoriagitman.github.io/talks/2019/04/19/set-theory-in-second-order.html</id>
        <link href="https://victoriagitman.github.io/talks/2019/04/19/set-theory-in-second-order.html">
        </link>
        <updated>2019-04-19T04:00:00Z</updated>
        <summary type="html"><![CDATA[<p>This is a talk at the Set Theory in UK 2 meeting, University of Bristol, May 8, 2019.<!--more--></p>

<p><strong>Abstract</strong>: Classes, from class forcing notions to elementary embeddings of the universe to inner models, play a fundamental role in modern set theory. But within first-order set theory we are limited to studying only definable classes and we cannot even express properties that necessitate quantifying over classes. Second-order set theory is a formal framework in which a model consists both of a collection of sets and a collection of classes (which are themselves collections of sets). In second-order set theory, we can study classes such as truth predicates, which can never be definable over a model of ${\rm ZFC}$, and properties that, for instance, quantify over all inner models. With this formal background we can develop a theory of class forcing that explains why and when class forcing behaves differently from set forcing. In this talk, I will discuss a hierarchy of second-order set theories, starting from the weak Gödel-Bernays set theory ${\rm GBC}$ and going beyond the relatively strong Kelley-Morse theory ${\rm KM}$. I will give an overview of a number of interesting second-order set theoretic principles that arose out of recent work in this area, such as, class choice principles, transfinite recursion with classes, determinacy of games on the ordinals, and the class Fodor Principle. The study of where these principles fit in the hierarchy of second-order set theories should serve as the beginning of a reverse mathematics program that I hope this talk will encourage set theorists to take part in.
</p>]]></summary>
        <author>
            <name>Victoria Gitman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The modal logic of potentialism, ILLC Amsterdam, May 2019]]></title>
        <id>http://jdh.hamkins.org/modal-logic-of-potentialism-amsterdam-may-2019/</id>
        <link href="http://jdh.hamkins.org/modal-logic-of-potentialism-amsterdam-may-2019/">
        </link>
        <updated>2019-04-15T13:57:23Z</updated>
        <summary type="html"><![CDATA[This will be a talk at the Institute of Logic, Language and Computation (ILLC) at the University of Amsterdam for events May 11-12, 2019. See Joel David Hamkins in Amsterdam 2019. Abstract: Potentialism can be seen as a fundamentally model-theoretic &#8230; <a href="http://jdh.hamkins.org/modal-logic-of-potentialism-amsterdam-may-2019/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is there just one mathematical universe? DRIFT, Amsterdam, May 2019]]></title>
        <id>http://jdh.hamkins.org/is-there-just-one-mathematical-universe-amsterdam-may-2019/</id>
        <link href="http://jdh.hamkins.org/is-there-just-one-mathematical-universe-amsterdam-may-2019/">
        </link>
        <updated>2019-04-14T13:19:04Z</updated>
        <summary type="html"><![CDATA[This will be a talk for the Wijsgerig Festival DRIFT 2019, held in Amsterdam May 11, 2019. The theme of the conference is: Ontology. Abstract. What does it mean to make existence assertions in mathematics? Is there a mathematical universe, &#8230; <a href="http://jdh.hamkins.org/is-there-just-one-mathematical-universe-amsterdam-may-2019/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Philosophy of Mathematics, graduate lecture seminar, Oxford, Trinity term 2019]]></title>
        <id>http://jdh.hamkins.org/philosophy-of-mathematics-graduate-oxford-tt19/</id>
        <link href="http://jdh.hamkins.org/philosophy-of-mathematics-graduate-oxford-tt19/">
        </link>
        <updated>2019-04-11T14:05:30Z</updated>
        <summary type="html"><![CDATA[This will be a graduate-level lecture seminar on the Philosophy of Mathematics, run jointly by Professor Timothy Williamson and myself, held during Trinity term 2019 at Oxford University. We shall meet every Tuesday 2-4 pm during term in the Ryle &#8230; <a href="http://jdh.hamkins.org/philosophy-of-mathematics-graduate-oxford-tt19/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Set theories with classes]]></title>
        <id>https://victoriagitman.github.io/talks/2019/04/11/set-theories-with-classes.html</id>
        <link href="https://victoriagitman.github.io/talks/2019/04/11/set-theories-with-classes.html">
        </link>
        <updated>2019-04-11T04:00:00Z</updated>
        <summary type="html"><![CDATA[<p>This is a talk at the special set theory session, <a href="https://asl2019.commons.gc.cuny.edu/">Association for Symbolic Logic 2019 Annual North American Meeting</a>, CUNY Graduate Center, May 20-23, 2019.<br><strong><a href="/files/secondOrderSetTheoryCUNY.pdf">Slides</a></strong><!--more--></p>

<p><strong>Abstract</strong>: Second-order set theory is the set-theoretic cousin of the extensively studied field of second-order arithmetic. It is formalized in a two-sorted logic with separate objects for sets and classes. Second-order set theory removes the limitation imposed by ${\rm ZFC}$ of having to work only with definable collections, and allows us to formally consider interesting never definable classes such as truth predicates. With this formal background, we can study properties of class forcing and understand how and why it fails to share many of the nice properties of set forcing. In this talk, I will discuss the hierarchy of second-order set theories from Gödel-Bernays set theory ${\rm GBC}$ to beyond Kelley-Morse theory ${\rm KM}$. Along the way, I will establish some unexpected connections between models of second-order set theories and models of ${\rm ZFC}$ without the powerset axiom. I will also introduce an incipient program of reverse mathematics of second-order set theory which aims to place in the hierarchy various natural class set-theoretic principles such as the class forcing theorem, transfinite recursion with classes, and determinacy of games on the ordinals.</p>

<div class="figure">
<img src="/images/asl2019.jpeg" />
</div>]]></summary>
        <author>
            <name>Victoria Gitman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kelley-Morse set theory does not prove the class Fodor principle]]></title>
        <id>https://victoriagitman.github.io/publications/2019/04/11/kelley-morse-theory-does-not-prove-the-class-fodor-principle.html</id>
        <link href="https://victoriagitman.github.io/publications/2019/04/11/kelley-morse-theory-does-not-prove-the-class-fodor-principle.html">
        </link>
        <updated>2019-04-11T04:00:00Z</updated>
        <summary type="html"><![CDATA[<p><span id="GitmanHamkinsKaragila:KM-set-theory-does-not-prove-the-class-Fodor-theorem">V. Gitman, J. D. Hamkins, and A. Karagila, “Kelley-Morse set theory does not prove the class Fodor theorem,” <i>Submitted</i>. </span></p>

<p>The <em>class Fodor principle</em> is the assertion that every regressive class function $F:S\to{\rm Ord}$ defined on a stationary class $S$ is constant on a stationary subclass of $S$. This statement can be expressed in the usual second-order language of set theory, and the principle can therefore be sensibly considered in the context of any of the various second-order set-theoretic systems, such as Gödel-Bernays ${\rm GBC}$ set theory or Kelley-Morse ${\rm KM}$ set theory. Just as with the classical Fodor's lemma in first-order set theory, the class Fodor principle is equivalent, over a weak base theory, to the assertion that the class club filter is normal. We shall investigate the strength of the class Fodor principle and try to find its place within the natural hierarchy of second-order set theories. We shall also define and study weaker versions of the class Fodor principle.</p>

<p>If one tries to prove the class Fodor principle by adapting one of the classical proofs of the first-order Fodor's lemma, then one inevitably finds oneself needing to appeal to a certain second-order class-choice principle, which goes beyond the axiom of choice and the global choice principle, but which is not available in Kelley-Morse set theory <a href="#GitmanHamkins:KMplus">[1]</a>. For example, in one standard proof, we would want for a given ${\rm Ord}$-indexed sequence of non-stationary classes to be able to choose for each member of it a class club that it misses. This would be an instance of class-choice, since we seek to choose classes here, rather than sets. The class choice principle ${\rm CC}(\Pi^0_1)$, it turns out, is sufficient for us to make these choices, for this principle states that if every ordinal $\alpha$ admits a class $A$ witnessing a $\Pi^0_1$-assertion $\varphi(\alpha,A)$, allowing class parameters, then there is a single class $B\subseteq {\rm Ord}\times V$, whose slices $B_\alpha$ witness $\varphi(\alpha,B_\alpha)$; and the property of being a class club avoiding a given class is $\Pi^0_1$ expressible.</p>

<p>Thus, the class Fodor principle, and consequently also the normality of the class club filter, is provable in the relatively weak second-order set theory ${\rm GBC}+{\rm CC}(\Pi^0_1)$. This theory is known to be weaker in consistency strength than the theory ${\rm GBC}+\Pi^1_1$-comprehension, which is itself strictly weaker in consistency strength than ${\rm KM}$.</p>

<p>But meanwhile, although the class choice principle is weak in consistency strength, it is not actually provable in ${\rm KM}$; indeed, even the weak fragment ${\rm CC}(\Pi^0_1)$ is not provable in ${\rm KM}$. Those results were proved several years ago by the first two authors <a href="#GitmanHamkins:KMplus">[1]</a>, but they can now be seen as  consequences of the main result of this article. In light of that result, however, one should perhaps not have expected to be able to prove the class Fodor principle in ${\rm KM}$.</p>

<p>Indeed, it follows similarly from arguments of the third author in <a href="#karagila:Fodor">[2]</a> that if $\kappa$ is an inaccessible cardinal, then there is a forcing extension $V[G]$ with a symmetric submodel $M$ such that $V_\kappa^M=V_\kappa$, which implies that $\mathcal M=(V_\kappa,\in, V^M_{\kappa+1})$ is a model of Kelley-Morse, and in $\mathcal M$, the class Fodor principle fails in a very strong sense.</p>

<p>In this article, adapting the ideas of <a href="#karagila:Fodor">[2]</a> to the second-order set-theoretic context and using similar methods as in  <a href="#GitmanHamkins:KMplus">[1]</a>, we shall prove that every model of ${\rm KM}$ has an extension in which the class Fodor principle fails in that strong sense: there can be a class function $F:{\rm Ord}\to\omega$, which is not constant on any stationary class. In particular, in these models, the class club filter is not $\sigma$-closed: there is a class $B\subseteq\omega\times{\rm Ord}$, each of whose vertical slices $B_n$ contains a class club, but $\bigcap B_n$ is empty.
</p>

<p><strong>Main Theorem</strong>
Kelley-Morse set theory ${\rm KM}$, if consistent, does not prove the class Fodor principle. Indeed, if there is a model of ${\rm KM}$, then there is a model of ${\rm KM}$ with a class function $F:{\rm Ord}\to \omega$, which is not constant on any stationary class; in this model, therefore, the class club filter is not $\sigma$-closed.
</p>

<p>We shall also investigate various weak versions of the class Fodor principle.</p>

<p><strong>Definition</strong>:
<ol>
<li>
For a cardinal $\kappa$, the <em>class $\kappa$-Fodor principle</em> asserts that every class function $F:S\to\kappa$ defined on a stationary class $S\subseteq{\rm Ord}$ is constant on a stationary subclass of $S$.
</li>
<li>
The <em>class $<{\rm Ord}$-Fodor principle</em> is the assertion that the $\kappa$-class Fodor principle holds for every cardinal $\kappa$.
</li>
<li>
The <em>bounded class Fodor principle</em> asserts that every regressive class function $F:S\to{\rm Ord}$ on a stationary class $S\subseteq{\rm Ord}$ is bounded on a stationary subclass of $S$.
</li>
<li>
The <em>very weak class Fodor principle</em> asserts that every regressive class function $F:S\to{\rm Ord}$ on a stationary class $S\subseteq{\rm Ord}$ is constant on an unbounded subclass of $S$.
</li>
</ol>
</p>

<p>We shall separate these principles as follows.</p>

<p>
<strong>Theorem</strong>: Suppose ${\rm KM}$ is consistent.
<ol>
<li>
There is a model of ${\rm KM}$ in which the class Fodor principle fails, but the class $<{\rm Ord}$-Fodor principle holds.
</li>
<li>
There is a model of ${\rm KM}$ in which the class $\omega$-Fodor principle fails, but the bounded class Fodor principle holds.
</li>
<li>
There is a model of ${\rm KM}$ in which the class $\omega$-Fodor principle holds, but the bounded class Fodor principle fails.
</li>
<li>
${\rm GB}^-$ proves the very weak class Fodor principle.
</li>
</ol>
</p>

<p>Finally, we show that the class Fodor principle can neither be created nor destroyed by set forcing.</p>

<p><strong>Theorem</strong>:
 The class Fodor principle is invariant by set forcing over models of ${\rm GBC}^-$. That is, it holds in an extension if and only if it holds in the ground model.
</p>
<p>
Let us conclude the introduction by mentioning the following easy negative instance of the class Fodor principle for certain ${\rm GBC}$ models. This argument seems to be a part of set-theoretic folklore. Namely, consider an $\omega$-standard model of ${\rm GBC}$ set theory $M$ having no $V_\kappa^M$ that is a model of ${\rm ZFC}$. A minimal transitive model of ${\rm ZFC}$, for example, has this property. Inside $M$, let $F(\kappa)$ be the least $n$ such that $V_\kappa^M$ fails to satisfy $\Sigma_n$-collection. This is a definable class function $F:{\rm Ord}^M\to\omega$ in $M$, but it cannot be constant on any stationary class in $M$, because by the reflection theorem there is a class club of cardinals $\kappa$ such that $V_\kappa^M$ satisfies $\Sigma_n$-collection.</p>
<h2>References</h2>
<ol class="bibliography"><li><span id="GitmanHamkins:KMplus">V. Gitman and J. D. Hamkins, “Kelley-Morse set theory and choice principles for classes.” </span></li>
<li><span id="karagila:Fodor">A. Karagila, “Fodor’s lemma can fail everywhere,” <i>Acta Math. Hungar.</i>, vol. 154, no. 1, pp. 231–242, 2018. Available at: https://doi.org/10.1007/s10474-017-0768-5</span></li></ol>]]></summary>
        <author>
            <name>Victoria Gitman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kelley-Morse set theory does not prove the class Fodor principle]]></title>
        <id>http://jdh.hamkins.org/km-does-not-prove-class-fodor/</id>
        <link href="http://jdh.hamkins.org/km-does-not-prove-class-fodor/">
        </link>
        <updated>2019-04-09T01:28:31Z</updated>
        <summary type="html"><![CDATA[[bibtex key="GitmanHamkinsKaragila:KM-set-theory-does-not-prove-the-class-Fodor-theorem"] <a href="http://jdh.hamkins.org/km-does-not-prove-class-fodor/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Rodgers-Saxl type conjecture for characters]]></title>
        <id>https://nickpgill.github.io/a-rodgers-saxl-conjecture-for-characters</id>
        <link href="https://nickpgill.github.io/a-rodgers-saxl-conjecture-for-characters">
        </link>
        <updated>2019-04-05T00:00:00Z</updated>
        <summary type="html"><![CDATA[<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p>This is a follow-up to my <a href="https://nickpgill.github.io/a-rodgers-saxl-theorem">previous post on a generalization of a theorem of Rodgers and Saxl</a>.</p>

<p>The story starts with a beautiful talk I heard by Martin Liebeck in which he outlined a result due to him, Shalev &amp; Tiep:</p>

<p><strong>Theorem</strong>: Let $f$ be a faithful irreducible of $Sym(n)$. Then $f^{*4n}$ (i.e.tensor product $4n$ times) contains every irreducible as a constituent.</p>

<p>This theorem can be interpreted as giving an upper bound on the diameter of the <a href="https://en.wikipedia.org/wiki/McKay_graph">McKay graphs</a> of the symmetric group. I won’t pursue this point of view, but it was within this context that the LST-team were working when they proved the theorem. I’m just stating the symmetric group version of their result – they had more general statements for finite (almost) simple groups.</p>

<p>Notice that the LPT-bound is pretty much as good as one could hope for: if $f^{*c}$ is to contain every irreducible as a constituent (for some positive integer $c$), then one needs $(\dim(f))^c &gt; \sum \dim(f_i)$ where the sum on the right hand side ranges over all irreducibles of $Sym(n)$. Now the theory of Frobenius-Schur indicators tells us that, since all complex reps of $Sym(n)$ are defined over the reals, then $\sum \dim(f_i)$ is equal to 1+ the number of elements of order $2$. Writing $I_n$ for this latter quantity, <a href="https://projecteuclid.org/download/pdf_1/euclid.bams/1183553478">a result of Moser and Wyman</a> asserts that</p>

<script type="math/tex; mode=display">I_n \sim\frac{1}{\sqrt{2}} n^{n/2} \exp(-n/2-1/4+\sqrt{n}).</script>

<p>Now, using the fact that there exists an irreducible of dimension $n-1$, we obtain that</p>

<script type="math/tex; mode=display">c>= \log (\sum \dim(f_i))/ \log(\dim(f) = \log (I_n+1)/ \log (n-1),</script>

<p>and we conclude that $c$ must be at least linear in $n$.</p>

<p>A well-known heuristic in finite group theory says that whenever one proves statements about (ordinary) characters, there is probably a statement about conjugacy classes lurking nearby (and vice versa). This heuristic sounds very wooly, but it can be made rigorous in very many different contexts, and in very many different ways.</p>

<p>Sure enough, there is a “conjugacy class version” of the theorem above – it was proved by Liebeck and Shalev:</p>

<p><strong>Theorem</strong>: There exists a constant $d$ such that if $C$ is a conjugacy class of $G$, a finite non-abelian simple group and if
<script type="math/tex">k >= d \log|G|/ \log|C|,</script>
then $C^k = G$.</p>

<p>Here we are taking products of conjugacy classes instead of tensor products of characters. But, again, the result is of the same kind – it says that by taking a product $d$ times, then you will obtain all conjugacy classes, and $d$ is as small as one could possibly ask for, up to a multiplicative constant.</p>

<p>So, now, recall that in the previous post, I made the following conjecture:</p>

<p><strong>Conjecture</strong>: There exists a constant $c$ such that if $G$ is a finite simple group, and $S_1,\dots, S_k$ are  subsets of $G$ satisfying 
$\Pi_{i=1}^k|S_i|\geq|G|^c$, then there exist elements $g_1,\dots, g_k$ such that $G=(S_1)^{g_1}\cdots (S_k)^{g_k}$.</p>

<p>A special case of this conjecture occurs when our sets $S_1,\dots, S_k$ are conjugacy classes of $G$. In this case, we obtain the following statement:</p>

<p><strong>Conjecture</strong>: There exists a constant $c$ such that if $G$ is a finite simple group, and $C_1,\dots, C_k$ are conjugacy classes of $G$ satisfying 
$\Pi_{i=1}^k|S_i|\geq|G|^c$, then $G=C_1\cdot C_2\cdots C_k$.</p>

<p>I don’t know how to prove this theorem, but it’s possible that it’s not out of reach. The Rodgers–Saxl theorem that started all this off implies that the conjecture is true for the family $PSL(n,q)$ with the constant $c=12$. The theorem I proved with Pyber and Szabo implies it for groups of Lie type of bounded rank, so one is left with (some of) the classicals of unbounded rank, and the alternating groups.</p>

<p>But back to chacters. What would be the character–theoretic version of the previous two conjectures? The first has, if I recall correctly, been stated by the LST-team:</p>

<p><strong>Conjecture</strong> There exists $C&gt;0$ such that if $\chi$ is a non-trivial character of a finite simple group $G$ and if
<script type="math/tex">c>C \log(\textrm{sum of dimensions of all irreducibles of }G)/ \log(\textrm{dimension of }\chi),</script> 
then $\chi^{*c}$ contains every irreducible of $G$ as a constituent.</p>

<p>The Rodgers-Saxl analogue of this would be:</p>

<p><strong>Conjecture</strong> There exists $C&gt;0$ such that if $\chi_1,…, \chi_t$ are non-trivial characters of a finite simple group $G$ and if</p>

<script type="math/tex; mode=display">\dim(\chi_1)*\dim(\chi_2)*...*\dim(\chi_t) > (\textrm{sum of dimensions of all irreducibles of }G)^C</script>

<p>then $\chi_{1}*\cdots *\chi_{t}$ contains every irreducible of $G$ as a constituent.</p>

<p>Let’s think about whether proving something like this might be possible just for the special case of $G=Sym(n)$ (OK, it’s not simple, but almost).</p>

<p>First let me note that LST prove their result by showing that if $f$ is a faithful character of $Sym(n)$, then $f * f$ or $f *f *f *f$ always contains $\chi_{1,n-1}$, from which the result follows (one just calculates how many tensor products of $\chi_{1,n-1}$ one needs to obtain all irreducibles as constituents).</p>

<p>My go-to man for symmetric group rep theory is Mark Wildon. I dropped him an email with the following question.</p>

<p><strong>Question</strong>: Does there exist a positive integer $N$ such that if $k&gt; N$ and $f_1, …, f_k$ are irreducible characters of Sym(n), then the tensor product of $f_1,…, f_k$ (in that order) contains an irreducible constituent isomorphic to $\chi_{1,n-1}$?</p>

<p>Mark was immediately able to shed light. This question can be answered affirmatively. Indeed the following argument (which is Mark’s) shows that something much stronger is true:</p>

<p>Let $k$ be a field and let $G$ be a finite group. On page 45 of Alperin, <em>Local Representation Theory</em>, it’s shown that if $V$ is a faithful $k$G-module then there exists $N$ such that the $N$-fold tensor product $V \otimes … \otimes V$ contains a free submodule. Since $V \otimes F \cong F \oplus … \oplus F$ (with $\dim(V)$ summands) for any free $kG$-module $F$, it follows that any product with more factors (which may be arbitrary kG-modules) also contains a free submodule.</p>

<p>In the language of characters: if $\chi$ is the character of $V$, and $\psi$ is any other character, then any character $\chi^N \times \psi$ contains the regular character.</p>

<p><strong>Corollary</strong>: there exists $M$ such that any product of any $M$ faithful irreducible characters of $Sym(n)$ contains the regular character as a constituent.</p>

<p><strong>Proof</strong>: let $P$ be the number of faithful irreducible characters of $Sym(n)$. (So $P$ is 2 less than the number of partitions of $n$, unless $n = 4$.) For each faithful character, let $N(\chi)$ be the $N$ given by Alperin’s result, and let $N = \max_\chi N(\chi)$. Take $M = NP$. Then in any product of $M$ faithful characters, some character appears at least $N$ times, and so the product contains the regular character. QED</p>

<p>That’s a brilliant start, but it doesn’t give us any information about what $M$ can be. The same argument as I gave at the top of this post implies that $M$ must be bounded below by some linear function in $n$: so, then, it it possible that one can choose $M$ to be linear in $n$?</p>

<p>Here’s what Mark had to say on the subject:</p>

<blockquote>
  <p><em>Some experiments in MAGMA suggest rather intriguingly that one can take 
$M = n - 1$ for $Sym(n)$. This bound is sharp for $n = 3,\dots, 10$.</em></p>
</blockquote>

<p>Is this enough evidence to make a conjecture? Hell, yeah!</p>

<p><strong>Conjecture</strong>: Suppose that $f_1,\dots, f_{n-1}$ are faithful irreducible characters of $Sym(n)$. Then $f_1* \cdots* f_{n-1}$  contains the regular character as a constituent.</p>

<p>I think of this as a “Rodgers-Saxl type conjecture for characters”. Now, the challenge is to turn it into a theorem….</p>]]></summary>
        <author>
            <name>Nick Gill</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Rodgers-Saxl type theorem]]></title>
        <id>https://nickpgill.github.io/a-rodgers-saxl-theorem</id>
        <link href="https://nickpgill.github.io/a-rodgers-saxl-theorem">
        </link>
        <updated>2019-03-29T00:00:00Z</updated>
        <summary type="html"><![CDATA[<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p>Pyber, Szabó and I have recently completed a paper entitled <em>A generalization of a theorem of Rodgers and Saxl for simple groups of bounded rank</em>. A copy of the paper can be found <a href="https://arxiv.org/abs/1901.09255">on the arXiv</a>.</p>

<p>Our result was inspired by a result of Rodgers and Saxl which appeared in <em>Communications of Algebra</em> in 2003:</p>

<p><strong>Theorem</strong>: Suppose that $C_1,\dots, C_k$ are conjugacy classes in $SL_n(q)$ such that 
$\Pi_{i=1}^k|C_i|\geq|SL_n(q)|^{12}$. Then 
$\Pi_{i=1}^kC_i=SL_n(q)$.</p>

<p>Our result has a similar flavour.</p>

<p><strong>Theorem</strong>: Let $G=G_r(q)$ be a finite simple group of Lie type of rank $r$. There exists $c=f(r)$ such that if $S_1,\dots, S_k$ are subsets of $G$ satisfying 
$\Pi_{i=1}^k|S_i|\geq|G|^c$, then there exist elements $g_1,\dots, g_k$ such that $G=(S_1)^{g_1}\cdots (S_k)^{g_k}$.</p>

<p>Our theorem differs to that of Rodgers and Saxl in three important respects, two good, one not so good: First, our result pertains to all finite simple groups $G$ of Lie type. Second, our result does not just pertain to conjugacy classes, but to subsets of the group, provided we are free to take conjugates.</p>

<p>The third difference is a weak point: our result replaces the constant ``12’’  in their thereom with an unspecified constant that depends on the rank of the group $G$. We conjecture that we should be able to do better, and not just for finite simple groups of Lie type, but for alternating groups as well:</p>

<p><strong>Conjecture</strong>: Let $G$ be a finite simple group. There exists $c$ such that if $S_1,\dots, S_k$ are  subsets of $G$ satisfying 
$\Pi_{i=1}^k|S_i|\geq|G|^c$, then there exist elements $g_1,\dots, g_k$ such that $G=(S_1)^{g_1}\cdots (S_k)^{g_k}$.</p>

<p>This conjecture seems hard! Our theorem has a rank-dependency because it makes use of the “Product Theorem” which was proved, independently by Pyber-Szabó and by Breuillard-Green-Tao. To prove the conjecture we would need to replace the Product Theorem in our argument with, um, something else… But what?!</p>

<p>One last remark: there is a fourth sense in which our theorem differs to that of Rodgers and Saxl – we are interested in finite simple groups, while they consider $SL_n(q)$ which is, in general, only quasi-simple.</p>

<p>It turns out that the distinction here is not significant: It is not hard to show that our theorem is true if and only if the analogous statement is true for quasi-simple groups (provided you require that the sets $S_i$ do not intersect the centre of $G$)… And the same is true of the conjecture stated above. So the stated conjecture would be a generalization of both our result and that of Rodgers and Saxl, albeit we don’t specify the value of $c$ as Rodgers and Saxl did.</p>

<p>Let me finish this post by thanking my two co-authors, Laci and Bandi. I have worked with these two guys on a previous paper, and they are both brilliant and generous with their many ideas. I hope to have the privilege of working with them more in the future.</p>]]></summary>
        <author>
            <name>Nick Gill</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kelley-Morse set theory does not prove the class Fodor Principle, CUNY Set Theory Seminar, March, 2019]]></title>
        <id>http://jdh.hamkins.org/kelley-morse-set-theory-does-not-prove-the-class-fodor-principle-cuny-set-theory-seminar-march-2019/</id>
        <link href="http://jdh.hamkins.org/kelley-morse-set-theory-does-not-prove-the-class-fodor-principle-cuny-set-theory-seminar-march-2019/">
        </link>
        <updated>2019-03-20T23:29:18Z</updated>
        <summary type="html"><![CDATA[This will be talk for the CUNY Set Theory seminar, Friday, March 22, 2019, 10 am in room 6417 at the CUNY Graduate Center. Abstract. I shall discuss recent joint work with Victoria Gitman and Asaf Karagila, in which we &#8230; <a href="http://jdh.hamkins.org/kelley-morse-set-theory-does-not-prove-the-class-fodor-principle-cuny-set-theory-seminar-march-2019/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On splitting and splittable families]]></title>
        <id>http://scoskey.org/splitsplit</id>
        <link href="http://scoskey.org/splitsplit">
        </link>
        <updated>2019-03-07T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>With Bryce Frederickson, Samuel Mathers, and Hao-Tong Yan.<!--more--></p>

<p><em>Abstract</em>: A set $A$ is said to <em>split</em> a finite set $B$ if exactly half the elements of $B$ (up to rounding) are contained in $A$. We study the dual notions: (1) a <em>splitting family</em>, a collection of sets such that any subset of ${1,\ldots,k}$ is split by a set in the family, and (2) a <em>splittable family</em>, a collection of sets such that there is a single set $A$ that splits each set in the family.</p>

<p>We study the minimum size of a splitting family on ${1,\ldots,k}$, as well as the structure of splitting families of minimum size. We use a mixture of computational and theoretical techniques. We additionally study the related notions of $\mathord{\leq}4$-splitting families and $4$-splitting families, and we provide lower bounds on the minimum size of such families.</p>

<p>Next we investigate splittable families that are just on the edge of unsplittability in several senses. First, we study splittable families that have the fewest number of splitters. We give a complete characterization in the case of two sets, and computational results in the case of three sets. Second, we define the <em>splitting game</em>, and study splittable families for which a splitter cannot be found under adversarial conditions.</p>]]></summary>
        <author>
            <name>Samuel Coskey</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[In praise of Replacement]]></title>
        <id>http://karagila.org/2019/in-praise-of-replacement/</id>
        <link href="http://karagila.org/2019/in-praise-of-replacement/">
        </link>
        <updated>2019-03-06T22:20:42Z</updated>
        <summary type="html"><![CDATA[<p>I have often seen people complain about Replacement axioms. For example, <a href="https://mathoverflow.net/q/208711/7206">this MathOverflow question</a>, or <a href="https://mathoverflow.net/q/121406/7206">this one</a>, or <a href="https://mathoverflow.net/q/228168/7206">that one</a>, and also <a href="https://mathoverflow.net/q/219040/7206">this one</a>. This technical-looking schema of axioms state that if \(\varphi\) defines a function on a set \(x\), then the image of \(x\) under that function is a set. And this axiom schema is a powerhouse! It is one of the three component that give \(\ZF\) its power (the others being power set and infinity, of course). </p>

<p>You'd think that people in category theory would like it, from a foundational point of view, it literally tells you that functions exists if you can define them! And category theory is all about the functions (yes, I know it's not, but I'm trying to make a point). <a href="http://karagila.org/2019/in-praise-of-replacement/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introduction to continuous logic and model theory for metric structures]]></title>
        <id>http://scoskey.org/presentation/introduction-to-continuous-logic-and-model-theory-for-metric-structures/</id>
        <link href="http://scoskey.org/presentation/introduction-to-continuous-logic-and-model-theory-for-metric-structures/">
        </link>
        <updated>2019-03-01T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Boise Set Theory Seminar, March 2019<!--more--></p>]]></summary>
        <author>
            <name>Samuel Coskey</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Must there be numbers we cannot describe or define? Definability in mathematics and the Math Tea argument, Norwich, February 2019]]></title>
        <id>http://jdh.hamkins.org/must-there-be-number-we-cannot-define-norwich-february-2019/</id>
        <link href="http://jdh.hamkins.org/must-there-be-number-we-cannot-define-norwich-february-2019/">
        </link>
        <updated>2019-02-19T12:54:35Z</updated>
        <summary type="html"><![CDATA[I shall speak for the Pure Mathematics Research Seminar at the University of East Anglia in Norwich on Monday, 25 February, 2019. Abstract. An old argument, heard perhaps at a good math tea, proceeds: “there must be some real numbers &#8230; <a href="http://jdh.hamkins.org/must-there-be-number-we-cannot-define-norwich-february-2019/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Partitioning a reflecting stationary set]]></title>
        <id>http://blog.assafrinot.com/?p=4559</id>
        <link href="http://blog.assafrinot.com/?p=4559">
        </link>
        <updated>2019-02-15T06:58:14Z</updated>
        <summary type="html"><![CDATA[<div class="thanks_button_div" 
                  style="margin-bottom: 30px;"><div id="thanksButtonDiv_4559_2" style="background-image:url(http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/thanks_compact_brown1.png); background-repeat:no-repeat; float: left; display: inline;"
                onmouseover="javascript:thankYouChangeButtonImage('thanksButtonDiv_4559_2', true);" 
                onmouseout="javascript:thankYouChangeButtonImage('thanksButtonDiv_4559_2', false);"
                onclick="javascript:thankYouChangeButtonImage('thanksButtonDiv_4559_2', false);" >
                <input type="button" onclick="thankYouButtonClick(4559, 'You left &ldquo;Thanks&rdquo; already for this post')" value="Like 23"
                  class="thanks_button thanks_compact thanks_brown"
                  style="  font-family: Verdana, Arial, Sans-Serif; font-size: 14px; font-weight: normal;; color:#ffffff;"
                  id="thanksButton_4559_2" title="Click to leave &ldquo;Thanks&rdquo; for this post"/>
             </div><div id="ajax_loader_4559_2" style="display:inline;visibility: hidden;"><img alt="ajax loader" src="http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/ajax-loader.gif" /></div></div><p>Joint work with <a href="http://www.logic.univie.ac.at/~levinem85/">Maxwell Levine</a>.</p>
<p><strong>Abstract.</strong> We address the question of whether a reflecting stationary set may be partitioned into two or more reflecting stationary subsets, providing various affirmative answers in ZFC. As an application to singular cardinals combinatorics, we infer that it is never the case that there exists a singular cardinal all of whose scales are very good.</p>
<p><span id="more-4559"></span></p>
<p><strong>Downloads:</strong></p>
<p><table class=paperruler"><tr><td><a onclick="thankYouButtonClick(4559, '')"  href="http://www.assafrinot.com/files/paper38.pdf" class="billet_author"></a><a onclick="thankYouButtonClick(4559, '')" href="http://arxiv.org/abs/1907.08581" class="billet_arxiv"></a><img src="/design/003_publish_dis.png"   class="opacity_icons"  height=90 width=64 border=1  alt="[No published version]" title="Published version not available"  /><img src="/design/004_review_dis.png"  class="opacity_icons" height=90 width=64 border=1  alt="[No entry on mathscinet]" title="No entry on mathscinet"  /><a onclick="thankYouButtonClick(4559, '')" href="http://www.assafrinot.com/talk/arctic2019" class="billet_slides"></a><a href="http://www.assafrinot.com/paper/29" class="billet_further"></a><a href="http://papers.assafrinot.com/list.php?bib=rinot.bib&key=paper38" class="billet_bibtex"></a><a href="http://www.assafrinot.com/paper/38" class="billet_perm"></a></td></tr></table></p>
<p><!--more--></p>]]></summary>
        <author>
            <name>Assaf Rinot</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[4th Arctic Set Theory Workshop, January 2019]]></title>
        <id>http://blog.assafrinot.com/?p=4556</id>
        <link href="http://blog.assafrinot.com/?p=4556">
        </link>
        <updated>2019-02-15T06:50:35Z</updated>
        <summary type="html"><![CDATA[<div class="thanks_button_div" 
                  style="margin-bottom: 30px;"><div id="thanksButtonDiv_4556_2" style="background-image:url(http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/thanks_compact_brown1.png); background-repeat:no-repeat; float: left; display: inline;"
                onmouseover="javascript:thankYouChangeButtonImage('thanksButtonDiv_4556_2', true);" 
                onmouseout="javascript:thankYouChangeButtonImage('thanksButtonDiv_4556_2', false);"
                onclick="javascript:thankYouChangeButtonImage('thanksButtonDiv_4556_2', false);" >
                <input type="button" onclick="thankYouButtonClick(4556, 'You left &ldquo;Thanks&rdquo; already for this post')" value="Like 2"
                  class="thanks_button thanks_compact thanks_brown"
                  style="  font-family: Verdana, Arial, Sans-Serif; font-size: 14px; font-weight: normal;; color:#ffffff;"
                  id="thanksButton_4556_2" title="Click to leave &ldquo;Thanks&rdquo; for this post"/>
             </div><div id="ajax_loader_4556_2" style="display:inline;visibility: hidden;"><img alt="ajax loader" src="http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/ajax-loader.gif" /></div></div><p>I gave an invited talk at the <a href="http://www.math.helsinki.fi/logic/arctic/2019/">Arctic Set Theory Workshop 4</a> in Kilpisjärvi, January 2019.</p>
<p><strong>Talk Title: </strong>Splitting a stationary set: Is there another way?</p>
<p><strong>Abstract:</strong> Motivated by a problem in <em>pcf</em> theory, we seek for a new way to partition stationary sets.</p>
<p>This is joint work with <a href="http://blog.assafrinot.com/?persons=maxwell-levine">Maxwell Levine</a>.</p>
<p><strong>Downloads:</strong></p>
<p><p><table class=paperruler"><tr><td><a onclick="thankYouButtonClick(4556, '')" href="http://www.assafrinot.com/files/rinot_arctic2019.pdf" class="billet_slides"></a><a href="http://www.assafrinot.com/paper/38" class="billet_further"></a><a href="http://www.assafrinot.com/talk/arctic2019" class="billet_perm"></a></td></tr></table></p><span id="more-4556"></span></p>]]></summary>
        <author>
            <name>Assaf Rinot</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Core Model Induction and Other Inner Model Theoretic Tools Rutgers - Tutorial: HOD Computations]]></title>
        <id>https://muellersandra.github.io/upcomingtalk/talk/invconftalk/2019/02/09/TalkCMIworkshop.html</id>
        <link href="https://muellersandra.github.io/upcomingtalk/talk/invconftalk/2019/02/09/TalkCMIworkshop.html">
        </link>
        <updated>2019-02-08T23:00:00Z</updated>
        <summary type="html"><![CDATA[<p>As a part of the workshop on “The Core Model Induction and Other Inner
Model Theoretic Tools” in Rutgers I gave a tutorial on HOD
Computations.</p>

<p><em>Abstract:</em> An essential question regarding the theory of inner models is the
analysis of the class of all hereditarily ordinal definable sets HOD
inside various inner models $M$ of the set theoretic universe $V$
under appropriate determinacy hypotheses. Examples for such inner
models $M$ are $L(\mathbb{R})$ or $L[x]$ on a cone of reals $x$. We
will outline Steel’s and Woodin’s analysis of
$HOD^{L(\mathbb{R})}$. Moreover, we will discuss their analysis of
$HOD^{L[x,G]}$ on a cone of reals $x$, where $G$ is
$Col(\omega,\kappa)$-generic and $\kappa$ is the least inaccessible
cardinal in $L[x]$. We will point out were the problems are when
trying to adapt this to analyze $HOD^{L[x]}$.</p>

<p><em>Reading List:</em></p>
<ul>
  <li>(Steel) An outline of inner model theory, Handbook of Set
  Theory, Section 8.</li>  
  <li>(Steel, Woodin) HOD as a core model, Cabal III.</li>
</ul>

<p><em>Necessary requirements:</em></p>

<p>A good understanding of mice, the comparison process and genericity
iterations, e.g. the fine structure tutorial given in the first week
or the relevant parts of Steel’s handbook chapter (Sections 1-3 and
7).</p>

<p>See <a href="/conferences/CMI2019">here</a> for more information about
the meeting and <a href="http://www.logic.univie.ac.at/~smueller/CMI2019/HODComputationNotes.pdf">here</a>
for lecture notes typed by James Holland.</p>]]></summary>
        <author>
            <name>Sandra Müller</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Logic Fest in the Windy City - The interplay between inner model theory and descriptive set theory in a nutshell]]></title>
        <id>https://muellersandra.github.io/upcomingtalk/talk/invconftalk/2019/02/08/TalkChicago.html</id>
        <link href="https://muellersandra.github.io/upcomingtalk/talk/invconftalk/2019/02/08/TalkChicago.html">
        </link>
        <updated>2019-02-07T23:00:00Z</updated>
        <summary type="html"><![CDATA[<p>On June 01, 2019 I was invited to give a talk at the <a href="https://homepages.math.uic.edu/~sinapova/Logic%20fest%202019.html">Logic
Fest in the Windy City</a> in Chicago, USA.</p>

<p><em>The interplay between inner model theory and descriptive set theory
 in a nutshell</em></p>

<p><em>Abstract:</em> The study of inner models was initiated by G"odel’s
 analysis of the constructible universe $L$. Later, it became
 necessary to study canonical inner models with large cardinals,
 e.g. measurable cardinals, strong cardinals or Woodin cardinals,
 which were introduced by Jensen, Mitchell, Steel, and others. Around
 the same time, the study of infinite two-player games was driven
 forward by Martin’s proof of analytic determinacy from a measurable
 cardinal, Borel determinacy from ZFC, and Martin and Steel’s proof of
 levels of projective determinacy from Woodin cardinals with a
 measurable cardinal on top. First Woodin and later Neeman improved
 the result in the projective hierarchy by showing that in fact the
 existence of a countable iterable model, a mouse, with Woodin
 cardinals and a top measure suffices to prove determinacy in the
 projective hierarchy.</p>

<p>This opened up the possibility for an optimal result stating the
equivalence between local determinacy hypotheses and the existence of
mice in the projective hierarchy, just like the equivalence of
analytic determinacy and the existence of $x^\sharp$ for every real
$x$ which was shown by Martin and Harrington in the 70’s. The
existence of mice with Woodin cardinals and a top measure from levels
of projective determinacy was shown by Woodin in the 90’s. Together
with his earlier and Neeman’s results this estabilishes a tight
connection between descriptive set theory in the projective hierarchy
and inner model theory.</p>

<p>In this talk, we will outline the main concepts and results connecting
determinacy hypotheses with the existence of mice with large
cardinals. Neeman’s methods mentioned above extend to show determinacy
of projective games of arbitrary countable length from the existence
of inner models with many Woodin cardinals. We will discuss a number
of more recent results, some of which are joint work with Juan
Aguilera, showing that inner models with many Woodin cardinals can be
obtained from the determinacy of countable projective games.</p>

<p><a href="http://www.logic.univie.ac.at/~smueller/Slides/2019Chicago/MuellerChicago.pdf">Slides.</a></p>]]></summary>
        <author>
            <name>Sandra Müller</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Potentialism and implicit actualism in the foundations of mathematics, Jowett Society lecture, Oxford, February 2019]]></title>
        <id>http://jdh.hamkins.org/potentialism-and-implicit-actualism-in-the-foundations-of-mathematics-jowett-society-oxford-february-2019/</id>
        <link href="http://jdh.hamkins.org/potentialism-and-implicit-actualism-in-the-foundations-of-mathematics-jowett-society-oxford-february-2019/">
        </link>
        <updated>2019-01-26T14:34:53Z</updated>
        <summary type="html"><![CDATA[This will be a talk for the Jowett Society on 8 February, 2019. The talk will take place in the Oxford Faculty of Philosophy, 3:30 &#8211; 5:30pm, in the Lecture Room of the Radcliffe Humanities building. Abstract. Potentialism is the view, &#8230; <a href="http://jdh.hamkins.org/potentialism-and-implicit-actualism-in-the-foundations-of-mathematics-jowett-society-oxford-february-2019/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Joel David Hamkins</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards a general method for accessible content trees or: deep aria-labels for equations revisited]]></title>
        <id>https://www.peterkrautzberger.org/0209/</id>
        <link href="https://www.peterkrautzberger.org/0209/">
        </link>
        <updated>2019-01-13T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Oh dear, that title is a mouth full. A while ago I wrote about <a href="https://www.peterkrautzberger.org/0208/">two interesting results from the AIM workshop</a> and I had promised to dive deeper. Well, take a deep breath.</p>
<h2>A simple example</h2>
<p>Here's a story. I think it was at the first web standard related event that I ever attended, the <a href="https://www.w3.org/2012/08/electronic-books/">W3C workshop on ebooks</a> back in 2012. Someone (maybe Janina?) presented an example of an accessible SVG and I was blown away. My memory, flawed as it is, says it was the <a href="https://commons.wikimedia.org/wiki/File:Ghostscript_Tiger.svg">classic SVG tiger</a> but it was set up in a way that demonstrated amazing exploration features, providing non-visual representations that could dive into the entirety of the graphic, starting with high-level descriptions (something like <em>a tiger's head</em>) all the way down to detailed nuances (<em>left whisker, 3 of 12</em>).</p>
<p>I'm prone ot get the specifics wrong so here's a different example:</p>
<figure>
<a href="https://commons.wikimedia.org/wiki/File:House.svg#/media/File:House.svg"><img src="https://upload.wikimedia.org/wikipedia/commons/2/24/House.svg" alt="clip art house" width="389" height="391"></a>
<figcaption>
By <a rel="nofollow" class="external text" href="http://openclipart.org/media/people/barretr">barretr</a> (Open Clip Art Library) - <a rel="nofollow" class="external free" href="http://openclipart.org/media/files/barretr/2941">http://openclipart.org/media/files/barretr/2941</a>, <a href="http://creativecommons.org/publicdomain/zero/1.0/deed.en" title="Creative Commons Zero, Public Domain Dedication">CC0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=3454675">Link</a><p></p>
</figcaption>
</figure>
<p>So this is a house. How would you describe it? Maybe: <em>A house with a red chimney and a blue door</em>? That's not bad but there's more so much more to be said about this house!</p>
<ul>
<li>It's a drawing of the front of a house (no other part is visible)</li>
<li>it has a dark gray, mono-pitched roof with a red chimney on the left</li>
<li>it has a blue door with a round, dark-gray doorknob on the left</li>
<li>it has a yellow front wall</li>
<li>the chimney aligns with the wall</li>
<li>some parts are drawn with gradient effects</li>
<li>...</li>
</ul>
<p>These descriptions could of course all be put into one very long textual representation, e.g., as a <code>&lt;title&gt;</code> or an <code>aria-labeledby</code> construction. And that would be ok. But I find it rather limited.</p>
<p>This is not how a human would describe things. Imagine I'd ask you to describe it. You would not start with the gradient of the doorknob on the first go. I bet you are much more inclined to provide some information at first and get into more detail if whoever is asking wants to dive deeper.</p>
<p>Sometimes, we are in the position to have more information like this on the web, too.</p>
<p>Imagine, this house was created in an authoring environment that specializes on such drawings; it may have been drag&amp;dropped using pre-fabricated components, each having detailed descriptions, integrating user changes such as shape or color modifications, and being able to generate composited descriptions, perhaps combining them using simple rule sets (maybe even author customizable rule sets).</p>
<p>The other thing you may notice is that the house is more than the sum of its parts, i.e., a description for the house (and parts thereof) may not sufficiently be represented by stringing the descriptions of the leafs together; for example, where would the <em>with</em> in <em>a roof with a chimney</em> come from? For that matter, where would <em>house</em> come from? Depending on the content and context, there may be additional connecting words or phrases, there may be details to drop or reveal. Maybe the fabric of the roof or the whether the door is locked can be deduced from visual styling given other context.</p>
<p>If you are lucky and you have more information, then you may find yourself in a situation where you want to add differing textual representations on every level of the tree, just like you would in a real conversation, and you may want a way for users to have access to all those varying levels of representation - but not all at once as that could be overwhelming.</p>
<p>The most important point: like all good web standards topics, this is about a general, low-level problem. (Although solving a more general problem might appeal to mathematicians, too.)</p>
<h2>Deep aria labels on tree structures (or: it's not <em>just</em> about equations)</h2>
<p>So let's try to outline what this is about. Imagine you have</p>
<ul>
<li>a complex DOM structure (e.g., an inline SVG, a complex grid structure, an equation layout thingie)</li>
<li>which is not represented well by its leafs alone (e.g., there might be abstract components, abbreviated content, inferred meaning)</li>
<li>that might have a semantic tree structure that does not match the DOM tree.</li>
</ul>
<p>Now imagine that you have</p>
<ul>
<li>appropriate textual representations for each node (e.g., aria-labels on all nodes)</li>
<li>yet those textual representations may have notable differences between non-leafs and their descendants, i.e., a node may be more than the sum of its descendants (or less or both/neither).</li>
<li>and you have proper aria-owns attributes all over the tree to represent the correct semantics</li>
</ul>
<h3>What to want</h3>
<p>Let's start with some fairly standard observations on accessible rendering:</p>
<p><strong>Unified rendering</strong> visual and non-visual rendering should not be apart. Textual representation should be intentional, reflect the intention of the author. (This does not contradict that both graphical and textual representation will likely be created with tools, even tools leveraging heuristics.)</p>
<p><strong>Progressive enhancement / graceful degradation</strong> a solution should work in a way that allows to progressively enhance content. For example, a top-level textual description (e.g., using <code>aria-label</code>) is a robust fallback. You may lose some convenience if that's all there is - and even some information - but it certainly isn't terrible.</p>
<p><strong>Performance</strong> a solution must be performant, especially if you apply it to hundreds or thousands of content fragments.</p>
<p>From an author's point of view, the key affordance is <strong>precision/control</strong>. This is worth repeating: Accessibility inevitably starts with author control. If authors cannot create content in a way that they can trust to render reliably, i.e., with the precision they put into their content, then they will not care to do so.</p>
<p>If there's no control, the platform is failing the authors. If it's failing the authors to create accessible content, then it's failing the user because they will not receive accessible content.</p>
<p>This primarily means that content should be authorable in a way that does not require <em>any</em> heuristics on the side of rendering (visually or non-visually). Imagine AT would have to guess how many items are in a list. Or AT would have to throw computer vision at each image to guess a description. That's ok for broken content but not acceptable for good content.</p>
<p>There are other useful things of course - ease of authoring comes to mind. But without a solution with tangible benefits, building authoring tools or practices is never going to happen.</p>
<p>From a screenreader user's point of view, there are more affordances that you probably don't want to ignore.</p>
<ul>
<li>support for reading/browse modes</li>
<li>support for full exploration (in focus mode)</li>
<li>seamlessly switch between exploration and reading/browse</li>
<li>synchronization of all rendering streams
<ul>
<li>visual (highlighting), aural and tactile rendering</li>
<li>enable customized Braille stream if specialized Braille formats exists</li>
</ul>
</li>
</ul>
<p>There are many more considerations beyond this but this would be a good start.</p>
<h3>Towards a solution: mathjax-sre-walker</h3>
<p><em>Note</em>: this is not a complete solution to all of the above. But I feel like it's heading in the right direction.</p>
<p>The codebase for this lighweight walker dubbed mathjax-sre-walker is on GitHub and for this first public summary we've tagged <a href="https://github.com/krautzource/mathjax-sre-walker/releases/tag/2.0.0">v2.0.0</a>. As I mentioned in <a href="https://www.peterkrautzberger.org/0208">208</a>, this work with <a href="https://www.peterkrautzberger.org/0209/www.progressiveaccess.com/">Volker Sorge</a> grew out of a demo that David Tseng, Volker Sorge and Davide Cervone built at the AIM workshop in San Jose last year. A simplified demo in a codepen is embedded below alongside a recording of a quick demonstration.</p>
<h3>what users get</h3>
<p>For the visual user, it will provide a means of visually exploring the underlying (and often hard to discern) tree structure by putting the tree in focus and using the arrow keys.</p>
<p>For the non-visual user, it will additionally provide textual representations for each tree node, in sync with the visual representation. It doesn't but could (should we get separate <a href="https://github.com/w3c/aria/issues/765">Braille streams in ARIA</a>) additionally provide a simultaneous rendering in specialized formats such as Nemeth or UEB, chemical Braille or others.</p>
<p>For the screenreader user, it will provide the top-level tree node in browse mode. When the tree's top-level DOM node is voiced, the screenreader should put in focus, triggering visual highlighting; the screenreader should also indicate the tree role to imply further functionality is available.</p>
<p>The user can switch to the screenreader's focus mode to use keyboard exploration with the arrow keys which is matched visually by the highlighting. When the user switches back to browse mode, they can continue naturally browsing to the next piece of content.</p>
<h3>how users get it</h3>
<p>The first, not too relevant part: the DOM tree has lots of information in <code>data-</code> attributes and in a first step we enrich the content with a secondary structure. Getting such information is of course not easy (luckily we can already automate that for equations thanks to speech-rule-engine) and this step can be done server-side. Ultimately that's not the hardest part - domain experts can build such tools - we're using Volker's <a href="https://github.com/zorkow/speech-rule-engine/">speech-rule-engine</a> for the equations (which is a marvel).</p>
<p>Yet all the extra information won't help if we can't make use of it on the web platform.</p>
<p>So how is this realized in the DOM tree? As a bunch of <code>aria-label</code>s (to add textual representations) and <code>aria-owns</code> to carve out the tree structure that might differ from the DOM tree; we also add a <code>role</code> to most nodes. In particular, we immediately get a top-level <code>aria-label</code> which serves as a fallback.</p>
<p>Now what we're missing is some kind of AT functionality that would give us an <code>aria-owns</code> tree walker. We have built-in table walkers in screen readers already so this does not seem like a massive stretch to imagine, especially given the evolution of the tree role so far. Sadly, we do not have general purpose tree walkers (yet).</p>
<p>In the second part, we overcome this by adding such a walker in JS. This walker consists of a tree structure (the <code>aria-owns</code> tree, generated from the embedded data for performance) and a keyboard listener. It is very close to the DOM's <a href="https://developer.mozilla.org/en-US/docs/Web/API/Treewalker">treewalker API</a> and <a href="https://www.w3.org/TR/wai-aria-practices-1.1/#TreeView">WCAG tree examples</a>, except that we're working on the <code>aria-owns</code> tree because that tree may have a different order/structure from the DOM. This walker is fairly minimal, probably ~100 lines of ES6 code if you strip it down to its minimum.</p>
<p>Here's a demo of v2 or you can look at the <a href="https://krautzource.github.io/mathjax-sre-walker/index.html">one in the repository</a>.</p>
<p data-height="896" data-theme-id="0" data-slug-hash="EGOZxm" data-default-tab="result" data-user="pkra" data-pen-title="mathjax-sre-walker v2 demo" class="codepen">See the Pen <a href="https://codepen.io/pkra/pen/EGOZxm/">mathjax-sre-walker v2 demo</a> by Peter Krautzberger (<a href="https://codepen.io/pkra">@pkra</a>) on <a href="https://codepen.io/">CodePen</a>.</p>
<script async="" src="https://static.codepen.io/assets/embed/ei.js"></script>
<h3>role role role your boat, gently down the stream</h3>
<p>A side note on the chosen <code>role</code> attributes. The tree role and its related roles may appear a good fit but they have been developed for specific application-like interfaces. It might be that it's smarter to use something different here, I honestly don't know.</p>
<p>Besides possibly being the right roles, they are also supported well across the accessibility tool chain, i.e., they happen to get the effects we'd like to see.</p>
<p>What are those effects?</p>
<ul>
<li>a top-level <code>aria-label</code> to provide a default textual representation, especially in browse mode</li>
<li>deeply nested <code>aria-labels</code> with the role <code>treeitem</code> provide detailed textual representation of all relevant nodes in exploration in focus mode</li>
<li>browse mode puts element in focus on-the-go which makes for good UX: just drop out of browse mode when you hear an equation to start exploring</li>
<li>switching back to browse mode continues smoothly</li>
<li><code>active-descendant</code> is used to move the the focus on the accessibility tree</li>
<li>thereby exposing the nested labels instead of the top-level node's label</li>
</ul>
<p>Other roles have too many negative side effects in practice. Perhaps they shouldn't but it's often too hard to dissect if a problem comes from the ARIA specs, browser implementations, OS APIs, or screenreaders.  For example, some approaches didn't work well on MathJax SVG output but worked well on the clip art house; this is probably due to <code>use</code> elements.</p>
<p>Some other roles we've tested across screenreaders:</p>
<ul>
<li><code>img</code> (nested) prevents exploration</li>
<li><code>application</code> loses the top level label when using browse mode and it is difficult to get back to browse mode after exploration</li>
<li><code>group</code> is similar to application (except easier to get back into browse mode) but works poorly with CSS rendering</li>
<li><code>button</code> and <code>math</code> mostly work the same as <code>tree</code> (very wrong, but hey)</li>
</ul>
<p>Maybe those issues are fixable or maybe just due to my lack of understanding of specs and implementations. Of course, the mythical <code>role=static</code> (<code>text</code> etc.) might be very appropriate but, alas, it doesn't exist.</p>
<p>Personally, I don't care which role I use. Whatever role works, I'm happy to use it. Tree seems both adequate and semantically fitting, and they have a history of steady improvement.</p>
<h2>In real life</h2>
<p>Below is a recording with NVDA and Chrome on Windows 10.</p>
<div style="display: flex">
<iframe width="720" height="748" src="https://www.youtube.com/embed/LWho3euldjM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" style="flex-grow: 1"></iframe>
</div>
<h2>Support</h2>
<p>Overall, this works well on Firefox and Chrome while Edge and Safari generally don't get your more than the top-level label, i.e., the fallback; I haven't taken the time to compile for IE11 to test it.</p>
<p>NVDA seems best so far, JAWS seems to have a problem tracking focus (it jumps away when getting back into browse mode / virtual cursor), and Orca <s>struggles with CSS rendering</s> (see update below). VoiceOver with Safari is doing its thing (treating everything as a group) but VO works well with Chrome on MacOS. On iOS and Android we get the top-level labels (except VO with CSS rendering for some reason). The current code lacks touch input because (as far as I know) neither Talkback nor VoiceOver have a way to switch into (some form of) focus mode; it could be added, perhaps the visual exploration is interesting enough. I'll be publishing more demo runs as we move along.</p>
<p>Overall, I'm excited about the robustness at this stage and I plan to use this at work soon(ish). I also hope to bring the discussion around standardization of tree walkers to the ARIA Working Group - it seems to align with the evolution of tree widgets (e.g., for tab focus management, positional information) and a lot of content could benefit from some defaults in AT (much like with table walkers). But first we really need separate Braille streams.</p>
<p><strong>update 2019-01-24</strong> Joanmarie Diggs was kind enough to look into the issues with CSS layout (commits <a href="https://gitlab.gnome.org/GNOME/orca/commit/9357aa9cd82f43a853704b98464eb7a76352d4ed">9357aa9c</a> and <a href="https://gitlab.gnome.org/GNOME/orca/commit/87d78dad097ce11a359e3bbebd77f5d32b2fccd6">87d78dad</a>) and Orca now matches NVDA beautifully.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Matrices for classical groups]]></title>
        <id>https://nickpgill.github.io/matrices-for-classical-groups</id>
        <link href="https://nickpgill.github.io/matrices-for-classical-groups">
        </link>
        <updated>2019-01-01T00:00:00Z</updated>
        <summary type="html"><![CDATA[<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p>A finite classical group is best thought of as a group of linear operators on some vector space defined over a finite field. Which means, of course, that I can take a basis for this vector space and then represent the elements of my group as matrices.</p>

<p>However, I have almost <strong>never</strong> seen anyone do this in the literature. “Taking a basis” is thought of as a rather crude thing to do when doing linear algebra – one generally tries to write general arguments that do not refer to any particular basis. However, speaking for myself, when I’m trying to work out what the hell is going on inside a finite matrix group, I often end up trying to write down individual elements as matrices… And then hiding all this when it comes to writing up the paper!</p>

<p>This means that I have never publicly written down any of these calculations, despite using many of them over and over again. So this page is designed to be a little repository for me to note down interesting observations about such calculations… And perhaps they’ll be useful for someone else some time…</p>

<h2 id="working-with-omega_4q">Working with $\Omega_4^+(q)$</h2>

<p>This family of groups has some weird behaviour, especially when $q$ is even. For instance, let us write $\mathcal{U}$ for the set of maximal totally singular subspaces in a formed space of type $O+$ and dimension $2m$. If $q$ is even, then, provided $(m,q)\neq (2,2)$, we can define $\Omega_{2m}^+(q)$ to be the group inducing odd permutations on $\mathcal{U}$…. If $(m,q)=(2,2)$, however, the group so defined is <strong>not</strong> $\Omega_4^+(2)$, and one needs to define it in a completely different way (see Kleidman and Liebeck, p.31).</p>

<h1 id="finding-some-elements-in-omega_4q">Finding some elements in $\Omega_4^+(q)$.</h1>

<p>Let $(e_1,f_1)$ and $(e_2, f_2)$ be hyperbolic pairs, and consider the basis $\mathcal{B}={e_1, e_2, f_2, f_1}$ maintaining order. Then, one can calculate directly that $O_4^+(q)$ contains elements which are written with respect to $\mathcal{B}$ in the form</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{pmatrix}
1 & a & b & ab \\ & 1 & & b \\ & & 1 & a \\ & & & 1
\end{pmatrix}; %]]]]><![CDATA[></script>

<p>these elements form a subgroup $S$ of size $q^2$; indeed, for $q$ odd, they form a Sylow $p$-subgroup of $O_4^+(q)$.</p>

<p>When $q$ is odd, one can look at orders to see directly that $S$ is actually a subgroup of $\Omega_4^+(q)$. Indeed, the same is true when $q$ is even, but to see this it is easiest to observe that $S$ is normalized by the element</p>

<script type="math/tex; mode=display">% <![CDATA[
g=\begin{pmatrix}
1 & & & \\ &  & 1 & \\ & 1 & & \\ & & & 1
\end{pmatrix}. %]]]]><![CDATA[></script>

<p>This element clearly takes one element $U=\langle e_1, e_2\rangle \in \mathcal{U}_2$ to another element $W=\langle e_1, f_2\rangle\in \mathcal{U}_2$. What is more $U\cap W$ has codimension $1$ in both $U$ and $W$. This allows us to conclude that $g\in SO_4^+(q)\setminus \Omega_4^+(q)$ (see Kleidman and Liebeck, p. 30). Now order considerations imply that $S$ must be a subgroup of $\Omega_4^+(q)$.</p>

<h1 id="finding-all-elements-in-omega_4q">Finding all elements in $\Omega_4^+(q)$.</h1>

<p>Let $R$ be the set of elements whose transpose is in $S$. One sees immediately that both $R$ and $S$ lie in $\Omega_4^+(q)$ and hence so does $\langle R,S\rangle$.</p>

<p>If one sets $a$ to equal $0$, while $b$ ranges across $\mathbb{F}_q$, in both $R$ and $S$, then one immediately observes a copy of $SL_2(q)$ in $\Omega_4^+(q)$. The same is true setting $b$ to equal $0$. Since these two copies effectively “avoid interaction” one immediately obtains a copy of $SL_2(q)\circ SL_2(q)$ inside $\Omega_4^+(q)$. (The central product is due to the fact that both copies of $SL_2(q)$ share $-I$ as an element.)</p>

<p>Now one can observe that $\Omega_4^+(q)$ also contains the element</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{pmatrix}
& & & 1\\ & & 1 & \\ & 1 & & \\ 1 & & & 
\end{pmatrix} %]]]]><![CDATA[></script>

<p>Now order considerations allow us to conclude that $\Omega_4^+(q)\cong (SL_2(q)\circ SL_2(q)):2$, and we have written down all elements of the group.</p>

<h2 id="sp_n-22a--omega_n2a">$Sp_{n-2}(2^a) &lt; \Omega_n^+(2^a)$</h2>

<p>When $q$ is even, $\Omega_n^+(q)$ has a maximal subgroup – the stabilizer of a non-degenerate $1$-space – isomorphic to $Sp_{n-2}(q)$. I will write down the elements of this subgroup for $n=4$; the general case follows similarly.</p>

<p>First, we adjust our basis from before to be $\mathcal{C}={z_1, x_1, x_2, y_2}$ where $z_1=x_1+y_1$.</p>

<p>With respect to this basis, our quadratic form becomes</p>

<script type="math/tex; mode=display">Q(a,b,c,d) = ab+a^2+cd</script>

<p>and we see that $z_1$ is non-singular. Now simply observe that the following elements stabilize $z_1$:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{pmatrix}
1 & & & c \\ & 1 & & \\ & c & 1 & c^2 \\ & & & 1
\end{pmatrix}. %]]]]><![CDATA[></script>

<p>Doing the “transpose trick” like before, one immediately obtains a copy of $SL_2(q)$ in this stabilizer and (using the perfectness of $SL_2(q)$ for $q&gt;3$ if necessary), one obtains that the stabilizer of $z_1$ in $\Omega_4^+(q)$ is isomorphic to $SL_2(q)\cong Sp_{2}(q)$.</p>

<p>One can do this more generally for larger $n$ – one simply has to exhibit the root groups of $Sp_{n-2}(q)$ inside the stabilizer of $z_1$ in $\Omega_4^+(q)$. There are two sorts of root group here: the first already ocur in $\Omega_{n-2}^+(q)$ and so are easy to write down in $\Omega_n^+(q)$; the second all take the form given above.</p>]]></summary>
        <author>
            <name>Nick Gill</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Foundations of analysis]]></title>
        <id>http://scoskey.org/course/1819s-314/</id>
        <link href="http://scoskey.org/course/1819s-314/">
        </link>
        <updated>2019-01-01T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Math 314, Spring 2019<!--more--></p>

<p><em>Catalog description</em>: The real number system, completeness and compactness, sequences, continuity, foundations of the calculus.</p>]]></summary>
        <author>
            <name>Samuel Coskey</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Groups with identical element counts]]></title>
        <id>https://nickpgill.github.io/groups-with-identical-element-counts</id>
        <link href="https://nickpgill.github.io/groups-with-identical-element-counts">
        </link>
        <updated>2018-12-20T00:00:00Z</updated>
        <summary type="html"><![CDATA[<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p>Some time ago I heard an interesting story about a remarkable mathematical fact. I can’t locate the source right now, so here is the story as I understand it.</p>

<p>If one consults the <em>Atlas of Finite Groups</em> and looks at the maximal subgroups of the Mathieu group $M_{23}$, one will observe that it has two rather different maximal subgroups, both of which have order 40320. The first is of form $PSL_3(4):2$; the second has form $2^4:A_7$.</p>

<p>It’s important to note how <strong>very different</strong> these two groups are, despite their shared order: in particular, they have different non-abelian composition factors.</p>

<p>John G. Thompson investigated these groups a little further and observed the following remarkable fact: they have <strong>exactly the same element count, by order</strong>. By which I mean that they have the same number of elements of order 2; the same number of elements of order 3; and so on. (How he realised this, I really don’t know – but I guess geniuses tend to realise more things than the rest of us…)</p>

<p>Thompson’s observation led him to make the following conjecture: <em>Suppose that two groups, G and H, have exactly the same element count, by order. Suppose, moreover, that G is solvable. Then H is solvable.</em></p>

<p>This conjecture can be interpreted as saying that it is, in principle, possible to recognise whether or not a group is solvable simply by knowing the number of elements in the group of each different order. Note, that I say “in principle”, as it is not proposing an algorithm for recognising solvability in this way – that is a harder question.</p>

<p>By way of comparison, it is easy to see that there is an algorithm to recognise <em>nilpotency</em> by knowing the number of elements in the group of each different order – one simply tests whether, for each prime <em>p</em> dividing the order of the group, the number of elements of order a power of <em>p</em> is equal to the highest power of <em>p</em> dividing the order of the group. If this is true for all <em>p</em>, then the group has a unique Sylow <em>p</em>-subgroup for each prime <em>p</em> dividing its order, and this property characterises nilpotency.</p>

<p>As I understand it, Thompson’s conjecture has been proved… but I’m not sure by whom. If anyone could point me to a source, I’d like to give appropriate credit! I don’t know if an algorithm for recognising solvability in this way has ever been written down. I’m also unable to point to the place where Thompson first made the observation about these subgroups of $M_{23}$ and where he first stated this conjecture; again any help with sources would be appreciated.</p>]]></summary>
        <author>
            <name>Nick Gill</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning LaTeX in Jupyter Notebooks]]></title>
        <id>https://mikepawliuk.ca/2018/12/16/learning-latex-in-jupyter-notebooks/</id>
        <link href="https://mikepawliuk.ca/2018/12/16/learning-latex-in-jupyter-notebooks/">
        </link>
        <updated>2018-12-17T05:47:06Z</updated>
        <summary type="html"><![CDATA[<p>I made a resource for teaching people how to use Jupyter notebooks. Really it&#8217;s about learning LaTeX anywhere, but Jupyter notebooks are very well suited to this.</p>
<p><a href="https://github.com/mpawliuk/Learning-LaTeX">The notebook is available for download here</a>.</p>
<p><span id="more-1804"></span></p>
<h2>1. Authentic resource</h2>
<p>The <a href="https://github.com/mpawliuk/Learning-LaTeX" target="_blank" rel="noopener">jupyter notebook is available for download here</a>. The intention is for it to be run on <a href="https://ucalgary.syzygy.ca/" target="_blank" rel="noopener">your free UCalgary syzygy server</a>. The document can be read on Github, but on Syzygy it can be <em>interacted with</em>.</p>
<h2>2. Background</h2>
<p>LaTeX (pronounced &#8220;Lay-Tech&#8221; or &#8220;Laa-Tech&#8221; ) is a computer language used by mathematicians and physicists to nicely format mathematical expressions. Every math student will eventually need to know how to write in LaTeX, since all math journals are written using LaTeX. It is also used in every online platform that supports math writting, such as D2L discussion posts, Github, WordPress blogs, and Mathoverflow.</p>
<p><img data-attachment-id="1807" data-permalink="https://mikepawliuk.ca/2018/12/16/learning-latex-in-jupyter-notebooks/latex_a09588720c5d1e3a1948e857b5e99c51/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/12/latex_a09588720c5d1e3a1948e857b5e99c51.png" data-orig-size="726,195" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="latex_a09588720c5d1e3a1948e857b5e99c51" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/12/latex_a09588720c5d1e3a1948e857b5e99c51.png?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/12/latex_a09588720c5d1e3a1948e857b5e99c51.png?w=660" class="alignnone size-full wp-image-1807" src="https://mikepawliuk.files.wordpress.com/2018/12/latex_a09588720c5d1e3a1948e857b5e99c51.png?w=660" alt="latex_a09588720c5d1e3a1948e857b5e99c51" srcset="https://mikepawliuk.files.wordpress.com/2018/12/latex_a09588720c5d1e3a1948e857b5e99c51.png?w=660 660w, https://mikepawliuk.files.wordpress.com/2018/12/latex_a09588720c5d1e3a1948e857b5e99c51.png?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/12/latex_a09588720c5d1e3a1948e857b5e99c51.png?w=300 300w, https://mikepawliuk.files.wordpress.com/2018/12/latex_a09588720c5d1e3a1948e857b5e99c51.png 726w" sizes="(max-width: 660px) 100vw, 660px"   /></p>
<p>Jupyter notebooks are a file type that blends HTML, formatted text (markdown), formatted mathematical formulas (LaTeX) and runnable code (Python). It is the standard way that data scientists communicate with each other online.</p>
<p><img style="display:block;margin-left:auto;margin-right:auto;" title="" src="https://i0.wp.com/community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/202/content_jupyternotebook7.gif" alt="" /></p>
<p style="text-align:center;">Source: <a href="https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook" rel="noopener">https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook</a></p>
<h2>3. Description</h2>
<p>My resource is an interactive guide to properly typing LaTeX. The format is a Jupyter notebook which is an authentic way in which LaTeX is used by data scientists. The resource could be used in any first-year course at the University of Calgary that requires written mathematics (such as MATH 265 &#8211; Calculus 1 or MATH 311 &#8211; Linear Algebra 2). The examples are geared towards students in those courses.</p>
<p><img data-attachment-id="1808" data-permalink="https://mikepawliuk.ca/2018/12/16/learning-latex-in-jupyter-notebooks/latex_8a906c4c6162313a7c99233a4201d667/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/12/latex_8a906c4c6162313a7c99233a4201d667.png" data-orig-size="874,176" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="latex_8a906c4c6162313a7c99233a4201d667" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/12/latex_8a906c4c6162313a7c99233a4201d667.png?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/12/latex_8a906c4c6162313a7c99233a4201d667.png?w=660" class=" size-full wp-image-1808 aligncenter" src="https://mikepawliuk.files.wordpress.com/2018/12/latex_8a906c4c6162313a7c99233a4201d667.png?w=660" alt="latex_8a906c4c6162313a7c99233a4201d667" srcset="https://mikepawliuk.files.wordpress.com/2018/12/latex_8a906c4c6162313a7c99233a4201d667.png?w=660 660w, https://mikepawliuk.files.wordpress.com/2018/12/latex_8a906c4c6162313a7c99233a4201d667.png?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/12/latex_8a906c4c6162313a7c99233a4201d667.png?w=300 300w, https://mikepawliuk.files.wordpress.com/2018/12/latex_8a906c4c6162313a7c99233a4201d667.png?w=768 768w, https://mikepawliuk.files.wordpress.com/2018/12/latex_8a906c4c6162313a7c99233a4201d667.png 874w" sizes="(max-width: 660px) 100vw, 660px"   /></p>
<h2>4. Rationale</h2>
<p>This was designed to be used as a resource outside of class that students could use whenever they want, as often as they want. In this sense it is a &#8220;flipped or blended&#8221; resource [3]. The nature of a jupyter notebook (it&#8217;s a fancy text file) means that students necessarily must download their own version of it and edit it as they go. This encourages them to personalize the material and take ownership of it. They can even modify the examples in the text instantly see how it changes the outcome.</p>
<div class="jetpack-video-wrapper"><iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/D8K90hX4PrE?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe></div>
<p>In the SAMR model [2] this is firmly in the &#8220;Redefinition&#8221; category, as the Jupyter notebook simultaneously acts as information, scratch pad, code compiler, notebook, and authentic outcome. In addition, completing the exercises in a Jupyter notebook is an authentic use of the skill being trained.</p>
<p><img style="max-width:100%;display:block;margin-left:auto;margin-right:auto;" title="" src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/The_SAMR_Model.jpg/975px-The_SAMR_Model.jpg" alt="" /></p>
<p>The main driver of solid pedagogical underpinnings is the <a href="http://udlguidelines.cast.org" target="_blank" rel="noopener">Universal Design guidelines </a>[1]. There I used all nine principles to make the resource more robust and drive student learning in many different, but natural, ways. In particular, the resource is low in passive learning, and high in active learning. Each section is a couple sentences, some examples, then right into activities. The activities are of use to a student in a first year math class, and many additional, alternative explanations are offered. See my activity design post for more discussion about this.</p>
<hr style="width:100%;height:auto;color:#ffffff;border:1px inset #cccccc;" />
<h2>5. References</h2>
<ol>
<li>CAST (2018). Universal Design for Learning Guidelines version 2.2. Retrieved from <a href="http://udlguidelines.cast.org" rel="noopener">http://udlguidelines.cast.org</a></li>
<li>Hamilton, Erica R., Joshua M. Rosenberg, and Mete Akcaoglu. &#8220;The substitution augmentation modification redefinition (SAMR) model: A critical review and suggestions for its use.&#8221; TechTrends 60.5 (2016): 433-441.</li>
<li>Kelly, Patrick, and Isabelle Barette-Ng. &#8220;Small FLICS to Big Flips: A Step-by-Step Guide to Flipping Your Classroom.&#8221; (2015). <a href="https://prism.ucalgary.ca/handle/1880/50856" rel="noopener">https://prism.ucalgary.ca/handle/1880/50856</a></li>
</ol>
<p> </p>]]></summary>
        <author>
            <name>Mike Pawliuk – Mathematics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unifying themes in Ramsey Theory – BIRS 2018]]></title>
        <id>https://mikepawliuk.ca/2018/12/02/unifying-themes-in-ramsey-theory-birs-2018/</id>
        <link href="https://mikepawliuk.ca/2018/12/02/unifying-themes-in-ramsey-theory-birs-2018/">
        </link>
        <updated>2018-12-03T04:39:05Z</updated>
        <summary type="html"><![CDATA[<p>In November 2018, 41 of the top researchers in Ramsey theory met at the BIRS in Banff for the Unifying Themes in Ramsey Theory conference. By all measures the conference was a big success. What makes Ramsey theory so special is that it has wide ranging impacts in diverse fields in mathematics. The participants gave talks showing how Ramsey theory has impacted fields like graph theory, topological dynamics, set theory, model theory, operator algebras, logic and statistics.</p>
<p>Since I have a somewhat broad base of knowledge in Ramsey theory, I tried my best to give a short description of each of the speakers in language that makes sense to me. My view is biased, and my intent is always to show off the amazing work everyone is doing. I hope nothing comes across as negative or critical; that is not my intent.</p>
<p>You can find all <a href="https://www.birs.ca/events/2018/5-day-workshops/18w5180/schedule">the abstracts here</a>, and all <a href="https://www.birs.ca/events/2018/5-day-workshops/18w5180/videos">the videos of their talks here</a>.</p>
<figure data-shortcode="caption" id="attachment_1802" aria-describedby="caption-attachment-1802" style="width: 4752px" class="wp-caption alignnone"><img data-attachment-id="1802" data-permalink="https://mikepawliuk.ca/2018/12/02/unifying-themes-in-ramsey-theory-birs-2018/groupphoto/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/12/groupphoto.jpg" data-orig-size="4752,3168" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;5.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS REBEL T1i&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1542637522&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;31&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.003125&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="groupphoto" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/12/groupphoto.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/12/groupphoto.jpg?w=660" class="alignnone size-full wp-image-1802" src="https://mikepawliuk.files.wordpress.com/2018/12/groupphoto.jpg?w=660" alt="groupphoto" srcset="https://mikepawliuk.files.wordpress.com/2018/12/groupphoto.jpg?w=660 660w, https://mikepawliuk.files.wordpress.com/2018/12/groupphoto.jpg?w=1320 1320w, https://mikepawliuk.files.wordpress.com/2018/12/groupphoto.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/12/groupphoto.jpg?w=300 300w, https://mikepawliuk.files.wordpress.com/2018/12/groupphoto.jpg?w=768 768w, https://mikepawliuk.files.wordpress.com/2018/12/groupphoto.jpg?w=1024 1024w" sizes="(max-width: 660px) 100vw, 660px"   /><figcaption id="caption-attachment-1802" class="wp-caption-text">The participants of the 2018 Unifying Themes in Ramsey Theory conference at BIRS, Banff, Alberta, Canada. November 18-23, 2018. <a href="https://www.birs.ca/events/2018/5-day-workshops/18w5180/participants">Full list of participants</a>.</figcaption></figure>
<p><span id="more-1790"></span></p>
<h2>The four must-watch presentations (IMHO)</h2>
<p>Here are four talks I picked out that I think are important and worth watching for an outsider to Ramsey Theory.</p>
<ul>
<li><strong>Aleksandra (Ola) Kwiatkowska</strong>: &#8220;<a href="https://www.birs.ca/events/2018/5-day-workshops/18w5180/videos/watch/201811221529-Kwiatkowska.html">Universal minimal flows of the homeomorphism groups of Wazewski dendrites</a>&#8220;. <strong>Watch it because</strong>: Ola presents a nice structure that answers two big problems in the field.</li>
<li><strong>Jordi Lopez-Abad</strong>: &#8220;<a href="https://www.birs.ca/events/2018/5-day-workshops/18w5180/videos/watch/201811221329-Lopez-Abad.html">Approximate Ramsey properties of Banach spaces</a>&#8221;. <strong>Watch it because</strong>: Jordi is doing cutting edge research on important open problems, and explains his thinking with clear examples and computations.</li>
<li><strong>Jaroslav Nesetril</strong>: &#8220;<a href="https://www.birs.ca/events/2018/5-day-workshops/18w5180/videos/watch/201811190900-Nesetril.html">Unifying Themes in Ramsey Theory</a>&#8221;. <strong>Watch it because</strong>: This gives an important unifying perspective on the place of Ramsey theory in mathematics.</li>
<li><strong>Stevo Todorcevic</strong>: &#8220;<a href="https://www.birs.ca/events/2018/5-day-workshops/18w5180/videos/watch/201811231059-Todorcevic.html">Concluding Remarks &#8211; Unifying Themes in Ramsey Theory</a>&#8221;. <strong>Watch it because</strong>: Stevo gives very deep and insightful perspectives on the connections of Ramsey theory to other fields.</li>
</ul>
<h2>Monday &#8211; Day 1A &#8211; Combinatorics and Ramsey classes</h2>
<p>To kick off the conference, <strong>Jaroslav Nesetril</strong> gave a nice overview of the types of Ramsey theorems, problems and perspectives we are likely to see this week. He told us about how Mendel (the biologist) was the first to use the <img src="https://s0.wp.com/latex.php?latex=%5Cbinom%7Bn%7D%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;binom{n}{k}" title="&#92;binom{n}{k}" class="latex" /> notation [LINK]. Of the many important questions related to Ramsey theory, Jarik mentioned two:</p>
<ul>
<li>Are there other good tools for showing that a graph has high chromatic number?</li>
<li>Does the class of graphs that forbid <img src="https://s0.wp.com/latex.php?latex=C_4&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="C_4" title="C_4" class="latex" /> have a Ramsey expansion?</li>
</ul>
<p>The second talk was supposed to be given by Michael Kompatscher, but he was unable to travel to Canada because of illness. So I (<strong>Mike Pawliuk</strong>) gave the second talk in his place, about connections to data science, big data, statistics and machine learning. Funny enough, I <em>could have</em> given Michael&#8217;s talk since it was about joint work that we did.</p>
<p><strong>Matej Konecny</strong> gave the final talk of the morning, showcasing new results that capture the completion algorithms of many different classes of metric spaces. Completing large cycles to a complete metric graph is an important step in showing that a class has a Ramsey expansion. This technique has become more and more explicit in recent years.</p>
<h2>Monday &#8211; Day 1B &#8211; EPPA/Hrushovski property</h2>
<p><strong>Natasha Dobrinen</strong> started the afternoon with a chalkboard talk showcasing new results about big Ramsey degrees. She showed how she overcame the difficulties with the random graph to find the big Ramsey degrees for graphs that forbid small complete graphs. At its core she was able to sidestep a difficulty that the Sauer construction presented by <em>starting</em> where the Sauer construction <em>ends</em>.</p>
<p><strong>Jan Hubicka</strong> highlighted exciting work that he&#8217;s been doing about general methods of proving the EPPA (Hrshovski property) for various classes of metric spaces. He was able to breathe life into the idea of valuations first presented elsewhere.</p>
<p>Finally, <strong>Macin Sabok</strong> presented work showing that the class of <em>hyper</em>tournaments does not have EPPA. It uses generalizations of the ideas present in Herwig-Lascar, together with other ideas from algebraic topology. It does not answer the (very hard) prized problem &#8220;Does the class of tournaments have EPPA?&#8221;, but it does prove EPPA for a specific class of isomorphisms.</p>
<p>The day ended with a small group of us going on <a href="https://www.strava.com/activities/1974581635">a fast hike of Tunnel mountain</a>.</p>
<h2>Tuesday &#8211; Day 2A &#8211; Dynamics</h2>
<p>The morning session focused on the fruitful connections that topological dynamics has had with Ramsey theory through <a href="https://mikepawliuk.ca/2016/11/16/topological-dynamics-and-ramsey-classes-ramsey-doccourse-prague-2016/">the KPT correspondence</a>.</p>
<p><strong><span class="item-title is-lecture">Friedrich Martin Schneider</span></strong> gave the first talk which presented the &#8220;Gromov-Milman&#8221; perspective on the KPT correspondence. We saw a Gromov result that is a concentration of measure result, which corresponds to a Ramsey result through the KPT correspondence. Martin then showed us a stronger version of Gromov&#8217;s result, answering a question of Pestov.</p>
<p><strong>Colin Jahel</strong>, a graduate student, gave an impressive talk about the semigeneric directed graph. It was especially interesting to me since it answered an open problem from my thesis that I was unable to solve. Colin presented results that reified techniques for proving unique ergodicity, and sidestepped using probabilistic arguments.</p>
<p><strong>Andy Zucker</strong> rounded out the morning by giving an alternate perspective on the work of Colin (who is a coauthor). He discussed the dynamical perspective of the amenability and metrizable flows. This work is another step in Andy giving a very clear picture of what is happening with the universal minimal flows. This is one of the clearest, most straightforward talks about this topic I&#8217;ve ever seen.</p>
<p>From the audience, Stevo Todorcevic mentioned a nice (classical) result that if the product of two spaces contains a copy of <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%5Cmathbb%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;beta &#92;mathbb{N}" title="&#92;beta &#92;mathbb{N}" class="latex" />, then one of the factors must contain a copy of it. In this way, <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%5Cmathbb%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;beta &#92;mathbb{N}" title="&#92;beta &#92;mathbb{N}" class="latex" /> is an &#8220;irreducible&#8221; space.</p>
<h2>Tuesday &#8211; Day 2B &#8211; Applications of Ramsey theory</h2>
<p>The afternoon session featured subtle uses of Ramsey theory underlying key theorems. This made many of the results possible, even if they didn&#8217;t directly invoke Ramsey results.</p>
<p><strong><span class="item-title is-lecture">Wieslaw Kubis</span></strong> started the afternoon by presenting results about uniform homogenity, Katetov functors and mixed sums of Fraisse classes. The mixed sum construction is a type of &#8220;bipartite&#8221; construction where each part is a Fraisse structure. While he used this construction to provide a counterexample, it is also a broadly useful construction.</p>
<p><strong>Milos Kurilis</strong> followed up with a proof of Vaught&#8217;s conjecture in the case of monomorphic functions. This result quietly uses the fact that chainable uses Ramsey type-results. It was a remarkably understandable talk (to me a non-expert in model theory), despite the technical nature of the material.</p>
<p>In his talk Milos produced one of the most beautiful diagrams I&#8217;ve ever seen in a math talk.</p>
<p><img data-attachment-id="1791" data-permalink="https://mikepawliuk.ca/2018/12/02/unifying-themes-in-ramsey-theory-birs-2018/54pfgvc/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/11/54pfgvc.jpg" data-orig-size="4160,3120" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="54pfgvc" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/11/54pfgvc.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/11/54pfgvc.jpg?w=660" class="alignnone size-full wp-image-1791" src="https://mikepawliuk.files.wordpress.com/2018/11/54pfgvc.jpg?w=660" alt="54pfgvc" srcset="https://mikepawliuk.files.wordpress.com/2018/11/54pfgvc.jpg?w=660 660w, https://mikepawliuk.files.wordpress.com/2018/11/54pfgvc.jpg?w=1320 1320w, https://mikepawliuk.files.wordpress.com/2018/11/54pfgvc.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/11/54pfgvc.jpg?w=300 300w, https://mikepawliuk.files.wordpress.com/2018/11/54pfgvc.jpg?w=768 768w, https://mikepawliuk.files.wordpress.com/2018/11/54pfgvc.jpg?w=1024 1024w" sizes="(max-width: 660px) 100vw, 660px"   /></p>
<p>The final talk of the afternoon was <strong>David Hartman</strong>, who ended the day with a high-energy punch. David separated two closely related embedding properties with lots of examples and constructions. The final payoff for the day was a nice construction of the Rado graph partitioned into finitely many pieces.</p>
<p>After the presentations we had a problem session, where participants in the conference shared problems of interest. <a href="https://www.overleaf.com/read/xpdrxyfhjynv">Here are the mostly-complete notes I took</a>.</p>
<p>Ending the day, <strong>Wieslaw Kubis</strong> lead us in a problem session about the weak amalgamation property. About half the participants showed up and many people contributed to the discussion. Finally, at 8:30 (almost 12 hours after starting) we called it a day.</p>
<h2>Wednesday &#8211; Day 3A &#8211;</h2>
<p>Wednesday contained only talks in the morning.</p>
<p><strong>Martin Balko</strong> explained the project of ordered Ramsey numbers. He started by surveying the classical results about (usual) Ramsey numbers and contrasting them with the ordered versions. In many cases the bounds on the ordered/unordered Ramsey numbers are very different, even in the case of paths.</p>
<p><span class="item-title is-lecture"><strong>Lionel Nguyen Van Thé</strong> followed up by reminding us about Erdos-Rado type results about canonical colourings and equivalence relations. Big Ramsey results would become a recurring theme in this workshop. This talk stirred the most discussion about how it relates to canonical functions in other areas (like algebra).</span></p>
<p>The final talk of the morning was <strong>Sam Braunfeld</strong>, who gave an overview of the classification of homogeneous finite-dimensional permutation structures. Sam compared and contrasted his results with Cameron&#8217;s 2002 classification. This type of work is of particular interest to people in structural Ramsey theory, who use these catalogues as a source of interesting examples.</p>
<p>In the afternoon, some of us <a href="https://www.strava.com/activities/1978027166">hiked up to Sundance Canyon</a>.</p>
<h2>Thursday &#8211; Day 4A &#8211; Set Theory and Logic</h2>
<p>Thursday&#8217;s schedule was anticipated to be rather heavy, but the speakers were very gentle to the audience and it ended up being one of the best days of the conference.</p>
<p><strong>Martino Lupini</strong> started us off by explaining his intuition for his recent results about the generalized Tetris operations relating to Gower&#8217;s theorem. In particular he showed us how he used a perspective from non-standard analysis and the idempotent ultrafilter proof of Hindman&#8217;s theorem.</p>
<p><strong>Francisco Guevara Parra</strong> gave a talk about Tukey orders and local Ramsey theory. This was one of the few talks to show the application of Ramsey theory to topological groups, and infinite combinatorics.</p>
<p><strong>David Chodounsky</strong> ended the morning with a problem motivated by set theoretic forcing, but of independent interest to those studying Ramsey theory. David stirred up interest in his question about Halpern-Lauchi ideals. He also gave us a survey of the landscape of HL ideals including a very nice map of the known implications.</p>
<figure data-shortcode="caption" id="attachment_1800" aria-describedby="caption-attachment-1800" style="width: 4160px" class="wp-caption alignnone"><img data-attachment-id="1800" data-permalink="https://mikepawliuk.ca/2018/12/02/unifying-themes-in-ramsey-theory-birs-2018/birs_4/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/12/birs_4.jpg" data-orig-size="4160,3120" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1039348800&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.79&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.0048309178743961&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BIRS_4" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/12/birs_4.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/12/birs_4.jpg?w=660" class="alignnone size-full wp-image-1800" src="https://mikepawliuk.files.wordpress.com/2018/12/birs_4.jpg?w=660" alt="BIRS_4" srcset="https://mikepawliuk.files.wordpress.com/2018/12/birs_4.jpg?w=660 660w, https://mikepawliuk.files.wordpress.com/2018/12/birs_4.jpg?w=1320 1320w, https://mikepawliuk.files.wordpress.com/2018/12/birs_4.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/12/birs_4.jpg?w=300 300w, https://mikepawliuk.files.wordpress.com/2018/12/birs_4.jpg?w=768 768w, https://mikepawliuk.files.wordpress.com/2018/12/birs_4.jpg?w=1024 1024w" sizes="(max-width: 660px) 100vw, 660px"   /><figcaption id="caption-attachment-1800" class="wp-caption-text">The Brazilian delegation either discussing approximate Ramsey theorems, or posing for an album cover.</figcaption></figure>
<h2>Thursday &#8211; Day 4B</h2>
<p><strong>Jordi Lopez-Abad</strong> gave us a very nice presentation of various approximate Ramsey properties. He put special effort in to give examples and pictures and it was very appreciated. We saw that some of the studied objects were &#8220;shapes&#8221; where the boundary is kind of blurry, but you can still tell the difference between a square and a hexagon. This context is &#8220;almost Euclidean&#8221;. There was a lot of motivating intuition here.</p>
<p><strong>Michael Pinsker</strong> described canonical functions but, funny enough, not the &#8220;canonical functions&#8221; he originally wanted to talk about! The motivation for his talk is a nearly complete paper he wrote in 2002 that contained a critical false lemma. This lemma is an (infinite) Ramsey theory problem, and Michael was hoping to spark some renewed interest in it.</p>
<p><strong>Aleksandra (Ola) Kwiatkowska</strong> gave the final talk for the day, and it was one of the best of the conference. Ola showed that an obscure (but natural!) Fraisse class (the Weiewski dendrites) negatively answers two fundamental (and related) questions in the field (Does every omega-categorical structure have a precompact Ramsey expansion?). <a href="https://mikepawliuk.ca/2016/11/07/hrushovski-constructions-ramsey-doccourse-prague-2016/">David Evans had given an answer to this in 2016</a>, but Ola&#8217;s example is more natural, and provides a counterexample to some other conjectures as well.</p>
<p>After dinner, Michael Hrusak led a working session about Ramsey-type problems on Borel Ideals. You can <a href="https://www.birs.ca/events/2018/5-day-workshops/18w5180/videos/watch/201811221932-Hrusak.html">watch the video of it</a>.</p>
<h2>Friday &#8211; Day 5A &#8211; New Frameworks</h2>
<p>The final day, like Wednesday, only had talks in the morning. The theme of the morning was new frameworks and directions for Ramsey theory.</p>
<p><strong>Noé de Rancourt</strong> opened the talks with a discussion about Ramsey spaces, and specifically, what kind of results can you get if you don&#8217;t have a pigeonhole principle in that space. Ramsey spaces are very nice combinatorial objects that capture the essential Ramsey behaviour of many geometric objects; it is related to combinatorical forcing. Noé showed us how to relate these to games and local Ramsey theory.</p>
<p><strong>Dragan Masulovic</strong> showed us how the tools of category theory can be used to view and prove <a href="https://mikepawliuk.ca/2016/12/12/dual-ramsey-an-introduction-ramsey-doccourse-prague-2016/">dual results in Ramsey theory</a>. He showed us the value and type of isomorphism of categories in the Ramsey context. There was a special attention to making the results usable and practical for the non-category theorist.</p>
<p><strong>Stevo Todorcevic</strong> gave concluding remarks for the conference. To be honest, I was so caught up in his talk that I didn&#8217;t take notes. <a href="https://www.birs.ca/events/2018/5-day-workshops/18w5180/videos/watch/201811231059-Todorcevic.html">I highly recommend watching his talk</a>.</p>
<p>And with that, we wrapped up this iteration of the Ramsey theory meeting.</p>
<figure data-shortcode="caption" id="attachment_1801" aria-describedby="caption-attachment-1801" style="width: 4160px" class="wp-caption alignnone"><img data-attachment-id="1801" data-permalink="https://mikepawliuk.ca/2018/12/02/unifying-themes-in-ramsey-theory-birs-2018/birs_1/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/12/birs_1.jpg" data-orig-size="4160,3120" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1039348800&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.79&quot;,&quot;iso&quot;:&quot;800&quot;,&quot;shutter_speed&quot;:&quot;0.03030303030303&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BIRS_1" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/12/birs_1.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/12/birs_1.jpg?w=660" class="alignnone size-full wp-image-1801" src="https://mikepawliuk.files.wordpress.com/2018/12/birs_1.jpg?w=660" alt="BIRS_1" srcset="https://mikepawliuk.files.wordpress.com/2018/12/birs_1.jpg?w=660 660w, https://mikepawliuk.files.wordpress.com/2018/12/birs_1.jpg?w=1320 1320w, https://mikepawliuk.files.wordpress.com/2018/12/birs_1.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/12/birs_1.jpg?w=300 300w, https://mikepawliuk.files.wordpress.com/2018/12/birs_1.jpg?w=768 768w, https://mikepawliuk.files.wordpress.com/2018/12/birs_1.jpg?w=1024 1024w" sizes="(max-width: 660px) 100vw, 660px"   /><figcaption id="caption-attachment-1801" class="wp-caption-text">The cafeteria early in the morning. You can see Venus to the left of one of the trees.</figcaption></figure>
<p>&nbsp;</p>]]></summary>
        <author>
            <name>Mike Pawliuk – Mathematics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Preserving Properness]]></title>
        <id>http://karagila.org/2018/preserving-properness/</id>
        <link href="http://karagila.org/2018/preserving-properness/">
        </link>
        <updated>2018-11-23T20:03:26Z</updated>
        <summary type="html"><![CDATA[<p>I just posted another problem in the <a href="../../problems.html">problems page</a>. The prize, by the way, is a bottle of port wine, or equivalent. And I truly hope to make good on that prize.</p>

<p>In another problem there, coming from a work with David Asperó, we asked if an \(\omega_2\)-closed forcing must preserve the property of being proper. Yasou Yoshinobu provided us with a negative answer based on Shelah's <em>&quot;Proper and Improper Forcing&quot; XVII Observation 2.12 (p.826)</em>. Take \(\kappa\) to be uncountable, by forcing with \(\Add(\omega,1)\ast\Col(\omega_1,2^\kappa)\) and appealing to the gap lemma, \((2^{<\kappa})\) is a tree with only \(\aleph_1\) branches. It can therefore be specialized by a ccc forcing in that model. The iteration of these three forcing (Cohen real, collapse, specialize) is clearly proper. But now by forcing with \(\Add(\kappa,1)\) we must in fact violate the properness of this forcing, which was defined in the ground model, since the new branch is also generic for the tree and will therefore collapse \(\omega_1\). <a href="http://karagila.org/2018/preserving-properness/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the subgroup lattice of a group]]></title>
        <id>https://nickpgill.github.io/on-the-subgroup-lattice</id>
        <link href="https://nickpgill.github.io/on-the-subgroup-lattice">
        </link>
        <updated>2018-11-20T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>A couple of months ago, I went to a very enjoyable <a href="https://groupsinflorence2.wordpress.com/">conference in Florence</a>. During the course of this conference, I found myself stood in a coffee queue next to Peter Pal Palfy, whom I had heard of but never had the privilege of meeting. I want to recount a very interesting bit of maths that he told me about while we were in that queue – although it concerns a very natural group theory question, I had never heard of it before.</p>

<p>Anyone who has done a little bit of group theory is familiar with the subgroup lattice of a group. This question concerns what can happen between a <em>second-maximal subgroup</em> of a group <em>G</em>, and the group <em>G</em> itself.</p>

<p>A <strong>second-maximal subgroup</strong>, <em>H</em>, of <em>G</em> is a group that is maximal in the lattice of subgroups of <em>G</em>, once we have removed <em>G</em> itself, along with all maximal subgroups of <em>G</em>. By definition, the only proper subgroups that contain such a group <em>H</em> are maximal subgroups of <em>G</em>. So we have this set-up:</p>

<p><img src="lattice.jpg" alt="Lattice image" /></p>

<p>So, observe, that our second-maximal subgroup <em>H</em> lies inside precisely <em>n</em> maximal subgroups of <em>G</em>. Now, here’s the question: <em>what are the possibilities for the number n in the diagram?</em></p>

<p>For instance, is it possible to find a group <em>G</em> which has a second-maximal subgroup <em>H</em> that lies in precisely 8 maximal subgroups of <em>G</em>. If the answer is “yes” to this question, then let’s say that 8 is an <strong>sml-number</strong>.</p>

<p>A preliminary observation: If <em>G</em> is elementary abelian of order <em>p^2</em> for some prime <em>p</em>, then the trivial subgroup is second-maximal, and basic linear algebra says that it lies in precisely <em>1+p</em> maximal subgroups of <em>G</em>. Thus, <em>p+1</em> is an sml-number, for every prime <em>p</em>.</p>

<p>With a bit of ingenuity, one can generalize this example to conclude that <em>q+1</em> is an sml-number, for every prime power <em>q</em>. What is more one can construct these examples so that the groups in question are solvable. Now, here’s a neat partial converse, due to Palfy and Pudlak: <em>If H is a second-maximal subgroup of a solvable group G, then H is contained in q+1 maximal subgroups for some prime power q</em>.</p>

<p>For solvable groups, then, we have a complete answer. What about non-solvable groups? Here, the situation is still unclear. A 1983 paper of Walter Feit established that both 7 and 11 are sml-number – remarkably, he does this by exhibiting two different second maximal subgroups <em>H</em> of the alternating group <em>A_31</em>, one of which lies in exactly 7 maximals (here <em>H</em> is the normalizer of a Sylow 31-subgroup in <em>PSL(5,2)</em>), the other in 11 (here <em>H</em> is the normalizer of a Sylow 31-subgroup in <em>PSL(3,5)</em>).</p>

<p>Subsequent work by Lucchini has shown that all numbers of the form <em>q+2</em> are sml-numbers for <em>q</em> a prime power. He has exhibited other infinite families of sml-numbers, although as far as I know Feit’s examples remain sporadic.</p>

<p>To my knowledge, a complete answer still remains to be proven. I find it quite remarkable that such a basic question should throw up such bizarre and sporadic behaviour, and thereby resist a complete solution…</p>]]></summary>
        <author>
            <name>Nick Gill</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pickles!]]></title>
        <id>http://karagila.org/2018/pickles/</id>
        <link href="http://karagila.org/2018/pickles/">
        </link>
        <updated>2018-11-16T10:03:26Z</updated>
        <summary type="html"><![CDATA[<p>Those who know me, also know my strong liking of the amazing <a href="https://www.spreewaldhof.de/products/warengruppe/get-one.html">Spreewaldhof Get One!</a> pickles (go, get one!). 
I got one as a present from a friend who visited Germany, and after that, I started obsessing over them. I found them in Vienna on my first visit (with the help of Jakob Kellner), 
and they became the standard Viennese gift from visitors to Jerusalem for me. Mozart chocolate balls for the rest, a bunch of pickles for me. Thanks, Viennese people!</p>

<p>So naturally I could not skip on this video. <a href="http://karagila.org/2018/pickles/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Three interesting results from the AIM workshop]]></title>
        <id>https://www.peterkrautzberger.org/0208/</id>
        <link href="https://www.peterkrautzberger.org/0208/">
        </link>
        <updated>2018-11-15T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>When I look back at <a href="https://www.peterkrautzberger.org/0201/">looking ahead to 2018</a>, I'm going to fall short of my goals for this year. Life was on full throttle this year; no regrets. But I want to at least acknowledge what an excellent adventure the <a href="https://aimath.org/webmath">AIM Workshop</a> in May has been. So let's take a look at three interesting results.</p>
<h2>The first rule of workshops</h2>
<p>It's all in the people.</p>
<p>Of course, the very best part of this workshop was the people who attended it. It's amazing to get people from NVDA, JAWS and ChromeVox into a room for a few days. It's even better when you have people from MathJax, MathLive, Desmos in the same room. It gets even better when you have publishing experts from Wiley and Pearson on board. It's incredibly much better to have the vast expertise of people such as T.V. Raman and Joanie Diggs there. But for me, the most thrilling was the educators in the room. They are the key and without them we are all lost. And I'm the first to admit the workshop didn't serve them well enough. Even more importantly, at future workshops we need to get students in the room as well. Because what the hell are we doing without them.</p>
<p>In extension, this is a compliment to AIM's workshop design. Providing funding not only for a workshop but for everyone's travel and accommodation was excellent but also crucial. We would never have been able to get all these people in a room. This is the right way to hold workshops, especially when inclusiveness is a huge issue.</p>
<h2>Towards an optional Braille stream</h2>
<p>There's a particular limitation of today's accessibility landscape: we cannot specify separate textual alternatives for voice and Braille.</p>
<p>Generally, not having separate streams for voice and Braille does not seem like a huge problem. As long as all accessibility needs are covered by a fixed set of standard elements that are designed for both aural and tacticle interfaces, then assistive technologies can reliably implement a split in the stream, i.e., present separate voice and Braille streams from that. For example, if you have a dedicated button element, it can represented as a <code>btn</code> contraction on a Braille display and voiced as <em>Button</em>.</p>
<p>As usual, not all things can be covered by standards. Say your button is is used as a control in a game then you may want to augment the button's accessible name to include the action. So if the button opens a selection of planets to travel your to in your game, then you may want to have this voiced as <em>planet</em>. You can do that of course and then you might get a voicing of <em>planet; button</em> and something akin to <code>pln btn</code> on a Braille display.</p>
<p>Unfortunately, you might find yourself in a situation where you need to prevent the addition of <em>button</em> in the voicing because it may be problematic for your aural users, e.g., users with learning disabilities may find it to be distracting noise. But now how do you identify the button on a Braille display?</p>
<p>For equation layout, the situation is much like that final situation. In many countries, specialized Braille formats such as Nemeth, UEB, or Marburg have been developed to represent equation layout in Braille. These are well established and there are not too difficult to create. But they differ considerably from what you would might want to render aurally (and visually). In fact, since most precede the web, they try to capture (simplified) visual layout, including all the ambiguities we face there.</p>
<p>For me, the greatest positive experience of the workshop was to see the group assess the problem, come to an agreement that it needs a solution, <a href="https://github.com/w3c/aria/issues/765">add it to the ARIA tracker</a>, <a href="https://sinabahram.github.io/aria-playground/CustomBrailleOutput.html">build demos</a> and even see NVDA whip up a first implementation that we could explore by the end of the week.</p>
<p>This was <strong>huge</strong>.</p>
<p>And yet, it is the easy part. Now the long road towards a proper standard with widespread implementations lies ahead.</p>
<h2>Progress on deep aria labels</h2>
<p>I brought my favorite problem to the workshop - <a href="https://www.peterkrautzberger.org/0192/">deep <code>aria-label</code>s</a> and I was not disappointed.</p>
<p>Assistive technologies for equation layout (in particular for MathML) have to apply heuristics (read: guess) the semantics of an expression so that they can generate meaningful non-visual representations. This is a problem because heuristics that are hard coded into an external tool such as screenreaders cannot be altered by standard means, leaving authors without adequate means to ensure the quality of their content. (If a screenreader voices every superscripted 2 as <em>squared</em> and you have no way of changing that, then you're screwed.)</p>
<p>More importantly, since equation layout is, ultimately, only visual, a perfectly correct representation in HTML is as <code>span</code>s, i.e., there are no semantics. Finally, ARIA (naturally) does not have a dictionary of equation layout terminology (let alone mathematical or scientific terminology) to use - a) because all past dictionary based approaches have failed and b) such a dictionary would have to be extensible (read: infinite) which ARIA, so far, does not really want to be (<code>role-description</code> notwithstanding).</p>
<p>So the pragmatic answer is: you'll just have to do it yourself and use deep <code>aria-label</code>s: you override every single accessible name computation by slapping a fixed label to things. Because, ultimately, this is how we read equational content - with words.</p>
<p>The trouble is that it's easy to add a single <code>aria-label</code> at the root but it is hard to provide an explorable structure that provides a decent user experience. You'll want to provide labels at the leaf level but the state of ARIA prevents those from adequately building up an explorable tree. (And we're not even talking about refinements such as providing summaries and structural and positional information during exploration.)</p>
<p>At the workshop, David Tseng from Google's ChromeVox team, Volker Sorge from Speech Rule Engine and Davide Cervone from MathJax sat down nd <a href="https://github.com/zorkow/AIM-Workshop/tree/master/annotations">build a first demo</a> that tries two things</p>
<ul>
<li>expose the semantic structure identified by Speech Rule Engine's heuristic using <code>aria-owns</code> attribute</li>
<li>expose (some of) the detailed speech information provided by SRE</li>
<li>provide exploration of that tree via <code>aria-active-descendant</code> manipulations</li>
</ul>
<p>This is, simply put, a fantastic step forward.</p>
<p>The approach builds on existing parts of ARIA and identifies reasonable, incremental improvements to it. It raises important questions on general exploration, e.g., how is there a generic <code>aria-table</code> walker in every screenreader but not some basic <code>aria-tree</code> walker (such as breadth or depth first)?. And yet it pragmatically builds an unobtrusive solution anyway that works at 60FPS. It works with any markup, in particular any approach using CSS or SVG markup. And to top it off, it leverages existing open-source tool to enrich pre-existing content. And while it shows just how far ahead MathJax and Speech Rule Engine are, this approach is transparent and easily used by any other equation layout library.</p>
<p>In terms of UX, this is also a critical step forward. The approach is should be able to provide a seamless an interaction for visual and non-visual users alike, in synchronization. Effectively, it pushes MathJax's Accessibility Extensions from client- to server-side, requiring minimal JavaScript (just a keyboard event listener) to expose the content, without live region hacks, and with a solid non-JS fallback. It provides a clear path for making even that bit of JS obsolete through natural improvements to ARIA. It opens a path to finally get rid of the horrible hackery such as JAWS did back in the day, manipulating IE's DOM to manipulate MathJax, or Texthelp is doing today by injecting JS on the client (yuck!, and also badly failing when content-security is in place).</p>
<p>Even better, if you combine it with the previous part (exposing specialized Braille which SRE can soon produce), then this would immediately become the by far best, universal rendering of equation layout on the web: robust, high-quality, customizable, precise. And it is a solution that will only get better as standards evolve while leaving the full control with the author (with or without aid of heuristics at authoring time).</p>
<p>I'll dig into this more some other time but admittedly, I'm pretty excited.</p>
<h2>Coda</h2>
<p>You can find the <a href="https://aimath.org/pastworkshops/webmath.html">organizers' report at aimath.org</a> but you can take one thing away: It's looking very good for accessible equation layout on the web these days. And it will only get better.</p>
<p>If we can continue these workshops, things will move faster for everyone. And maybe, just maybe, we can even finally move on to actual mathematics (and other STEM content) on the web.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[6 Thoughts on accessibility of equation layout]]></title>
        <id>https://www.peterkrautzberger.org/0207/</id>
        <link href="https://www.peterkrautzberger.org/0207/">
        </link>
        <updated>2018-10-28T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><q>Of course it is more complicated than that.</q></p>
<p>Isn't it always?</p>
<p><button onclick="document.body.innerHTML = body.innerHTML.replace(/equation/g,'formula');">Replace <em>equation</em> with <em>formula</em></button>, if you prefer.</p>
<h1>The first rule of equation layout accessibility</h1>
<p>Don't talk about &quot;math accessibility&quot; when you mean equation layout accessibility.</p>
<p>Mathematics is an ancient domain of human knowledge, formula or equation layout a visual layout technique developed primarily in the 19th and 20th century.</p>
<p>Mathematical content is far more than content that needs equation layout and equation layout appears in many more domains than just mathematics.</p>
<p>We will fail to make equation layout accessible if we think we can treat equation layout identically across mathematics, physics, chemistry, computer science, biology etc (and their various sub-fields). For example, voicing a superscript 2 as &quot;squared&quot; may be a reasonable heuristic for middle school mathematics but a miserable heuristic for chemistry.</p>
<p>We will fail to make mathematical content accessible if we only make equation layout accessible and vice versa.</p>
<h1>2. Augmentation is a must (or: <em>aria-labels must work</em>)</h1>
<p>Manually overriding accessible name calculations (e.g., via aria-label) on text(-like) content is generally considered a last resort and it is clearly not a long term strategy for accessibility.</p>
<p>But we have aria-labels because we know from experience that there's always a situation where you need them.</p>
<p>Currently, it is extremely hard to augment equation layout with aria-labels let alone anything beyond simple overrides. This is a problem of authoring but much more of rendering and assistive technologies. MathML-based solutions in browsers and AT are particularly bad at this and to some degree this cannot be fixed (we should get to that later).</p>
<p>Whatever solutions might arise in the future of equation layout, like everything else on the web, they must be able to work together with interspersed aria-labels, together with potentially many interspersed aria-labels, and ultimately with only aria-labels.</p>
<p>In other words, <em>deep aria labels</em> aka <em>aria labels all the way down</em> must work as well.</p>
<p>This is a problem as ARIA has limitations when it comes to exposing custom tree structures and making them explorable.</p>
<p>More general author-driven augmentation must also work. Equation layout may have a natural tree structure derived from the DOM but we must be able to modify that. Aria-owns might be a solution here but right now it appears to too limited (either by spec or implementations).</p>
<h1>3. Visual quality must come first (and that's a problem)</h1>
<p>If equation layout is visually inadequate, it cannot be considered accessible. The problem is: we have no solid basis for measuring this.</p>
<p>While TeX-style layout is generally considered the <em>highest quality</em> among heavy users of equation layout, there seems to be no research evaluating this from an accessibility point of view. For example, TeX layout is largely unconcerned with K12 content and (as a print technology) has no concept for the kind of dynamic modifications we can realize on the web. While there are minor variations, e.g., elementary education preferring sans-serif fonts and requiring fonts with an open glyph for 4, it's unclear to me in how far these preferences are evidence-based (pointers very welcome); in any case, they are also deeply rooted in print and might be moot on the web, e.g., there might be better ways for get whatever effect such variations are supposed to achieve.</p>
<p>On the web, it probably means that equation layout must be flexible enough to allow all kinds of (user or author enabled) customizations. Some obvious questions: What should happen when the line-height changes? The letter spacing? When a transform or animation is applied to a descendant? A color changes on something with a specific color? A font (style) changes on a mathvariant? These all might be useful for accessibility purposes (e.g., with visual impairments, learning disabilities). And there are likely many more things we cannot imagine yet.</p>
<p>I think we greatly lack research as to what features in visual layout might be important for accessibility <em>on the web</em>. Without such research, we have no adequate basis on which to discuss improvements to equation layout and the standards that enable it on the web.</p>
<h1>4. Heuristics should be used at authoring time</h1>
<p>Heuristics are important across the assistive technology chain to recover from bad input (content). However, heuristics should not be necessary with <em>good</em> markup, e.g., markup that is ideal according to specs.</p>
<p>Equation layout is tremendously ambiguous, primarily due to its history and the limitations of print technology. For example, it is near impossible to differentiate the typical vertical fraction layout from the various other notations that share a similar vertical stack (2-3 children, depending on a line in between).</p>
<p>In other words, even high quality markup for equation layout requires heavy use of heuristics to guess the semantics.</p>
<p>Heuristics for non-visual representation of equation layout have existed for a very long time (and before the web). Today, some assistive technologies integrate heuristics for equation layout when done as MathML markup.</p>
<p>This is a problem because most of these heuristics are fairly bad. Heuristics for equation layout are largely of low quality at scale. It is unsurprising when (e.g.) Nemeth's math speak rules were invented for a person reading to another; such limitations could easily be overcome in that situations. At the scale of the web, it is much easier to run into edge cases where heuristics are too coarse or too fine grained. An almost universal limitation is the restrictions to individual fragments of equation layout, ignoring the context (both equational and otherwise).</p>
<p>Relying on heuristics in AT for <em>good</em> content poses a serious issue (hinted to earlier): heuristics interfere with augmentation. For example, the commonly used heuristic that every superscript 2 is voiced <q>square</q>, then no override may be possible; even if it is, will an override override the phrasing (e.g., <q>to the power of two</q>) or also consider the superscript position? Do you need two overrides to clarify? If a heuristic identifies (1+2+3) as a summation and provides summary information (e.g. <q>sum with three summands</q>), what happens when an author augment one of the + signs (say, with <code>aria-label=&quot;times&quot;</code>)?  We would need to augment both the content and the heuristics. As the saying goes: and now we have two problems.</p>
<p>Much like with textual descriptions of other visual content (e.g., image alttext, video captions, SVG descriptions) heuristical tools (human or machine guided) should be used at authoring time.</p>
<h1>5. Describing layout is a red herring</h1>
<p>There is a position that I encounter every once in a while: just give non-visual users access to the visual layout and stop. That's a very appealing proposition: instead of trying to make sense of visual layout semantically, we <em>just</em> provide information about what letter/word is where on a two-dimensional canvas. It also appeals to a basic idea of equality: visual users only have visual access, why would non-visual users get additional information?</p>
<p>Unfortunately, it is a red herring: it is neither easy nor helpful nor what anyone has ever done.</p>
<p>It is obviously not easy on the web because layout is dynamic; if two users read a document on two different devices, they might have a very different idea as to what is where. Even within equation layout, automatic linebreaking/reflow can shift parts around, more advanced methods (e.g., MathJax's collapsing feature) can vary even more greatly.</p>
<p>But ignoring this larger problem, traditional equation layout has a few odd concepts that make this even more difficult. For example, movable limits can move elements from sub/superscript positions to under/overscript positions based on the context of a subexpression, without any change in the markup; reversely, this can happen when changing text content (thanks to things like the operator dictionary). Another example is the concept of embellished operators which make it difficult to identify reasonable layout blocks to describe; similarly, brackets may or may not be marked up in a way that groups open and closing brackets. Essentially, you will still need to analyze the layout <em>semantically</em> to identify what really belongs where and together with what because that is ultimately a question of <em>why</em>.</p>
<p>As a consequence, the idea of <em>just</em> describing layout is not helpful to anyone, no matter what assistive technologies they might use (even if it's just a screen). Even more so, when you have to do the same analysis as you would for identifying semantics of an expression.</p>
<p>What's more important is that describing layout is not what anyone has ever done (so I would surmise nobody wanted to do it). Some layout information is always ignored, other layout is always inferred as semantic. As way back as Nemeth's math speak rules for print we have had heuristics that will read any superscript 2 as <em>squared</em>, inferring semantics where there are none. Reversely, no assistive technology for equation layout will tell you about the dimension of a stretchy character (neither directly nor transformatively e.g. via audio cues). Again, a good example is a movable limit where rule sets get around describing (unreliable) layout in favor of heuristically determined semantics, e.g., in a sum they might voice <q>sum from [subscript] to [superscript]</q>, neatly avoiding the layout. Above all, human beings do not speak equation layout as layout. Nobody says <q>vertical bar A vertical bar</q> they say absolute value or determinant or something completely different, nobody says <q>C O subscript 2</q> they say CO2 or carbon dioxide or possibly some more precise wording if it appears inside a checmical equation.</p>
<p>Of course, describing visual layout is nevertheless a decent fallback mechanism, e.g., when semantic heuristics fail but you can still recover layout information and it is important to be able to enable users to explore the layout if they need to (e.g., so as to reproduce it for their own work). But edge cases should not limit the expressiveness of accessible equation layout in general.</p>
<p>(An independent issue is to expose layout so that a user can guess how something was authored (e.g., when voicing gives you <q>determinant A</q>, the questions may be if it was represented  visually as <code>det A</code> or <code>|A|</code>.)</p>
<h1>6. We must strive for multi-directionality</h1>
<p>Accessibility is not a one way street, equation layout even more so. Accessibility must handle directionality on many axes.</p>
<p>Accessibility means to improve access to content no matter whether a user can access it with all theoretically possible human capacity or only using a small fragment thereof at a time. Due to its highly compressed form, equation layout requires more back and forth across a particular equation fragment as well as the entire document than most other forms of content. This is both a bug and a feature but either way it won't go away any time soon.</p>
<p>Accessibility means to improve interaction with content so as to allow all users to transfer knowledge better. Equation layout has a huge discrepancy between authoring formats and rendering. We must strive to improve this.</p>
<p>Acccessibility means improving the interaction between human beings. If two students explore a document, they should be able to do so together so that they can engage each other. Therefore, the effects of exploring content should be equivalent between different exploration methods. At the AIM workshop earlier this year, Sam Dooley told the story of a young blind person joyously celebrating that their parent could <q>read my math</q> as they used an accessible authoring and rendering environment together.</p>
<p>Interaction in these multiple directions will provide more information to more people, enabling wider accessibility, whether people identify as AT users or not. More importantly, it will show the path towards what the web can really do for the knowledge traditionally represented in equation layout.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cohen's Oddity]]></title>
        <id>http://karagila.org/2018/cohens-oddity/</id>
        <link href="http://karagila.org/2018/cohens-oddity/">
        </link>
        <updated>2018-10-20T11:05:13Z</updated>
        <summary type="html"><![CDATA[<p>We all know and love Cohen's first model where the axiom of choice fails. It is the O.G. symmetric extension. But Cohen didn't invent the idea on his own, he used Fraenkel's ideas 
from his work on set theory with atoms and permutation models. The two results, however, are significantly different.</p>

<p>Fraenkel's construction does not affect sets of ordinals, in particular the real numbers can still be well-ordered in his models. Cohen's work, however, directly breaks that. The 
Dedekind-finite set added is a set of reals. In particular, the reals cannot be well-ordered no more. <a href="http://karagila.org/2018/cohens-oddity/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MSc thesis on matrix completion]]></title>
        <id>https://nickpgill.github.io/2018/10/05/victor-tomno-msc-thesis/</id>
        <link href="https://nickpgill.github.io/2018/10/05/victor-tomno-msc-thesis/">
        </link>
        <updated>2018-10-05T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><a href="http://users.mct.open.ac.uk/is3649/index.php">Ian Short</a> and I have had the great pleasure of helping to supervise Victor Tomno, an MSc student at Moi University, Kenya. Victor has just submitted his thesis entitled <em>The weakly sign symmetric P_{p,1}^+-matrix completion problem</em>; a copy is <a href="/MSc_VictorTomno.pdf">here</a>. I want to congratulate Victor on his hard work!</p>

<p>Victor’s work looks at the problem of taking a <em>partial matrix</em> (i.e. one which does not have all entries filled), and completing it to obtain a matrix with certain prescribed properties. In the course of this research, Victor used the theory of digraphs as well as a lot of linear algebra.</p>

<p>Ian and my involvement with Victor was facilitated by the <em>Mentoring African Research Mathematicians</em> programme of the London Mathematical Society; details of that scheme are <a href="https://www.lms.ac.uk/grants/mentoring-african-research-mathematics">here</a>. Ian and I held a 2 year grant which allowed us to visit with, and host, Kenyan mathematicians, one of whom was Victor. The grant finished up in September 2018, although Ian and my connection with Kenya endures through supervision of two PhD students. We would like to thank the LMS for their financial support – this collaboration has been a very rewarding experience for all involved.</p>

<p>I should note that, in the end, Ian and I removed ourselves from the list of Victor’s official supervisors, as Moi University regulations only allowed for two supervisors on an MSc thesis. Nonetheless we are very proud to be associated with Victor’s excellent work.</p>]]></summary>
        <author>
            <name>Nick Gill</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Souslin trees at successors of regular cardinals]]></title>
        <id>http://blog.assafrinot.com/?p=4550</id>
        <link href="http://blog.assafrinot.com/?p=4550">
        </link>
        <updated>2018-10-01T13:49:23Z</updated>
        <summary type="html"><![CDATA[<div class="thanks_button_div" 
                  style="margin-bottom: 30px;"><div id="thanksButtonDiv_4550_2" style="background-image:url(http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/thanks_compact_brown1.png); background-repeat:no-repeat; float: left; display: inline;"
                onmouseover="javascript:thankYouChangeButtonImage('thanksButtonDiv_4550_2', true);" 
                onmouseout="javascript:thankYouChangeButtonImage('thanksButtonDiv_4550_2', false);"
                onclick="javascript:thankYouChangeButtonImage('thanksButtonDiv_4550_2', false);" >
                <input type="button" onclick="thankYouButtonClick(4550, 'You left &ldquo;Thanks&rdquo; already for this post')" value="Like 64"
                  class="thanks_button thanks_compact thanks_brown"
                  style="  font-family: Verdana, Arial, Sans-Serif; font-size: 14px; font-weight: normal;; color:#ffffff;"
                  id="thanksButton_4550_2" title="Click to leave &ldquo;Thanks&rdquo; for this post"/>
             </div><div id="ajax_loader_4550_2" style="display:inline;visibility: hidden;"><img alt="ajax loader" src="http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/ajax-loader.gif" /></div></div><p><strong>Abstract.</strong> We present a weak sufficient condition for the existence of Souslin trees at successor of regular cardinals. The result is optimal and simultaneously improves an old theorem of Gregory and a more recent theorem of the author.</p>
<p><strong>Downloads:</strong></p>
<p><table class=paperruler"><tr><td><a onclick="thankYouButtonClick(4550, '')"  href="http://www.assafrinot.com/files/paper37.pdf" class="billet_author"></a><a onclick="thankYouButtonClick(4550, '')" href="https://arxiv.org/abs/1812.08743" class="billet_arxiv"></a><a onclick="thankYouButtonClick(4550, '')" href="https://doi.org/10.1002/malq.201800065" class="billet_publish"></a><img src="/design/004_review_dis.png"  class="opacity_icons" height=90 width=64 border=1  alt="[No entry on mathscinet]" title="No entry on mathscinet"  /><a onclick="thankYouButtonClick(4550, '')" href="http://www.assafrinot.com/talk/asl2017" class="billet_slides"></a><a href="http://www.assafrinot.com/paper/24" class="billet_further"></a><a href="http://papers.assafrinot.com/list.php?bib=rinot.bib&key=paper37" class="billet_bibtex"></a><a href="http://www.assafrinot.com/paper/37" class="billet_perm"></a></td></tr></table></p>
<p><strong>Citation information:</strong></p>
<p>A. Rinot, <em>Souslin trees at successors of regular cardinals</em>, Math. Log. Q., 65(2): 200-204, 2019.</p>
<p><span id="more-4550"></span></p>]]></summary>
        <author>
            <name>Assaf Rinot</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How does the size of a cookie depend on the size of the ball of dough?]]></title>
        <id>https://mikepawliuk.ca/2018/09/23/how-does-the-size-of-a-cookie-depend-on-the-size-of-the-ball-of-dough/</id>
        <link href="https://mikepawliuk.ca/2018/09/23/how-does-the-size-of-a-cookie-depend-on-the-size-of-the-ball-of-dough/">
        </link>
        <updated>2018-09-24T04:39:42Z</updated>
        <summary type="html"><![CDATA[<p>This term I&#8217;m teaching Calculus 3 which involves learning about the concept of <strong>curvature</strong>. This is a measurement of how bendy or curvy something is. The flatter something is, the less curvature it has.</p>
<p>We learn in class that a circle or sphere of radius r has curvature inversely proportional to its radius, that is it has curvature <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7Br%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;frac{1}{r}" title="&#92;frac{1}{r}" class="latex" />.</p>
<p>In this class we used baking cookies to illustrate how the curvature of an object can change over time. Seen from over top, a ball of cookie dough flattens out as it bakes.</p>
<p><img data-attachment-id="1777" data-permalink="https://mikepawliuk.ca/2018/09/23/how-does-the-size-of-a-cookie-depend-on-the-size-of-the-ball-of-dough/giphy/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/09/giphy.gif" data-orig-size="963,542" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="giphy" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/09/giphy.gif?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/09/giphy.gif?w=660" class="alignnone size-full wp-image-1777" src="https://mikepawliuk.files.wordpress.com/2018/09/giphy.gif?w=660" alt="giphy"   /></p>
<p>This got me thinking about how <em>exactly</em> is the size of the ball of cookie dough related to the size of the cookie you get in the end? So I did some science.</p>
<p><span id="more-1776"></span></p>
<h2>The recipe</h2>
<p>A student in my class provided me with the following recipe:</p>
<div class="d2l_1_76_295 d2l_1_77_59 d2l_1_78_590 d2l_1_19_438">
<div class="d2l-htmlblock d2l-htmlblock-deferred d2l-htmlblock-untrusted">
<blockquote><p>Here&#8217;s a simple peanut butter recipe that&#8217;s safe for people with gluten and/or dairy allergies:</p>
<p>If change in curvature is desired:</p>
<ul>
<li>1 cup peanut butter</li>
<li>3/4 &#8211; 1 cup sugar</li>
<li>1 egg</li>
<li>1 tsp baking soda</li>
<li>tiny splash of vinegar</li>
<li>tiny pinch of salt</li>
</ul>
<p>Preheat oven to 350 degrees. Roll dough into balls and place on cookie sheet. Bake for ~10-12 minutes.</p>
<p>For those who desire nearly constant curvature:</p>
<ul>
<li>1 cup peanut butter</li>
<li>1 cup sugar</li>
<li>1 egg</li>
<li>pinch of salt</li>
</ul>
<p>Preheat oven to 350 degrees. Roll dough into balls, place on cookie sheet and flatten to desired curvature with fork. Bake for ~10-12 minutes.</p></blockquote>
<p><img data-attachment-id="1778" data-permalink="https://mikepawliuk.ca/2018/09/23/how-does-the-size-of-a-cookie-depend-on-the-size-of-the-ball-of-dough/cookie1/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie1.jpg" data-orig-size="4160,1317" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1039348800&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.79&quot;,&quot;iso&quot;:&quot;700&quot;,&quot;shutter_speed&quot;:&quot;0.05&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="cookie1" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie1.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie1.jpg?w=660" class="alignnone size-full wp-image-1778" src="https://mikepawliuk.files.wordpress.com/2018/09/cookie1.jpg?w=660" alt="cookie1" srcset="https://mikepawliuk.files.wordpress.com/2018/09/cookie1.jpg?w=660 660w, https://mikepawliuk.files.wordpress.com/2018/09/cookie1.jpg?w=1320 1320w, https://mikepawliuk.files.wordpress.com/2018/09/cookie1.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/09/cookie1.jpg?w=300 300w, https://mikepawliuk.files.wordpress.com/2018/09/cookie1.jpg?w=768 768w, https://mikepawliuk.files.wordpress.com/2018/09/cookie1.jpg?w=1024 1024w" sizes="(max-width: 660px) 100vw, 660px"   /></p>
<p>After mixing everything together (using 3/4 cup sugar), since I used natural peanut butter the dough was too goopy to form into balls. So I made the following additions:</p>
<ul>
<li>1/2 cut oats</li>
<li>1/4 cup cricket powder (for protein)</li>
<li>1 tsp cinnamon</li>
</ul>
<h2>Baking and data</h2>
<p>For my first batch I planned to take them out after 11 minutes, but they needed additional time, so I left them in the oven for an additional 5 minutes. This could potentially introduce some <a href="https://www.npr.org/sections/money/2016/01/15/463237871/episode-677-the-experiment-experiment">p-value hacking</a> because I changed my experiment in the middle of it. I don&#8217;t think the additional time changed the shape of the cookies, just how gooey they were in the inside.</p>
<figure data-shortcode="caption" id="attachment_1779" aria-describedby="caption-attachment-1779" style="width: 4160px" class="wp-caption alignnone"><img data-attachment-id="1779" data-permalink="https://mikepawliuk.ca/2018/09/23/how-does-the-size-of-a-cookie-depend-on-the-size-of-the-ball-of-dough/cookie2/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie2.jpg" data-orig-size="4160,1533" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1039348800&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.79&quot;,&quot;iso&quot;:&quot;700&quot;,&quot;shutter_speed&quot;:&quot;0.05&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="cookie2" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie2.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie2.jpg?w=660" class="alignnone size-full wp-image-1779" src="https://mikepawliuk.files.wordpress.com/2018/09/cookie2.jpg?w=660" alt="cookie2" srcset="https://mikepawliuk.files.wordpress.com/2018/09/cookie2.jpg?w=660 660w, https://mikepawliuk.files.wordpress.com/2018/09/cookie2.jpg?w=1320 1320w, https://mikepawliuk.files.wordpress.com/2018/09/cookie2.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/09/cookie2.jpg?w=300 300w, https://mikepawliuk.files.wordpress.com/2018/09/cookie2.jpg?w=768 768w, https://mikepawliuk.files.wordpress.com/2018/09/cookie2.jpg?w=1024 1024w" sizes="(max-width: 660px) 100vw, 660px"   /><figcaption id="caption-attachment-1779" class="wp-caption-text">Batch 1 (Before)</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1780" aria-describedby="caption-attachment-1780" style="width: 4160px" class="wp-caption alignnone"><img data-attachment-id="1780" data-permalink="https://mikepawliuk.ca/2018/09/23/how-does-the-size-of-a-cookie-depend-on-the-size-of-the-ball-of-dough/cookie21/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie21.jpg" data-orig-size="4160,2526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1039348800&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.79&quot;,&quot;iso&quot;:&quot;1600&quot;,&quot;shutter_speed&quot;:&quot;0.1&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="cookie21" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie21.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie21.jpg?w=660" class="alignnone size-full wp-image-1780" src="https://mikepawliuk.files.wordpress.com/2018/09/cookie21.jpg?w=660" alt="cookie21" srcset="https://mikepawliuk.files.wordpress.com/2018/09/cookie21.jpg?w=660 660w, https://mikepawliuk.files.wordpress.com/2018/09/cookie21.jpg?w=1320 1320w, https://mikepawliuk.files.wordpress.com/2018/09/cookie21.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/09/cookie21.jpg?w=300 300w, https://mikepawliuk.files.wordpress.com/2018/09/cookie21.jpg?w=768 768w, https://mikepawliuk.files.wordpress.com/2018/09/cookie21.jpg?w=1024 1024w" sizes="(max-width: 660px) 100vw, 660px"   /><figcaption id="caption-attachment-1780" class="wp-caption-text">Batch 1 (After)</figcaption></figure>
<p>I got the following results for Batch 1:</p>
<table>
<tbody>
<tr>
<td><strong>Diameter of dough ball (cm)</strong></td>
<td><strong>Diameter of cookie (cm)</strong></td>
</tr>
<tr>
<td> 2</td>
<td>4.5</td>
</tr>
<tr>
<td>2</td>
<td>4.5</td>
</tr>
<tr>
<td>2.5</td>
<td>5</td>
</tr>
<tr>
<td>3</td>
<td>6</td>
</tr>
<tr>
<td>3</td>
<td>6.5</td>
</tr>
<tr>
<td>3</td>
<td>6</td>
</tr>
<tr>
<td>3.5</td>
<td>6.5</td>
</tr>
<tr>
<td>3.5</td>
<td>7</td>
</tr>
<tr>
<td>4</td>
<td>8</td>
</tr>
<tr>
<td>3.5</td>
<td>8</td>
</tr>
<tr>
<td>4</td>
<td>8</td>
</tr>
<tr>
<td>4.5</td>
<td>9.5</td>
</tr>
<tr>
<td>5.5</td>
<td>11</td>
</tr>
</tbody>
</table>
<p>The three biggest cookies pushed into each other and didn&#8217;t spread out completely. This made them a little more square than they should have been.</p>
<p>Batch 2 was in for a full 16 minutes, but it needed even more time! I put them in for an additional 4 minutes.</p>
<figure data-shortcode="caption" id="attachment_1781" aria-describedby="caption-attachment-1781" style="width: 4002px" class="wp-caption alignnone"><img data-attachment-id="1781" data-permalink="https://mikepawliuk.ca/2018/09/23/how-does-the-size-of-a-cookie-depend-on-the-size-of-the-ball-of-dough/cookie3/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie3.jpg" data-orig-size="4002,2031" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1039348800&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.79&quot;,&quot;iso&quot;:&quot;2400&quot;,&quot;shutter_speed&quot;:&quot;0.1&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="cookie3" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie3.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie3.jpg?w=660" class="alignnone size-full wp-image-1781" src="https://mikepawliuk.files.wordpress.com/2018/09/cookie3.jpg?w=660" alt="cookie3" srcset="https://mikepawliuk.files.wordpress.com/2018/09/cookie3.jpg?w=660 660w, https://mikepawliuk.files.wordpress.com/2018/09/cookie3.jpg?w=1320 1320w, https://mikepawliuk.files.wordpress.com/2018/09/cookie3.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/09/cookie3.jpg?w=300 300w, https://mikepawliuk.files.wordpress.com/2018/09/cookie3.jpg?w=768 768w, https://mikepawliuk.files.wordpress.com/2018/09/cookie3.jpg?w=1024 1024w" sizes="(max-width: 660px) 100vw, 660px"   /><figcaption id="caption-attachment-1781" class="wp-caption-text">Batch 2 (Before)</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1782" aria-describedby="caption-attachment-1782" style="width: 3511px" class="wp-caption alignnone"><img data-attachment-id="1782" data-permalink="https://mikepawliuk.ca/2018/09/23/how-does-the-size-of-a-cookie-depend-on-the-size-of-the-ball-of-dough/cookie4/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie4.jpg" data-orig-size="3511,1924" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1039348800&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.79&quot;,&quot;iso&quot;:&quot;1100&quot;,&quot;shutter_speed&quot;:&quot;0.1&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="cookie4" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie4.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie4.jpg?w=660" class="alignnone size-full wp-image-1782" src="https://mikepawliuk.files.wordpress.com/2018/09/cookie4.jpg?w=660" alt="cookie4" srcset="https://mikepawliuk.files.wordpress.com/2018/09/cookie4.jpg?w=660 660w, https://mikepawliuk.files.wordpress.com/2018/09/cookie4.jpg?w=1320 1320w, https://mikepawliuk.files.wordpress.com/2018/09/cookie4.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/09/cookie4.jpg?w=300 300w, https://mikepawliuk.files.wordpress.com/2018/09/cookie4.jpg?w=768 768w, https://mikepawliuk.files.wordpress.com/2018/09/cookie4.jpg?w=1024 1024w" sizes="(max-width: 660px) 100vw, 660px"   /><figcaption id="caption-attachment-1782" class="wp-caption-text">Batch 2 (After)</figcaption></figure>
<p>Here are those results:</p>
<table>
<tbody>
<tr>
<td><strong>Diameter of dough ball (cm)</strong></td>
<td><strong>Diameter of cookie (cm)</strong></td>
</tr>
<tr>
<td>5.5</td>
<td>11</td>
</tr>
<tr>
<td>6.5</td>
<td>14.5</td>
</tr>
</tbody>
</table>
<p>The biggest cookie was pretty unstable at first, but after leaving it on the pan a little longer it firmed up.</p>
<h2>Data analysis and results</h2>
<p>Here&#8217;s what the cookies look like stacked from largest diameter to smallest.</p>
<p><img data-attachment-id="1783" data-permalink="https://mikepawliuk.ca/2018/09/23/how-does-the-size-of-a-cookie-depend-on-the-size-of-the-ball-of-dough/cookie6/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie6.jpg" data-orig-size="1873,3149" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1039348800&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.79&quot;,&quot;iso&quot;:&quot;800&quot;,&quot;shutter_speed&quot;:&quot;0.058823529411765&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="cookie6" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie6.jpg?w=178" data-large-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie6.jpg?w=609" class=" size-large wp-image-1783 aligncenter" src="https://mikepawliuk.files.wordpress.com/2018/09/cookie6.jpg?w=609&#038;h=1024" alt="cookie6" width="609" height="1024" srcset="https://mikepawliuk.files.wordpress.com/2018/09/cookie6.jpg?w=609&amp;h=1024 609w, https://mikepawliuk.files.wordpress.com/2018/09/cookie6.jpg?w=1218&amp;h=2048 1218w, https://mikepawliuk.files.wordpress.com/2018/09/cookie6.jpg?w=89&amp;h=150 89w, https://mikepawliuk.files.wordpress.com/2018/09/cookie6.jpg?w=178&amp;h=300 178w, https://mikepawliuk.files.wordpress.com/2018/09/cookie6.jpg?w=768&amp;h=1291 768w" sizes="(max-width: 609px) 100vw, 609px" /></p>
</div>
<p>&nbsp;</p>
<p>Of course I had to plot this data, so I did and got the following line of best fit:</p>
<figure data-shortcode="caption" id="attachment_1786" aria-describedby="caption-attachment-1786" style="width: 640px" class="wp-caption alignnone"><img data-attachment-id="1786" data-permalink="https://mikepawliuk.ca/2018/09/23/how-does-the-size-of-a-cookie-depend-on-the-size-of-the-ball-of-dough/cookie_line2/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie_line2.png" data-orig-size="640,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cookie_line2" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie_line2.png?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/09/cookie_line2.png?w=640" class="alignnone size-full wp-image-1786" src="https://mikepawliuk.files.wordpress.com/2018/09/cookie_line2.png?w=660" alt="cookie_line2" srcset="https://mikepawliuk.files.wordpress.com/2018/09/cookie_line2.png 640w, https://mikepawliuk.files.wordpress.com/2018/09/cookie_line2.png?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/09/cookie_line2.png?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"   /><figcaption id="caption-attachment-1786" class="wp-caption-text">Line of best fit is <img src="https://s0.wp.com/latex.php?latex=y%3D2.01x-0.1&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="y=2.01x-0.1" title="y=2.01x-0.1" class="latex" />, with standard deviation 0.1 and a very small p-value.</figcaption></figure>
<p>In English:</p>
<blockquote><p>The <strong>diameter</strong> of a cookie is <strong>twice</strong> the diameter of the ball of dough used to make it.</p></blockquote>
<p>In terms of radius, since the radius is half the diameter, and they compound, we get:</p>
<blockquote><p>The <strong>radius</strong> of the cookie is <strong>four times</strong> the radius of the ball of dough.</p></blockquote>
<p>Since curvature is inversely proportional to curvature, we get:</p>
<blockquote><p>The <strong>curvature</strong> of the cookie is a quarter the curvature of the ball of dough.</p></blockquote>
<h2>Conclusions</h2>
<p>I think we can actually make some interesting conclusions about this.</p>
<blockquote><p>What size cookies should I make to avoid wasted space on my cookie sheet?</p></blockquote>
<p>It turns out that by using this relationship between the size of the dough ball and the size of the cookie, if you have a fixed amount of dough V, and a fixed area of your cookie sheet you should make:</p>
<blockquote><p><img src="https://s0.wp.com/latex.php?latex=n%3D%5Cfrac%7B%5Cpi%5E2+A%5E3%7D%7B2304+V%5E2+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="n=&#92;frac{&#92;pi^2 A^3}{2304 V^2 }" title="n=&#92;frac{&#92;pi^2 A^3}{2304 V^2 }" class="latex" /> cookies of diameter <img src="https://s0.wp.com/latex.php?latex=d+%3D+%5Cfrac%7B24V%7D%7B%5Cpi+A%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="d = &#92;frac{24V}{&#92;pi A}" title="d = &#92;frac{24V}{&#92;pi A}" class="latex" />.</p></blockquote>
<p>I hope you had as much fun as I did! Thanks for reading.</p>
<p>Thanks to Robert Fajber for improvements to the graph, and Jessie Lamontagne for further directions and questions.</p>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>Math Appendix</h2>
<p>If you&#8217;re interested in the nitty-gritty details about how I came up with those formulas, here they are.</p>
<p>Fix <img src="https://s0.wp.com/latex.php?latex=A%2CV&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="A,V" title="A,V" class="latex" />. Assume we want n cookies of diameter D ( that start with diameter d). We know <img src="https://s0.wp.com/latex.php?latex=2d+%3D+D&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="2d = D" title="2d = D" class="latex" />. We want to space out the cookies so that their bounding squares do not overlap. These squares give us</p>
<p><img src="https://s0.wp.com/latex.php?latex=A+%3D+nD%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="A = nD^2" title="A = nD^2" class="latex" /></p>
<p>The volume of the dough gives us</p>
<p><img src="https://s0.wp.com/latex.php?latex=V+%3D+n+%5Cfrac%7B4%5Cpi%7D%7B3%7D+%28%5Cfrac%7Bd%7D%7B2%7D%29%5E3+%3D+n+%5Cfrac%7B4%5Cpi%7D%7B3%7D%28%5Cfrac%7BD%7D%7B4%7D%29%5E3+%3D+n+%5Cfrac%7B%5Cpi%7D%7B48%7DD%5E3&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="V = n &#92;frac{4&#92;pi}{3} (&#92;frac{d}{2})^3 = n &#92;frac{4&#92;pi}{3}(&#92;frac{D}{4})^3 = n &#92;frac{&#92;pi}{48}D^3" title="V = n &#92;frac{4&#92;pi}{3} (&#92;frac{d}{2})^3 = n &#92;frac{4&#92;pi}{3}(&#92;frac{D}{4})^3 = n &#92;frac{&#92;pi}{48}D^3" class="latex" /></p>
<p>This is two equations and two unknowns. Solving that gives us the desired formulas for D and n. Then we related D back to d.</p>]]></summary>
        <author>
            <name>Mike Pawliuk – Mathematics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Five Star Theorems]]></title>
        <id>http://karagila.org/2018/five-star-theorems/</id>
        <link href="http://karagila.org/2018/five-star-theorems/">
        </link>
        <updated>2018-08-24T15:35:13Z</updated>
        <summary type="html"><![CDATA[<p>Talks. Giving talks. We usually don't give talks about past research. Talks are meant to present recent research, things you've just finished, that you're finishing right now, that 
you've found out!</p>

<p>So often times, it seems, it is very tempting to talk about theorems that you haven't finished writing their proofs in full. Usaully, we put &quot;work in progress&quot; to indicate that this 
is something not fully verified, not fully vetted (at the very least by ourselves). <a href="http://karagila.org/2018/five-star-theorems/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11th Young Set Theory Workshop, June 2018]]></title>
        <id>http://blog.assafrinot.com/?p=4537</id>
        <link href="http://blog.assafrinot.com/?p=4537">
        </link>
        <updated>2018-06-30T18:49:57Z</updated>
        <summary type="html"><![CDATA[<div class="thanks_button_div" 
                  style="margin-bottom: 30px;"><div id="thanksButtonDiv_4537_2" style="background-image:url(http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/thanks_compact_brown1.png); background-repeat:no-repeat; float: left; display: inline;"
                onmouseover="javascript:thankYouChangeButtonImage('thanksButtonDiv_4537_2', true);" 
                onmouseout="javascript:thankYouChangeButtonImage('thanksButtonDiv_4537_2', false);"
                onclick="javascript:thankYouChangeButtonImage('thanksButtonDiv_4537_2', false);" >
                <input type="button" onclick="thankYouButtonClick(4537, 'You left &ldquo;Thanks&rdquo; already for this post')" value="Like 25"
                  class="thanks_button thanks_compact thanks_brown"
                  style="  font-family: Verdana, Arial, Sans-Serif; font-size: 14px; font-weight: normal;; color:#ffffff;"
                  id="thanksButton_4537_2" title="Click to leave &ldquo;Thanks&rdquo; for this post"/>
             </div><div id="ajax_loader_4537_2" style="display:inline;visibility: hidden;"><img alt="ajax loader" src="http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/ajax-loader.gif" /></div></div><p>I gave a 4-lecture tutorial at the <a href="http://youngsettheory2018.altervista.org/index.php">11th Young Set Theory Workshop</a>, Lausanne, June 2018.</p>
<p><strong>Title:</strong> In praise of C-sequences.</p>
<p><strong>Abstract. </strong> Ulam and Solovay showed that any stationary set may be split into two. Is it also the case that any fat set may be split into two? Shelah and Ben-David proved that, assuming GCH, if the successor of a singular cardinal carries a special Aronszajn tree, then it also carries a distributive Aronszajn tree. What happens if we relax &#8220;special Aronszajn&#8221; to just &#8220;Aronszajn&#8221;? Shelah proved that the product of two $\omega_2$-cc posets need not be $\omega_2$-cc. How about the product of countably many $\omega_2$-Knaster posets?</p>
<p>It turns out that a common strategy for answering all of the above questions is the study of C-sequences. In this series of lectures, we shall provide a toolbox for constructing C-sequences, and unveil a spectrum of applications.</p>
<p><strong>Downloads:</strong></p>
<p><table class=paperruler"><tr><td><a onclick="thankYouButtonClick(4537, '')" href="http://www.assafrinot.com/files/rinot_yst2018.pdf" class="billet_slides"></a><a href="http://www.assafrinot.com/paper/34" class="billet_further"></a><a href="http://www.assafrinot.com/talk/yst2018" class="billet_perm"></a></td></tr></table></p>
<p><span id="more-4537"></span></p>]]></summary>
        <author>
            <name>Assaf Rinot</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[IMO resources for Graph Theory]]></title>
        <id>https://mikepawliuk.ca/2018/06/24/imo-resources-for-graph-theory/</id>
        <link href="https://mikepawliuk.ca/2018/06/24/imo-resources-for-graph-theory/">
        </link>
        <updated>2018-06-24T17:47:29Z</updated>
        <summary type="html"><![CDATA[<p>I will be participating as a trainer for Canada&#8217;s 2018 IMO Summer Training camp. I&#8217;m giving a session on graph theory. As I prepared my notes I found many resources online that already cover some aspects of graph theory. So here are those resources:</p>
<h2><a href="http://euclid.ucc.ie/mathenr/IMOTraining/2008SummerCamp-AdrianTang-GraphTheory.pdf">&#8220;IMO Training 2008: Graph Theory&#8221; by Adrian Tung.</a></h2>
<p>This is an in-depth description of the basic combinatorial and geometric techniques in graph theory. It is a very thorough and helpful document with many Olympiad level problems for each topic. (No solutions are given.)</p>
<p>Topics include:</p>
<ol>
<li>Trees and Balancing</li>
<li>Friends, Strangers and Cliques</li>
<li>Directed Graphs and Tournaments</li>
<li>Matchings</li>
<li>Hamiltonian/Eulerian Paths/Cycles</li>
</ol>
<h2><a href="http://www.math.cmu.edu/~lohp/docs/math/mop2008/graph-theory-soln.pdf">&#8220;Graph Theory&#8221; by Po-Shen Lo. (2008)</a></h2>
<p>A large collection of problems and topics almost all of which have solutions or hints.</p>
<p>Topics include:</p>
<ol>
<li>Basic facts</li>
<li>Extremal Graph Theory</li>
<li>Matchings</li>
<li>Ramsey Theory</li>
<li>Planarity</li>
</ol>
<h2><a href="https://321da88a-a-62cb3a1a-s-sites.googlegroups.com/site/imocanada/2014-winter-camp/Graph%20Theory%20-%20Matthew%20Brennan%20-%202014%20winter%20camp.pdf?attachauth=ANoY7crZrgFzj1lbqst28kD-pT2TfTYu6_1ncydc5SpmEgNP8R_S1b1-ZzINpx1MQgqD5lPx9S8bVBP8CeeZURav22VfS__NlwDPitjVD-IAWKZbpDrtyU69SOUOCtnjpwC0ubjG6TGKzb0QHe4XQtTfKcZ9y6Cp1sUa83ct-MbDwgIk6CswNZJ36OQdxJpIld6qIK7E0DgWuuoRmK7HSExY-jt-0RVW8cksnc8DnNhYvTgjtgjVrJVtWiDW4n2vfO5oamlEBWe88mScP6Fi2pzdEBg0Uu3KX0oMICJNjfebrNndhJQOpMY%3D&amp;attredirects=0">&#8220;Graph Theory&#8221; by Matthew Brennan. (Canada Winter Camp, 2014)</a></h2>
<p>Contains a concise list of important results together with a guided discussion to five example problems that use graph theory.</p>
<h2><a href="https://docs.google.com/viewer?a=v&amp;pid=sites&amp;srcid=ZGVmYXVsdGRvbWFpbnxpbW9jYW5hZGF8Z3g6OThkMWRhZDA2MGYzODhh">&#8220;Probabilistic Method/Graph Theory&#8221; by James Rickards. (Canada Summer Camp, 2015)</a></h2>
<p>An introduction to the probabilistic method in graph theory along with 10 problems.</p>
<h2><a href="http://sms.math.nus.edu.sg/simo/training2003/smograph.pdf">&#8220;SIMO Graph Theory Training&#8221;. (SIMO training 2003)</a></h2>
<p>A list of about 30 problems and solutions in graph theory.</p>
<p>Topics:</p>
<ol>
<li>Graph Theory</li>
<li>Coloring problems</li>
</ol>
<h2><a href="https://www.jstor.org/stable/3621841?seq=1#page_scan_tab_contents">&#8220;Ramsey Theory and the IMO&#8221; by Ben Green. (2008)</a></h2>
<p>This is a 4 page article that introduces Ramsey Theory for graphs and arithmetic progressions and its historical relation to the IMO.</p>
<h2><a href="https://www.cut-the-knot.org/proofs/two_color.shtml">&#8220;Coloring Points&#8221; at Cut-the-knot</a></h2>
<p>A collection of 12 topics about coloring graphs and planes. There are many problems with solutions.</p>
<h2><a href="http://robertborgersen.info/Presentations/GS-05R-1.pdf">&#8220;Equivalence of seven major theorems in combinatorics&#8221; by Robert Borgersen (2004).</a></h2>
<p>This series of slides states 7 results in extremal combinatorics that are really the same.</p>
<p>Topics:</p>
<ol>
<li>Dilworth&#8217;s Theorem</li>
<li>Konig&#8217;s Bipartite Theorem</li>
<li>Hall&#8217;s Marriage Theorem</li>
<li>Menger&#8217;s Theorem</li>
<li>(Others)</li>
</ol>]]></summary>
        <author>
            <name>Mike Pawliuk – Mathematics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Definable Models Without Choice]]></title>
        <id>http://karagila.org/2018/definable-models-without-choice/</id>
        <link href="http://karagila.org/2018/definable-models-without-choice/">
        </link>
        <updated>2018-06-07T22:48:13Z</updated>
        <summary type="html"><![CDATA[<p>Suppose that a parameter formula defines an inner model. Does that inner model satisfy choice?</p>

<p>Well, obviously, if choice failed then the answer is no, just by taking \(x=x\). But what if we remove that option. Namely, if the inner model is not the entire universe, then choice 
holds. <a href="http://karagila.org/2018/definable-models-without-choice/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Booles' Rings is dead, long live Booles' Rings!]]></title>
        <id>https://www.peterkrautzberger.org/0206/</id>
        <link href="https://www.peterkrautzberger.org/0206/">
        </link>
        <updated>2018-05-31T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Yesterday, <a href="http://scoskey.org/">Sam</a> and I removed all remaining WordPress installations that we were hosting for people that are part of <a href="https://boolesrings.org/">Booles' Rings</a>, including the original multisite installations that <a href="https://www.peterkrautzberger.org/0069/">started it all</a>.</p>
<h2>Boole's Rings is dead</h2>
<p>My regular meetings with Sam are one of my great pleasures. Since our friendship is almost exclusively virtual, it's surprising that we have kept it alive for quite a while now. Almost weekly, we get on video to work on new ideas or and projects - or just chitchat about life, work and being young parents (or parents of young kids anyway).</p>
<p>Perhaps unsurprisingly given that we met at a <a href="https://www.peterkrautzberger.org/0054/">Young Set Theory Workshop</a>, it all started with us setting up Set Theory Talks which grew turned into <a href="http://settheory.mathtalks.org/">settheory.mathtalks.org</a> (and you can get a subdomain with the same semi-automatic features if you like). Nowadays, <a href="http://blog.assafrinot.com/">Assaf</a> is handling the real work of grooming the site while Sam and I continue the little bits of technical support as needed. Later, I pulled Sam into maintaining <a href="https://mathblogging.org/">mathblogging.org</a> with me after Fred and Felix dropped out.</p>
<p>I suppose it was inevitable ever since I left research 6 years ago.  But, really, life just got busier and hosting more complex so late last year, Sam and I decided that we do not have the time (nor the abilities) to continue hosting more and more sites. We let everyone know what's happening and helped them in their transitions.</p>
<p>Yesterday, we pulled the plug on all the WordPress goodness we had built over the years. And thus, Booles' Rings has passed - in its original form, a literal network of WordPress sites for academics.</p>
<h2>Long live Booles' Ring!</h2>
<p>Of course, none of the sites have disappeared. In many ways we're now where I wanted to get everyone to: not just researchers taking the web seriously as a fixed point of a research career, building a stable presence of one's research persona, overcoming the cacophony of ever-changing, dead-or-dying department pages where Google page rank inevitably yields the outdated ones.</p>
<p>No, I always wanted more: get researchers to take this platform seriously, embrace it as a medium with new (and old) idiosyncrasies. Take it seriously as a tool that you should wield confidently and, in need, wield independently, no matter what. No more lock in.</p>
<p>And this is where Booles' Rings is now. The people are still here, the site now merely works as lightweight connection (and an aggregator). And no matter how we all approach this medium, it's fine. Whether it's self-hosted WordPress installations or statically generated sites, whether slow-churning long form or near-daily activity, whether research-only or life's breadth. The point is not that one thing is better than the other. The point is that we are on the web, our shared and world wide web - and that we're here to stay.</p>
<p>Even though I left research years ago, I still love to follow this community. I look forward to the next 7 years of Booles' Rings.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Experimenting with fractions for the web]]></title>
        <id>https://www.peterkrautzberger.org/0205/</id>
        <link href="https://www.peterkrautzberger.org/0205/">
        </link>
        <updated>2018-05-29T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I just got back from a week in San Jose at the <a href="https://aimath.org/workshops/upcoming/webmath/">AIM workshop on web accessibility of mathematics</a>. It was an intense week for me and there's a ton to write about.</p>
<p>This morning I came back to something I had drafted after Joanmarie Diggs proposed a session on a particular hack (but the group didn't end up focusing on this in the unconference-style workshop setting).</p>
<h2>That's not a fraction. <em>That's</em> a fraction!</h2>
<p>One of my <a href="https://www.peterkrautzberger.org/0205/0199/">go</a>-<a href="https://www.peterkrautzberger.org/0205/0196/">to</a> <a href="https://www.peterkrautzberger.org/0205/0192/">examples</a> when explaining that Presentation MathML is devoid of semantics is the <code>&lt;mfrac&gt;</code> element. While it clearly hints at being a fraction, the spec itself <a href="https://www.w3.org/TR/2014/REC-MathML3-20140410/chapter3.html#presm.mfrac">clearly states</a> that it is not, semantically, a fraction but that it may be used for completely different things that visually look like fractions, e.g., binomial coefficients or the Legendre symbol; in fact, you can find many even less fraction-like examples (such as logical deductions) in the wild because a vertical stack with a properly aligned line is simply a neat layout feature.</p>
<p>Since Presentation MathML never specifies semantics, let's look how Content MathML encodes fractions. The <a href="https://www.w3.org/TR/2014/REC-MathML3-20140410/chapter4.html#contm.cn">spec</a> would have you write something like <code>&lt;cn type=&quot;rational&quot;&gt;22&lt;sep/&gt;7&lt;/cn&gt;</code>. It's a terribly good example for how Content MathML is a bit too strong in its abstraction for human communication (also, check the transcription to Presentation MathML). As an aside, if you need more examples of why <code>&lt;mfrac&gt;</code> is not meaningful, just search that section.</p>
<h2>Hacking tips for accessibility experiments</h2>
<p>Anyway, at the workshop Joanie had proposed the following. It turns out, Firefox is <s>too lazy</s> <em>ahem</em> too performance-oriented to sanitize invalid ARIA roles. This allows you to experiment with made-up properties fairly easily (assuming you can modify your screenreader of choice).</p>
<p>So for example, you could slap an <code>aria-math</code> attribute to your markup and this would show up in OS-level accessibility inspectors such as <a href="https://developer.paciellogroup.com/resources/aviewer/">aViewer</a> or <a href="https://help.gnome.org/users/accerciser/stable/introduction.html.en">accerciser</a>. What Joanie had in mind (I believe) is that we could have tried to expose additional information this way so that Joanie could hack something into <a href="https://help.gnome.org/users/orca/stable/index.html.en">ORCA</a> and then get Mick and Reef to modify <a href="https://www.nvaccess.org/">NVDA</a> or David to modify <a href="http://www.chromevox.com/">ChromeVox</a> (and maybe even hear what Glen thinks of it from a JAWS perspective). And yes, all these incredible people were actually there in person.</p>
<h2>To fractinity, and beyond!</h2>
<p>Since an idea that I had proposed to the group (exploring web components for mathematical documents) also didn't stick, I thought I'd combine the two when I get the chance. Luckily, I had a long flight home.</p>
<p><span lang="fr">Et voilà</span>, a custom element fraction that adds <code>aria-math</code> roles to itself magically (using <code>fraction</code>, <code>numerator</code>, <code>denominator</code> and<code>fraction-line</code>).</p>
<p data-height="265" data-theme-id="0" data-slug-hash="MGdmQj" data-default-tab="html,result" data-user="pkra" data-embed-version="2" data-pen-title="AIM Workshop custom element: fraction" class="codepen">See the Pen <a href="https://codepen.io/pkra/pen/MGdmQj/">AIM Workshop custom element: fraction</a> by Peter Krautzberger (<a href="https://codepen.io/pkra">@pkra</a>) on <a href="https://codepen.io/">CodePen</a>.</p>
<script async="" src="https://static.codepen.io/assets/embed/ei.js"></script>
<p>It's not much and not really a &quot;document&quot;-level element as I was thinking about (then again, Joanie had hoped for improving an <code>&lt;mfrac&gt;</code> directly) but it's a nice (non-functional) concept, and perhaps helpful when thinking about ARIA <code>role-description</code>.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[My teaching advice and resources (so far)]]></title>
        <id>https://mikepawliuk.ca/2018/05/11/my-teaching-advice-and-resources-so-far/</id>
        <link href="https://mikepawliuk.ca/2018/05/11/my-teaching-advice-and-resources-so-far/">
        </link>
        <updated>2018-05-12T02:57:35Z</updated>
        <summary type="html"><![CDATA[<p>As I general rule I find thinking about math pedagogy deeply rewarding. Teaching a technical and beautiful discipline like math is difficult to do well. Students come from all sorts of backgrounds, the material can be challenging, and there are tons of moving parts in a course. It&#8217;s a challenge that I find exhilarating.</p>
<p>On the other hand, I find the act of reading the scholarship of math education to be dreadful and unpleasant. It is filled with jargon and hero-worship.</p>
<p>That being said, I&#8217;ve been extremely lucky to have great mentors and colleagues to bounce ideas off of. I&#8217;ve collected some of this advice in <a href="https://www.reddit.com/r/matheducation/comments/8iqlxt/math_pedagogy/dyue9fd/">a Reddit post</a>, which I&#8217;ll recreate here.</p>
<p><span id="more-1748"></span><br />
<img data-attachment-id="1749" data-permalink="https://mikepawliuk.ca/2018/05/11/my-teaching-advice-and-resources-so-far/tools-2145770_640/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/05/tools-2145770_640.jpg" data-orig-size="640,334" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;5.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;X-A2&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;16&quot;,&quot;iso&quot;:&quot;640&quot;,&quot;shutter_speed&quot;:&quot;0.05&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tools-2145770_640" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/05/tools-2145770_640.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/05/tools-2145770_640.jpg?w=640" class=" size-full wp-image-1749 aligncenter" src="https://mikepawliuk.files.wordpress.com/2018/05/tools-2145770_640.jpg?w=660" alt="tools-2145770_640" srcset="https://mikepawliuk.files.wordpress.com/2018/05/tools-2145770_640.jpg 640w, https://mikepawliuk.files.wordpress.com/2018/05/tools-2145770_640.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/05/tools-2145770_640.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<h2>Concepts that I&#8217;ve found useful</h2>
<p>Here is some vocabulary that is commonly used when discussing math pedagogy, or pedagogy in general. In general the literature is pretty annoying and frustrating; there&#8217;s lots of jargon and lots of stuff is too-high level.</p>
<ul>
<li><strong>Active learning</strong>. Is the primary activity in your classroom listening and writing, or discussing and thinking? This could be anything from students working on calculations in-class, to group discussions. <strong>Teaching math is not about convincing your students that you the instructor know the material</strong>, it&#8217;s about helping the students learn the material.</li>
<li><strong>Scaffolding</strong>. This is the technique of &#8220;building up&#8221; exercises or assignments through many small but achievable steps. E.g. You might ask a student to compute (1) the slope of a line between two points, then (2) the full equation of that line, then (3) the tangent line of a specific parabola at a specific point, then (4) the general derivative of a parabola.</li>
<li><strong>Think-pair-share</strong>. Give a question to the class, then (1) let each person <em>think</em> about it on their own, then (2) they can discuss it in <em>pairs</em>, then (3) any group that wants can share with the entire class. At first this sounds super cheesy, but it&#8217;s extremely useful at getting students involved, empowering them and lowering anxiety.</li>
<li><strong>Inverted/Flipped classroom and Peer Instruction</strong>. This is the idea that lecturing is largely ineffective, so classroom time is spent with a tiny bit of lecturing (for definitions/motivation) and most of the class time is spent discussing, writing, calculating, experimenting, arguing, making and testing hypotheses, etc. This is related to the <a href="https://en.wikipedia.org/wiki/Moore_method">Moore method</a>, and Eric Mazur&#8217;s <a href="https://www.youtube.com/watch?v=Z9orbxoRofI">Peer Instruction</a>.</li>
<li><strong>VNPS- Vertical Non Permanent Surfaces</strong>. The name is a joke, but it&#8217;s a good idea. This is related to the idea that we should be getting students up and working together at chalkboards/flip charts/windows. The energy in the classroom changes a lot when people are standing up. <a href="https://mstamp36.com/2015/12/18/vnps-vertical-non-permanent-surfaces/">Source.</a></li>
<li><strong>Signature pedagogies</strong>. This name is <em>misleading</em>, but the idea is to remember to teach students not just the material, but how to use the material as a scientist/mathematician/statistician/programmer would use it. At some point we need to teach people curiosity, problem solving, how to make and test a hypothesis, precise writing, oral communication, algorithmic thinking, etc.</li>
<li><strong>RUME and SOTL</strong>. These stand for &#8220;Research in undergrad mathematics education&#8221; and &#8220;Scholarship of Teaching and Learning&#8221;. These are the two major movements for peer-reviewed research into teaching and education that are relevant to math teaching. There&#8217;s a recent push to inject good science into teaching with controlled (ethical) experiments, backed up with data. I find these papers excruciating to read because there is a lot of jargon and hero-worship in them. They also tend to not be written for a mathematician audience. Sometimes though you can find useful things here, but it&#8217;s rare. <a href="https://www.maa.org/rume-a-way-to-get-started">RUME starting point</a>.</li>
<li><strong>&#8220;Try, Fail, Understand, Win.&#8221; and &#8220;Productive failure/struggle&#8221;</strong>. <a href="http://maamathedmatters.blogspot.ca/2013/06/try-fail-understand-win.html">Source</a>. This is the ethos of the effective math student. It stems from the method of <a href="http://maamathedmatters.blogspot.ca/2013/05/what-heck-is-ibl.html">Inquiry based learning</a> (IBL) a method where students discover math on their own through guided exercises and questioning. This is rooted in the idea that students learn much, much better by doing rather than listening, and by struggling rather than having the answers given. See <a href="http://maateachingtidbits.blogspot.ca/2017/11/the-role-of-failure-and-struggle-in.html">this amazing and persuasive exercise</a>.</li>
</ul>
<p><img data-attachment-id="1750" data-permalink="https://mikepawliuk.ca/2018/05/11/my-teaching-advice-and-resources-so-far/tools-498202_640/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/05/tools-498202_640.jpg" data-orig-size="640,519" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tools-498202_640" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/05/tools-498202_640.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/05/tools-498202_640.jpg?w=640" class=" size-full wp-image-1750 aligncenter" src="https://mikepawliuk.files.wordpress.com/2018/05/tools-498202_640.jpg?w=660" alt="tools-498202_640" srcset="https://mikepawliuk.files.wordpress.com/2018/05/tools-498202_640.jpg 640w, https://mikepawliuk.files.wordpress.com/2018/05/tools-498202_640.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/05/tools-498202_640.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<h2>Some ideas I find useful, that don&#8217;t have jargon-y names associated to them</h2>
<ul>
<li><strong>Everything should serve a well-defined purpose.</strong> Decide on the goals of the course (jargon: learning outcomes, learning objectives) and build everything towards that goal. The structure of the course, how you deliver material, the content of the labs, the types of assignments, <em>everything</em> should work towards that goal.</li>
<li><strong>Test the thing you want to test</strong>. When writing tests it&#8217;s natural to want to include &#8220;clever&#8221; questions or questions with many moving parts. One issue with this is that students can potentially stumble on an early part of the question and not even have a chance to show off what they know. Be as direct as you can be.</li>
<li><strong>We call on men to answer questions more frequently than women</strong>. Be aware of this bias.</li>
<li><strong>Collaboration over competition</strong>. When possible, set up your class so that people can build each other up, instead of pushing each other down. In practice math is very collaborative. This has the additional nice benefits of lowering anxiety and encouraging women.</li>
<li><strong>There is more to math than just Western Europe</strong>. When including history or historical exercises try to draw from places other than just Western Europe. For example, India (<a href="https://www.newscientist.com/article/2147450-history-of-zero-pushed-back-500-years-by-ancient-indian-text/">invention of 0</a>), Iran (Astronomy, Geodesy, Optics), Egypt (<a href="https://en.wikipedia.org/wiki/Rhind_Mathematical_Papyrus">Rhind Papyrus</a>) and Mesopotamia (<a href="http://semiramis-speaks.com/record-keeping-and-the-origins-of-writing-in-mesopotamia/">first recording counting</a>) all have deep, interesting math history associated to them. Representation matters, and helps students find heroes. <a href="http://www-history.mcs.st-and.ac.uk/">MacTutor</a> is a great resource.</li>
<li><strong>Have many entry points and perspectives</strong>. Give students a variety of reasons to care about a topic: historical interest, practical application, theoretical interest, beauty, application to a specific domain, etc.. The goal is to make sure that each student has at least one thing they care about. Case-in-point: the comic Far Side often talked about hyper-specific domains of science and most people didn&#8217;t really care, but those that did care <em>cared a lot</em> and were really invested. Do stuff that <em>someone</em> loves rather than doing something that everyone finds acceptable but boring.</li>
<li><strong>Student evaluations do not reflect how good of an instructor you are.</strong> <a href="https://www.insidehighered.com/news/2016/09/21/new-study-could-be-another-nail-coffin-validity-student-evaluations-teaching">Source</a>. The way to get high marks is to: make the course easy, give the students past-exams and make your exams similar, show that you care about them, be engaging and to be an attractive dude. The way to get bad numerical scores is to: try something new, challenge the students, get them to do mathematics and grapple with questions, give unexpected questions on tests (even if the questions are easy).</li>
<li><strong>Talk to students as a human</strong>. Find opportunities (before class, before tests) to talk to students as a fellow human. Talk about music you like, or the new avengers movie. This has really helped me connect with students, and in some cases helped me find good summer research students.</li>
</ul>
<p><img data-attachment-id="1751" data-permalink="https://mikepawliuk.ca/2018/05/11/my-teaching-advice-and-resources-so-far/scissors-3239673_640/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/05/scissors-3239673_640.jpg" data-orig-size="640,420" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="scissors-3239673_640" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/05/scissors-3239673_640.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/05/scissors-3239673_640.jpg?w=640" class=" size-full wp-image-1751 aligncenter" src="https://mikepawliuk.files.wordpress.com/2018/05/scissors-3239673_640.jpg?w=660" alt="scissors-3239673_640" srcset="https://mikepawliuk.files.wordpress.com/2018/05/scissors-3239673_640.jpg 640w, https://mikepawliuk.files.wordpress.com/2018/05/scissors-3239673_640.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/05/scissors-3239673_640.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<h2>Some other advice</h2>
<ul>
<li><strong>Talk to your colleagues</strong>. Find people you trust that you can bounce ideas off of. Go for lunch frequently. Discuss pedagogy. Laugh about the jargon. Find potential pitfalls. Complain about students for your sanity.</li>
<li><strong>Find a mentor or two</strong>. You&#8217;ll need someone to guide you through your career path and challenge you to improve. Respect their time and find ways to benefit them.</li>
<li><strong>Be a mentor and a good supervisor</strong>. Encourage your TAs and junior colleagues. Treat them with respect and dignity. You were in that position once. Value their time and find ways to benefit them. Challenge and encourage them.</li>
<li><strong>Take measured risks</strong>. At this stage of your career you should be trying lots of different things to find what works. Some of it will go well, and some of it will flop, but it&#8217;s all okay!</li>
<li><strong>Make sure important people see you teach</strong>. At some point you&#8217;ll ask for a reference letter and it&#8217;s really important that they&#8217;ve seen you teach.</li>
</ul>
<p><img data-attachment-id="1752" data-permalink="https://mikepawliuk.ca/2018/05/11/my-teaching-advice-and-resources-so-far/steel-3309870_640/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/05/steel-3309870_640.jpg" data-orig-size="640,426" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="steel-3309870_640" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/05/steel-3309870_640.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/05/steel-3309870_640.jpg?w=640" class=" size-full wp-image-1752 aligncenter" src="https://mikepawliuk.files.wordpress.com/2018/05/steel-3309870_640.jpg?w=660" alt="steel-3309870_640" srcset="https://mikepawliuk.files.wordpress.com/2018/05/steel-3309870_640.jpg 640w, https://mikepawliuk.files.wordpress.com/2018/05/steel-3309870_640.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/05/steel-3309870_640.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<h2>Other Resources</h2>
<ul>
<li><a href="https://firstyearmath.ca/">First Year Math in Canada</a> is a (brand new) collection of resources for teaching first-year classes available to instructors.</li>
<li><a href="http://maamathedmatters.blogspot.ca/">MathedMatters</a>. A blog that the &#8220;Try, Fail, Understand, Win&#8221; post comes from. Lots of great stuff here.</li>
<li><a href="http://www.inquirybasedlearning.org/">Academy of IBL</a>. Resources for IBL.</li>
</ul>]]></summary>
        <author>
            <name>Mike Pawliuk – Mathematics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Critical Cardinals]]></title>
        <id>http://karagila.org/2018/critical-cardinals/</id>
        <link href="http://karagila.org/2018/critical-cardinals/">
        </link>
        <updated>2018-05-10T06:48:13Z</updated>
        <summary type="html"><![CDATA[<p>Yup. I posted a new paper on arXiv. And if you're one of my three regular readers, you know that I am not going to talk about the paper itself (I leave that to the paper), but 
rather about the process leading to it. If you don't care, that's fine, the paper is on <a href="https://arxiv.org/abs/1805.02533">arXiv</a> and you can check the <strong>Papers</strong> section 
of the site to see if it's been published or whatnot.</p>

<p>So, this one has been on the back burner for a while. And it actually started as two separate projects that merged and separated and merged again. <a href="http://karagila.org/2018/critical-cardinals/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Knaster and friends I: Closed colorings and precalibers]]></title>
        <id>http://blog.assafrinot.com/?p=4530</id>
        <link href="http://blog.assafrinot.com/?p=4530">
        </link>
        <updated>2018-04-26T19:12:43Z</updated>
        <summary type="html"><![CDATA[<div class="thanks_button_div" 
                  style="margin-bottom: 30px;"><div id="thanksButtonDiv_4530_2" style="background-image:url(http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/thanks_compact_brown1.png); background-repeat:no-repeat; float: left; display: inline;"
                onmouseover="javascript:thankYouChangeButtonImage('thanksButtonDiv_4530_2', true);" 
                onmouseout="javascript:thankYouChangeButtonImage('thanksButtonDiv_4530_2', false);"
                onclick="javascript:thankYouChangeButtonImage('thanksButtonDiv_4530_2', false);" >
                <input type="button" onclick="thankYouButtonClick(4530, 'You left &ldquo;Thanks&rdquo; already for this post')" value="Like 31"
                  class="thanks_button thanks_compact thanks_brown"
                  style="  font-family: Verdana, Arial, Sans-Serif; font-size: 14px; font-weight: normal;; color:#ffffff;"
                  id="thanksButton_4530_2" title="Click to leave &ldquo;Thanks&rdquo; for this post"/>
             </div><div id="ajax_loader_4530_2" style="display:inline;visibility: hidden;"><img alt="ajax loader" src="http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/ajax-loader.gif" /></div></div><p>Joint work with <a href="http://people.vcu.edu/~cblambiehanso/">Chris Lambie-Hanson</a>.</p>
<p><strong>Abstract.</strong> The productivity of the $\kappa$-chain condition, where $\kappa$ is a regular, uncountable cardinal, has been the focus of a great deal of set-theoretic research.<br />
In the 1970s, consistent examples of $\kappa$-cc posets whose squares are not $\kappa$-cc were constructed by Laver, Galvin, Roitman and Fleissner. Later, <strong>ZFC</strong> examples were constructed by Todorcevic, Shelah, and others. The most difficult case, that in which $\kappa = \aleph_2$, was resolved by Shelah in 1997.</p>
<p>In this work, we obtain analogous results regarding the infinite productivity of strong chain conditions, such as the Knaster property. Among other results, for any successor cardinal $\kappa$, we produce a <strong>ZFC</strong> example of a poset with precaliber $\kappa$ whose $\omega^{\mathrm{th}}$ power is not $\kappa$-cc.<br />
To do so, we carry out a systematic study of colorings satisfying a strong unboundedness condition. We prove a number of results indicating circumstances under which such colorings exist, in particular focusing on cases in which these colorings are moreover closed.</p>
<p><span id="more-4530"></span></p>
<p><strong>Downloads:</strong></p>
<p><table class=paperruler"><tr><td><a onclick="thankYouButtonClick(4530, '')"  href="http://www.assafrinot.com/files/paper34.pdf" class="billet_author"></a><a onclick="thankYouButtonClick(4530, '')" href="https://arxiv.org/abs/1809.08480" class="billet_arxiv"></a><a onclick="thankYouButtonClick(4530, '')" href="http://dx.doi.org/10.1007/s00012-018-0565-1" class="billet_publish"></a><a href="http://www.ams.org/mathscinet-getitem?mr=3878671" class="billet_review"></a><a onclick="thankYouButtonClick(4530, '')" href="https://speakerdeck.com/player/418487216b03498997c2716ba2c80802" class="billet_slides"></a><a href="http://www.assafrinot.com/paper/18" class="billet_further"></a><a href="http://papers.assafrinot.com/list.php?bib=rinot.bib&key=paper34" class="billet_bibtex"></a><a href="http://www.assafrinot.com/paper/34" class="billet_perm"></a></td></tr></table></p>
<p><strong>Citation information:</strong></p>
<p>C. Lambie-Hanson and A. Rinot, <em>Knaster and friends I: closed colorings and precalibers</em>, Algebra Universalis, 79(4): 90, 2018.</p>
<p><!--more--></p>]]></summary>
        <author>
            <name>Assaf Rinot</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Brace(s) yourself]]></title>
        <id>https://www.peterkrautzberger.org/0204/</id>
        <link href="https://www.peterkrautzberger.org/0204/">
        </link>
        <updated>2018-04-19T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I recently read <a href="https://css-tricks.com/why-would-you-do-that-in-css/">Why would you do that?</a> on CSS Tricks and it reminded me that I had meant to write this piece a month ago.</p>
<p>So <a href="https://www.peterkrautzberger.org/0203/">I recently wrote about a fragment of mathematical content</a> and a big part of it was the problem of stretchy braces. After building the &quot;plain&quot; HTML+CSS example at the end (re-using an extremely clever solution from the upcoming MathJax v3), I kept thinking: this should be easier. Luckily, this year I'm dedicating a chunk of my spare time to the <a href="https://w3c.github.io/mathonwebpages/">MathOnWeb Community Group</a>'s new task force focused on CSS, looking for (old and new) ideas that might help simplify equation layout using CSS.</p>
<p>So one thing led to another and I found myself coming back to an old thought of mine.</p>
<h2>What's in a name?</h2>
<p>Stretchy characters like those braces, what are they <em>really</em>? Like, <em>really really</em>?</p>
<p>Let's look at what they are called. As a matter of fact, they are called various things but the most generic term is possibly <a href="https://en.wikipedia.org/wiki/Bracket"><em>bracket</em></a>. However in the context of equation layout, the more common terminology might be <em>delimiter</em> and <em>fence</em>. In particular, MathML provides an <code>&lt;mfenced&gt;</code> tag (though for various reasons the equivalent <code>&lt;mrow&gt;</code>+<code>&lt;mo&gt;</code> constructions tend to be preferred by most tools).</p>
<p>Now both brackets, fences and delimiters sound awfully similar to a very common concept. Where do you usually put up a fence? Where do you delimit something? <strong>At a border.</strong> It's a small idea, obviously, but what if we could solve the problem of stretchy constructions using borders?</p>
<p>What if somebody else already has?</p>
<h2>Previous Art</h2>
<p>Well, you could go visit codepen and <a href="https://codepen.io/search/pens?q=brace&amp;page=1&amp;order=popularity&amp;depth=everything&amp;show_forks=false">simply search for <em>brace</em></a> and, lo and behold, you find 4 perfectly fine specimens in CSS. Turns out, designers love pretty things, who'd have thunk.</p>
<p>If you dig a little deeper, you'll end up with basically three approaches.</p>
<p>The first one (with several interesting forks) is by <a href="https://codepen.io/lrenhrda/">Lauren Herda</a>.</p>
<p data-height="265" data-theme-id="0" data-slug-hash="hkLIe" data-default-tab="result" data-user="lrenhrda" data-embed-version="2" data-pen-title="Single-Element Curly Brace" class="codepen">See the Pen <a href="https://codepen.io/lrenhrda/pen/hkLIe/">Single-Element Curly Brace</a> by Lauren Herda (<a href="https://codepen.io/lrenhrda">@lrenhrda</a>) on <a href="https://codepen.io/">CodePen</a>.</p>
<script async="" src="https://static.codepen.io/assets/embed/ei.js"></script>
<p>It is really pretty -- look Ma, <a href="https://a.singlediv.com/">a single div</a>! (Except that it doesn't quite work on Chrome since an <code>&lt;hr&gt;</code> gets <code>overflow:hidden</code> from the user agent style sheet.)</p>
<p>That was fun. Let's do two more: one from <a href="https://codepen.io/MasterThrasher/">Jakob Christoffersen</a></p>
<p data-height="265" data-theme-id="0" data-slug-hash="mOEjoK" data-default-tab="result" data-user="MasterThrasher" data-embed-version="2" data-pen-title="curly braces css" class="codepen">See the Pen <a href="https://codepen.io/MasterThrasher/pen/mOEjoK/">curly braces css</a> by Jakob Christoffersen (<a href="https://codepen.io/MasterThrasher">@MasterThrasher</a>) on <a href="https://codepen.io/">CodePen</a>.</p>
<script async="" src="https://static.codepen.io/assets/embed/ei.js"></script>
<p>and one from <a href="https://codepen.io/mexn/">@mexn</a>:</p>
<p data-height="265" data-theme-id="0" data-slug-hash="xegaF" data-default-tab="result" data-user="mexn" data-embed-version="2" data-pen-title="CSS Curly Brace" class="codepen">See the Pen <a href="https://codepen.io/mexn/pen/xegaF/">CSS Curly Brace</a> by Markus (<a href="https://codepen.io/mexn">@mexn</a>) on <a href="https://codepen.io/">CodePen</a>.</p>
<script async="" src="https://static.codepen.io/assets/embed/ei.js"></script>
<p>Both are slighly more complicated than the first one. Instead of the radial gradient for the middle piece, they both use 6 elements with border-radius (though the last one has only two elements with pseudo-elements). If you dive into their forks, you'll find lots of interesting variations, too.</p>
<p>The point is: this problem has in a very real sense actually been solved in CSS and you can do lots of fun variations yourself.</p>
<p>Such as this one</p>
<p data-height="265" data-theme-id="0" data-slug-hash="YagEJb" data-default-tab="result" data-user="pkra" data-embed-version="2" data-pen-title="stretchy brace " class="codepen">See the Pen <a href="https://codepen.io/pkra/pen/YagEJb/">stretchy brace </a> by Peter Krautzberger (<a href="https://codepen.io/pkra">@pkra</a>) on <a href="https://codepen.io/">CodePen</a>.</p>
<script async="" src="https://static.codepen.io/assets/embed/ei.js"></script>
<p>or this one</p>
<p data-height="265" data-theme-id="0" data-slug-hash="OvYeoq" data-default-tab="result" data-user="pkra" data-embed-version="2" data-pen-title="stretchy brace, single-div" class="codepen">See the Pen <a href="https://codepen.io/pkra/pen/OvYeoq/">stretchy brace, single-div</a> by Peter Krautzberger (<a href="https://codepen.io/pkra">@pkra</a>) on <a href="https://codepen.io/">CodePen</a>.</p>
<script async="" src="https://static.codepen.io/assets/embed/ei.js"></script>
<p>(Fun fact: using percentages in the border radius leads to some really cute behavior across sizes.)</p>
<h2>Objection!</h2>
<p>Now you might say it hasn't solved the <em>real</em> problem. Here are a couple of counterarguments:</p>
<p><strong>It has no character!</strong> Gasp! It's true that in typical print equation layout engines you'll still have a character there. Well, you could just add a hidden one, no?</p>
<p><strong>It doesn't work well on small sizes!</strong> In typical print equation layout, you'll see several sizes of a brace being used for smaller heights (with possibly slight design variations for readability) after which the layout would switch over to a stretchy constructions (made up of several glyphs stitched together). This is a very interesting problem to solve. And you know what? This touches on one of the hottest topics of CSS discussions in the past few years: it is a perfect use case for <a href="https://github.com/WICG/container-queries/">container queries</a>. Go add a use case and push the web forward for everyone!</p>
<p>But perhaps current CSS is sufficient and someone will find a clever approach to achieve a similar effect. As I mentioned above, percentages in border radius have a neat effect; there is a lot of room to play with once you stop thinking about everything in terms of print traditions.</p>
<p><strong>It's not semantic!</strong> Gosh. What exactly does a (stretched) brace represent, semantically speaking? And, should you have decided to imbue it with such rich meaning yourself, are you really unable to expose the relevant information using the web platform's rich accessibility stack? No? Excellent - you should file a bug with ARIA and help push the web forward for everyone!</p>
<p><strong>It can't look like font x!</strong> Some fonts have a really tricky curly brace with basically an S shape in each half. I admit my CSS-foo is not good enough to do that. But besides the fact that a better designer might find a solution, I find the trade-off acceptable. And if there's a limitation in CSS, please file a bug with the CSS WG and help push the web forward for everyone!</p>
<p><strong>It can't do delimiter y!</strong> There are <a href="https://en.wikipedia.org/wiki/Bracket#Encoding_in_digital_media">quite a few brackets</a>, some more complex than others (<em>Mathematical left white tortoise shell bracket</em> anyone?) but few of those are used in stretchy ways and fewer still occur often (for comparison, the STIX-2 fonts support ~30 delimiters). I really don't have a problem with such edge cases remaining difficult for the time being if we can solve a practical problem for 99% of use cases. And if you do, ... you know what to do.</p>
<h2>Moar fences!</h2>
<p>So let's do two more, the most important ones:</p>
<p>Parentheses,</p>
<p data-height="265" data-theme-id="0" data-slug-hash="pLWRwx" data-default-tab="result" data-user="pkra" data-embed-version="2" data-pen-title="Stretchy parenthesis" class="codepen">See the Pen <a href="https://codepen.io/pkra/pen/pLWRwx/">Stretchy parenthesis</a> by Peter Krautzberger (<a href="https://codepen.io/pkra">@pkra</a>) on <a href="https://codepen.io/">CodePen</a>.</p>
<script async="" src="https://static.codepen.io/assets/embed/ei.js"></script>
<p>and square brackets</p>
<p data-height="265" data-theme-id="0" data-slug-hash="bvYBje" data-default-tab="result" data-user="pkra" data-embed-version="2" data-pen-title="Stretchy brackets" class="codepen">See the Pen <a href="https://codepen.io/pkra/pen/bvYBje/">Stretchy brackets</a> by Peter Krautzberger (<a href="https://codepen.io/pkra">@pkra</a>) on <a href="https://codepen.io/">CodePen</a>.</p>
<script async="" src="https://static.codepen.io/assets/embed/ei.js"></script>
<p>See now, that wasn't so hard?</p>
<h2>Coda</h2>
<p>I suspect that if we work a bit harder to unstuck ourselves from the traditions of (print) equation layout engines, then we might just find a lot of interesting solutions like this; solutions that help make equation layout on the web as easy as as designing a good page layout with CSS; solutions that work <em>with</em> the grain of the web; solutions that perhaps even lack but help identify (and resolve) shortcomings in the web platform that affect a much wider community; solutions that help move the web forward.</p>
<p>PS: I've started <a href="https://codepen.io/collection/njBkMa/">a little collection on codepen</a>. Ping me if you see something that might fit!</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open Problems!]]></title>
        <id>http://karagila.org/2018/problems/</id>
        <link href="http://karagila.org/2018/problems/">
        </link>
        <updated>2018-04-08T00:14:52Z</updated>
        <summary type="html"><![CDATA[<p>I've decided to have a list of <a href="http://karagila.org/problems.html">open problems</a> on my site. I am no Erdős, nor Hilbert, nor Knuth.</p>

<p>But I want my own problems page, and it's my site. So to celebreate the new website, I created just that. For the first couple of problems, I've chosen to focus on the axiom of 
choice. And I don't think that I have much choice, but to keep that interest running. But I can promise that this is not the only type of problems that I will add there. <a href="http://karagila.org/2018/problems/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MMath thesis on Mathieu groups]]></title>
        <id>https://nickpgill.github.io/2018/04/06/sam-hughes-mmath-dissertation/</id>
        <link href="https://nickpgill.github.io/2018/04/06/sam-hughes-mmath-dissertation/">
        </link>
        <updated>2018-04-06T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>My MMath student, Sam Hughes, recently submitted his dissertation entitled “<em>Representation and character theory of the small Mathieu groups</em>”; a copy is <a href="/MMath_Sam.Hughes.pdf">here</a>.</p>

<p>The dissertation studies the ordinary (complex) character theory of <em>M<sub>11</sub></em> and <em>M<sub>12</sub></em>; it includes the foundations of character theory, as well as details on how to construct <em>M<sub>11</sub></em> and <em>M<sub>12</sub></em> via the notion of “transitive extension”. I think Sam has done a beautiful job and should be congratulated!</p>

<p>We are in the process of writing up a paper including some of Sam’s results. In fact the paper comes from a slightly different point of view. Our main result is the following:</p>

<p><strong>Theorem</strong></p>
<ol>
  <li>If <em>G</em> is a sharply 5-transitive subgroup of Alt(12), then the character table of <em>G</em> is given by Table ***.</li>
  <li>If <em>G</em> is a sharply 4-transitive subgroup of Alt(11), then the character table of <em>G</em> is given by Table ***.</li>
</ol>

<p>The point of this theorem is that we are able to construct the character table of <em>G</em> using only the assumption about multiple-transitivity – there is no direct reference to the Mathieu groups in this paper.</p>

<p>In the course of this research, I asked a question on MathOverflow <a href="https://mathoverflow.net/questions/293859/what-did-frobenius-prove-about-m-12">here</a>. Now seems a good time to thank the contributors to that discussion, especially Frieder Ladisch, for their help!</p>]]></summary>
        <author>
            <name>Nick Gill</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New website!]]></title>
        <id>http://karagila.org/2018/new-site/</id>
        <link href="http://karagila.org/2018/new-site/">
        </link>
        <updated>2018-04-05T17:02:17Z</updated>
        <summary type="html"><![CDATA[<p>Welcome to my new website!</p>

<p>It is a static website, because I am tired of the WordPress format for a long long time now. So for the occasion, I also got a new domain, <strong>karagila.org</strong>. Isn't this nice? The only 
domain and all the links should work, at least for the foreseeable future. So there's nothing to worry about linkrot for now. But please do update your links! <a href="http://karagila.org/2018/new-site/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How does modern AI work? – Math for my mom]]></title>
        <id>https://mikepawliuk.ca/2018/03/31/how-does-modern-ai-work-math-for-my-mom/</id>
        <link href="https://mikepawliuk.ca/2018/03/31/how-does-modern-ai-work-math-for-my-mom/">
        </link>
        <updated>2018-04-01T05:01:42Z</updated>
        <summary type="html"><![CDATA[<blockquote><p>This is part of <a href="https://mikepawliuk.ca/2012/09/06/the-battery-problem-math-for-my-mom/">a series of posts</a> aimed at helping my mom, who is not a scientist, understand what I&#8217;m up to as a mathematician.</p></blockquote>
<p>&nbsp;</p>
<p>Lately, Artificial Intelligence (AI) has made some remarkable milestones. There are computers that are better than humans at <a href="https://www.theatlantic.com/technology/archive/2017/10/alphago-zero-the-ai-that-taught-itself-go/543450/">the strategy board game GO</a> and at <a href="https://www.youtube.com/watch?v=jLXPGwJNLHk">Poker</a>. Computers can <a href="https://www.theverge.com/2016/9/12/12886698/machine-learning-video-image-prediction-mit">turn pictures into short moving clips</a> and <a href="https://www.fastcodesign.com/90149773/this-ai-turns-unrecognizable-pixelated-photos-into-crystal-clear-images">can &#8220;enhance&#8221; blurry pictures</a> as in television crime shows. They can also produce <a href="https://www.youtube.com/watch?v=SacogDL_4JU">new music in the style of Bach</a> or <a href="http://computoser.com/">customized to your tastes</a>. It&#8217;s all very exciting, and it feels pretty surreal; remember back when Skype video calling felt like the future?</p>
<p>I&#8217;m going to give you a broad overview for how these types of AI work, and how they learn. There won&#8217;t be any equations or algebra.</p>
<p><span id="more-1724"></span></p>
<h2>Let&#8217;s play</h2>
<p><img data-attachment-id="1726" data-permalink="https://mikepawliuk.ca/2018/03/31/how-does-modern-ai-work-math-for-my-mom/arcade/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/03/arcade.jpg" data-orig-size="640,426" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;E-M10&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;14&quot;,&quot;iso&quot;:&quot;500&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="arcade" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/03/arcade.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/03/arcade.jpg?w=640" class=" size-full wp-image-1726 aligncenter" src="https://mikepawliuk.files.wordpress.com/2018/03/arcade.jpg?w=660" alt="arcade" srcset="https://mikepawliuk.files.wordpress.com/2018/03/arcade.jpg 640w, https://mikepawliuk.files.wordpress.com/2018/03/arcade.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/03/arcade.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p>Before we jump into the computer stuff, let&#8217;s make our very first AI. Well, this will be more &#8220;I&#8221; than &#8220;AI&#8221;, because I want you to play a game. You are going to be the &#8220;AI&#8221; that&#8217;s going to learn a task!</p>
<p>I want you to <a href="https://armorgames.com/zrist-game/18314">play Zrist</a> for about 5 minutes (or longer if you like it). It&#8217;s a fun little platform game. See how far you can get. My best score was 37 400. We&#8217;ll use this experience to help describe how AI works. <strong>Okay, go play now!</strong></p>
<p><img data-attachment-id="1727" data-permalink="https://mikepawliuk.ca/2018/03/31/how-does-modern-ai-work-math-for-my-mom/zrist/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/03/zrist.png" data-orig-size="620,320" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zrist" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/03/zrist.png?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/03/zrist.png?w=620" class=" size-full wp-image-1727 aligncenter" src="https://mikepawliuk.files.wordpress.com/2018/03/zrist.png?w=660" alt="zrist" srcset="https://mikepawliuk.files.wordpress.com/2018/03/zrist.png 620w, https://mikepawliuk.files.wordpress.com/2018/03/zrist.png?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/03/zrist.png?w=300 300w" sizes="(max-width: 620px) 100vw, 620px"   /></p>
<p><strong>Welcome back!</strong> I hope you had fun playing that game.</p>
<p>I want you to think about these questions, and give an answer to each of them. (It&#8217;s not a test, there are no wrong answers.)</p>
<ol>
<li>What was the goal of the game?</li>
<li>How did you know you were doing well at the game?</li>
<li>How did you adapt to the rules changes? Did you get them on the first try?</li>
<li>How did you make decisions about what to do next? (What did you look for, and what did you ignore?)</li>
</ol>
<h2>Mar I/O plays mario</h2>
<p>We&#8217;ll come back to your answers in a moment. For now, I want you to watch a bit of a video of an AI (called Mar I/O) learning to play the original 1985 Super Mario Brothers. Watch maybe the first 4 or 5 minutes, and then skip to the middle of the video. You only need to watch a little bit to get the sense of what&#8217;s going on.</p>
<div class="jetpack-video-wrapper"><iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/l5_sWT_5I1o?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe></div>
<p>(If you like this, you can watch <a href="https://www.youtube.com/watch?v=oWU48a2nNLA">a livestream of Mar I/O&#8217;s attempts</a> to beat the game level by level.)</p>
<p>First of all, this program starts off only knowing a couple of things:</p>
<ol>
<li>It can see a simplified version of the screen (that&#8217;s what appears in the top left of the video).</li>
<li>It can press any buttons on a normal controller.</li>
<li>It knows that it wants to increase its <strong>&#8220;fitness&#8221;</strong> score, which is increased the further mario gets in the level, but <em>it doesn&#8217;t know why its fitness score increases</em>.</li>
</ol>
<p>Here are some things it doesn&#8217;t know:</p>
<ol>
<li>It doesn&#8217;t know the rules of the game or what the buttons on the controller do.</li>
<li>It doesn&#8217;t know that it controls mario.</li>
<li>It doesn&#8217;t know that touching an enemy will kill mario.</li>
</ol>
<p>If you&#8217;re interested, Mar I/O is a <strong>Recurrent Neural Net</strong>. There are other types of AI, but this is the we&#8217;ll look at today.</p>
<h2>&#8220;See how many envelopes you can lick in an hour, then try to break that record!&#8221;</h2>
<div class="jetpack-video-wrapper"><iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/2Pbywpi64Tg?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;start=25&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe></div>
<p>So at first it tries random stuff to increase its fitness score: jumping, standing still, ducking, running left, and none of these seem to increase its fitness. Then, when it presses right, mario starts progressing in the level and its fitness score goes up.</p>
<p>This is called <strong>training the AI</strong>. It measures its progress against a fitness score, and it reinforces behaviour that increases that score. i.e. It starts to favour pressing right because that seems to increase its fitness score.</p>
<p>This works great until it gets to the first enemy and mario runs right into it and dies. After a couple more tries, it starts to experiment some more (just like it was trying random things at the beginning of the level). Around the 2:20 mark of the video, Mar I/O presses the jump button right before the enemy and successfully clears it, allowing mario to move further right and increase its fitness score.</p>
<p>To recap:</p>
<ol>
<li>The AI tries random things, until something increases its <strong>&#8220;fitness score&#8221;</strong>.</li>
<li>When it does something that increases its fitness score, it tries to do more of that in the future. (<strong>Training</strong> and <strong>learning</strong>.)</li>
<li>It keeps repeating this procedure over and over. Training takes time!</li>
</ol>
<h2>Back to Zrist</h2>
<p>Let&#8217;s go back to the platform game you played and look at how you learned to play the game.</p>
<blockquote><p>What was the goal of the game?<br />
How did you know you were doing well at the game?</p></blockquote>
<p>I asked you to get as far in the level as you could; that was your goal. The game kept track of it by telling you your current high score. That was your <strong>fitness score</strong>!</p>
<blockquote><p>How did you adapt to the rules changes? Did you get them on the first try?</p></blockquote>
<p>If you&#8217;re anything like me, when the rules changed for the first time you thought, &#8220;Oh crap, what&#8217;s this?&#8221;, and then promptly died when the screen said &#8220;Mode: lag&#8221;. <em>What were you supposed to do?! No one told you what to do!</em></p>
<p>When my character turned invisible, the screen stopped scrolling and I wasn&#8217;t sure what to do. At that point I just pressed buttons until it started to scroll again; i.e. <strong>I tried random things when I got stuck</strong>. As I continued to get stuck and unstuck, I recognized that I was getting stuck at the short walls, and that jumping over them saved me then. Trying the same trick saved me again when I was invisible. i.e. I was <strong>training</strong> on the short walls.</p>
<p>This is very similar to how Mar I/O trains and learns.</p>
<p>For comparison, here&#8217;s a video of one of the best Mario players in the world, CarlSagan42, taking 18 hours to beat an extremely difficult fan-made level. (<strong>Warning</strong>: there are a bunch of swear words.)</p>
<div class="jetpack-video-wrapper"><iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/iqjUuQD4PJY?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe></div>
<p>Notice a couple things:</p>
<ol>
<li>When faced with a new obstacle, he often just &#8220;tries something&#8221;. Maybe it works, maybe it doesn&#8217;t; Either way he gets information.</li>
<li>The more he plays a section the easier it gets; he&#8217;s training on the earlier sections more.</li>
<li>The sections near the end are harder to get to, sometimes taking 10+ minutes just to reach that section again. It means those sections don&#8217;t get trained very much.</li>
</ol>
<p>These are all in common with Mar I/O.</p>
<h2>Neurons and memory; an artificial brain</h2>
<p><img data-attachment-id="1728" data-permalink="https://mikepawliuk.ca/2018/03/31/how-does-modern-ai-work-math-for-my-mom/robot_brain/" data-orig-file="https://mikepawliuk.files.wordpress.com/2018/03/robot_brain.jpg" data-orig-size="640,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="robot_brain" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2018/03/robot_brain.jpg?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2018/03/robot_brain.jpg?w=640" class=" size-full wp-image-1728 aligncenter" src="https://mikepawliuk.files.wordpress.com/2018/03/robot_brain.jpg?w=660" alt="robot_brain" srcset="https://mikepawliuk.files.wordpress.com/2018/03/robot_brain.jpg 640w, https://mikepawliuk.files.wordpress.com/2018/03/robot_brain.jpg?w=150 150w, https://mikepawliuk.files.wordpress.com/2018/03/robot_brain.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<blockquote><p>How did you make decisions about what to do next? (What did you look for, and what did you ignore?)</p></blockquote>
<p>In Zrist, you were probably looking for gaps (to jump over), those horrible red death blocks, and big walls to slide under. For each of these you developed a reaction: &#8220;When I see a gap, then I press C (to jump over it)&#8221;.</p>
<p>For each of these you had to remember a task: If I see a gap, then I jump over it.</p>
<p>For AI like Mar I/O, it stores these tasks by associating visual cues and inputs with button presses. For example, when it sees a wide open space it learns to press the right button. When it sees a gap in the ground it learns to press the A button (to jump).</p>
<p>Now Mar I/O doesn&#8217;t have any extra code which tells it &#8220;this is what a pit looks like&#8221; or &#8220;this is what a pipe is&#8221; or anything like that, (although it can see enemies as black tiles, it doesn&#8217;t know what an enemy <em>is</em>).</p>
<p>Each time it succeeds at increasing its fitness score it strengthens the connections between the visual cues and the sequence of button presses that got it there. Each connection like this is stored in the AI as an <strong>&#8220;artificial neuron&#8221;</strong>. So when you were playing Zrist, you probably developed a neuron relating to gaps (&#8220;If gap, then jump&#8221;), one for tall walls (&#8220;If tall wall, then slide&#8221;), and many others.</p>
<h2>&#8220;Features don&#8217;t have any deep meaning. They&#8217;re just stupid drawings that give you a cheap laugh&#8221;</h2>
<div class="jetpack-video-wrapper"><iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/QjbyFM7fW9o?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe></div>
<p>The very cool thing about modern AI is that you typically don&#8217;t need to tell it what or how many artificial neurons to make ahead of time, <em>Mar I/O adds neurons as it learns</em>. It&#8217;s just like how you didn&#8217;t need to know how many types of obstacles you would face in Zrist, you built up a list as you went. This is very powerful!</p>
<p>The flip side to this is that after Mar I/O learns to beat a level, we humans will have a hard time understanding what it&#8217;s using to make its decisions. It won&#8217;t always be clear to us what visual elements (called <strong>&#8220;features&#8221;</strong>) it&#8217;s using to make its decisions.</p>
<h2>Human learning</h2>
<div class="jetpack-video-wrapper"><iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/YvhlOtQAU0A?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe></div>
<p>Hopefully you see some of the parallels between the way AIs learn things and the way humans learn things. There are a lot of similarities. Mimicking human learning has been very useful for creating AIs.</p>
<p>I&#8217;m going to point out a couple other ways that humans learn that help illustrate ways in which AI can learn.</p>
<ol>
<li>Muscle memory.</li>
<li>Learning from others.</li>
</ol>
<p>Have you ever <a href="https://lifehacker.com/why-you-dont-remember-your-commute-677732950">driven somewhere familiar and then forgotten how you got there</a>? You were on autopilot. Similarly, have you ever been doing something with your hands, like playing the piano, but when you stop to think about what you&#8217;re actually doing, the task suddenly becomes much harder. This sort of muscle memory is very similar to what Mar I/O is doing. It learns sequences of moves and button presses, but there is no underlying reasoning.</p>
<p>I skipped over a big part of Mar I/O&#8217;s learning, which is that it actually contains many different &#8220;styles&#8221; of players (called <strong>species</strong>); it&#8217;s not just a single mario learning. After each species completes about 10 attempts at beating the level, we rank the species by which achieved the highest fitness. We then delete the bottom 10% of the species and replace them by blending some of the best species (in a process called <strong>breeding</strong>). This ensures that if one of the mediocre species discovers something useful (like shooting fireballs can kill enemies) it still has a chance to give that idea to the best performers. Similarly, the best performers get to share their ideas with the mediocre performers.</p>
<p>One of these processes is called a <strong>generation</strong>. For easy levels, Mar I/O only needed 40 or so generations. For difficult levels, Mar I/O needed over 250 generations! It can take a long time for these random mutations to produce helpful effects.</p>
<p>If this feels a lot like evolution, well that&#8217;s because it is! These AI learn by evolving and refining their strategies. This is a very deep and powerful idea, but I&#8217;ve already gone on long enough, so I&#8217;ll save it for another time.</p>
<h2>The limits of AI</h2>
<div class="jetpack-video-wrapper"><iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/weAcVf6QUX4?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe></div>
<p>The advancement of AI evokes many feelings: Awe and wonder, but also fear and skepticism. So I&#8217;ll end this post talking about what the future might look like.</p>
<p>AI are machines. The term artificial intelligence might better be described as artificial <em>skill</em>. Mar I/O is only able to maximize a fitness score. It&#8217;s quite good at that, but that&#8217;s the only thing it can do. This AI is highly specialized to Super Mario Brothers. While it&#8217;s possible that the underlying Mar I/O code can be adapted to other games (like <a href="https://www.youtube.com/watch?v=Ipi40cb_RsI">Mario Kart</a>), it requires human knowledge, judgement and skill to adapt it to other settings.</p>
<p>We don&#8217;t expect that Mar I/O will turn ever turn into a killer robot. At its core, Mar I/O is a (complicated) machine that presses buttons and is good at increasing a number (its fitness score).</p>
<h2>Further resources</h2>
<p>If you want to learn more about AI, here are some good resources based on your background.</p>
<p>I just want nice pictures and videos. NO MATH!:</p>
<ul>
<li><a href="https://youtu.be/42B-O6TK1bg?t=7m50s">How AI is used to test Candy Crush</a>. This one&#8217;s specifically for my mom.</li>
<li><a href="https://www.youtube.com/watch?v=3bhP7zulFfY">AI learns to play snake using genetic algorithm and Deep Learning</a> by Code Bullet. (Also see their stuff about Asteroid and Pool.)</li>
<li><a href="https://youtu.be/rGt3iMAJVT8">Mona Lisa approximated with 150 circles through hill climbing genetic algorithm</a> by <a class="yt-simple-endpoint style-scope yt-formatted-string" href="https://www.youtube.com/channel/UCZTv5n0QMGIvewBGnXk6Omg">pɹɐddǝɥS Ɔ</a>.</li>
</ul>
<p>I am comfortable with the topics described here, but want a bit more substance:</p>
<ul>
<li>&#8220;<a href="https://www.youtube.com/watch?v=aircAruvnKk">But what *is* a neural net</a>&#8221; by 3Blue1Brown.</li>
</ul>
<p>I have a degree in math or computer science and want all the details. Leave no stone unturned:</p>
<ul>
<li>&#8220;<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The unreasonable effectiveness of Recurrent Neural Nets</a>&#8221; by Andrej Karpathy.</li>
<li>&#8220;<a href="http://neuralnetworksanddeeplearning.com/chap1.html">Neural Networks and Deep Learning</a>&#8221; by <a href="http://michaelnielsen.org">Michael Nielsen</a>. This book, available online is a unicorn: readable, informative, detailed. I love it.</li>
</ul>]]></summary>
        <author>
            <name>Mike Pawliuk – Mathematics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[In praise of failure]]></title>
        <id>http://karagila.org/2018/in-praise-of-failure/</id>
        <link href="http://karagila.org/2018/in-praise-of-failure/">
        </link>
        <updated>2018-03-13T17:30:17Z</updated>
        <summary type="html"><![CDATA[<p>I had a recent back and forth on Math.SE with a user that asked whether or not some exercise he found in some textbook is correct. The OP asked <em>not</em> to provide a proof, but rather to confirm if this statement is at all provable. When I asked why not just try and prove the damn thing, the reply was that if there is a typo or a mistake and the statement is in fact not provable, then they would have wasted their time trying an impossible task.</p>

<p>Well. Actually no. When I was a dewy eyed freshman, I had taken all my classes with 300 students from computer science and software engineering (Ben-Gurion University has changed that since then). Our discrete mathematics professor was someone who was renowned as somewhat careless when it comes to details in questions and stuff like this (my older brother took calculus with the same professor about ten years before, one day he didn't show up to class, when my brother and two others went to see if he is at his office, he was surprised to find out that today is Tuesday). <a href="http://karagila.org/2018/in-praise-of-failure/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Site is being updated]]></title>
        <id>https://mikepawliuk.ca/2018/03/11/the-journey-begins/</id>
        <link href="https://mikepawliuk.ca/2018/03/11/the-journey-begins/">
        </link>
        <updated>2018-03-11T21:42:46Z</updated>
        <summary type="html"><![CDATA[<p>I&#8217;m in the process of changing domains, so please bear with me during this transition. I&#8217;m working on fixing the bugs and making everything look pretty.</p>
<p>In the mean time, <a href="https://cocalc.com/blobs//home/user/.sage/temp/project-fbeb3d9c-3251-4e88-9e27-82a1c37642e1/270/tmp_uijHct.svg?uuid=3877e5a6-2b20-41df-b57d-9d862c4d7394" target="_blank" rel="noopener">here&#8217;s a nice graph</a>. It answers <a href="https://www.reddit.com/r/math/comments/82yzln/if_i_had_a_sequence_of_16_actors_some_recurring/dve2bb8/?context=10000">a question posed on Reddit</a> that uses Chromatic numbers to solve a real life problem!</p>
<p>Here&#8217;s another irrelevant picture.</p>
<figure data-shortcode="caption" id="attachment_1056" aria-describedby="caption-attachment-1056" style="width: 517px" class="wp-caption alignnone"><img data-attachment-id="1056" data-permalink="https://mikepawliuk.ca/vdw-full/" data-orig-file="https://mikepawliuk.files.wordpress.com/2013/12/vdw-full.png" data-orig-size="517,116" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="VDW full" data-image-description="" data-medium-file="https://mikepawliuk.files.wordpress.com/2013/12/vdw-full.png?w=300" data-large-file="https://mikepawliuk.files.wordpress.com/2013/12/vdw-full.png?w=517" src="https://mikepawliuk.files.wordpress.com/2013/12/vdw-full.png?w=660" alt="VDW full"   class="alignnone size-full wp-image-1056" srcset="https://mikepawliuk.files.wordpress.com/2013/12/vdw-full.png 517w, https://mikepawliuk.files.wordpress.com/2013/12/vdw-full.png?w=150 150w, https://mikepawliuk.files.wordpress.com/2013/12/vdw-full.png?w=300 300w" sizes="(max-width: 517px) 100vw, 517px" /><figcaption id="caption-attachment-1056" class="wp-caption-text">This is the colouring.</figcaption></figure>]]></summary>
        <author>
            <name>Mike Pawliuk – Mathematics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A case study in mathematical content]]></title>
        <id>https://www.peterkrautzberger.org/0203/</id>
        <link href="https://www.peterkrautzberger.org/0203/">
        </link>
        <updated>2018-03-01T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>As <a href="https://www.peterkrautzberger.org/202/">I wrote a while ago</a>, I've been working to change my language to keep the notion of &quot;mathematics on the web&quot; and &quot;equation/formula rendering on the web&quot; separate. That's hard since I've been mostly writing about equation rendering in the past few years; a professional risk, when you spent those years managing <a href="https://www.mathjax.org/">the open source project</a> that provides the best and by far most popular equation rendering solution for the web.</p>
<p>It's also difficult because most people in this field <em>like</em> this confusion, especially if they have a stake in it. It's obviously a better sales pitch to say you're helping all of STEM even if you're actually working on a set of (arguably tricky) visual/print layout techniques. I don't want to sound too cynical here; for many people it does come from the heart, they think they are helping STEM this way and it is what drives them. Besides, as they say, you cannot change others only yourself.</p>
<h2>A real life math fragment</h2>
<p>These days I spent much more time on the document level and, mostly, on mathematical documents. That brings up a slew of interesting problems but many are too ephemeral to share. The other day I had a particularly interesting piece of content as it highlights some aspects of the problem of this identification.</p>
<p>In <a href="https://arxiv.org/abs/1412.8106">this paper</a> you find the following</p>
<img aria-labelledby="204-explainer" src="https://www.peterkrautzberger.org/assets/2018/arxiv_1412_8106.png">
<p id="204-explainer">
The layout captured in this image combines a label (5.4) with an ordered list of three mathematical statement, one of which include a sublist of two items. Of course, these statements include quite a few bits of equational content but those aren't that important here. Instead, what's interesting is that a stretchy brace is used a visual cue that connects the single label with the list of statements, aligning its center with the label and extending to the height of the list.
</p>
<h2>Take me to the web</h2>
<p>How do you realize this kind of layout on the web? (And, for that matter, in LaTeX?) Before answering that, it's worth to dive a little deeper.</p>
<p>There are two conflicting details here. On the one hand, the label (as per source and context) is actually an equation label. This means the authors intended this list of statements (each being a self-contained sentence with several equational elements interspersed) to be treated as a single piece of equational content. Much like tables, images, or (since we're in a math paper) theorem environments, this is an important piece of structural information and should not be lost.</p>
<p>On the other hand, the list is (nested) ordered (text) list and it is encoded as such by the authors. This is obviously an important piece of structural information and should not be lost.</p>
<p>And that's a bit of a problem both for the web and for LaTeX: there's no system for equation layout with a concept for ordered list built-in. And there's no text layout system with stretchy braces.</p>
<p>If you look in the TeX source of the paper, you'll see how this was hacked using <code>\parbox</code>. On the web, you have a harder time since in practical terms you can't really do this kind of hack of switching from equation layout to text layout. In theory (i.e., HTML5 spec dream land), you could try something like this</p>
<pre><code class="language-html">&lt;math side=&quot;left&quot;&gt;
  &lt;mtable&gt;
    &lt;mlabeledtr&gt;
        &lt;mtd&gt;
          &lt;mtext&gt;(5.4)&lt;/mtext&gt;
        &lt;/mtd&gt;
        &lt;mtd&gt;
          &lt;mo&gt;{&lt;/mo&gt;
          &lt;mtext&gt;
            &lt;ol&gt;
              ...
            &lt;/ol&gt;
          &lt;/mtext&gt;
        &lt;/mtd&gt;
    &lt;/mlabeledtr&gt;
  &lt;/mtable&gt;
&lt;/math&gt;
</code></pre>
<p>Now this won't work that well in real life. But the real question for me is: is that even correct? (in which sense)? This is a <code>&lt;math&gt;</code> element consisting really only of text while the purely visual brace is the only element with &quot;semantic&quot; markup. Hm...</p>
<h2>so what?</h2>
<p>I find this one interesting because the problem is a case of visual layout clouding one's judgement. You want to use stretchy braces, so in TeX you need math mode and the rest follows pretty &quot;rationally&quot;, no matter the hackiness. After all, it's print; no need to care about anything but the looks.</p>
<p>On the one hand, there's the gut reaction to say that authors should not do things like this. This may be based on the simple principle that, when you need to hack around a lot, you're probably doing something wrong.</p>
<p>A less toxic response may be to criticize the content structure: should this really be an equation label? Isn't it more like a theorem-environment anyway? If not, should this enumeration not be numbered as sub-equations? And isn't the brace a legacy from organizing content on a blackboard rather than something for print layout to mimic (let alone web layout)?</p>
<p>If I was one of the authors, I'd probably respond grumpily: how dare you question that this is the best (perhaps not good but best) way to represent this particular piece of mathematical content that I arrived at after years of study of a deep and complex research topic?</p>
<p>And they'd be right because this really only evades the two actual problems: the confusion of &quot;equation&quot; and &quot;mathematical fragment&quot; and the problem of stretchy characters.</p>
<p>On the one hand, it's clear that this is a (complicated) unit of <em>mathematical</em> information. It must be treated as one. And while I would argue it is not an equation/formula (and certainly not in the sense of &quot;equational layout&quot; let alone MathML's idea of it), if the authors want to count it as such, there should be a way. But on the web we're severely limited when it comes to marking anything &quot;an equation&quot;, especially when it structures like regular lists come into play.</p>
<p>From a layout perspective is, however, the only notable problem is the stretched brace. It has no meaning here (if it ever has); it's merely a stylistic element to help visually connect a list with a label. It is not &quot;mathematics&quot; or even &quot;equational&quot; in any sense of the word. And yet with the current state of web technology, the only way to realize it is by using tools specialized for precisely equation layout (and usually with misleading &quot;semantics&quot; to boot).</p>
<p>But we should be able to do this, no?</p>
<hr>
<h2>Coda.</h2>
<p>Here's an example (using a technique of pure CSS stretchy braces developed by Davide Cervone for <a href="https://www.mathjax.org/">MathJax</a> v3).</p>
<p data-height="265" data-theme-id="dark" data-slug-hash="OQQVgx" data-default-tab="result" data-user="pkra" data-embed-version="2" data-pen-title="case study: arxiv.org/1412.8106" class="codepen">See the Pen <a href="https://codepen.io/pkra/pen/OQQVgx/">case study: arxiv.org/1412.8106</a> by Peter Krautzberger (<a href="https://codepen.io/pkra">@pkra</a>) on <a href="https://codepen.io/">CodePen</a>.</p>
<script async="" src="https://static.codepen.io/assets/embed/ei.js"></script>
<hr>
<h2>Addendum 2018-05-29</h2>
<p>I read up on the changes in the HTML 5.3 working draft and realized that my HTML5-ish example above (using an ordered list inside MathML) is not even valid HTML - oh my! As it turns out, the integration of MathML into <a href="https://html.spec.whatwg.org/#mathml">HTML</a> states that only <a href="https://html.spec.whatwg.org/#phrasing-content-2">phrasing content</a> is allowed inside MathML token elements (and lists are not phrasing content). Well, one more reason never to use MathML on the web - but you already knew that.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quote by Yoda in The Last Jedi]]></title>
        <id>http://dcernst.github.io/yoda-quote/</id>
        <link href="http://dcernst.github.io/yoda-quote/">
        </link>
        <updated>2018-02-17T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>The Jedi Master <a href="https://en.wikipedia.org/wiki/Yoda">Yoda</a> has had some <a href="http://awakenthegreatnesswithin.com/40-inspirational-yoda-quotes-to-awaken-the-force-within-you/">awesome quotes</a> over the years.  The quote below from <a href="https://en.wikipedia.org/wiki/Star_Wars:_The_Last_Jedi">The Last Jedi</a> is one of my all-time favorites from Yoda because it embraces productive failure.</p>

<blockquote>
<p>Pass on what you have learned. Strength, mastery. But weakness, folly, failure also. Yes, failure most of all. The greatest teacher, failure is.</p>
<footer>Yoda</footer>
</blockquote>]]></summary>
        <author>
            <name>Dana C. Ernst</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New domain]]></title>
        <id>http://normanspace.org/2018/02/07/stand-by-for-configuration/</id>
        <link href="http://normanspace.org/2018/02/07/stand-by-for-configuration/">
        </link>
        <updated>2018-02-07T05:05:00Z</updated>
        <summary type="html"><![CDATA[<p>After many years on Booles&#8217; Rings, I am moving my academic and work blog to a new domain, normanspace.org. Thanks so much to Booles&#8217; Rings for hosting my site for all these years!</p>
<p>&nbsp;</p>]]></summary>
        <author>
            <name>Norman Lewis Perlmutter</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Written elsewhere, booknet canada edition; Equations ≠ Math]]></title>
        <id>https://www.peterkrautzberger.org/0202/</id>
        <link href="https://www.peterkrautzberger.org/0202/">
        </link>
        <updated>2018-01-30T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I wrote a few things in the last few months that I'd like to cross post (and I'll eventually archive them here).</p>
<p>First off, there's <a href="https://www.booknetcanada.ca/blog/2018/1/12/equations-math-or-equation-layout-as-a-print-artifact">Equations ≠ Math (Or: Equation layout as a print artifact)</a> (<a href="https://web.archive.org/save/https://www.booknetcanada.ca/blog/2018/1/12/equations-math-or-equation-layout-as-a-print-artifact">archive.org</a>). This somewhat of a continuation (and hopefully a refinement) on <a href="https://www.peterkrautzberger.org/0196/">#196</a>.</p>
<p>You should also totally <a href="http://techforum.booknetcanada.ca/register/">register</a> for my upcoming workshop on equation rendering in ebooks at <a href="http://techforum.booknetcanada.ca/speakers/">Ebookcraft in March</a>!</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[2018 in preview]]></title>
        <id>https://www.peterkrautzberger.org/0201/</id>
        <link href="https://www.peterkrautzberger.org/0201/">
        </link>
        <updated>2018-01-21T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I miss writing here; alot. I technically wrote twice as much here in 2017 than in 2016 (and up to No. 200) but it was still less than once a month; it became hard at some point. I used to be able to blame my work <a href="https://www.mathjax.org/">for MathJax</a> because I was (at times) writing a lot for the project; I don't have that particular excuse <a href="https://groups.google.com/d/msg/mathjax-dev/k48Q0NxiNoU/BRYlaDuaCAAJ">anymore</a>.</p>
<figure>
<img alt="A simplistic drawing of a person embracing a large furry, horned creature with caption 'I care about this ALOT'" src="https://www.peterkrautzberger.org/assets/2018/ALOT2.png">
<figcaption>
From <a href="https://hyperboleandahalf.blogspot.de/2010/04/alot-is-better-than-you-at-everything.html">The Alot is Better Than You at Everything</a> by <a xmlns:cc="http://creativecommons.org/ns#" href="http://hyperboleandahalf.blogspot.com/" property="cc:attributionName" rel="cc:attributionURL">Allie Brosh</a>, <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/3.0/us/">cc-by-nd</a>.
</figcaption>
</figure>
<p>I've never been one for looking back at the end of a year. But since the last year was complex (and this one is set up to be equally so) I thought maybe I should motivate myself by looking ahead to the things I want to write about this year (including things in my actual schedule for 2018).</p>
<ul>
<li>wrap up the series &quot;The Problem with MathML as a web standard&quot;, my 10,000ft view of MathML's flaws.
<ul>
<li>this has taken far too much time already and I've started to hate coming back to it because of all the negativity around MathML (both the spec and the community).</li>
</ul>
</li>
<li>think about my upcoming workshop on equation rendering in ebooks at <a href="http://techforum.booknetcanada.ca/speakers/">Ebookcraft in March</a> (you should totally <a href="http://techforum.booknetcanada.ca/register/">register</a>!)</li>
<li>think about the workshop I'm co-organizing at AIM on <a href="https://aimath.org/workshops/upcoming/webmath/">web accessibility of mathematics in May</a></li>
<li>reminisce about my time at MathJax which shaped the past 5 years of my life
<ul>
<li>in particular, write about MathJax v3 a bit</li>
</ul>
</li>
<li>write about the future of equation rendering on the web as I think it could unfold
<ul>
<li>maybe wonder a bit about the future of real STEM content</li>
</ul>
</li>
<li>write up some thoughts and experiments from last year on how the web can (should and probably will) replace LaTeX for most people</li>
<li>write down some observations from a workshop on authoring accessible STEM content for the web which I did together with <a href="https://twitter.com/bfisseler">Björn Fisseler</a> at FernUni Hagen last year.</li>
<li>status updates for <a href="https://mathblogging.org/">mathblogging.org</a> and <a href="https://boolesrings.org/">boolesrings.org</a></li>
<li>write about <a href="http://www.ams.org/publications/journals/journalsframework/AMSMathViewer">AMS MathViewer</a></li>
</ul>
<p>Ok, maybe stop here; it's a lot already.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamical sets whose union with infinity is connected]]></title>
        <id>https://sixsmith2017.wordpress.com/2018/01/19/dynamical-sets-whose-union-with-infinity-is-connected/</id>
        <link href="https://sixsmith2017.wordpress.com/2018/01/19/dynamical-sets-whose-union-with-infinity-is-connected/">
        </link>
        <updated>2018-01-19T19:58:48Z</updated>
        <summary type="html"><![CDATA[<p>Available on the <a href="https://arxiv.org/abs/1712.08375">arXiv</a>. <span id="more-378"></span></p>
<p>Suppose that <span id="MathJax-Element-1-Frame" class="MathJax"><span id="MathJax-Span-1" class="math"><span id="MathJax-Span-2" class="mrow"><span id="MathJax-Span-3" class="mi">f</span></span></span></span> is a transcendental entire function. In 2014, Rippon and Stallard showed that the union of the escaping set with infinity is always connected. In this paper we consider the related question of whether the union with infinity of the bounded orbit set, or the bungee set, can also be connected. We give sufficient conditions for these sets to be connected, and an example a transcendental entire function for which all three sets are simultaneously connected. This function lies, in fact, in the Speiser class.<br />
It is known that for many transcendental entire functions the escaping set has a topological structure known as a spider&#8217;s web. We use our results to give a large class of functions in the Eremenko-Lyubich class for which the escaping set is not a spider&#8217;s web. Finally we give a novel topological criterion for certain sets to be a spider&#8217;s web.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>]]></summary>
        <author>
            <name>Dave Sixsmith – I am a mathematician, not a calculator</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The dynamics of quasiregular maps of punctured space]]></title>
        <id>https://sixsmith2017.wordpress.com/2018/01/19/the-dynamics-of-quasiregular-maps-of-punctured-space/</id>
        <link href="https://sixsmith2017.wordpress.com/2018/01/19/the-dynamics-of-quasiregular-maps-of-punctured-space/">
        </link>
        <updated>2018-01-19T19:51:12Z</updated>
        <summary type="html"><![CDATA[<p>Accepted for publication by Indiana Univ. Math. J. Available on the <a href="https://arxiv.org/abs/1607.06649">arXiv</a>. This is a joint work with <a href="http://arxiv.org/find/math/1/au:+Nicks_D/0/1/0/all/0/1">Dan Nicks</a>.<span id="more-376"></span></p>
<p>The Fatou-Julia iteration theory of rational and transcendental entire functions has recently been extended to quasiregular maps in more than two real dimensions. Our goal in this paper is similar; we extend the iteration theory of analytic self-maps of the <em>punctured plane</em> to quasiregular self-maps of <em>punctured space</em>.</p>
<p>We define the Julia set as the set of points for which the complement of the forward orbit of any neighbourhood of the point is a finite set. We show that the Julia set is non-empty, and shares many properties with the classical Julia set of an analytic function. These properties are stronger than those known to hold for the Julia set of a general quasiregular map of space.</p>
<p>We define the quasi-Fatou set as the complement of the Julia set, and generalise a result of Baker concerning the topological properties of the components of this set. A key tool in the proof of these results is a version of the fast escaping set. We generalise various results of Marti-Pete concerning this set, for example showing that the Julia set is equal to the boundary of the fast escaping set.</p>
<p>&nbsp;</p>]]></summary>
        <author>
            <name>Dave Sixsmith – I am a mathematician, not a calculator</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quote by Marcus Aurelius]]></title>
        <id>http://dcernst.github.io/marcus-aurelius-quote/</id>
        <link href="http://dcernst.github.io/marcus-aurelius-quote/">
        </link>
        <updated>2018-01-03T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I recently listened to <a href="http://www.powercompanyclimbing.com/blog/2017/11/6/episode-64-fixed-vs-growth-mindset-with-trevor-ragan-from-trainugly">Episode 64</a> of <a href="http://www.powercompanyclimbing.com/podcast/">The Power Company Podcast</a>. In this episode, the host interviews <a href="http://trainugly.com/trevor-ragan/">Trevor Ragan</a> from <a href="http://trainugly.com">TrainUgly</a> and the topic of discussion is fixed versus growth mindset. For an introduction to growth mindset, a good place to start is the post I wrote for the <a href="http://maateachingtidbits.blogspot.com">Teaching Tidbits Blog</a> called <a href="http://maateachingtidbits.blogspot.com/2017/11/the-role-of-failure-and-struggle-in.html">The Role of Failure and Struggle in the Mathematics Classroom</a>. At the end of the podcast, Ragan suggests some further reading.  One of those books is <a href="https://www.amazon.com/Obstacle-Way-Timeless-Turning-Triumph/dp/1591846358">The Obstacle is the Way: The Timeless Art of Turning Trials into Triumph</a> by Ryan Holiday, which I recently started reading.  The beginning of this book contains the following quote by Roman emperor <a href="https://en.wikipedia.org/wiki/Marcus_Aurelius">Marcus Aurelius</a> that embraces obstacles and discourages the fear of failure:</p>

<blockquote>
<p>The impediment to action advances action. What stands in the way becomes the way.</p>
<footer>Marcus Aurelius</footer>
</blockquote>]]></summary>
        <author>
            <name>Dana C. Ernst</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quote by Bruce Lee]]></title>
        <id>http://dcernst.github.io/bruce-lee-quote/</id>
        <link href="http://dcernst.github.io/bruce-lee-quote/">
        </link>
        <updated>2017-12-31T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Here’s a great quote about failure by Chinese-American martial arts master and actor <a href="https://en.wikipedia.org/wiki/Bruce_Lee">Bruce Lee</a> (1940–1973):</p>

<blockquote>
<p>Don’t fear failure.  Not failure, but low aim, is the crime. In great attempts it is glorious even to fail.</p>
<footer>Bruce Lee</footer>
</blockquote>

<p>This quote appears on page 121 of <a href="https://www.amazon.com/Bruce-Lee-Striking-Thoughts-Library/dp/0804834717">Striking Thoughts: Bruce Lee’s Wisdom for Daily Living</a>.  For more great quotes, check out the <a href="https://en.wikiquote.org/wiki/Bruce_Lee">Wikiquote page for Bruce Lee</a>.</p>]]></summary>
        <author>
            <name>Dana C. Ernst</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quote by Henri Poincaré]]></title>
        <id>http://dcernst.github.io/poincare-quote/</id>
        <link href="http://dcernst.github.io/poincare-quote/">
        </link>
        <updated>2017-11-24T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I love the following quote by French mathematician Henri Poincaré (1854-1912).  I’m not sure what the original source is, but it is cited in the introduction to <em>The Divine Proportion</em> (1970) by H.E. Huntley.</p>

<blockquote>
<p>The mathematician does not study pure mathematics because it is useful; he studies it because he delights in it, and he delights in it because it is beautiful.</p>
<footer>Henri Poincaré</footer>
</blockquote>]]></summary>
        <author>
            <name>Dana C. Ernst</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A remark on Schimmerling’s question]]></title>
        <id>http://blog.assafrinot.com/?p=4456</id>
        <link href="http://blog.assafrinot.com/?p=4456">
        </link>
        <updated>2017-11-14T19:59:58Z</updated>
        <summary type="html"><![CDATA[<div class="thanks_button_div" 
                  style="margin-bottom: 30px;"><div id="thanksButtonDiv_4456_2" style="background-image:url(http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/thanks_compact_brown1.png); background-repeat:no-repeat; float: left; display: inline;"
                onmouseover="javascript:thankYouChangeButtonImage('thanksButtonDiv_4456_2', true);" 
                onmouseout="javascript:thankYouChangeButtonImage('thanksButtonDiv_4456_2', false);"
                onclick="javascript:thankYouChangeButtonImage('thanksButtonDiv_4456_2', false);" >
                <input type="button" onclick="thankYouButtonClick(4456, 'You left &ldquo;Thanks&rdquo; already for this post')" value="Like 97"
                  class="thanks_button thanks_compact thanks_brown"
                  style="  font-family: Verdana, Arial, Sans-Serif; font-size: 14px; font-weight: normal;; color:#ffffff;"
                  id="thanksButton_4456_2" title="Click to leave &ldquo;Thanks&rdquo; for this post"/>
             </div><div id="ajax_loader_4456_2" style="display:inline;visibility: hidden;"><img alt="ajax loader" src="http://blog.assafrinot.com/wp-content/plugins/thanks-you-counter-button/images/ajax-loader.gif" /></div></div><p>Joint work with <a href="http://u.math.biu.ac.il/~brodska/">Ari Meir Brodsky</a>.</p>
<p><strong>Abstract.</strong> Schimmerling asked whether $\square^*_\lambda$ together with GCH entails the existence of a $\lambda^+$-Souslin tree, for a singular cardinal $\lambda$. Here, we provide an affirmative answer under the additional assumption that there exists a non-reflecting stationary subset of $E^{\lambda^+}_{\neq cf(\lambda)}$.<br />
As a bonus, the outcome $\lambda^+$-Souslin tree is moreover <em>free</em>.</p>
<p><strong>Downloads:</strong></p>
<p><p><table class=paperruler"><tr><td><a onclick="thankYouButtonClick(4456, '')"  href="http://www.assafrinot.com/files/paper32.pdf" class="billet_author"></a><img src="/design/002_arxiv_dis.png"   class="opacity_icons"  height=90 width=64 border=1  alt="[No arXiv entry]" title="No arXiv entry"  /><a onclick="thankYouButtonClick(4456, '')" href="http://doi.org/10.1007/s11083-019-09482-7" class="billet_publish"></a><img src="/design/004_review_dis.png"  class="opacity_icons" height=90 width=64 border=1  alt="[No entry on mathscinet]" title="No entry on mathscinet"  /><a onclick="thankYouButtonClick(4456, '')" href="http://www.assafrinot.com/talk/luminy2017" class="billet_slides"></a><a href="http://www.assafrinot.com/paper/26" class="billet_further"></a><a href="http://papers.assafrinot.com/list.php?bib=rinot.bib&key=paper32" class="billet_bibtex"></a><a href="http://www.assafrinot.com/paper/32" class="billet_perm"></a></td></tr></table></p><span id="more-4456"></span></p>]]></summary>
        <author>
            <name>Assaf Rinot</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trust me, I'm a doctor!]]></title>
        <id>http://karagila.org/2017/trust-me-im-a-doctor/</id>
        <link href="http://karagila.org/2017/trust-me-im-a-doctor/">
        </link>
        <updated>2017-11-02T19:31:38Z</updated>
        <summary type="html"><![CDATA[<p>Finally!</p>

<p>Six months after I had turned in my dissertation, I have finally received the approval on the damn thing. <a href="http://karagila.org/2017/trust-me-im-a-doctor/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamics in the Eremenko-Lyubich class]]></title>
        <id>https://sixsmith2017.wordpress.com/2017/10/08/dynamics-in-the-eremenko-lyubich-class/</id>
        <link href="https://sixsmith2017.wordpress.com/2017/10/08/dynamics-in-the-eremenko-lyubich-class/">
        </link>
        <updated>2017-10-08T18:18:22Z</updated>
        <summary type="html"><![CDATA[<p>Available on the <a href="https://arxiv.org/abs/1709.09095">arXiv</a>. <span id="more-365"></span></p>
<p>We survey the dynamics of functions in the Eremenko-Lyubich class, <span id="MathJax-Element-1-Frame" class="MathJax"><span id="MathJax-Span-1" class="math"><span id="MathJax-Span-2" class="mrow"><span id="MathJax-Span-3" class="texatom"><span id="MathJax-Span-4" class="mrow"><span id="MathJax-Span-5" class="mi"><img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BB%7D.&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="&#92;mathcal{B}." title="&#92;mathcal{B}." class="latex" /></span></span></span></span></span></span> Among transcendental entire functions, those in this class have properties that make their dynamics markedly accessible to study. Many authors have worked in this field, and the dynamics of class <span id="MathJax-Element-1-Frame" class="MathJax"><span id="MathJax-Span-1" class="math"><span id="MathJax-Span-2" class="mrow"><span id="MathJax-Span-3" class="texatom"><span id="MathJax-Span-4" class="mrow"><span id="MathJax-Span-5" class="mi"><img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BB%7D&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="&#92;mathcal{B}" title="&#92;mathcal{B}" class="latex" /></span></span></span></span></span></span> functions is now particularly well-understood and well-developed. There are many striking and unexpected results. Several powerful tools and techniques have been developed to help progress this work. We consider the fundamentals of this field, review some of the most important results, techniques and ideas, and give stepping-stones to deeper inquiry.</p>
<p>&nbsp;</p>]]></summary>
        <author>
            <name>Dave Sixsmith – I am a mathematician, not a calculator</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The problem with MathML as a web standard (part 4)]]></title>
        <id>https://www.peterkrautzberger.org/0200/</id>
        <link href="https://www.peterkrautzberger.org/0200/">
        </link>
        <updated>2017-09-29T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Let's continue from <a href="https://www.peterkrautzberger.org/0199/">part 3</a> (after some traveling of mine).</p>
<h2>Prelude</h2>
<p>As I wrote last time, the usual way to describe MathML's double-spec is this: <q><a href="https://www.w3.org/Math/draft-spec/mathml.html#chapter3_">Presentation MathML</a> is for layout and <a href="https://www.w3.org/Math/draft-spec/mathml.html#chapter4_">Content MathML</a> is for semantics.</q></p>
<p>Last time I wrote about how semantics are effectively absent from MathML on the web. Unfortunately, layout does not fare much better.</p>
<h2>The fourth problem: MathML does not specify layout</h2>
<p>So at first the spec will tell you that's absolutely not true:</p>
<blockquote>
<p>Presentation markup [...] is used to display mathematical expressions; and Content markup [...] is used to convey mathematical meaning.</p>
<footer><a href="https://www.w3.org/Math/draft-spec/mathml.html#chapter1_intro.overview">1.3 Overview</a></footer>
</blockquote>
<p>So you will naturally start by thinking Presentation MathML is what you're after regarding equation layout (<a href="https://www.peterkrautzberger.org/0196/"><em>not</em> mathematics</a>).</p>
<p>The spec, however, throws you a curveball:</p>
<blockquote>
<p>MathML presentation elements only recommend (i.e., do not require) specific ways of rendering; this is in order to allow for medium-dependent rendering and for individual preferences of style.</p>
<footer><a href="https://www.w3.org/Math/draft-spec/mathml.html#chapter2_fund.renderingmodel">2.1.4 MathML and Rendering</a></footer>
</blockquote>
<p>So Presentation MathML spec is about layout but not actually specifying how that should work.</p>
<p>This is obviously a problem when you want to see standards-compliant implementations in all major web browsers (even if it's just 4 engines). Usually (say with CSS or SVG), you can assume that a standard ensures developers that they are able to get consistent results across systems. Of course any standard will have gaps and edge cases but then, at least, specs can be clarified and either fixed in both standards and implementations or a standard can be identified as problematic (and ideally a less inconsistent standard can replace it).</p>
<p>However, this is not some kind of accident and you can easily find many statements in the same vein throughout the spec. For example, the section for <a href="https://www.w3.org/Math/draft-spec/mathml.html#chapter3_presm.mfrac"><code>&lt;mfrac&gt;</code></a> says effectively nothing about the spacing between numerator, fraction line, and denominator.</p>
<p>Or you get gems like this one from <a href="https://www.w3.org/Math/draft-spec/mathml.html#chapter3_id.3.6.5.1"><code>&lt;mscarries&gt;</code></a></p>
<blockquote>
<p>This means that the second row, even if it does not draw, visually uses some (undefined by this specification) amount of space when displayed.</p>
</blockquote>
<p>In contrast, start with any random part of contemporary CSS, e.g., <a href="https://www.w3.org/TR/css-flexbox-1/#box-model">flex container</a> to start down the rabbit hole that are the result of quite meticulous discussions of layout specifics.</p>
<p>In other words, Presentation MathML does not even <em>want</em> to give you the same (messy) path to improvements as we're used to on the web (and we're still ignoring the practical problem that the Working Group is dead in the water so no fixes can be made).</p>
<p>At this point you might be wondering how that could be possible. After all, ther are plenty of equation rendering enginens out there that handle MathML. How do you reconcile this?</p>
<p>I think it is fairly simple (yet no less problematic). Presentation MathML assumes an implementor already knows how equation layout is supposed to work, in fact reading the spec you will get the feeling that it assumes you already have an equation layout engine at your disposal and you are merely adding MathML support, interpreting it in your engine.</p>
<p>in other words, Presentation MathML does not specify layout but is an abstraction layer, an exchange format for equation layout engines, a format that a rendering engine can (easily) make sense of within its already existing system.</p>
<p>(And yes, you could troll MathML enthusiasts by saying that Chrome and Edge support all layout requirements of the MathML spec. But <a href="http://dontbeadickday.com/">please don't</a>.)</p>
<h3>The fourth-and-a-half problem</h3>
<p>Since I considered the value of Presentation MathML's semantics in the previous post, it's only prudent to double check the value of Content MathML for layout. Unsuprisingly, Content MathML really does not want to help either. The spec speaks quite clearly:</p>
<blockquote>
<p>[...] encoding the underlying mathematical structure explicitly, without regard to how it is presented aurally or visually,</p>
<footer><a href="https://www.w3.org/Math/draft-spec/mathml.html#chapter4_contm.intro">4.1.1 The Intent of Content Markup</a></footer>
</blockquote>
<p>So no visual layout nowhere.</p>
<p>By the way, it seems easy to misunderstand this point in the spec. Of course we can render MathML content - lots of tools do. But what no tool can rely on is the MathML spec when it comes to deciding on how to render Content MathML content visually. As I already mentioned, few rendering engines are &quot;MathML-based&quot; because they literally cannot be, they need to base their layout decisions on a more reliable source.</p>
<p>The other side of that coin is that you might disagree how to visually render Content MathML. In real life (at MathJax), we've actually had one or two complaints over the year how our Content-to-Presentation conversion is <q>wrong</q>.</p>
<h2>Coda</h2>
<p>This is really just the core, the fundamental issue around MathML layout on the web. Even if you make the assumption that an equation layout engine should be added to browsers, there are more problems. And then we're still not talking about the problems of the shoddy implementations in Gecko and WebKit. Let's see if I'll get around to that. For now, let's continue the 10,000 ft view a bit longer.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some thoughts about teaching introductory courses in set theory]]></title>
        <id>http://karagila.org/2017/some-thoughts-about-teaching-introductory-courses-in-set-theory/</id>
        <link href="http://karagila.org/2017/some-thoughts-about-teaching-introductory-courses-in-set-theory/">
        </link>
        <updated>2017-09-21T23:39:02Z</updated>
        <summary type="html"><![CDATA[<p>Dianna Crown, the physics woman on YouTube, has posted a video where she is interviewed by her editor about why and how she found herself majoring in physics in MIT.</p>

<p>Here is the video: <a href="http://karagila.org/2017/some-thoughts-about-teaching-introductory-courses-in-set-theory/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is maths imaginary?]]></title>
        <id>https://sixsmith2017.wordpress.com/2017/09/16/is-maths-imaginary/</id>
        <link href="https://sixsmith2017.wordpress.com/2017/09/16/is-maths-imaginary/">
        </link>
        <updated>2017-09-16T13:49:27Z</updated>
        <summary type="html"><![CDATA[<p>I was &#8220;talking&#8221; to someone on twitter recently, who claimed that mathematical objects are &#8216;imaginary&#8217;. I guess this is received wisdom; after all, if mathematical objects are not imaginary, they must exist somewhere. And no-one (at least not anyone I know) has stumbled across an exponential function at the bottom of their garden, or stubbed their toe on a stray modular domain, or been attacked by a swarm of acute angle triangles.</p>
<p>Yet, the fact that mathematical objects are real is the daily experience of mathematicians (though few would ever claim this, because they are much too cautious). I&#8217;d like to try to explain this experience. Since I am not a philosopher, there will be no robust philosophical arguments. I will not discuss ontology. Try not to be disappointed.</p>
<p>Imagine you were an astronomer. (No, go on. Give it a go.) You point your telescope up in the air and &#8211; lo &#8211; a new star appears. You call a friend, and tell her the news. She points her telescope in the same place and &#8211; lo &#8211; the same star. You write up your discovery, and a team of astronomers in Belgium train their more powerful telescopes on the same spot, and describe the colour and size of the star. You have another look, and see they are correct. An international team in Chile use radioastronomy to discover that your star is actually two stars, orbiting around each other. It is later discovered that there is a large exoplanet orbiting one of these stars.</p>
<p>Now &#8211; I guess &#8211; it could be argued that there is <em>no star</em>. It could be argued that you invented it, and then let everyone else know how to do the same. The star is some sort of socially constructed illusion. In my view this is a purest nonsense. There is a real star, it is really out there. That, after all, is the belief of (most) astronomers. Otherwise, we might as well give up the whole astronomy thing altogether.</p>
<figure data-shortcode="caption" id="attachment_298" aria-describedby="caption-attachment-298" style="width: 696px" class="wp-caption alignnone"><img data-attachment-id="298" data-permalink="https://sixsmith2017.wordpress.com/death-star-v2/" data-orig-file="https://sixsmith2017.files.wordpress.com/2017/09/death-star-v2.jpg" data-orig-size="696,392" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Death-Star-v2" data-image-description="" data-medium-file="https://sixsmith2017.files.wordpress.com/2017/09/death-star-v2.jpg?w=300" data-large-file="https://sixsmith2017.files.wordpress.com/2017/09/death-star-v2.jpg?w=640" class="alignnone size-full wp-image-298" src="https://sixsmith2017.files.wordpress.com/2017/09/death-star-v2.jpg?w=640" alt="Death-Star-v2" srcset="https://sixsmith2017.files.wordpress.com/2017/09/death-star-v2.jpg?w=640 640w, https://sixsmith2017.files.wordpress.com/2017/09/death-star-v2.jpg?w=150 150w, https://sixsmith2017.files.wordpress.com/2017/09/death-star-v2.jpg?w=300 300w, https://sixsmith2017.files.wordpress.com/2017/09/death-star-v2.jpg 696w" sizes="(max-width: 640px) 100vw, 640px"   /><figcaption id="caption-attachment-298" class="wp-caption-text">This star really is imaginary. Or so I am told.</figcaption></figure>
<p>So I am getting to my point. Thanks for being patient.</p>
<p>My point is that this is also the daily experience of mathematicians. Let&#8217;s suppose I am studying transcendental dynamics (as I do), and I study a new set which seems of interest (well, you never know). I email a colleague, and they confirm the set looks as I said, and maybe they spot something else; perhaps it has dimension one, or is dense in the plane, or something technical like that. We write a paper. A team of Belgian mathematicians read our paper, and note that, in fact, our set has other interesting properties. They email us and we find that this is indeed the case. More papers follow, and then someone (in Chile, perhaps) observes that our set is actually the union of two interesting sets, and gives some further properties of each. When we look into it, we see that this is indeed the case. This is how (pure) maths is done.</p>
<figure data-shortcode="caption" id="attachment_314" aria-describedby="caption-attachment-314" style="width: 600px" class="wp-caption alignnone"><img data-attachment-id="314" data-permalink="https://sixsmith2017.wordpress.com/2017/09/16/is-maths-imaginary/600px-mandel/" data-orig-file="https://sixsmith2017.files.wordpress.com/2017/09/600px-mandel.png" data-orig-size="600,480" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="600px-Mandel" data-image-description="" data-medium-file="https://sixsmith2017.files.wordpress.com/2017/09/600px-mandel.png?w=300" data-large-file="https://sixsmith2017.files.wordpress.com/2017/09/600px-mandel.png?w=600" class="alignnone size-full wp-image-314" src="https://sixsmith2017.files.wordpress.com/2017/09/600px-mandel.png?w=640" alt="600px-Mandel" srcset="https://sixsmith2017.files.wordpress.com/2017/09/600px-mandel.png 600w, https://sixsmith2017.files.wordpress.com/2017/09/600px-mandel.png?w=150 150w, https://sixsmith2017.files.wordpress.com/2017/09/600px-mandel.png?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"   /><figcaption id="caption-attachment-314" class="wp-caption-text">The famous Mandelbrot set, as drawn in the late 1970s.</figcaption></figure>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>Essentially this story (for it is a story; I have not discovered any sets of interest to Belgians) is no different to the story about the star. And it is very difficult not to believe the punchline is the same; the set exists &#8216;outside our heads&#8217;, just as the star exists &#8216;outside the heads of the astronomers&#8217;. (I&#8217;m not trying to claim mathematical proof here; I&#8217;m just trying to communicate how it feels to do mathematics).</p>
<figure data-shortcode="caption" id="attachment_327" aria-describedby="caption-attachment-327" style="width: 360px" class="wp-caption aligncenter"><img data-attachment-id="327" data-permalink="https://sixsmith2017.wordpress.com/2017/09/16/is-maths-imaginary/5lrpp/" data-orig-file="https://sixsmith2017.files.wordpress.com/2017/09/5lrpp.png" data-orig-size="360,270" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5LrPp" data-image-description="" data-medium-file="https://sixsmith2017.files.wordpress.com/2017/09/5lrpp.png?w=300" data-large-file="https://sixsmith2017.files.wordpress.com/2017/09/5lrpp.png?w=360" class=" size-full wp-image-327 aligncenter" src="https://sixsmith2017.files.wordpress.com/2017/09/5lrpp.png?w=640" alt="5LrPp" srcset="https://sixsmith2017.files.wordpress.com/2017/09/5lrpp.png 360w, https://sixsmith2017.files.wordpress.com/2017/09/5lrpp.png?w=150 150w, https://sixsmith2017.files.wordpress.com/2017/09/5lrpp.png?w=300 300w" sizes="(max-width: 360px) 100vw, 360px"   /><figcaption id="caption-attachment-327" class="wp-caption-text">We can now draw the Mandelbrot set in much more detail. But it is still the same set.</figcaption></figure>
<p>A real-life example of this story is the famous Mandelbrot set. This was first discovered in the 1970s, when it was very difficult to draw a picture of it. But mathematician talked unto mathematician, and more and more properties were discovered. Technology has moved on, and now highly detailed pictures exist. It is a remarkable object: for example, the set is so intricate that if you try to draw a line around the edge, you will find that your &#8216;line&#8217; is actually two-dimensional. It is even more intricate than the coast of Norway. Nonetheless, all mathematicians would agree they have been studying &#8216;the same thing&#8217; all this time.</p>
<p>So it seems undoubtedly true that mathematical objects exist. I am as confident in the existence of the Mandelbrot set, or the sine function, or Riemann surfaces of genus zero as I am in the existence of Belgium. When we study mathematical objects, we discover them &#8211; we do not invent them. There are thing that exist that are not material objects.</p>
<p>You may feel that this is silly, because if they exist, then where is their home? (It is probably not Belgium). How do we see them? What are they made of? These are a good questions.</p>
<p>&nbsp;</p>]]></summary>
        <author>
            <name>Dave Sixsmith – I am a mathematician, not a calculator</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The problem with MathML as a web standard (part 3)]]></title>
        <id>https://www.peterkrautzberger.org/0199/</id>
        <link href="https://www.peterkrautzberger.org/0199/">
        </link>
        <updated>2017-08-28T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Let's continue from <a href="https://www.peterkrautzberger.org/0198/">part 2</a>.</p>
<h2>Prelude</h2>
<p>This one's slightly tricky. And I also have a confession to make. In the first two parts I pretended I've written about MathML when I really only wrote with half of it in mind.</p>
<p>One problem of the MathML spec in general is that it's really two, quite distinct specs: <a href="https://www.w3.org/Math/draft-spec/mathml.html#chapter3_">Presentation MathML</a> and <a href="https://www.w3.org/Math/draft-spec/mathml.html#chapter4_">Content MathML</a>.</p>
<p>Now the common description is: Presentation describes layout and Content describes semantics. I think one of the problems for MathML in general is that it is not that easy.</p>
<h2>The third problem: MathML does not specify semantics</h2>
<p>So obviously that's wrong. After all there is Content MathML and it specifies an enormous amount of semantics. Such an enormous amount actually that you can express lambda calculus. You also get a whole bunch of fantastic elements (for <code>&lt;reals&gt;</code>) and on top of that built-in, infinite extensibility via content dictionaries. So you can do quite literally everything in Content MathML.</p>
<p>So what's the problem?</p>
<figure><a href="https://commons.wikimedia.org/wiki/File:Tumbeasts_sign1.png#/media/File:Tumbeasts_sign1.png"><img src="https://upload.wikimedia.org/wikipedia/commons/0/0d/Tumbeasts_sign1.png" alt="Tumbeasts sign1.png"></a><figcaption>By <a href="https://en.wikipedia.org/wiki/Matthew_Inman" class="extiw" title="en:Matthew Inman">Matthew Inman</a> - <a rel="nofollow" class="external free" href="http://theoatmeal.com/comics/state_web_summer#tumblr">http://theoatmeal.com/comics/state_web_summer#tumblr</a>, <a href="http://creativecommons.org/licenses/by/3.0" title="Creative Commons Attribution 3.0">CC BY 3.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=38250223">via Wikimedia Commons</a></figcaption></figure>
<p>It's the simplest and most practical problem: Content MathML plays no significant role in real world documents. You can find it in niche projects (such as NISTS's hand-crafted <a href="http://dlmf.nist.gov/">DLMF</a>), you can find it hidden in commercial enclosures (such as Pearson's assessment system where I wonder why you'd need its expressiveness), you can also get it by exportig it from computational tools (Maple, Mathematica etc.). But in real world documents, it's non-existent.</p>
<p>I can't really tell you why that is. Perhaps like most formal abstractions of mathematical knowledge, it ignores the practicalities of humans communicating knowledge. Perhaps, when it comes to its computational prowess, it probably fails on the web because it cannot compete with the practicality of JavaScript or server-based computation (<i lang="fr">à la</i> Jupyter Notebooks).</p>
<p>I also have heard repeatedly that it's simply too difficult to create. And from my limited experience with MathJax users it doesn't help that <a href="https://www.w3.org/Math/draft-spec/mathml.html#chapter4_id.4.1.1">the spec itself</a> warns people that it encodes structure <q>without regard to how it is presented aurally or visually</q>, i.e., it's sometimes not clear how Content MathML should be rendered.</p>
<p>Ultimately, lack of content (pardon the pun) makes Content MathML of little relevance on the web. (An interesting but separate question might be whether the way Content MathML expresses semantics fits into the style that HTML has adopted in recent years; another time perhaps.)</p>
<h3>The third-and-a-half problem</h3>
<p>But there's actually a second problem for MathML and semantics on the web here: <em>Presentation MathML</em>.</p>
<p>It's easy to think that Presentation MathML specifies at least some semantics. And if it specifies some, maybe it's a good basis to build upon. After all, how semantic was HTML really, back in the day?</p>
<p>For example, there's the <a href="https://www.w3.org/Math/draft-spec/mathml.html#chapter3_presm.mfrac"><code>&lt;mfrac&gt;</code></a> element and you might think it specifies a fraction. Unfortunately, you'd be wrong. The spec itself speaks of <q>fraction-like objects such as binomial coefficients and Legendre symbol</q> which are about as far from fractions as you can think of. Of course you can find even more egregious examples in the wild such as plain vectors encoded with <code>mfrac</code>. Similarly, <code>&lt;msqrt&gt;</code> does not represent <i>square root</i> but <i>root without index</i> and it is used accordingly in the wild (while <code>&lt;mroot&gt;&lt;mrow&gt;...&lt;/mrow&gt;&lt;none/&gt;&lt;/mroot&gt;</code> constructions are practically unheard of).</p>
<p>The point is that you can't complain about some kind of abuse of markup because Presentation MathML does not make this kind of a distinction.</p>
<figure>
<a href="https://commons.wikimedia.org/wiki/File%3AAurelia-aurita-3-0009.jpg"><img width="512" alt="Photo of Aurelia aurita after applying ten iterations of DeepDream" src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/89/Aurelia-aurita-3-0009.jpg/512px-Aurelia-aurita-3-0009.jpg"></a><figcaption>By MartinThoma (Own work) [CC0], via Wikimedia Commons</figcaption></figure>
<p>Now for a long time, I thought there might just be enough semantics in Presentation MathML to get away with. Working with Volker Sorge and his <a href="https://github.com/zorkow/speech-rule-engine">speech-rule-engine</a> and integrating SRE's semantic analysis into MathJax meant a deep dive into what kind o structure you can find in Presentation MathML. And as amazing as its heuristics are, it becomes clear how brittle they remain and how quickly you find (real world) examples that break things. This isn't to say you can't guess the meaning of a large selection of real world content. It just makes it clear that you are working with a format void of semantic information. (And we're not talking about <a href="https://arxiv.org/abs/1707.08945">tricking machine learning models</a> here, just run of the mill content.)</p>
<p>When you get down to it, I would say that there are effectively only two elements in Presentation MathML that appear reliably semantic in the real world:  <code>&lt;mn&gt;</code> and <code>&lt;mroot&gt;</code>. And even these examples are stretching it. For for the former, <a href="https://www.w3.org/Math/draft-spec/mathml.html#chapter3_presm.mn.examples">the spec suggests</a> that <code>&lt;mn&gt;twenty one&lt;/mn&gt;</code> is sensible markup. For the latter, it seems to be mostly accidental that roots simply haven't been sufficiently abused in the literature (yet) and thereby retain a unique place of being a visual layout feature that is used consistently to describe (many different concepts of) &quot;rootness&quot;. (For the record, there's also <code>&lt;merror&gt;</code> which is pretty solid, semantically speaking; just not very mathematical.)</p>
<h2>Coda</h2>
<p>There are other, more indirect signs of the failure of MathML to specify semantics. For example the absence of typical benefits of semantic content such as usable search engines or knowledge management tools. But that's a very different problem to discuss.</p>
<p>Anyway, so MathML that specifies semantics could exist but does not. On to layout.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The problem with MathML as a web standard (part 2)]]></title>
        <id>https://www.peterkrautzberger.org/0198/</id>
        <link href="https://www.peterkrautzberger.org/0198/">
        </link>
        <updated>2017-08-15T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Time to continue from <a href="https://www.peterkrautzberger.org/0197/">part 1</a>. This is one is about a minor problem but a problem which keeps coming up.</p>
<h2>Prelude</h2>
<p>One advantage of MathML on the web is that it's XML, i.e., it looks a lot like HTML and SVG and does not require a lot of extra tooling (e.g., parsers). In addition since you can preserve its structure when converting to HTML or SVG, you can can hack MathML markup to improve the result on the web, e.g., by adding CSS or <a href="https://www.peterkrautzberger.org/0192/">ARIA</a>.</p>
<p>Still, being XML is obviously not enough to make anything a good web standard.</p>
<h2>The second problem: MathML vs. other equation input formats</h2>
<p>Obviously this depends a lot on what qualities you are after but I've found it to be a common misconception that MathML is somehow universally superior to other ways of marking up equations. That misconception is getting it backwards.</p>
<p>Like any exchange format, MathML's design is more that of a least common denominator between document systems and, in particular, between visual rendering engines for equational content. By definition, this means it is the least expressive, least flexible, and least powerful format.</p>
<p>A good exchange format would of course be a great thing to have and it can still be very powerful if the ecosystem's diversity is not too great. Unfortunately, that's not the case for MathML where rendering engines for equational content exist and vary considerably between ancients like troff or TeX, modern word processors, computer algebra systems, and more.</p>
<p>So while it is easy to create MathML from other equation input formats it is effectively dumbed down in the process. Reversely, it is not easily interpreted in another system without significant loss of information. This is of course nothing special, just look at binary image formats or text processing. But this is a problem for MathML because it is designed for this purpose; however, it neither reaches the quality of, say, SVG as an exchange for vector graphics, nor does it provide real-life advantages over, say, subsets of LaTeX notation (e.g., in <a href="http://jats4r.org/math">jats4reuse</a>) or even ASCII-style notation.</p>
<p>A particular example of this loss of information is that importing MathML into other systems, while often possible, is rarely re-usable. This is a bit like importing a binary image format into another editor; yes it works, but there are limits to how well you can edit the import without re-doing the whole thing. To give a simple example, David Carlisle's <a href="https://github.com/davidcarlisle/web-xslt/tree/master/pmml2tex">pmml2tex</a> provides perfectly nice visual output in print but rather unusual TeX markup.</p>
<p>The fact that after 20 years there are virtually no rendering systems out there that use MathML internally indicates that MathML fails to provide a decent solution for another basic use case.</p>
<h2>Coda</h2>
<p>After these basic, to some degree <i>social</i> problems, let's talk about core problems of the spec itself next.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dangerous knowledge in the Information Age]]></title>
        <id>http://karagila.org/2017/dangerous-knowledge-in-the-information-age/</id>
        <link href="http://karagila.org/2017/dangerous-knowledge-in-the-information-age/">
        </link>
        <updated>2017-08-11T12:09:46Z</updated>
        <summary type="html"><![CDATA[<p>Back in the days of yore, if one wanted to know mathematics, one would have to go to the university and take a course; or hire a tutor; or go to the library and open a book and learn on their own.</p>

<p>And that was fine. All three options are roughly equivalent, in the sense that they present you the material in a very structured way (or they at least intend to). You don't reach the definition of \(\aleph_0\) because you defined <em>what</em> is equipotency and cardinality. You don't reach the definition of a derivative before you have some semblance of notion of continuity. Knowledge was built in a very structural way. Sometimes you use crutches (e.g. some naive understanding of the natural numbers before you formally introduce them later on as finite ordinals), but for the most part there is a method to the madness. <a href="http://karagila.org/2017/dangerous-knowledge-in-the-information-age/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The problem with MathML as a web standard (part 1)]]></title>
        <id>https://www.peterkrautzberger.org/0197/</id>
        <link href="https://www.peterkrautzberger.org/0197/">
        </link>
        <updated>2017-08-09T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Time to wrap things up.</p>
<h2>Prelude</h2>
<p>After finishing <a href="https://www.peterkrautzberger.org/0186/">MathML as a failed web standard</a> last year, I've been meaning to write a follow-up to discuss fundamental issues I see with MathML as a web standard. I found it very difficult, even painful to do so. Over the past few years I realized that most people simply don't know much about <em>both</em> MathML and modern web technology. I don't claim I'm a great expert myself but running <a href="https://www.mathjax.org/">MathJax</a> for the past 5 years has given me some ideas.</p>
<p><em>Caveat Emptor</em>. The problems I hope to outline may seem to be a general rejection of MathML as a whole; that's not what I'm after. It'd actually be silly to try to bash MathML because it is simply too successful. I also actually kind of like MathML, despite its many horrors; I think it was a great idea <a href="https://en.wikipedia.org/wiki/MathML#History">20 years</a> ago and it's still useful to hack it to get to better things.</p>
<p>Primarily, what follows is the result of me trying to understand why MathML failed on the web. I think there are a few key reasons for its failure. My motivation is to form an opinion on whether MathML is salvageable as a web standard or fundamentally unfit to be part of today's web technology (and should then best be deprecated).</p>
<p>The success outside of the web is an important factor as it limits how much MathML can realistic change. So let's start there.</p>
<h2>The first problem: not <i>of the web</i></h2>
<p>MathML is the dominant format for storing equations in XML document workflows today. It's a reasonable assumption that the vast majority of equational content today is available in (or ready to convert to) MathML: virtually all STEM publishers use MathML in their workflows, major tools like Microsoft Word (favored throughout education) use formats intentionally close to MathML, and most other forms of equation input can be converted more or less easily.</p>
<p>MathML has a <a href="https://en.wikipedia.org/wiki/HTML#HTML_versions_timeline">long history</a> as a W3C standard and it's natural to think that MathML's success is somehow connected to the web's success.</p>
<p>However, that's not the case (except perhaps by making an ultimately empty promise). The<code>&lt;math&gt;</code> tag was first proposed in HTML 3.0 in 1995 but was remove from HTML 3.2 in 1997. It was transformed into one of the first XML applications and MathML was born in 1998 and lived in XML/XHTML limbo for the next decade. Finally, MathML returned to HTML proper with HTML 5 in 2014.</p>
<p>It should seem obvious that because MathML was not part of HTML (or any other web standard implemented by browsers), it could not have succeeded because of the web's success. Instead, it was MathML's success <em>outside</em> of the web that allowed it to survive and eventually make it back into HTML5.</p>
<p>So there naturally was a disconnect. Unfortunately, even when MathML came back in HTML5, that disconnect remained effectively unchanged. A simple example is the timeline. MathML 3's first public working draft was published in 2007, the year <a href="https://www.w3.org/2007/03/HTML-WG-charter.html">HTML WG was just being re-chartered</a> to bring together HTML5 (which took 7 years). The difference between the early working drafts of MathML 3 and the eventual REC (in 2010) seems to include little fundamental change (lots of details being hashed out but the core seems in place pretty early on). Only a handful of changes were made between 2010 and 2016 (when the Math Working Group shut down). It seems only mild hyperbole to say that MathML 3 was effectively done before the HTML5 was really getting started.</p>
<p>Overall, it seems clear from the various specs that the return to HTML5 had not much influence on MathML — or vice versa. For example, there is no hint of giving MathML the &quot;CSS treatment&quot; that HTML got (e.g., clarifying HTML layouts like tables via CSS) nor is there a sign that HTML and CSS ever considered what MathML brought to the table in terms of semantics and layout. This disconnect (and the lack of interest in overcoming it later on) is likely the root cause for MathML's failure.</p>
<p>I think one of the reasons why this disconnect was not overcome is the success of MathML and where that success occurred.</p>
<p>If you speak to early adopters of MathML, you will notice that MathML's success was due to its efficacy in print workflows (with rendering to binary images perhaps being a nice extra in the pitch). That's what XML workflows were producing and while the web was a nice thing to hope for, if MathML hadn't done a good job in print, it would not have gone anywhere in XML-land. This also means that MathML suffers from the <a href="https://www.peterkrautzberger.org/0196/">general problem of equational content</a> (shameless self-plug).</p>
<p>I suspect this success made the MathML community a bit blind to the fact that the web platform was moving away from any common ancestry there may have been, especially on the implementation level but perhaps more importantly in terms of being a rapidly growing technology being practiced by a similarly growing group of specialists (aka web developers).</p>
<p>A sign of this effect is that (especially among non-experts) it seems many people confused the hopes of MathML in HTML5 with a promise and in extreme cases some sort of moral obligation for browser vendors to implement MathML support natively. In retrospect, I think there may have been a short window where things could have turned out differently (and I hope I'll get to that idea later on). More likely, my brain is playing tricks on me because I <a href="http://radar.oreilly.com/2013/11/mathml-forges-on.html">shared that hope</a>.</p>
<p>In any case I find the history to be rather odd, overall. A failed web standard became successful in print production and that success was so significant that it was reintroduced to HTML.</p>
<p>What I think is often missed when discussing MathML is how the success outside the web took its toll on the MathML specification. Its development was focused almost entirely on legacy (print) content and completely detached from the <s>direction</s> random twists and turns of the more successful web standards (first and foremost HTML and CSS). Still, MathML neither tried to align its own direction with the platform nor did it try to take inspiration or to influence those developments.</p>
<p>Finally, I think the particulars of print (and image) rendering of MathML has produced a crucial misconception about MathML: the fact that MathML works well in those settings does not imply that MathML works well as a web technology.</p>
<h3>Coda</h3>
<p>Next I'll try to step a bit back and maybe talk about some of the basics of the spec.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Moving to GitHub!]]></title>
        <id>http://www.dorais.org/news/2017-08-02-moving-to-github.html</id>
        <link href="http://www.dorais.org/news/2017-08-02-moving-to-github.html">
        </link>
        <updated>2017-08-02T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>After struggling to keep up my old WordPress site, I’ve decided to move my research website to <a href="https://pages.github.com/">GitHub Pages</a>. As you can see, I’ve already migrated and updated all of my old posts. I hope you enjoy the new design as much as I do!</p>

<p>There is still much work to be done. The main work to be done has to do with comments. Currently, there is no way to comment on posts here. Indeed, since this is a static site, dynamic features like comments are not available straight out of the box. An indirect consequence of this is that old comments haven’t been migrated from WordPress. I’m keeping the old WordPress site alive in its current state until comments have been migrated.</p>

<p>Another item to do is to integrate the new site into <a href="https://boolesrings.org">Boole’s Rings</a>. Currently, most of the Boole’s Rings sites are WordPress based. <a href="https://www.peterkrautzberger.org/0181/">Peter Krautzberger</a> moved to GitHub Pages a two years ago; it seems from my current experience that migrating is much easier now. I don’t know how well integration will work but the experiment itself is well within the <a href="http://boolesrings.org/about/">spirit of Boole’s Rings</a>.</p>

<p>These next steps will happen over the next weeks (… or months! … or years?)
In the mean time, there are a few small intermediate steps like setting up a <a href="https://help.github.com/articles/using-a-custom-domain-with-github-pages/">custom domain name</a>. Anyway, you can track my progress <a href="https://github.com/fgdorais/fgdorais.github.io">on GitHub</a>…</p>]]></summary>
        <author>
            <name>François G. Dorais</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On checking a proof]]></title>
        <id>https://sixsmith2017.wordpress.com/2017/07/24/on-checking-a-proof/</id>
        <link href="https://sixsmith2017.wordpress.com/2017/07/24/on-checking-a-proof/">
        </link>
        <updated>2017-07-24T14:06:47Z</updated>
        <summary type="html"><![CDATA[<p>In many respects the most difficult part of mathematics lies in communicating your work. That is not to say that proving results is easy; but the proof is just the tip of the iceberg (even though it often feels like the principal goal). The proof is of no value or interest unless you can communicate it. And to communicate it, you have to be able to write it down accurately. I&#8217;ve not found any notes on how best to do this, so here are a few thoughts of my own.</p>
<p>When I look back at some of the proofs I wrote when I started work on my PhD, I realise how much I have learned. My supervisors &#8211; who were very gracious, very helpful, and very dedicated &#8211; used to cover my early work in <span style="color:#ff0000;">red ink</span>. I then learned how to write a proof through an iterative (and very painful) process, in which I would write something, receive the <span style="color:#ff0000;">red ink</span>, fix those problems, receive further <span style="color:#ff0000;">red ink</span>, and so on. I became very familiar with <span style="color:#ff0000;">red ink</span>. Very, very familiar.</p>
<figure data-shortcode="caption" id="attachment_210" aria-describedby="caption-attachment-210" style="width: 500px" class="wp-caption aligncenter"><a href="https://sixsmith2017.files.wordpress.com/2017/07/redink.jpg"><img data-attachment-id="210" data-permalink="https://sixsmith2017.wordpress.com/2017/07/24/on-checking-a-proof/redink/" data-orig-file="https://sixsmith2017.files.wordpress.com/2017/07/redink.jpg" data-orig-size="1023,623" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="redink" data-image-description="" data-medium-file="https://sixsmith2017.files.wordpress.com/2017/07/redink.jpg?w=300" data-large-file="https://sixsmith2017.files.wordpress.com/2017/07/redink.jpg?w=640" class="wp-image-210" src="https://sixsmith2017.files.wordpress.com/2017/07/redink.jpg?w=500&#038;h=304" alt="" width="500" height="304" srcset="https://sixsmith2017.files.wordpress.com/2017/07/redink.jpg?w=500&amp;h=304 500w, https://sixsmith2017.files.wordpress.com/2017/07/redink.jpg?w=998&amp;h=608 998w, https://sixsmith2017.files.wordpress.com/2017/07/redink.jpg?w=150&amp;h=91 150w, https://sixsmith2017.files.wordpress.com/2017/07/redink.jpg?w=300&amp;h=183 300w, https://sixsmith2017.files.wordpress.com/2017/07/redink.jpg?w=768&amp;h=468 768w" sizes="(max-width: 500px) 100vw, 500px" /></a><figcaption id="caption-attachment-210" class="wp-caption-text">An early example of the great value of <span style="color:#ff0000;">red ink</span></figcaption></figure>
<p>In this note I&#8217;d like to comment on how one might spot problems oneself, rather than depend on one&#8217;s supervisors in this way. This is not a trivial task, but a really important one. Perhaps I can offer a few pointers which might be of help.</p>
<p>Let&#8217;s suppose you have proved a result. You&#8217;ve written it all up to your own satisfaction, and wish to share your  achievement with your fellows. I began to make a list of the things you should do, but it was very long, exceedingly tedious, and all boiled down to the word <strong>check</strong>. Which is a bit boring. So let&#8217;s try the following, which is less prescriptive if possibly less all-encompassing. It&#8217;s just three words. How hard could that be?</p>
<p style="padding-left:30px;">First <span style="color:#008000;"><strong>forget</strong></span>. In developing your proof you, no doubt, came up with all sorts of ideas and intuitions and implications and pictures. You have to (somehow) now lay these all to one side. Your reader will not have any of this in front of <em>them</em>, so you have to be sure that none of your work now depends or uses anything other than the words in front of <em>you</em>. (Incidentally, the best way to do this is to put your proof to one side for a few months, and then come back to it. You&#8217;ll be astonished how terrible it will look).</p>
<p style="padding-left:30px;">Second <span style="color:#808000;"><strong>focus</strong></span>. Focus on the words in front of you, and what they say. This is easier said than done; because you <em>expect</em> your words to say one thing, you will tend to interpret them in that way. Try not to. Look at what is written and nothing else.</p>
<p style="padding-left:30px;">Third <span style="color:#808000;"><strong>check</strong></span>. Read what you have written, word by word, sentence by sentence, and ask yourself the question &#8220;<em>why on earth does that follow?&#8221; </em>Notice the negation; if you expect things to be wrong you are more likely to spot mistakes than if you expect them to be correct. In my personal experience they are probably incorrect.</p>
<p>I could probably make a list of common mistakes, but it really is hard to make that interesting. So I will highlight just three (three is a useful number here):</p>
<p style="padding-left:30px;"><strong>The word &#8220;</strong><em><strong>clearly&#8221;:</strong> </em>It is very easy to make the mistake of writing &#8220;<em>clearly XYZ&#8221;</em> when what you mean is &#8220;XYZ seems pretty darned obvious to me but I can&#8217;t quite work out why&#8221;. If you can&#8217;t work out why XYZ is true, chance is that is isn&#8217;t.</p>
<p style="padding-left:30px;"><strong>Things that are true but don&#8217;t actually follow</strong>: This is a very easy mistake to make; you write something like &#8220;Since X, then Y&#8221; and assume it is OK because Y really is true. But you are not asserting here that Y is true, and that is not what you need to check. You need to check that Y follows from X <em>and nothing else!</em></p>
<p style="padding-left:30px;"><strong>Failure to satisfy all necessary conditions:</strong> If you use another result (maybe a book result, or a lemma of your own from earlier) you need to be sure that all the conditions are checked. This is especially true of a book result &#8211; if that says something like &#8220;If A, B, C, D and E, then F&#8221;, then there is no chance to use this result if only A, B, C and D are true.</p>
<p><strong>Yes</strong>, this is all amazingly tedious. <strong>Yes</strong>, this is a very lengthy process. <strong>No</strong>, there is no alternative (apart from asking a friend to check). <strong>Yes</strong>, you will be a better mathematician when you can do all this. <strong>No</strong>, I do not claim to be able to do this all the time myself.<strong> Yes</strong>, I welcome feedback and other suggestions.</p>]]></summary>
        <author>
            <name>Dave Sixsmith – I am a mathematician, not a calculator</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The transitive multiverse]]></title>
        <id>http://karagila.org/2017/the-transitive-multiverse/</id>
        <link href="http://karagila.org/2017/the-transitive-multiverse/">
        </link>
        <updated>2017-07-22T21:18:32Z</updated>
        <summary type="html"><![CDATA[<p>There are many discussions on the multiverse of set theory generated by a model. The generic multiverse is given by taking all the generic extensions and grounds of some countable transitive model.</p>

<p>Hamkins' multiverse is essentially taking a very ill-founded model and closing it to forcing extensions, thus obtaining a multiverse which is more of a philosophical justification, for example every model is a countable model in another one, and every model is ill-founded by the view of another model. The problem with this multiverse is that if we remove the requirement for genericity, then everything else can be satisfied by the same model. Namely, \(\{(M,E)\}\) would be an entire multiverse. That's quite silly. Moreover, we sort of give up on a concrete notion of natural numbers that way, and this seems a bit... off putting. <a href="http://karagila.org/2017/the-transitive-multiverse/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The fundamental problem of math on the web]]></title>
        <id>https://www.peterkrautzberger.org/0196/</id>
        <link href="https://www.peterkrautzberger.org/0196/">
        </link>
        <updated>2017-07-21T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I usually describe my interest as <i>all things math on the web</i>. I've come to realize that <i>math on the web</i> is mostly a misnomer. Actually, I realized this quite some time ago, but I always thought it wasn't such a big deal. Lately, I've started to think it actually is and I'm actively working to change my language (so damn hard!).</p>
<h2>what's in a name or political correct terminology</h2>
<p>When people speak about <i>math content</i> in the context of the web they usually mean <i>equational content</i> (or simply <i>equations</i>). That is, they don't mean content in a mathematical field (which often enough does not qualify as equations), they simply mean <i>something that looks like an equation</i>.</p>
<p>Now you might argue that an equation in physics is still basically mathematical content but in reality both mathematician and physicist will frequently disagree with you (and each other, possibly explosively so). You quickly get to the edge when considering chemical equations and if you want to classify the nonsense notations in the life sciences you might question your sanity.</p>
<p>It's not hard to understand why this is. For example, most typesetting tools with support for equations will have some kind of <i>math mode</i> for them.  But I think it's worth while differentiating the two so I'll try my best to stick to <i>equational content</i>. On the one hand, the importance of <i>math on the web</i> is often exaggerated because it is really non-mathematical <i>equational content</i> that's the majority (and even that is a blip on the radar). On the other hand, it does not help to confuse a field of study with what effectively comes down to a layout tradition.</p>
<p>Also, sorry-not-sorry for misleading you with the title here.</p>
<p>The fundamental problem of equational content is that, well, that it's simply pretty terrible all around. It's convoluted,extremely compressed, archaic, and generally undecipherable. It destroys academic careers by the millions and it can often only be understood when you can see it written live (i.e., animated). At its best equations are like good abstract drawings, at worst (usually?) they're deafening gibberish.</p>
<h2>interlude</h2>
<p>Stray thoughts.</p>
<p>One. I always thought Bret Victor's (in)famous <a href="http://worrydream.com/KillMath/">Kill math</a> was largely wrong about the specifics of his criticism (for one, he seems to dismiss the incredible power of compression that differential equations exhibit - along with the obvious problems that stem from compression). But he is of course utterly right with his incredible work exploring how modern media like the web allow for a much richer expression of human thought, one that opens the content up to more people, often by adding means of interacting with it, especially means for untrained people (like tiny humans).</p>
<p>Two. Every once in a while I've wondered: what if Tim Berners-Lee had given the web some basic building blocks for equations. Just a fraction and a square root; maybe instead of image renditions of print equations we'd have immediately seen the same creativity applied to equations as there was with hacking general layout (1px GIF anyone?). Of course, that's hopelessly romanticizing the evolution of the web. Why can't I stop wondering.</p>
<p>Three. On and off (and I've come full circle on this several times) I've wondered whether math is ahead of other sciences on the web. I mean the <code>&lt;math&gt;</code> tag was proposed in fricking HTML 3. So is math ahead? Maybe. But then why is scientific content so much more vibrant and transformative on the web compared to math?</p>
<h2>10 PRINT &quot;Hello World!&quot;; 20 GOTO 10</h2>
<p>The most obvious flaw of equational content is that it's deeply rooted in print. Given the limitations of print technology, equational content has needed to adopt bad practices for such a long time that many people consider them good.</p>
<p>I'm not (just) thinking about the problem of general comprehension as it is too tainted by poorly trained practitioners on all levels. Sure, equational content is often more difficult to parse than necessary but that's not different from poorly phrased prose.</p>
<p>The main problem is the <i>tradition</i> of abusing print technology to get more and more variations of notation squeezed into the medium. The constant abuse of sub- and superscripts is a great example; if you need to add a variant of an object you've already introduced in your notation, just slap some sub/superscripts around it, et voilà, a new object.</p>
<p>The abuse of letters with different fonts is another horror in equational content. If you have ever run into a paper where a dozen variations of <code>G</code> appear, denoting a convoluted set of somewhat related concepts, you'll know this horror well. Unbelievably enough, Unicode has deemed this abuse of notation important enough that we now have such wonders as the Unicode point <i>mathematical bold italic G</i> in the <a href="https://en.wikipedia.org/wiki/Mathematical_Alphanumeric_Symbols">Mathematical Alphanumeric Symbols<br>
Block</a>.</p>
<p>Another historic accident are stylistic separations. For example, in print it's abhorred to make math content bold when the surrounding content is bold (e.g., in a heading) yet on the web people complain that an equation in a link doesn't get the <i>correct</i> text decoration (what would that be??).</p>
<p>Obviously, there's little point in criticizing the historic development of equational content. Given that print was mostly limited to (at best) grayscale with a limited character set, naturally people had to be creative. It is amazing what this accomplished.</p>
<p>The real problem comes up when pretending that this tradition should do more than vaguely inform a medium such as the web. The web so far developed without much influence from equational content. It has adopted a rather different approach to separating content and presentation and the traditions of equational content are essentially incompatible with the web's approach.</p>
<p>I can find no argument for why the web stack should bend over backwards to accommodate these mostly quite bad traditions of equational content for print. This is perhaps similar to the situation of CSS paged media.</p>
<p>Obviously, it's not like you shouldn't be able to put traditional equational content on the web - you should (and you can very well today). But I've come to think it's perfectly fine, in fact, it is appropriate that this continues to be a difficult problem. For example, traditional equational content is almost always inaccessible (without heuristic algorithms, i.e., guessing around); it's basically a bunch of glyphs placed in a weird 2D patterns (like above and below a line which in turn is magically centered on some baseline and may or may not indicate it corresponds to the notion of a mathematical fraction). Pretending that this is a basis for accessible rendering on the web strikes me as foolish (or ridiculously zealous).</p>
<p>If you think that all equational content should be limited to the traditions of the print era, fine. I think humanity can do better on the web. Though I think we would need to acknowledge that the (print) traditions enshrined in equational content are flawed and should (and invariably will) be replaced with better concepts and narratives that are appropriate for this medium.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Strong coloring]]></title>
        <id>http://karagila.org/2017/strong-coloring/</id>
        <link href="http://karagila.org/2017/strong-coloring/">
        </link>
        <updated>2017-07-07T11:02:35Z</updated>
        <summary type="html"><![CDATA[<p>I am sitting in the 6th European Set Theory Conference in Budapest, and watching all these wonderful talks, and many of them use colors for emphasis of some things. But yesterday one of the talks was using &quot;too many colors&quot;, enough to make me make a comment at the end of the talk after all the questions were answered. Since I received some positive feedback from other people here, I decided to write about it on my blog, if only to raise some awareness of the topic.</p>

<p>There is a nontrivial percentage of the population which have some sort of color vision deficiency. Myself included. Statistically, I believe, if you have 20 male participants, then one of them is likely to have some sort of color vision issues. Add this to the fairly imperfect color fidelity of most projectors, and you get something that can be problematic. <a href="http://karagila.org/2017/strong-coloring/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Elusive semantics]]></title>
        <id>https://www.peterkrautzberger.org/0195/</id>
        <link href="https://www.peterkrautzberger.org/0195/">
        </link>
        <updated>2017-06-24T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I don't like &quot;semantics zealots&quot;, people who claim that content always can (let alone always must) be &quot;fully semantic&quot; (for whatever value of &quot;semantic&quot; they favor). In the same vein, I also don't like the thinking that any format can fully separate semantics and presentation - human thought is to fickle a beast to tolerate such confinement. You may blame my old training as a set theorist, but the gray area of neither true nor false is much more important to me.</p>
<p>Still, the things you can do well, you obviously should. And yet, every once in a while, somebody throws you a curveball and you just have to shout: <q><em>This</em> is why we can't have good things!</q>.</p>
<h2>where did you come from, where did you go</h2>
<p>The other day on a client project, the QA specialist pointed out that the content was consistently using <code>&lt;em&gt;</code> where it should be using <code>&lt;i&gt;</code>. Can we fix that?</p>
<p>The semantics of these and related HTML5 tags is a bit subtle, but there is a difference and it should be easy to just replace one with the other, right? Right? Famous last words.</p>
<p>At first sight, this was easy. The HTML came out of some JATS-like XML, which was using <code>&lt;italic&gt;</code> elements. So map to <code>&lt;i&gt;</code>, right? But hold on, you'll say, HTML5 reinterpreted <code>&lt;i&gt;</code> to no longer indicate layout but semantics; it now indicates a <i>change of voice</i>. Unfortunately, JATS's <code>&lt;italic&gt;</code> is focused on the typographic aspects, so it does not really help. The again, it could help a little bit more because <code>&lt;italic&gt;</code> allows for a <code>toggle</code> attribute to indicate <em>emphasis</em>. Sadly, the actual XML did not provide that information.</p>
<p>Since the piece of the tool chain that turned <code>&lt;italic&gt;</code> into <code>&lt;em&gt;</code> was actually my doing, I was clearly at fault. <em>However</em>, I had my reasons. Namely, that all of this came from a LaTeX source and in this real world LaTeX content, <code>\emph{}</code> and its brethren were the dominant source for <code>&lt;italic&gt;</code>. So <i>clearly</i> that should be <code>&lt;em&gt;</code> in the end?</p>
<p>Now of course, almost all LaTeX authors don't give a damn beyond getting that PDF to look how they want it, so while they mostly use <code>\emph{}</code>-like macros, they mix it freely (and inconsistently) with <code>\textit{}</code> and its brethren. So the conversion (written by an absolute expert) rightly says <q>screw it, all I can say is it wants italics here</q>, thus merging them both together.</p>
<h2>where the wild things are</h2>
<p>It's my job to dig deeper than that so I took the time to look through the actual content available. Not the TeX, not the XML but the actual writing.</p>
<p>Lo and behold, the actual text use is pretty different: by far, most occurrences of <code>&lt;em&gt;</code> happened in the context of quick, inline definitions. Invariably, you find these in introductions of mathematical research articles where you include commonly known definitions from a field so as not to cause bloat (because publishers and editorial boards continue to care more about page numbers than well documented research results).</p>
<h2>there's an <s>app</s> element for that.</h2>
<p>A definition does not really fit either <code>&lt;i&gt;</code> or <code>&lt;em&gt;</code>. The closest you get <a href="https://www.w3.org/TR/html5/text-level-semantics.html#the-i-element">in the spec</a>, is an example of using <code>&lt;i&gt;</code> to reference a past definition.</p>
<blockquote>
<p><code>&lt;p&gt;The term &lt;i&gt;prose content&lt;/i&gt; is defined above.&lt;/p&gt;</code></p>
</blockquote>
<p>To make matters worse, there is of course <a href="https://www.w3.org/TR/html5/text-level-semantics.html#the-dfn-element">an entirely different element</a> that fits perfectly:</p>
<blockquote>
<p>The <code>&lt;dfn&gt;</code> element represents the defining instance of a term.</p>
</blockquote>
<p>Perfect match for the vast majority of the content in question. So we should switch everything over, right?</p>
<p>The answer is, of course, no. Not because some content would end up with the wrong semantics (scroll to top) but because that was not the only use I found:  almost without exception, the samples includes the use as a definition alongside the use as <code>&lt;em&gt;</code> or <code>&lt;i&gt;</code>.</p>
<p>And that is why we can't have good things.</p>
<h2>who cares, you suck</h2>
<p>All of this is about as surprising as finding a handwritten table of contents in a Word document. TeX is for print layout and font styles are used for all manners of cruelty. The question I had to answer with my client was: can we do anything about it?</p>
<p>In the end, beauty lies in the eye of the beholder and semantics in the eyes of the reader. We did, in fact, switch to <code>&lt;i&gt;</code> with the plan to expose more information from the original source regarding emphasis so we can gather more data on its usage. Fundamentally, this won't help because it doesn't solve the problem of inline definitions. Still, some analysis might reveal pragmatic improvements down the line.</p>
<p>In the end, it's not hard to argue that a definition that is well known in the field and that is done inline in the introduction of an article is more like the kind of reference to a definition as in the above example from the spec (in fact, often enough it is done in the vicinity of a bibliographic reference). Of course, we're still conflating <code>\emph</code> and <code>\textit</code>.</p>
<h2>coda</h2>
<p>Now <s>zealots</s> idealists will argue that authors &quot;just&quot; have to learn to use semantic macros in TeX. After all, there are plenty of &quot;semantic&quot; LaTeX packages out there; just start writing good markup already!</p>
<p>Besides the lack of pragmatism, the only viable solution I can see would be a LaTeX package matching specifically HTML5 markup. After all, we have the tags and they have established definitions; any &quot;semantics&quot; beyond that will only cause issues down the line (what if a tag is introduced to HTML but with a slightly different meaning?). Even then, it doesn't solve the social problem at the heart of so many publishing technology issues: who would make the effort and use it? It's extra work and does nothing for print; why would an author do extra work when they think print rules?</p>
<p>I think only someone interested in creating HTML output would make the effort. And at that point you have to ask: Why would those authors bother with an archaic programming language like TeX to write HTML? They will find it invariably easier to just write HTML or their favorite lightweight markup for creating HTML, especially given the speed at which HTML-to-PDF solutions are improving). Building tools for LaTeX to solve this would just create extra work but help nobody. Just build better tools for writing HTML.</p>
<p><i lang="de">Doch das ist eine andere Geschichte und soll ein andermal erzählt werden.</i></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[My Students’ Favorite Problems from Spring 2017]]></title>
        <id>http://dcernst.github.io/students-favorite-problems/</id>
        <link href="http://dcernst.github.io/students-favorite-problems/">
        </link>
        <updated>2017-06-20T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>A few semesters ago we launched a course for mathematics majors, called MAT 220: Introduction to Mathematical Reasoning. The focus of the course is on reasoning and communication through problem solving and written mathematical arguments in order to provide students with more experience and training early in their university studies. The goal is for the students to work on interesting yet challenging multi-step problems that require almost zero background knowledge. The hope is that students will develop (or at least move in the direction of) the habits of mind of a mathematician. The problem solving of the type in this course is a fundamental component of mathematics that receives little focused attention elsewhere in most mathematics programs. I love teaching this course!</p>

<p>This past semester I taught the course for the second time.  You can find the syllabus, list of problems, etc. for the Spring 2017 semester by going <a href="https://dcernst.github.io/teaching/mat220s17/">here</a>. On the students’ final exam, I asked them which problem was their favorite from the semester.  Below is the list of problems that they mentioned including the number of votes that each received. The level of difficulty of the problems covers the spectrum.  Some of these are not easy. Have fun playing!</p>

<ol>
  <li>(6 votes; several students commented that their favorite part about this problem was how excited the student was that solved it) An overfull prison has decided to terminate some prisoners. The jailer comes up with a game for selecting who gets terminated. Here is his scheme. 10 prisoners are to be lined up all facing the same direction. On the back of each prisoner’s head, the jailer places either a black or a red dot. Each prisoner can only see the color of the dot for all of the prisoners in front of them and the prisoners do not know how many of each color there are. The jailer may use all black dots, or perhaps he uses 3 red and 7 black, but the prisoners do not know. The jailer tells the prisoners that if a prisoner can guess the color of the dot on the back of their head, they will live, but if they guess incorrectly, they will be terminated. The jailer will call on them in order starting at the back of the line. Before lining up the prisoners and placing the dots, the jailer allows the prisoners 5 minutes to come up with a plan that will maximize their survival. What plan can the prisoners devise that will maximize the number of prisoners that survive? Some more info: each prisoner can hear the answer of the prisoner behind them and they will know whether the prisoner behind them has lived or died. Also, each prisoner can only respond with the word “black” or “red.” Now, suppose that there are 11 prisoners. Describe a strategy for maximizing the number of prisoners that will live. What if there are $n$ prisoners?</li>
  <li>(4 votes) Four prisoners are making plans to escape from jail. Their current plan requires them to cross a narrow bridge in the dark that has no handrail. In order to successfully cross the bridge, they must use a flashlight.  However, they only have a single flashlight.  To complicate matters, at most two people can be on the bridge at the same time.  So, they will need to make multiple trips across the bridge, returning the flashlight back to the first side of the bridge by having someone walk it back.  Unfortunately, they can’t throw the flashlight.  It takes 1, 2, 5, and 10 minutes for prisoner $A$, prisoner $B$, prisoner $C$, and prisoner $D$ to cross the bridge and when two prisoners are walking together with the flashlight, it takes the time of the slower prisoner.  What is the minimum total amount of time it takes all four prisoners to get across the bridge?</li>
  <li>(3 votes; we encountered several variations of this problem) Suppose you have 12 coins, all identical in appearance and weight except for one that is either heavier or lighter than the other 11 coins. What is the minimum number of weighing one must do with a two-pan scale in order to identify the counterfeit? Now, suppose you have $n$ coins. For which $n$ is it possible to devise a procedure for identifying the counterfeit coin in only 3 weighings with a two-pan scale?</li>
  <li>(3 votes) 100 prisoners are isolated in individual jail cells with no way to communicate. They are currently serving life sentences.  Due to an overcrowded prison, the jailer decides to offer the prisoners the following deal. There is a room with nothing in it except a light switch (that starts in the off position). At random, the jailer will escort a single prisoner into the room with the light switch. After 5 seconds, the jailer will escort the prisoner back to his/her jail cell. The jailer will repeat this over and over again.  He tells each of the prisoners that if one of the prisoners can indicate when every prisoner has been in the room with the light switch at least once, he will let all the prisoners go.  However, if a prisoner erroneously states that each prisoner has been in the room with the light switch, then all the prisoners will be executed.  Before beginning, the jailer gets all 100 prisoners together and gives them 5 minutes to come up with a plan.  What should their plan be?  It’s important to note that the jailer is choosing prisoners at random to take in the room.  That is, by chance, the same prisoner may be escorted to the room several times in a row.  Also, your task is to devise a scheme for the prisoners to communicate with the light switch.  You shouldn’t bother searching for other ways for the prisoners to communicate.</li>
  <li>(2 votes; we encountered several variations of this problem) A soul swapping machine swaps the souls inside two bodies placed in the machine. Soon after the invention of the machine an unforeseen limitation is discovered: swapping only works on a pair of bodies once. Souls get more and more homesick as they spend time in another body and if a soul is not returned to its original body after a few days, it will kill its current host. Bart (B), Lisa (L), Homer (H), Marge (M), and Ned (N) were involved in a soul-swapping bonanza that resulted in Bart’s soul being Lisa’s body, Lisa’s soul being in Homer’s body, Homer’s body being in Marge’s body, Marge’s soul in Ned’s body, and Ned’s soul being in Bart’s body.  Thankfully, Krusty the Clown (K) and Santa’s Little Help (S) never utilized the machine and are available to help put everyone’s soul back in the appropriate body.  Find a way to return all the souls to their respective owner.</li>
  <li>(1 vote; see the discussion of Problem 86 on the <a href="https://dcernst.github.io/teaching/mat220s17/journal/">class journal</a> for Monday, May 1) The first vote counts of the papal conclave resulted in 33 votes each for candidates A and B and 34 votes for candidate C. The cardinals then discussed the candidates in pairs. In the second round each pair of cardinals with differing first votes changed their votes to the third candidate they did not vote for in the first round. The new vote counts were 16, 17 and 67. They were about to start the smoke signal when Cardinal Ordinal shouted “wait”. What was his reason?</li>
  <li>(1 vote) Recent archaeological work on Mars shows a number of sites, each site containing a large mound of white spheres, each about the size of a tennis ball. Each ball contains a jewel. The jewels come in many different colors, but at each site, strictly more than half of the spheres contain jewels of the same color. When two balls are brought together, they both glow white if their internal jewels are the same color; otherwise, no glow. You have recently stumbled on a cache of 13 spheres. In how few tests can you find a sphere that you are certain holds a jewel of the majority color?</li>
  <li>(1 vote) A certain fast-food chain sells a product called “nuggets” in boxes of $6, 9$, and $20$. A number $n$ is called <em>nuggetable</em> if one can buy exactly $n$ nuggets by buying some number of boxes. For example, $21$ is nuggetable since you can buy two boxes of six and one box of nine to get 21. Here are the first few nuggetable numbers: $6, 9, 12, 15, 18, 20, 21, 24, 26, 27,\ldots$
and here are the first few non-nuggetable numbers: $1,2,3,4,5,7,8,10,11,13,\ldots$. What is the largest non-nuggetable number?</li>
  <li>(1 vote) A signed permutation of the numbers 1 through $n$ is a fixed arrangement of the numbers 1 through $n$, where each number can be either be positive or negative. For example, $(-2,1, -4,5,3)$ is a signed permutation of the numbers 1 through 5.  In this case, think of positive numbers as being right-side-up and negative numbers as being upside-down. A <em>reversal</em> of a signed permutation is the act of performing a 180-degree rotation to some consecutive subsequence of the permutation. That is, a reversal swaps the order of a subsequence of numbers while changing the sign of each number in the subsequence. Performing a reversal to a signed permutation results in a new signed permutation. For example, if we perform a reversal on the second, third, and fourth entries in $(-2,1,-4,5,3)$, we obtain $(-2,-5,4,-1,3)$.  The <em>reversal distance</em> of a signed permutation of 1 through $n$ is the minimum number of reversals required to transform the given signed permutation into $(1,2,\ldots,n)$. It turns out that the reversal distance of $(3,1,6,5,-2,4)$ is 5. Find a sequence of 5 reversals that transforms $(3,1,6,5,-2,4)$ into $(1,2,3,4,5,6)$.</li>
  <li>(1 vote) My Uncle Robert owns a stable with 25 race horses.  He wants to know which three are the fastest.  He owns a race track that can accommodate five horses at a time. What is the minimum number of races required to determine the fastest three horses?</li>
  <li>(1 vote) Each integer on the number line is colored with exactly one of three possible colors, red, green, or blue, according to the following two rules:
    <ul>
      <li>(Rule 1) The negative of a red number must be colored blue;</li>
      <li>(Rule 2) The sum of two blue numbers (not necessarily distinct) must be colored red.
Using this information, determine all possible colorings of the integers that satisfy these rules.</li>
    </ul>
  </li>
  <li>(1 vote) Annie, Bob, and Cristy are sitting by a campfire when Cristy announces that she is thinking of a 3-digit number.  She then tells Annie and Bob that the number she is thinking of is one of the following: $515, 516, 519, 617, 618, 714, 716, 814, 815, 817$.  Next, Cristy whispers the leftmost digit in Annie’s ear and then whispers the remaining two digits in Bob’s ear. The following conversation then takes place:
    <ul>
      <li>Annie: I don’t know what the number is, but I know Bob doesn’t know too.</li>
      <li>Bob: At first I didn’t know what the number was, but now I know.</li>
      <li>Annie: Ah, then I know the number, too.
From that information, determine Cristy’s number.</li>
    </ul>
  </li>
  <li>(1 vote) Consider a $8\times 8$ grid with light-up squares. In the starting configuration, some subset of the squares are lit up. At each stage, a square lights up if at least two of its immediate neighbors (horizontal or vertical) were “on” during the previous stage. It’s easy to see that for the starting configuration in which eight squares along a diagonal of the board are lit up, the entire board is eventually covered by “on” squares. Several other simple starting configurations with eight “on” squares also result in the entire board being covered. Is it possible for a starting configuration with fewer than eight squares to cover the entire board? If yes, find it; if no, give a proof.</li>
  <li>(1 vote) Suppose we draw $n$ distinct lines in the plane that have the maximum number of unique intersections. How many intersections are there?  The resulting configuration partitions the plane into disjoint regions (some of which are polygons with finite area and some are not).  Suppose we color each of the regions so that no two adjacent regions (i.e., share a common edge) have the same color.  What is the fewest colors we could use to accomplish this?</li>
  <li>(1 vote) The Infinite Hotel has rooms numbered $1,2,3,4,\ldots$. Every room in the Infinite Hotel is currently occupied.  Is it possible to make room for one more guest (assuming they want a room all to themselves)?  An infinite number of new guests, say $g_1, g_2,g_3,\ldots$, show up in the lobby and each demands a room.  Is it possible to make room for all the new guests even in the hotel is already full? The full infinite bus brings new guests to the full infinite hotel. How can they stay at the hotel?</li>
  <li>(1 vote) What size rectangles can be tiled with L-shaped trominoes?</li>
</ol>

<p>A while back I wrote a similar post that highlighted <a href="https://dcernst.github.io/fifteen-fun-problems/">15 fun problems</a> from the first time I taught the course.  You’ll notice that there is some overlap between the two lists.</p>]]></summary>
        <author>
            <name>Dana C. Ernst</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Carnival of Math No. 146]]></title>
        <id>https://www.peterkrautzberger.org/0194/</id>
        <link href="https://www.peterkrautzberger.org/0194/">
        </link>
        <updated>2017-06-03T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>This month I have the pleasure to host the <strong>146th Carnival of Mathematics</strong>, the moveable feast of mathematical blogging shepherded by the best math blogging collective on the planet, <a href="http://aperiodical.com/carnival-of-mathematics/">The Aperiodical</a>.</p>
<p>As tradition decrees, we shall begin our show by taking a closer look at our number.</p>
<p>146 is an <a href="https://en.wikipedia.org/wiki/Octahedral_number">octahedral number</a> (and thus a <a href="https://en.wikipedia.org/wiki/Figurate_number">figurate number</a>).</p>
<figure>
<a title="By David Eppstein (Own work) [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File%3AOctahedral_number.jpg"><img width="512" alt="146 magnetic balls, packed in the form of an octahedron" src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Octahedral_number.jpg/512px-Octahedral_number.jpg"></a>
<figcaption>
An octahedral number represents the number of spheres in an octahedron formed from close-packed spheres (146 the image above).
</figcaption>
</figure>
<p>Even more amazingly 146 is an <a href="https://en.wikipedia.org/wiki/Untouchable_number">untouchable number</a> which means it cannot be expressed as the sum of all the proper divisors of <strong>any</strong> positive integer (including itself). Can you guess how many untouchable numbers there are? Of course, infinitely many and, of course, this was first proved by <a href="https://en.wikipedia.org/wiki/Paul_Erd%C5%91s">Paul Erdős</a>. But did you know that the only known proof that 5 is the only <em>odd</em> untouchable number depends on a stronger version of the <a href="https://en.wikipedia.org/wiki/Goldbach_conjecture">Goldbach conjecture</a>? Amazing!</p>
<p>Now that you've warmed up, let us enter the magnificent, magnetic madness of the mathematical blogging carnival.</p>
<hr>
<p>If you have any affinity to football (the real kind, not the funny American stuff), then start off with <a href="http://nirachamberlain.com/a-mathematical-verdict-on-aston-villas-first-season-in-the-championship/">Nira Chamberlain</a> who reviews the mathematical simulation model he built for his favorite team - you know, like any <s>normal</s> awesome football fan would do.</p>
<p>Next, follow Sean and Jamidi to the depths of the <a href="http://chalkdustmagazine.com/interviews/conversation-marcus-du-sautoy/">chalkdust magazine</a> where they spoke with one of the great mathematical storytellers, Marcus du Sautoy.</p>
<p>Beware now, lest you be pulled into the enchanted world of <a href="https://www.youtube.com/channel/UChwcAFGJZVE2hqAiZSFSyug">The Mathemactivist</a> who can draw a <a href="https://en.wikipedia.org/wiki/Hilbert_curve">Hilbert Curve</a> by hand.</p>
<div style="position: relative; padding-bottom: 56.25%; /* 16:9 */ padding-top: 25px; height: 0">
<iframe style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" width="854" height="480" src="https://www.youtube.com/embed/qRuHzitPEKs" frameborder="0" allowfullscreen=""></iframe>
</div>
See if you can spot the two mistakes!
<p>Come now, and follow us to the trickster's lair where <a href="https://tomrocksmaths.com/2017/05/03/funbers-2/">Tom rocks math</a> takes a closer look at three fun numbers to tell you things you didn't realize you ever wanted to know. From here, follow us to the depth of the mathvault and let Scott Hartshorn lure you with an <a href="http://mathvault.ca/statistical-significance/0">introduction to statistical significance</a> after which all your paper-nerd needs will be met by Nick Higham, who looks at the benefits of <a href="https://nickhigham.wordpress.com/2017/05/08/dot-grid-paper-for-writing-mathematics/">dot grid paper</a> (including, of course, a LaTeX template).</p>
<p>Before you leave, be sure to witness the spectacle of John Cook taming <a href="https://www.johndcook.com/blog/2017/05/02/weibull-distribution-and-benfords-law/">the Weibull distribution</a> and connecting it with Benford’s law. And as an encore, John will take you far from the <a href="https://www.johndcook.com/blog/2017/05/13/grobner-bases/">equation systems you solved in algebra when you were a kid</a> to the &quot;simple&quot; generalization that can be solved using a <a href="https://en.wikipedia.org/wiki/Gr%C3%B6bner_basis">Gröbner basis</a> (which, as so many things in mathematics, were not actually discovered by Gröbner).</p>
<p>And if you still can't get enough, be sure to check out <a href="https://mathstodon.xyz/tags/proofinatoot">the many fabulous results</a> of Christian Lawson-Perfect's call for <a href="http://aperiodical.com/2017/05/we-want-your-best-proofinatoot-on-mathstodon-xyz/">proof-in-a-toot</a>.</p>
<hr>
<p>That’s it for the beautiful month of May!</p>
<p>Be sure to stop by next month’s Carnival, hosted by Lucy at <a href="http://cambridgemaths.org/">Cambridge Mathematics</a>. You should <a href="http://aperiodical.com/carnival-of-mathematics/">submit your favorite blog posts/videos/content</a> from the month of June. If you’d like to host an upcoming show, please get in touch with <a href="mailto:katie@aperiodical.com">Katie</a>.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Euclidean Ramsey Theory 2 – Ramsey DocCourse Prague 2016]]></title>
        <id>https://mikepawliuk.ca/2017/05/23/euclidean-ramsey-theory-2-ramsey-doccourse-prague-2016/</id>
        <link href="https://mikepawliuk.ca/2017/05/23/euclidean-ramsey-theory-2-ramsey-doccourse-prague-2016/">
        </link>
        <updated>2017-05-24T00:22:44Z</updated>
        <summary type="html"><![CDATA[<p>The following notes are from the <a href="http://iuuk.mff.cuni.cz/events/doccourse/">Ramsey DocCourse in Prague 2016</a>. The notes are taken by me and I have edited them. In the process I may have introduced some errors; email me or comment below and I will happily fix them.</p>
<div class="summary">
<p style="padding-left:30px;"><strong>Title</strong>: Euclidean Ramsey Theory 2 (of 3).</p>
<p style="padding-left:30px;"><strong>Lecturer</strong>: David Conlon.</p>
<p style="padding-left:30px;"><strong>Date</strong>: November 25, 2016.</p>
<p style="padding-left:30px;"><strong>Main Topics</strong>: Ramsey implies spherical, an algebraic condition for spherical, partition regular equations, an analogous result for edge Ramsey.</p>
<p style="padding-left:30px;"><strong>Definitions</strong>: Spherical, partition regular.</p>
</div>
<p>Lecture 1 &#8211; Lecture 2 &#8211; Lecture 3</p>
<p><a href="https://mikepawliuk.ca/mpawliuk/ramsey-doccourse-2016/">Ramsey DocCourse Prague 2016 Index of lectures.</a></p>
<p><span id="more-1531"></span></p>
<hr />
<h2>Introduction</h2>
<p>In the first lecture we defined the relevant terms and then established that all (non-degenerate) triangles are Ramsey. In this lecture we will compare the property of being spherical with being Ramsey. In this lecture we will show that Ramsey implies spherical (or more precisely, that non spherical sets cannot be Ramsey).</p>
<div class="defn">
<p><strong>Definition</strong>. A set <img src="https://s0.wp.com/latex.php?latex=X+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="X " title="X " class="latex" /> is <strong>spherical</strong> if there is an <img src="https://s0.wp.com/latex.php?latex=n+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="n " title="n " class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=X+%5Csubseteq+S%5En+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="X &#92;subseteq S^n " title="X &#92;subseteq S^n " class="latex" />.</p>
<p>Typically <img src="https://s0.wp.com/latex.php?latex=S+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="S " title="S " class="latex" /> will be finite, but this is not formally required.</p>
</div>
<p>The proofs are those of Erdos et Al, and go by establishing a tight algebraic condition for a set being spherical.</p>
<ol>
<li>Show that three points in a line are not Ramsey.</li>
<li>Define a partition regular equation.</li>
<li>Prove two colouring lemmas about partition regular equations.</li>
<li>Relate spherical sets to a tight algebraic condition.</li>
<li>Put everything together to prove that Ramsey implies spherical.</li>
</ol>
<h2>(Evenly spaced) lines aren&#8217;t Ramsey</h2>
<p>Let <img src="https://s0.wp.com/latex.php?latex=L+%3D+%5C%7Bx%2Cy%2Cz%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="L = &#92;{x,y,z&#92;} " title="L = &#92;{x,y,z&#92;} " class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=d%28x%2Cy%29+%3D+d%28y%2Cz%29+%3D+1+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="d(x,y) = d(y,z) = 1 " title="d(x,y) = d(y,z) = 1 " class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=d%28x%2Cz%29+%3D+2+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="d(x,z) = 2 " title="d(x,z) = 2 " class="latex" />; it is a line segment with three points equally spaced.</p>
<div class="thm"><strong>Theorem</strong>. The line segment <img src="https://s0.wp.com/latex.php?latex=L+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="L " title="L " class="latex" /> is not Ramsey.</div>
<p>&#8220;The reason is you can take a `spherical shell&#8217; colouring.&#8221; These shell colourings are very important.</p>
<p>This doesn&#8217;t work for `cube colourings&#8217; (i.e. using a different norm) since by Dvoretsky&#8217;s Theorem, hyperplane slices of cubes basically look spherical.</p>
<div class="proof">
<p><strong>Proof</strong>. Fix <img src="https://s0.wp.com/latex.php?latex=n+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="n " title="n " class="latex" />. Define the colouring <img src="https://s0.wp.com/latex.php?latex=%5Cchi+%3A+%5Cmathbb%7BR%7D%5En+%5Crightarrow+%5C%7B0%2C1%2C2%2C3%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi : &#92;mathbb{R}^n &#92;rightarrow &#92;{0,1,2,3&#92;} " title="&#92;chi : &#92;mathbb{R}^n &#92;rightarrow &#92;{0,1,2,3&#92;} " class="latex" /> by <img src="https://s0.wp.com/latex.php?latex=%5Cchi%28x%29+%3D+%5Clfloor+x+%5Ccdot+x+%5Crfloor+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi(x) = &#92;lfloor x &#92;cdot x &#92;rfloor " title="&#92;chi(x) = &#92;lfloor x &#92;cdot x &#92;rfloor " class="latex" />. (You&#8217;re taking spherical shells of radii <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;sqrt{n} " title="&#92;sqrt{n} " class="latex" />.)</p>
<p>[Picture]</p>
<p>By the Cosine rule we get <img src="https://s0.wp.com/latex.php?latex=a%5E2+%3D+b%5E2+%2B+1+-+2b%5Ccos%28%5Ctheta%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="a^2 = b^2 + 1 - 2b&#92;cos(&#92;theta) " title="a^2 = b^2 + 1 - 2b&#92;cos(&#92;theta) " class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=c%5E2+%3D+b%5E2+%2B+1+%2B+2b%5Ccos%28%5Ctheta%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="c^2 = b^2 + 1 + 2b&#92;cos(&#92;theta) " title="c^2 = b^2 + 1 + 2b&#92;cos(&#92;theta) " class="latex" />. So we get <img src="https://s0.wp.com/latex.php?latex=a%5E2+%2B+c%5E2+%3D+2b%5E2+%2B2+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="a^2 + c^2 = 2b^2 +2 " title="a^2 + c^2 = 2b^2 +2 " class="latex" />.</p>
<p>Suppose that <img src="https://s0.wp.com/latex.php?latex=x%2Cy%2Cz+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x,y,z " title="x,y,z " class="latex" /> have the same colour. This means that there is an <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5C%7B0%2C1%2C2%2C3%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="i &#92;in &#92;{0,1,2,3&#92;} " title="i &#92;in &#92;{0,1,2,3&#92;} " class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=a%5E2+%3D+4k_1+%2B+i+%2B+%5Cepsilon_1+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="a^2 = 4k_1 + i + &#92;epsilon_1 " title="a^2 = 4k_1 + i + &#92;epsilon_1 " class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=b%5E2+%3D+4k_2+%2B+i+%2B+%5Cepsilon_2+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="b^2 = 4k_2 + i + &#92;epsilon_2 " title="b^2 = 4k_2 + i + &#92;epsilon_2 " class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=c%5E2+%3D+4k_3+%2B+i+%2B+%5Cepsilon_3+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="c^2 = 4k_3 + i + &#92;epsilon_3 " title="c^2 = 4k_3 + i + &#92;epsilon_3 " class="latex" />, where each <img src="https://s0.wp.com/latex.php?latex=0+%5Cleq+%5Cepsilon_j+%3C+1+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="0 &#92;leq &#92;epsilon_j &lt; 1 " title="0 &#92;leq &#92;epsilon_j &lt; 1 " class="latex" />.</p>
<p>Putting this into our cosine law info gives<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+4%28k_1+%2B+k_3+-+2k_2%29+-2+%3D+2%5Cepsilon_2+-+%5Cepsilon_1+-+%5Cepsilon_3%2C+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle 4(k_1 + k_3 - 2k_2) -2 = 2&#92;epsilon_2 - &#92;epsilon_1 - &#92;epsilon_3, " title="&#92;displaystyle 4(k_1 + k_3 - 2k_2) -2 = 2&#92;epsilon_2 - &#92;epsilon_1 - &#92;epsilon_3, " class="latex" /><br />
which is a contradiction since the left is <img src="https://s0.wp.com/latex.php?latex=2+%5Cmod+4+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="2 &#92;mod 4 " title="2 &#92;mod 4 " class="latex" /> but the right is strictly between <img src="https://s0.wp.com/latex.php?latex=-2+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="-2 " title="-2 " class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=2+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="2 " title="2 " class="latex" />.</p>
</div>
<h2>Partition regular equations</h2>
<p>Eventually we will relate the condition of a set being spherical with a tight algebraic condition. With this in mind, we examine when algebraic conditions can yield Ramsey witnesses. We start with a general discussion of partition regular equations.</p>
<div class="defn"><strong>Definition</strong>. An equation is <strong>partition regular</strong> if every finite colouring of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5En+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;mathbb{R}^n " title="&#92;mathbb{R}^n " class="latex" /> contains a monochromatic solution to the equation.</div>
<p>For example,</p>
<ol>
<li><strong>Schur</strong>. <img src="https://s0.wp.com/latex.php?latex=x+%2B+y+%3D+z+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x + y = z " title="x + y = z " class="latex" />.</li>
<li><strong>Van der Waerden</strong>. <img src="https://s0.wp.com/latex.php?latex=x+%2B+y+%3D+2z+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x + y = 2z " title="x + y = 2z " class="latex" />.</li>
<li><strong>Rado</strong>. A simple equation <img src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5Ek+c_i+x_i+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;sum_{i=1}^k c_i x_i = 0 " title="&#92;sum_{i=1}^k c_i x_i = 0 " class="latex" /> is partition regular if and only if there is a non empty <img src="https://s0.wp.com/latex.php?latex=I+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="I " title="I " class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi+%5Cin+I%7D+c_i+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;sum_{i &#92;in I} c_i = 0 " title="&#92;sum_{i &#92;in I} c_i = 0 " class="latex" />.</li>
</ol>
<div class="exercise">
<p><strong>Exercise</strong>. If the equation is translation invariant then you get a corresponding density result.</p>
<p>Use this to show that you always get a non-trivial solution.</p>
</div>
<h2>Are there inhomogeneous equations that are partition regular? Two lemmas.</h2>
<p>First an example.</p>
<p><strong>Example</strong>. <img src="https://s0.wp.com/latex.php?latex=x+%2B+y+%3D+z+%2B+1+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x + y = z + 1 " title="x + y = z + 1 " class="latex" />.</p>
<p>We can homogenize this equation by replacing the variables. Use <img src="https://s0.wp.com/latex.php?latex=x+%3D+x%5E%5Cprime%2B1%2C+y+%3D+y%5E%5Cprime+%2B1+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x = x^&#92;prime+1, y = y^&#92;prime +1 " title="x = x^&#92;prime+1, y = y^&#92;prime +1 " class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=z+%3D+z%5E%5Cprime%2B1+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="z = z^&#92;prime+1 " title="z = z^&#92;prime+1 " class="latex" />. This gives the equation <img src="https://s0.wp.com/latex.php?latex=x%5E%5Cprime+%2B+y%5E%5Cprime+%3D+z%5E%5Cprime+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x^&#92;prime + y^&#92;prime = z^&#92;prime " title="x^&#92;prime + y^&#92;prime = z^&#92;prime " class="latex" />.</p>
<p>Basically, these are the only types of partition regular equations.</p>
<div class="thm"><strong>Lemma 1</strong>. There is a <img src="https://s0.wp.com/latex.php?latex=2n+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="2n " title="2n " class="latex" /> colouring <img src="https://s0.wp.com/latex.php?latex=%5Cchi+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi " title="&#92;chi " class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;mathbb{R} " title="&#92;mathbb{R} " class="latex" /> with no solution of<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%3D1%7D%5En+%28x_i+-+x%5E%5Cprime_i%29+%3D+1+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle &#92;sum_{i=1}^n (x_i - x^&#92;prime_i) = 1 " title="&#92;displaystyle &#92;sum_{i=1}^n (x_i - x^&#92;prime_i) = 1 " class="latex" /><br />
with <img src="https://s0.wp.com/latex.php?latex=%5Cchi%28x_i%29+%3D+%5Cchi%28x%5E%5Cprime_i%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi(x_i) = &#92;chi(x^&#92;prime_i) " title="&#92;chi(x_i) = &#92;chi(x^&#92;prime_i) " class="latex" /> for all <img src="https://s0.wp.com/latex.php?latex=i+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="i " title="i " class="latex" />.</div>
<p>The number of colours is equal to the number of variables.</p>
<p>This is a strong result of the equation not being partition regular. You can&#8217;t have a monochromatic solution, you can&#8217;t even have all the paired variables agree!</p>
<p>The idea is to colour whether you are in a certain interval.</p>
<div class="proof">
<p><strong>Proof</strong>. Fix <img src="https://s0.wp.com/latex.php?latex=n+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="n " title="n " class="latex" />. Colour <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5Cmathbb%7BR%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x &#92;in &#92;mathbb{R} " title="x &#92;in &#92;mathbb{R} " class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=j+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="j " title="j " class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5B2m+%2B+%5Cfrac%7Bj%7D%7Bn%7D%2C+2m+%2B+%5Cfrac%7Bj%2B1%7D%7Bn%7D%5D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x &#92;in [2m + &#92;frac{j}{n}, 2m + &#92;frac{j+1}{n}] " title="x &#92;in [2m + &#92;frac{j}{n}, 2m + &#92;frac{j+1}{n}] " class="latex" /> for some integer <img src="https://s0.wp.com/latex.php?latex=m+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="m " title="m " class="latex" />.</p>
<p>If <img src="https://s0.wp.com/latex.php?latex=%5Cchi%28x_i%29+%3D+%5Cchi%28x%5E%5Cprime_i%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi(x_i) = &#92;chi(x^&#92;prime_i) " title="&#92;chi(x_i) = &#92;chi(x^&#92;prime_i) " class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=x_i+-+x%5E%5Cprime_i+%3D+2m_i+%2B+%5Cepsilon_i+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x_i - x^&#92;prime_i = 2m_i + &#92;epsilon_i " title="x_i - x^&#92;prime_i = 2m_i + &#92;epsilon_i " class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%5Cvert+%5Cepsilon_i+%5Cvert+%3C+%5Cfrac%7B1%7D%7Bn%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;vert &#92;epsilon_i &#92;vert &lt; &#92;frac{1}{n} " title="&#92;vert &#92;epsilon_i &#92;vert &lt; &#92;frac{1}{n} " class="latex" />.</p>
<p>So<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+1+%3D+%5Csum_%7Bi%3D1%7D%5En+%28x_i+-+x%5E%5Cprime_i%29+%3D+%5Csum_%7Bi%3D1%7D%5En+2m_i+%2B+%5Csum_%7Bi%3D1%7D%5En+%5Cepsilon_i.+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle 1 = &#92;sum_{i=1}^n (x_i - x^&#92;prime_i) = &#92;sum_{i=1}^n 2m_i + &#92;sum_{i=1}^n &#92;epsilon_i. " title="&#92;displaystyle 1 = &#92;sum_{i=1}^n (x_i - x^&#92;prime_i) = &#92;sum_{i=1}^n 2m_i + &#92;sum_{i=1}^n &#92;epsilon_i. " class="latex" /></p>
<p>Here the first sum is an even number, and the second is <img src="https://s0.wp.com/latex.php?latex=%3C+1+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&lt; 1 " title="&lt; 1 " class="latex" />, a contradiction.</p>
</div>
<p>Now we increase the number of colours to deal with a more general equation.</p>
<div class="thm"><strong>Lemma 2</strong>. There is a <img src="https://s0.wp.com/latex.php?latex=%282n%29%5En+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(2n)^n " title="(2n)^n " class="latex" /> colouring <img src="https://s0.wp.com/latex.php?latex=%5Cchi+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi " title="&#92;chi " class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;mathbb{R} " title="&#92;mathbb{R} " class="latex" /> with no solution of<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%3D1%7D%5En+c_i+%28x_i+-+x%5E%5Cprime_i%29+%3D+b+%5Cneq+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle &#92;sum_{i=1}^n c_i (x_i - x^&#92;prime_i) = b &#92;neq 0 " title="&#92;displaystyle &#92;sum_{i=1}^n c_i (x_i - x^&#92;prime_i) = b &#92;neq 0 " class="latex" /><br />
with <img src="https://s0.wp.com/latex.php?latex=%5Cchi%28x_i%29+%3D+%5Cchi%28x%5E%5Cprime_i%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi(x_i) = &#92;chi(x^&#92;prime_i) " title="&#92;chi(x_i) = &#92;chi(x^&#92;prime_i) " class="latex" /> for all <img src="https://s0.wp.com/latex.php?latex=i+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="i " title="i " class="latex" />.</div>
<div class="proof">
<p><strong>Proof</strong>. Fix <img src="https://s0.wp.com/latex.php?latex=n+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="n " title="n " class="latex" />. By dividing by <img src="https://s0.wp.com/latex.php?latex=b+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="b " title="b " class="latex" /> it suffices to consider <img src="https://s0.wp.com/latex.php?latex=b+%3D+1+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="b = 1 " title="b = 1 " class="latex" />.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%5Cchi+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi " title="&#92;chi " class="latex" /> be the (<img src="https://s0.wp.com/latex.php?latex=2n+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="2n " title="2n " class="latex" />) colouring from Lemma 1.</p>
<p>Define <img src="https://s0.wp.com/latex.php?latex=%5Cchi%5E%5Cprime%28x%29+%3D+%28%5Cchi%28c_1+x%29%2C+%5Cchi%28c_2+x%29%2C+%5Cldots%2C+%5Cchi%28c_n+x%29%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi^&#92;prime(x) = (&#92;chi(c_1 x), &#92;chi(c_2 x), &#92;ldots, &#92;chi(c_n x)) " title="&#92;chi^&#92;prime(x) = (&#92;chi(c_1 x), &#92;chi(c_2 x), &#92;ldots, &#92;chi(c_n x)) " class="latex" />.</p>
<p>Now if <img src="https://s0.wp.com/latex.php?latex=%5Cchi%5E%5Cprime%28x_i%29+%3D+%5Cchi%5E%5Cprime%28x%5E%5Cprime_i%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi^&#92;prime(x_i) = &#92;chi^&#92;prime(x^&#92;prime_i) " title="&#92;chi^&#92;prime(x_i) = &#92;chi^&#92;prime(x^&#92;prime_i) " class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=%5Cchi%28c_i+x_i%29+%3D+%5Cchi%28c_i+x%5E%5Cprime_i%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi(c_i x_i) = &#92;chi(c_i x^&#92;prime_i) " title="&#92;chi(c_i x_i) = &#92;chi(c_i x^&#92;prime_i) " class="latex" />.</p>
<p>So <img src="https://s0.wp.com/latex.php?latex=c_i%28x_i+-+x_i%5E%5Cprime%29+%3D+2m_i+%2B+%5Cepsilon_i+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="c_i(x_i - x_i^&#92;prime) = 2m_i + &#92;epsilon_i " title="c_i(x_i - x_i^&#92;prime) = 2m_i + &#92;epsilon_i " class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%5Cvert+%5Cepsilon_i+%5Cvert+%3C+%5Cfrac%7B1%7D%7Bn%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;vert &#92;epsilon_i &#92;vert &lt; &#92;frac{1}{n} " title="&#92;vert &#92;epsilon_i &#92;vert &lt; &#92;frac{1}{n} " class="latex" />.</p>
<p>If this happens for all <img src="https://s0.wp.com/latex.php?latex=i+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="i " title="i " class="latex" />, then we have a contradiction identical to the one in Lemma 1.</p>
</div>
<p>In the original paper there was a similar lemma but it had a worse bound on the number of colours. This improvement was observed by Strauss a little later.</p>
<p>Note that these equations are not susceptible to the &#8220;translation trick&#8221; since <img src="https://s0.wp.com/latex.php?latex=%28y_i+%2B+1%29+-+%28y_i%5E%5Cprime+%2B+1%29+%3D+y_i+-+y_i%5E%5Cprime+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(y_i + 1) - (y_i^&#92;prime + 1) = y_i - y_i^&#92;prime " title="(y_i + 1) - (y_i^&#92;prime + 1) = y_i - y_i^&#92;prime " class="latex" />.</p>
<h2>Characterizing spherical in terms of an algebraic condition</h2>
<p>The following is the main technical lemma. The proof is purely algebraic.</p>
<div class="thm"><strong>Theorem</strong>. A set <img src="https://s0.wp.com/latex.php?latex=X+%3D+%5C%7B%5Cvec%7Bx%7D_0%2C+%5Cldots%2C+%5Cvec%7Bx%7D_t%5C%7D+%5Csubset+%5Cmathbb%7BR%7D%5En+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="X = &#92;{&#92;vec{x}_0, &#92;ldots, &#92;vec{x}_t&#92;} &#92;subset &#92;mathbb{R}^n " title="X = &#92;{&#92;vec{x}_0, &#92;ldots, &#92;vec{x}_t&#92;} &#92;subset &#92;mathbb{R}^n " class="latex" /> is not spherical if and only if there are constants <img src="https://s0.wp.com/latex.php?latex=c_i+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="c_i " title="c_i " class="latex" />, not all <img src="https://s0.wp.com/latex.php?latex=0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="0 " title="0 " class="latex" />, such that<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%3D1%7D%5Et+c_i+%28%5Cvec%7Bx%7D_i+-+%5Cvec%7Bx%7D_0%29+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle &#92;sum_{i=1}^t c_i (&#92;vec{x}_i - &#92;vec{x}_0) = 0 " title="&#92;displaystyle &#92;sum_{i=1}^t c_i (&#92;vec{x}_i - &#92;vec{x}_0) = 0 " class="latex" /><br />
and<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%3D1%7D%5Et+c_i+%28%5Cvec%7Bx%7D_i%5E2+-+%5Cvec%7Bx%7D_0%5E2%29+%3D+%5Cvec%7Bb%7D.+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle &#92;sum_{i=1}^t c_i (&#92;vec{x}_i^2 - &#92;vec{x}_0^2) = &#92;vec{b}. " title="&#92;displaystyle &#92;sum_{i=1}^t c_i (&#92;vec{x}_i^2 - &#92;vec{x}_0^2) = &#92;vec{b}. " class="latex" /></div>
<p>For readability, we will write <img src="https://s0.wp.com/latex.php?latex=x+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x " title="x " class="latex" /> instead of <img src="https://s0.wp.com/latex.php?latex=%5Cvec%7Bx%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;vec{x} " title="&#92;vec{x} " class="latex" />. We will make use of the following useful fact:</p>
<div class="thm"><strong>Useful identity</strong>.<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+a%5E2+-+b%5E2+%3D+%28a+-+c%29%5E2+-+%28b+-+c%29%5E2+%2B+2a+%5Ccdot+c+-+2+b+%5Ccdot+c.+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle a^2 - b^2 = (a - c)^2 - (b - c)^2 + 2a &#92;cdot c - 2 b &#92;cdot c. " title="&#92;displaystyle a^2 - b^2 = (a - c)^2 - (b - c)^2 + 2a &#92;cdot c - 2 b &#92;cdot c. " class="latex" /><br />
Using <img src="https://s0.wp.com/latex.php?latex=c%3Db+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="c=b " title="c=b " class="latex" /> yields<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+a%5E2+-+b%5E2+%3D+%28a+-+b%29%5E2+%2B+2b%28a+-+b%29.+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle a^2 - b^2 = (a - b)^2 + 2b(a - b). " title="&#92;displaystyle a^2 - b^2 = (a - b)^2 + 2b(a - b). " class="latex" /></div>
<div class="proof">
<p><strong>Proof of <img src="https://s0.wp.com/latex.php?latex=%5CLeftarrow+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;Leftarrow " title="&#92;Leftarrow " class="latex" /></strong>. Assume that <img src="https://s0.wp.com/latex.php?latex=X+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="X " title="X " class="latex" /> is spherical and satisfies the first equation. We will show the second equality fails.</p>
<p>Say <img src="https://s0.wp.com/latex.php?latex=X+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="X " title="X " class="latex" /> has centre <img src="https://s0.wp.com/latex.php?latex=w+%28%5Cin+%5Cmathbb%7BR%7D%5En%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="w (&#92;in &#92;mathbb{R}^n) " title="w (&#92;in &#92;mathbb{R}^n) " class="latex" /> and radius <img src="https://s0.wp.com/latex.php?latex=r+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="r " title="r " class="latex" />.</p>
<p>For each <img src="https://s0.wp.com/latex.php?latex=i+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="i " title="i " class="latex" /> we have:</p>
<ul style="list-style-type:none;"><img src="https://s0.wp.com/latex.php?latex=r%5E2+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="r^2 " title="r^2 " class="latex" /></p>
<li><img src="https://s0.wp.com/latex.php?latex=%3D+%28x_i+-+w%29+%5Ccdot+%28x_i+-+w%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="= (x_i - w) &#92;cdot (x_i - w) " title="= (x_i - w) &#92;cdot (x_i - w) " class="latex" /></li>
<li><img src="https://s0.wp.com/latex.php?latex=%3D+%28%28x_i+-x_0%29+%2B+%28x_0+-+w%29%29+%5Ccdot+%28%28x_i+-x_0%29+%2B+%28x_0+-+w%29%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="= ((x_i -x_0) + (x_0 - w)) &#92;cdot ((x_i -x_0) + (x_0 - w)) " title="= ((x_i -x_0) + (x_0 - w)) &#92;cdot ((x_i -x_0) + (x_0 - w)) " class="latex" /></li>
<li><img src="https://s0.wp.com/latex.php?latex=%3D+%28x_i+-x_0%29%5E2+%2B+%28x_0+-+w%29%5E2+%2B+2%28x_i+-+x_0%29%28x_0-w%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="= (x_i -x_0)^2 + (x_0 - w)^2 + 2(x_i - x_0)(x_0-w) " title="= (x_i -x_0)^2 + (x_0 - w)^2 + 2(x_i - x_0)(x_0-w) " class="latex" />. Here the second term is <img src="https://s0.wp.com/latex.php?latex=r%5E2+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="r^2 " title="r^2 " class="latex" />.</li>
</ul>
<p>So we must have <img src="https://s0.wp.com/latex.php?latex=%28x_i+-x_0%29%5E2+%3D+-2%28x_i+-+x_0%29%28x_0-w%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(x_i -x_0)^2 = -2(x_i - x_0)(x_0-w) " title="(x_i -x_0)^2 = -2(x_i - x_0)(x_0-w) " class="latex" /> for each <img src="https://s0.wp.com/latex.php?latex=i+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="i " title="i " class="latex" />. So by multiplying by <img src="https://s0.wp.com/latex.php?latex=c_i+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="c_i " title="c_i " class="latex" /> and adding up we get<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%3D1%7D%5Et+c_i+%28x_i+-+x_0%29%5E2+%3D+-2%28x_0-w%29%5Csum_%7Bi%3D1%7D%5Et+c_i+%28x_i-x_0%29+%3D+0.+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle &#92;sum_{i=1}^t c_i (x_i - x_0)^2 = -2(x_0-w)&#92;sum_{i=1}^t c_i (x_i-x_0) = 0. " title="&#92;displaystyle &#92;sum_{i=1}^t c_i (x_i - x_0)^2 = -2(x_0-w)&#92;sum_{i=1}^t c_i (x_i-x_0) = 0. " class="latex" /></p>
<p>By using the special case of the useful identity, we get:<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%3D1%7D%5Et+c_i+%28x_i%5E2+-+x_0%5E2%29+%3D+%5Csum_%7Bi%3D1%7D%5Et%28x_i-x_0%29%5E2+-+2x_0+%5Csum_%7Bi%3D1%7D%5Et+c_i+%28x_0+-+x_i%29.+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle &#92;sum_{i=1}^t c_i (x_i^2 - x_0^2) = &#92;sum_{i=1}^t(x_i-x_0)^2 - 2x_0 &#92;sum_{i=1}^t c_i (x_0 - x_i). " title="&#92;displaystyle &#92;sum_{i=1}^t c_i (x_i^2 - x_0^2) = &#92;sum_{i=1}^t(x_i-x_0)^2 - 2x_0 &#92;sum_{i=1}^t c_i (x_0 - x_i). " class="latex" /></p>
<p>We know the first sum is <img src="https://s0.wp.com/latex.php?latex=0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="0 " title="0 " class="latex" /> by our above calculations, and by assumption we know<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+2x_0+%5Ccdot+%5Csum_%7Bi%3D1%7D%5Et+c_i+%28x_i+-+x_0%29+%3D+0%2C+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle 2x_0 &#92;cdot &#92;sum_{i=1}^t c_i (x_i - x_0) = 0, " title="&#92;displaystyle 2x_0 &#92;cdot &#92;sum_{i=1}^t c_i (x_i - x_0) = 0, " class="latex" /><br />
a contradiction.</p>
</div>
<div class="proof">
<p><strong>Proof of <img src="https://s0.wp.com/latex.php?latex=%5CRightarrow+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;Rightarrow " title="&#92;Rightarrow " class="latex" /></strong>. Assume <img src="https://s0.wp.com/latex.php?latex=X+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="X " title="X " class="latex" /> is not spherical, and moreover that it is minimal (in the sense that removing any one point makes it spherical). In particular, <img src="https://s0.wp.com/latex.php?latex=X+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="X " title="X " class="latex" /> is not a non-degenerate simplex. So there is a linear relation<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%3D1%7D%5Et+c_i+%28x_i+-+x_0%29.+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle &#92;sum_{i=1}^t c_i (x_i - x_0). " title="&#92;displaystyle &#92;sum_{i=1}^t c_i (x_i - x_0). " class="latex" /></p>
<p>Assume that <img src="https://s0.wp.com/latex.php?latex=c_t+%5Cneq+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="c_t &#92;neq 0 " title="c_t &#92;neq 0 " class="latex" />. By minimality, <img src="https://s0.wp.com/latex.php?latex=%5C%7Bx_0%2C+%5Cldots%2C+x_%7Bt-1%7D%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;{x_0, &#92;ldots, x_{t-1}&#92;} " title="&#92;{x_0, &#92;ldots, x_{t-1}&#92;} " class="latex" /> is spherical, and is on a sphere with centre <img src="https://s0.wp.com/latex.php?latex=w+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="w " title="w " class="latex" /> and radius <img src="https://s0.wp.com/latex.php?latex=r+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="r " title="r " class="latex" />.</p>
<p>Thus<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+x_i%5E2+-+x_0%5E2+%3D+%28x_i+-+w%29%5E2+-+%28x_0+-+w%29%5E2+%2B+2x_i+%5Ccdot+w+-+2+x_0+%5Ccdot+w.+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle x_i^2 - x_0^2 = (x_i - w)^2 - (x_0 - w)^2 + 2x_i &#92;cdot w - 2 x_0 &#92;cdot w. " title="&#92;displaystyle x_i^2 - x_0^2 = (x_i - w)^2 - (x_0 - w)^2 + 2x_i &#92;cdot w - 2 x_0 &#92;cdot w. " class="latex" /></p>
<p>So<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum+c_i+%28x_i%5E2+-+x_0%5E2%29+%3D+%5Csum+c_i+%28%28x_i+-+w%29%5E2+-+%28x_0+-+w%29%5E2%29+%2B+2w+%5Ccdot+%5Csum+c_i+%28x_i+-+x_0%29%2C+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle &#92;sum c_i (x_i^2 - x_0^2) = &#92;sum c_i ((x_i - w)^2 - (x_0 - w)^2) + 2w &#92;cdot &#92;sum c_i (x_i - x_0), " title="&#92;displaystyle &#92;sum c_i (x_i^2 - x_0^2) = &#92;sum c_i ((x_i - w)^2 - (x_0 - w)^2) + 2w &#92;cdot &#92;sum c_i (x_i - x_0), " class="latex" /></p>
<p>here the second sum is <img src="https://s0.wp.com/latex.php?latex=0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="0 " title="0 " class="latex" />, and the first, by minimality, is<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+c_t+%28%28x_t+-+w%29%5E2+-+%28x_0+-+w%29%5E2%29+%5Cneq+0%2C+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle c_t ((x_t - w)^2 - (x_0 - w)^2) &#92;neq 0, " title="&#92;displaystyle c_t ((x_t - w)^2 - (x_0 - w)^2) &#92;neq 0, " class="latex" /><br />
which isn&#8217;t <img src="https://s0.wp.com/latex.php?latex=0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="0 " title="0 " class="latex" /> since the distances of <img src="https://s0.wp.com/latex.php?latex=x_t+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x_t " title="x_t " class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=x_0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x_0 " title="x_0 " class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=w+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="w " title="w " class="latex" /> are different.</p>
</div>
<h2>Ramsey implies spherical</h2>
<p>We are now in a position to put everything together.</p>
<div class="thm"><strong>Theorem</strong>. All Ramsey sets are spherical.</div>
<div class="proof">
<p><strong>Proof</strong>. Assume <img src="https://s0.wp.com/latex.php?latex=X+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="X " title="X " class="latex" /> is not spherical. So there are constants <img src="https://s0.wp.com/latex.php?latex=c_1%2C+%5Cldots%2C+c_t+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="c_1, &#92;ldots, c_t " title="c_1, &#92;ldots, c_t " class="latex" /> and a vector <img src="https://s0.wp.com/latex.php?latex=%5Cvec%7Bb%7D+%5Cneq+%5Cvec%7B0%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;vec{b} &#92;neq &#92;vec{0} " title="&#92;vec{b} &#92;neq &#92;vec{0} " class="latex" /> such that<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum+c_i+%28%5Cvec%7Bx%7D_i+-+%5Cvec%7Bx%7D_0%29+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle &#92;sum c_i (&#92;vec{x}_i - &#92;vec{x}_0) = 0 " title="&#92;displaystyle &#92;sum c_i (&#92;vec{x}_i - &#92;vec{x}_0) = 0 " class="latex" /><br />
and<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum+c_i+%28%5Cvec%7Bx%7D_i%5E2+-+%5Cvec%7Bx%7D_0%5E2%29+%3D+%5Cvec%7Bb%7D.+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle &#92;sum c_i (&#92;vec{x}_i^2 - &#92;vec{x}_0^2) = &#92;vec{b}. " title="&#92;displaystyle &#92;sum c_i (&#92;vec{x}_i^2 - &#92;vec{x}_0^2) = &#92;vec{b}. " class="latex" /></p>
<div class="exercise">
<p><strong>Technical exercise</strong>. Any congruent copy of <img src="https://s0.wp.com/latex.php?latex=X+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="X " title="X " class="latex" /> satisfies the same equations.</p>
<p>(Use the fact that congruence is formed by rotations and translations. The translations will spit out terms like <img src="https://s0.wp.com/latex.php?latex=%5Cstar+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;star " title="&#92;star " class="latex" />.)</p>
</div>
<p>In every non-zero coordinate of <img src="https://s0.wp.com/latex.php?latex=%5Cvec%7Bb%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;vec{b} " title="&#92;vec{b} " class="latex" /> use the colouring <img src="https://s0.wp.com/latex.php?latex=%5Cchi+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi " title="&#92;chi " class="latex" /> from Lemma 2, and set <img src="https://s0.wp.com/latex.php?latex=%5Cchi%5E%5Cprime%28x%29+%3D+%5Cchi%28x%5E2%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi^&#92;prime(x) = &#92;chi(x^2) " title="&#92;chi^&#92;prime(x) = &#92;chi(x^2) " class="latex" />. This will give no monochromatic solution to<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum+c_i+%28%5Cvec%7Bx%7D_i%5E2+-+%5Cvec%7Bx%7D_0%5E2%29+%3D+%5Cvec%7Bb%7D.+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle &#92;sum c_i (&#92;vec{x}_i^2 - &#92;vec{x}_0^2) = &#92;vec{b}. " title="&#92;displaystyle &#92;sum c_i (&#92;vec{x}_i^2 - &#92;vec{x}_0^2) = &#92;vec{b}. " class="latex" /></p>
</div>
<p>This is the end of this lecture&#8217;s material on point-Ramsey. We shift gears a little now.</p>
<h2>Edge Ramsey</h2>
<p>Instead of colouring points, we can colour pairs of points. This leads to the notion of <strong>edge Ramsey</strong>. We mention two results in this area.</p>
<div class="thm"><strong>Theorem</strong>. If the edge set <img src="https://s0.wp.com/latex.php?latex=X+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="X " title="X " class="latex" /> is not vertex spherical and not bipartite, it is not edge Ramsey.</div>
<div class="proof">
<p><strong>Proof</strong>. Suppose the vertex set is not spherical. Colour the points, using <img src="https://s0.wp.com/latex.php?latex=%5Cchi+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi " title="&#92;chi " class="latex" />, so that no copy of <img src="https://s0.wp.com/latex.php?latex=X+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="X " title="X " class="latex" /> has a monochromatic vertex set.</p>
<p>Now colour the edge <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(x,y) " title="(x,y) " class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%5Cchi%5E%5Cprime+%28x%2Cy%29+%3D+%28%5Cchi%28x%29%2C+%5Cchi%28y%29%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;chi^&#92;prime (x,y) = (&#92;chi(x), &#92;chi(y)) " title="&#92;chi^&#92;prime (x,y) = (&#92;chi(x), &#92;chi(y)) " class="latex" />.</p>
<p>Each edge has the same colour and must contain two distinct vertex colours. So the edge set is bi-partite.</p>
</div>
<p>This gives us an analogous theorem to the theorem that Ramsey implies spherical.</p>
<div class="thm"><strong>Theorem</strong>. If <img src="https://s0.wp.com/latex.php?latex=X+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="X " title="X " class="latex" /> is edge Ramsey then the points lie on two concentric spheres.</div>
<p>The proof is a variation on what we&#8217;ve seen.</p>
<h2>References</h2>
<p>See lecture 1 for references.</p>]]></summary>
        <author>
            <name>Mike Pawliuk – Mathematics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Moment of Zen]]></title>
        <id>http://karagila.org/2017/moment-of-zen/</id>
        <link href="http://karagila.org/2017/moment-of-zen/">
        </link>
        <updated>2017-05-16T13:26:40Z</updated>
        <summary type="html"><![CDATA[<p><blockquote>When one is ascending a difficult path uphill, it is a good idea to keep your eyes on the path as you move forward. However, it is not a bad idea to stop sometimes, look back, and appreciate the beauty of the ground you have already covered.</blockquote> <a href="http://karagila.org/2017/moment-of-zen/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What a long strange trip it's been...]]></title>
        <id>http://karagila.org/2017/what-a-long-strange-trip-its-been/</id>
        <link href="http://karagila.org/2017/what-a-long-strange-trip-its-been/">
        </link>
        <updated>2017-04-25T08:28:11Z</updated>
        <summary type="html"><![CDATA[<p>As some of you may have noticed, I don't use this blog to write about my papers in the &quot;traditional way&quot; math bloggers summarize and explain their recent work. I think my papers are prosaic enough to do that on their own. I do use this blog as an outlet when I have to complain about the arduous toil of being a mathematician (which has an immensely bright light side, of course, so in the big picture I'm quite happy with it).</p>

<p>This morning I woke up to see that my paper about the Bristol model was announced on arXiv. But unbeknownst to the common arXiv follower, this also marks the end of my thesis. The Hebrew University is kind enough to allow you to just stitch a bunch of your papers (along with an added introduction) and call it a thesis. And by &quot;stitch&quot; I mean literally. If they were published, you're even allowed to use the published .pdf (on the condition that no copyright infringement occurs). <a href="http://karagila.org/2017/what-a-long-strange-trip-its-been/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The MacLane class and the Eremenko–Lyubich class]]></title>
        <id>https://sixsmith2017.wordpress.com/2017/04/21/the-maclane-class-and-the-eremenko-lyubich-class/</id>
        <link href="https://sixsmith2017.wordpress.com/2017/04/21/the-maclane-class-and-the-eremenko-lyubich-class/">
        </link>
        <updated>2017-04-21T18:17:21Z</updated>
        <summary type="html"><![CDATA[<p>Accepted for publication by Ann. Acad. Sci. Fenn. Math (2017). Available on the <a href="https://arxiv.org/abs/1611.03292">arXiv</a>. This is a joint work with <a href="http://www.mathematics.open.ac.uk/people/phil.rippon">Phil Rippon</a> and <a href="http://math.syr.edu/Bios/Barth.html">Karl Barth</a>.<span id="more-191"></span></p>
<p>In 1970 G. R. MacLane asked if it is possible for a locally univalent function in the class <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BA%7D&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="&#92;mathcal{A}" title="&#92;mathcal{A}" class="latex" /> to have an arc tract, and this question remains open despite several partial results. Here we significantly strengthen these results by introducing new techniques associated with the Eremenko-Lyubich class for the disc. Also, we adapt a recent powerful technique of C. J. Bishop in order to show that there is a function in the Eremenko-Lyubich class for the disc that is not in the class <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BA%7D&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="&#92;mathcal{A}" title="&#92;mathcal{A}" class="latex" />.</p>
<p>&nbsp;</p>]]></summary>
        <author>
            <name>Dave Sixsmith – I am a mathematician, not a calculator</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Privilege-based Open Source]]></title>
        <id>https://www.peterkrautzberger.org/0193/</id>
        <link href="https://www.peterkrautzberger.org/0193/">
        </link>
        <updated>2017-04-01T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><small>(Another one from the drafts.)</small> A while back I ranted on twitter about privilege-based open-source and Patrick Honner asked me what I meant with it.</p>
<p>A surprisingly large number of open-source software (OSS) projects is run by volunteers. And I don't mean that &quot;hello world&quot; code you pushed to GitHub (which probably makes up 99% of all OSS repositories), I mean the many successful open-source projects that provide the fertile soil other (small and large) software projects are built on.</p>
<p>In other words, the majority of OSS is run by people privileged enough to spend hours on end to produce something that they then give a way for free. Whether or not OSS developers do it out of conviction, it's often a problem when people end up using privilege-based OSS without realizing it.</p>
<h2>Houston, we have a problem</h2>
<p>The most obvious problem is that privilege-based OSS can essentially go away at any moment. You don't have to look to extreme cases (left-pad, anyone?) to see this happen; projects simply slowly die. You might praise OSS for the fact that anyone can pick up the code and fork it if need be, but in reality dead, privilege-based OSS is more like an unfinished construction site; it's easier to start from scratch and thus the cycle repeats.</p>
<p>However, this is so obvious, it's not really a problem, I think. In any case it's not what I mean.</p>
<h2>Toxicity</h2>
<p>There's a lot to be said in favor of developing OSS out of conviction. It frequently helps people and adds diversity to the ecosystem. The trouble is that privilege-based OSS can be highly toxic.</p>
<p>One toxic variant is &quot;Silicon Valley style OSS&quot; where developers do not act out of conviction but more out of necessity to get ahead in a questionable job market (&quot;GitHub is your resume&quot;-kind-of-thing). If your hipster company hires people only due to their volunteer OSS credentials, then you are effectively hiring them by their privilege, creating a toxic environment and reducing diversity.</p>
<p>Reversely, you have the toxicity of people relying on OSS software not being willing to contribute to the development of OSS because privileged people make it work. Just the other day I was talking with a potential client who described how they use pandoc in production. If you do this at scale, then you're basing the integrity of your production workflow on how much John MacFarlane could procrastinate over the years.</p>
<p>For OSS developer, this can turn into a toxic reality because users often think they deserve access to the developer's privilege. That is, they can become highly aggressive when they find a bug in the OSS software they're using, especially when it impacts them. This gets extreme when we're talking about companies and use of privilege-based OSS in production. Company employees quickly try to exert pressure on OSS projects to fix things -- yet refuse to actually contribute to development any which way or even acknowledging the work that went into a piece of software that they themselves chose to build upon.</p>
<p>Obviously, there are other ways of doing OSS software development. There's transparency-driven OSS (e.g., security related tools, browsers), there's shared-burden OSS (e.g., joining forces to lower costs), there's donation-based, crowd-sourced, and bounty-driven OSS and many others -- Nadia Eghbal lists a few in her <a href="https://github.com/nayafia/lemonade-stand">lemonade-stand on GitHub</a>. Also ask about <a href="http://oss-watch.ac.uk/resources/governancemodels">governance models</a>.</p>
<p>Long story short, if you're using open-source software, especially in a professional context, make sure to check what model it's based on. Also, don't be toxic.</p>
<h2>Reading list</h2>
<p>These thoughts were far from original.</p>
<ul>
<li>Ian Cordasco, <a href="http://www.coglib.com/~icordasc/blog/2015/11/corporations-and-oss-do-not-mix.html">Corporations and OSS Do Not Mix</a></li>
<li>Jan Lehnardt, <a href="http://writing.jan.io/2015/11/20/sustainable-open-source.html">Sustainable Open Source</a>, especially the section &quot;Money&quot;.</li>
<li>Marijn Haverbeke <a href="http://marijnhaverbeke.nl/blog/sustainable-maintenance.html">More Money For Better Open-Source Software</a></li>
<li>Noah Kantrowitz, <a href="https://coderanger.net/funding-foss/">Funding FOSS</a></li>
<li>Isaacs, <a href="https://medium.com/open-source-life/money-and-open-source-d44a1953749c">Money and Open Source</a></li>
<li>David Heinemeier Hansson, <a href="http://david.heinemeierhansson.com/2013/the-perils-of-mixing-open-source-and-money.html">The perils of mixing open source and money</a></li>
<li>Nadia Eghbal <a href="https://medium.com/@nayafia/what-success-really-looks-like-in-open-source-2dd1facaf91c">What success really looks like in open source</a></li>
<li><a href="https://stackoverflow.com/insights/survey/2017/">StackOverflow survey 2017</a>, privilege in all its glory.</li>
<li>
<blockquote><p lang="en" dir="ltr">This is where I have an issue with the &quot;hire people for their side projects&quot; mentality.</p>&mdash; Stewart Scott-Curran (@stewartsc) <a href="https://twitter.com/stewartsc/status/735273897721921536">May 25 2016</a></blockquote>
</li>
<li>The reverse opinion: <a href="http://blog.ieeesoftware.org/2016/04/dissecting-myth-that-open-source.html">Dissecting The Myth That Open Source Software Is Not Commercial</a> on the IEEE software blog makes several good points but I think misses how many key projects are effectively run by privileged developers (even if those might be involved in large commercial open-source projects at the same time).</li>
</ul>
<p>Wider scope</p>
<ul>
<li>PPK touches on entitlement and privilege in <a href="http://www.quirksmode.org/blog/archives/2016/03/the_webs_origin.html">The web’s original sin</a>.</li>
<li>William Stein <a href="http://sagemath.blogspot.de/2016/02/if-you-were-new-faculty-member-again.html">&quot;If you were new faculty, would you start something like SageMathCloud sooner?&quot;</a>
<blockquote>
<p>Overall, the mathematical community does not value open source mathematical software in proportion to its value, and doesn't understand its importance to mathematical research and education. I would like to say that things have got a lot better over the last decade, but I don't think they have. My personal experience is that much of the &quot;next generation&quot; of mathematicians who would have changed how the math community approaches open source software are now in industry, or soon will be, and hence they have no impact on academic mathematical culture. Every one of my Ph.D. students are now at Google/Facebook/etc.</p>
</blockquote>
</li>
<li>Cameron Neylon, <a href="http://cameronneylon.net/blog/beyond-the-culture-clash-developing-leadership-for-open-organisations/">Beyond the culture clash: Developing leadership for open organisations</a>
<blockquote>
<p>Organisations in “the open space” are often community driven. Groups come together to solve a problem, and in a few cases they succeed. Most fail, and most fail pretty early. Those that survive the initial phase often experience massive growth, sometimes beyond the wildest dreams of those who started them. This brings some challenges.<br>
Sustainability is a big one: too many of these organisations lurch from grant to grant, depending on the largesse of philanthropists or government funders. Most of these eventually fail or stagnate. Some negotiate this transition by turning private and obtaining VC or Angel funds. Eventually most of these are sold off to incumbent players, and gradually lose the central thread of openness and just becoming part of the service background in their space. Nothing wrong with that but they’re no longer really part of the open community at the end of this process.<br>
But some organisations succeed and find a model: donations, memberships, advertising, fee for service have all been successful in different spaces. These can grow to be sizeable companies, ones that need professional staff and business discipline to manage complex operations, significant infrastructures, and substantial financial flows and reporting. No multi-million dollar a year organisation is going to run for very long on volunteer labour, at least not where those volunteers need to work for a living.<br>
Passion can also be a problem, as well as being a driver. Without that passion and without that community nothing gets done. Indeed without the passion many not-for-profit organisations wouldn’t be able to attract staff at the rates that they can reasonably pay. The community is a core asset.</p>
</blockquote>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Experiments with ARIA in math rendering]]></title>
        <id>https://www.peterkrautzberger.org/0192/</id>
        <link href="https://www.peterkrautzberger.org/0192/">
        </link>
        <updated>2017-03-30T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>It's been almost a year since we launched the <a href="https://w3c.github.io/mathonwebpages/">W3C Math-on-web Community Group</a>. The initial meetings were a bit all over the place and as you might expect, there are far too few people who have the resources (and inclination) to think about math on the web openly.</p>
<p>Still, there's now a small but clear core within the CG together with a useful group of &quot;lurkers&quot;. I think this year we're entering the productive stage for this community group.</p>
<p>The dominant interest of the core group (i.e., the people actually doing work) is accessibility. What surprised me somewhat was that the core group seems to be in agreement that MathML is not suitable for accessibility, not just because it is effectively deprecated on the web but also because of its inherent limitations. (If you care for nuance and read on, this doesn't mean MathML isn't a decent intermediary for creating accessible web content.)</p>
<p>My own focus has been on &quot;deep labels&quot; which will now tie nicely into our work at MathJax for our recent <a href="https://www.mathjax.org/simons-grant-2017/">grant from the Simons Foundation</a>. The idea is quite simple, really.</p>
<ul>
<li>Math on the web today is effectively void of semantic information that could be passed to <a href="http://whatsock.com/training/">the accessibility tree</a>. (This includes MathML even if tools like <a href="https://github.com/zorkow/speech-rule-engine">speech-rule-engine</a> will convert MathML into another, semantic format using heuristics.)</li>
<li>In the real world, math on the web is represented as HTML and SVG representations, producing suitable visual layout and information for the accessibility tree.</li>
<li>ARIA provides the tools for enriching HTML and SVG in a way that improves the rendering to the accessibility tree.</li>
</ul>
<p>Thus I've been building and testing demos that work with what we've got -- HTML and SVG enriched via ARIA.</p>
<p>While I'm currently building manual prototypes, obviously one eye is on our work on the speech-rule-engine, i.e., keeping automation of the process in mind. Similarly, I've been trying to think about potential improvements to standards that might give us much larger improvements / simplifications (but that's for another post).</p>
<p>At the same time, while automated analysis of content will only improve, I think manual overrides will continue to be critical. Whether it's to fix a poor result from the heuristics or whether it is to customize content (e.g., to match author preferences).</p>
<p>Obviously, I didn't want to enrich the output but the input. Given that these demos work with MathJax, the natural starting point is MathML (since that's MathJax's internal format). But MathML isn't really special or better than any other format; whatever input format your favorite tool uses, the same methods should be applicable (though some things will undoubtedly be harder/easier to do in other formats).</p>
<p>MathML in itself lacks the means to provide meaningful information to the accessibility tree; at most, it can present (pretty vague) layout information, combined with some misleading information on semantics (e.g., thinking that <code>&lt;mfrac&gt;</code> always indicates some kind of fraction). But MathML has the benefit of being XML so we can easily add ARIA attributes without running into practical issues.</p>
<p>Here's a very simple but typical example: a common notation for the derivative of a function is a dot above it. In MathML, this is usually realized as an <code>&lt;mover&gt;</code>.</p>
<pre><code>&lt;math&gt;
    &lt;mover&gt;
        &lt;mi&gt;x&lt;/mi&gt;
        &lt;mo&gt;&amp;#x02D9;&lt;!-- ˙ --&gt;&lt;/mo&gt;
    &lt;/mover&gt;
&lt;/math&gt;
</code></pre>
<p>You might be tempted to think that the &quot;real&quot; solution would be some kind of semantic markup (e.g., using <a href="https://www.w3.org/Math/draft-spec/mathml.html#chapter4_contm.diff"><code>&lt;diff&gt;</code></a>) but in the real world, the content is what it is and you want to enhance it.</p>
<p>Now even the simplest MathML accessibility tool should have the sense to voice the Unicode content (&quot;x, dot above&quot;) but it might also try to convey the layout information of an <code>mover</code> (&quot;x with dot over it&quot;). But it shouldn't try anything beyond that because the markup does not provide more information than that. In reality, those few tools with decent heuristics will easily cause issues, e.g., any superscripted 2 is read as &quot;squared&quot;.</p>
<p>Unfortunately, a dot above can mean other things besides &quot;derivative of&quot;, depending on the context and content -- if you ever run into a dot above an equal sign or a digit you'll probably guess that the dot does not represent the concept of a derivative of (then again someone probably used it that way so have fun figuring that one out).</p>
<p>So it's a mess.</p>
<p>Let's use what ARIA has given us to make it less of a mess: a simple and efficient means of providing meaningful textual alternatives for visual presentation:</p>
<pre><code>&lt;math&gt;
    &lt;mover aria-label=&quot;derivative of x&quot;&gt;
        &lt;mi&gt;x&lt;/mi&gt;
        &lt;mo&gt;&amp;#x02D9;&lt;!-- ˙ --&gt;&lt;/mo&gt;
    &lt;/mover&gt;
&lt;/math&gt;
</code></pre>
<p>This is obviously a very simple example. The most immediate questions are probably:</p>
<ul>
<li>Can you enrich arbitrary MathML constructions this way?</li>
<li>Does this have the desired effect in the wild, in particular, if MathML is converted to HTML or SVG?</li>
</ul>
<p>I believe the answer to both is yes.</p>
<h3>The real world</h3>
<p>The main demo I built is work in progress. It is available <a href="https://codepen.io/pkra/pen/xRBZjq">on Codepen</a> and I recently started versioning it <a href="https://gist.github.com/pkra/3dc56add129faa2def1452602985983d">as a gist</a>.</p>
<p>The demo covers several examples that hopefully already cover many common situations and I'll continue to work on them.</p>
<p>A lot of tweaking happened once I started to test this in screenreaders in earnest.</p>
<h4>hacks</h4>
<p>One of the first problems I ran into is what James Teh described in <a href="http://blog.jantrid.net/2015/12/woe-aria-surprisingly-but-ridiculously.html">Woe-ARIA</a>: it's not always clear what AT should expose when we muck about by aria-labeling things like this.</p>
<p>Inevitably, I also needed a common accessibility hack,  &quot;off-screen&quot; rendering of content. As a simple but extremely important example, you need this when facing the fact that, in MathML's <code>&lt;mfrac&gt;</code> the fraction bar is only implicit and thus lacks an node we could attach a label to (arguably the biggest <s>WTF</s> collision between traditional math rendering aka print and web markup).</p>
<p>I currently favor a somewhat convoluted solution:</p>
<pre><code>&lt;mrow aria-label=&quot;screen-reader only&quot;&gt;&lt;mpadded width=&quot;-1em&quot;&gt;&lt;mphantom&gt;&lt;mtext&gt;M&lt;/mtext&gt;&lt;/mphantom&gt;&lt;/mpadded&gt;&lt;/mrow&gt;
</code></pre>
<p>The main advantage is backward  compatibility and re-usability because this should render in any MathML renderer without (many) side-effects. It also (in part) gets us around the &quot;ARIA-woe&quot; or the fact that an empty <code>&lt;span&gt;</code> with <code>aria-label</code> should be ignored.</p>
<h4>Testing</h4>
<p>So far I've tested NVDA, JAWS, VoiceOver, Orca, and ChromeVox in several browsers. Some recordings are already available in <a href="https://www.youtube.com/playlist?list=PL1ATLkPgTEBqYOb7CYz7Kv6gNHh_pXbQq">a dedicate playlist</a> on MathJax's YouTube channel. Since I didn't want to add commentary, they are a bit difficult to follow so the summary below should be helpful.</p>
<h5>NVDA</h5>
<ul>
<li>SVG
<ul>
<li>IE 11 (Windows 7)
<ul>
<li>reads whole expression</li>
<li>allows exploration</li>
<li>repetitive voicing &quot;graphics&quot; and &quot;outer graphics&quot; during exploration; I believe that's caused by browser/OS.</li>
</ul>
</li>
</ul>
</li>
<li>HTML
<ul>
<li>IE 11 (Windows 7)
<ul>
<li>reads whole expression</li>
<li>allows exploration</li>
<li>ignores <code>aria-label</code>s completely</li>
</ul>
</li>
</ul>
</li>
</ul>
<h6>VoiceOver</h6>
<p>OSX El Capitan</p>
<ul>
<li>SVG
<ul>
<li>Safari 10
<ul>
<li>does not read whole expression</li>
<li>reads first label in SVG when trying to explore</li>
</ul>
</li>
<li>Chrome 54
<ul>
<li>content not exposed (complains about missing title)</li>
</ul>
</li>
<li>Firefox 51
<ul>
<li>does not read whole expression (just &quot;unknown&quot;)</li>
<li>allows exploration</li>
<li>reads &quot;unknown&quot; following each exploration step</li>
</ul>
</li>
</ul>
</li>
<li>HTML-CSS
<ul>
<li>Safari 10, Chrome 54
<ul>
<li>reads whole expression</li>
<li>allows exploration</li>
<li>with duplicate content in label, repetitive voicing &quot;group&quot; (which gets to be nagging during exploration)</li>
<li>character exploration leads to double voicing if aria-label duplicates the text content</li>
</ul>
</li>
<li>Firefox 51
<ul>
<li>breaks all the things (all it voices after rendering is 'busy')</li>
</ul>
</li>
</ul>
</li>
<li>original MathML
<ul>
<li>Safari 10, Firefox 50
<ul>
<li>ignores aria-labels (just provides VO MathML voicing)</li>
</ul>
</li>
<li>Chrome 54
<ul>
<li>content not exposed (bug in Chrome)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h6>Orca</h6>
<p>Orca 3.20, Ubuntu 16.10</p>
<ul>
<li>SVG
<ul>
<li>Firefox 51
<ul>
<li>reads only first label when reaching SVG</li>
<li>allows for exploration</li>
</ul>
</li>
</ul>
</li>
<li>HTML-CSS
<ul>
<li>Firefox 51
<ul>
<li>ignores aria-labels</li>
<li>reads Unicode content</li>
</ul>
</li>
</ul>
</li>
<li>MathML
<ul>
<li>Firefox 51
<ul>
<li>ignores aria-labels (just provides ORCA MathML voicing)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4>JAWS</h4>
<p>JAWS 17, Windows 7</p>
<ul>
<li>SVG
<ul>
<li>IE11
<ul>
<li>reads whole expression</li>
<li>allows exploration</li>
<li>reads content very poorly, e.g., &quot;derivative of x&quot; gobbled together as &quot;derivativeofks&quot;.</li>
</ul>
</li>
<li>Firefox 51</li>
</ul>
</li>
<li>HTML-CSS
<ul>
<li>IE 11
<ul>
<li>ignores aria-label content</li>
<li>reads Unicode content</li>
</ul>
</li>
<li>Firefox 51<br>
*</li>
</ul>
</li>
<li>MathML
<ul>
<li>IE11, Firefox 51
<ul>
<li>reads &quot;error describing element with math content&quot; on every expression</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4>ChromeVox</h4>
<p>ChromeVox v53</p>
<ul>
<li>SVG
<ul>
<li>Chrome 54
<ul>
<li>reads whole expression</li>
<li>does not allow exploration</li>
</ul>
</li>
</ul>
</li>
<li>HTML-CSS
<ul>
<li>Chrome 54
<ul>
<li>reads whole expression</li>
<li>allows exploration</li>
<li>reads content poorly, e.g., (&quot;x y&quot; as &quot;xi&quot;)</li>
<li>during exploration, just reads Unicode content (not labels)</li>
</ul>
</li>
</ul>
</li>
<li>MathML
<ul>
<li>Chrome 54
<ul>
<li>ignores aria-label (provides ChromeVox MathML voicing)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5>Recap</h5>
<p>As you can see, the results are mixed. For each combination of AT+browser+OS, there's some combination that works roughly as expected but that's about it. SVG seems a clear winner despite VO's reluctance; I need to explore<code>title</code>/<code>desc</code> a bit further (which has different support levels).</p>
<p>Still, I think the situation is already better than what MathML can give you today, in particular because the few significant issues are nothing particular to MathML or math, they're just annoying SVG or HTML accessibility issues, many of which can be easily fixed (as opposed to implementing good math support based on MathML). The fact that MathML accessiblity tools fail to support aria-labels is not surprising, of course, and a typical example of how MathML support (as little as it is) continues to fall further and further behind HTML and SVG. And that's a good thing.</p>
<p>Now some might see this &quot;fixed&quot; enrichment as a step back compared to MathJax's Accessibility Extensions (using speech-rule-engine on the client) because the extensions can provide numerous speech rules and verbosity settings as well as summary information. I would disagree. I've never been a fan of varying speech rules (just like I wouldn't be a fan of AT re-arranging a sentence). Also, speech rules mostly differ by newer ones being more refined than older ones.</p>
<p>Verbosity is simply a general accessibility problem and it should be dealt with in generality (as it already is, e.g., for punctuation). Summary information is a great problem but really a limitation of current web technology and something that's just as needed for infographics or data visualization as it is for mathematics. We do not need isolated solutions here either.</p>
<h3>What's next</h3>
<p>Simple: more testing.</p>
<p>On the one hand, testing more AT combinations and evaluating other approaches. On the other hand, creating more and complex samples.</p>
<p>Others on the MathOnWeb CG have tried different approaches and so we will also work on getting feedback from the accessibility community in general, in particular figuring out how improved standards might help us.</p>
<p>For me personally, the goal is to develop a strategy for next year's work at MathJax where we want the speech-rule-engine to add deep labels directly. I think that would solve the last major piece of the puzzle for math on the web in its current form. Then we can finally leave the legacy approaches with isolated standards and tools behind to focus on moving the web forward as a whole.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stationary preserving permutations are the identity on a club]]></title>
        <id>http://karagila.org/2017/stationary-preserving-permutations-are-the-identity-on-a-club/</id>
        <link href="http://karagila.org/2017/stationary-preserving-permutations-are-the-identity-on-a-club/">
        </link>
        <updated>2017-03-20T23:50:40Z</updated>
        <summary type="html"><![CDATA[<p>This is not something particularly interesting, I think. But it's a nice exercise in Fodor's lemma.</p>

<p><strong>Theorem.</strong> Suppose that \(\kappa\) is regular and uncountable, and \(\pi\colon\kappa\to\kappa\) is a bijection mapping stationary sets to stationary sets. Then there is a club \(C\subseteq\kappa\) such that \(\pi\restriction C=\operatorname{id}\). <a href="http://karagila.org/2017/stationary-preserving-permutations-are-the-identity-on-a-club/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[overlay journals]]></title>
        <id>https://www.peterkrautzberger.org/0191/</id>
        <link href="https://www.peterkrautzberger.org/0191/">
        </link>
        <updated>2017-03-16T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><small>Holy shit, it's been a long time since I wrote anything over here. Well, maybe get a few old notes out that won't ever turn into real drafts?</small></p>
<p>I was reminded of this old note <a href="https://twitter.com/jasonpriem/status/842099694281019392">yesterday</a>. This snippet goes back to JMM 2016 when I had coffee with Izabella Łaba. Of course, Izabella is one of my favorite <a href="https://www.peterkrautzberger.org/0191/">bloggers</a> (starting all the way back when procrastination made us launch <a href="https://mathblogging.org/">mathblogging.org</a> -- shout out to Felix, Fred, and Sam!) but she is also a kick-ass researcher who amongst the many great things she does happens to sit on the editorial board of the (then newly fandangled) arXiv overlay journal <a href="http://discreteanalysisjournal.com/">Discrete Analysis</a> otherwise known as &quot;that Tim Gowers journal thing&quot;.</p>
<p>Discrete Analysis is probably the most relevant arXiv overlay journal in mathematics (ok, I admit I didn't search around much for other noteworthy ones) and the gut reaction when it comes to arXiv overlay journals (and Discrete Analysis in particular) seems to be: &quot;What if it fails?&quot;. But like jumping in the Matrix, failure really wouldn't mean anything.</p>
<p>Instead, I've been wondering more about &quot;What if it succeeds?&quot;. Of course that's because I expect it to succeed but in either way I don't think people think a lot about that. Arguably, I'm not awfully qualified but then again anyone can go through <a href="https://scholarlykitchen.sspnet.org/2016/02/01/guest-post-kent-anderson-updated-96-things-publishers-do-2016-edition/">Kent Anderson's list of 96 things Publishers Do</a>. Most of these, I'm guessing, you don't care about as an arXiv overlay journal so perhaps <a href="http://cameronneylon.net/blog/polecon-of-oa-publishing-i-what-is-it-publishers-do-anyway/">Cameron Neylon's shorter list</a> is more on point. Ultimately, I think, it is simple: what does a journal need to succeed? High-quality papers.</p>
<p>Quality comes in many forms but basically there are two areas: scientific quality and production quality. Scientific quality includes, at least, attracting papers the community will approve of, attracting authors that impress the community, and an editorial board that can spot the former and attract the latter. Of course, those are not at all separate but papers make journals influential, journals make authors influential etc pp. (And no, merit does not come into play, don't be silly.) I can't really judge it (not being a research mathematician anymore, let alone a discrete analysis person) but the editorial board looks to be full of influential, high-profile people and the first paper was Terry Tao's solution to Erdős's discrepancy problem; so it seems likely that part will work.</p>
<p>Production quality includes, at least, typography, copy-editing, archiving, and marketing. Discrete Analaysis can probably make that work as well as they care because, as Gowers pointed out, they expect they won't have to. That might seem arrogant to anyone with even a bit of knowledge from the trenches of academic publishing, but I think they're probably right in expecting they won't have to. I admit that is in part speculation, but I would expect that a high profile math journal can probably expect both their authors to have spent more time on their manuscript (more pre-submission review from peers, more iterations from themselves as the result is &quot;big&quot; etc) and they can probably expect their editors to work harder (they actually give a damn about the paper they read b/c the result is interesting, they have themselves higher expectations thus provide more detailed reports, they have simply more experience and relevant skills etc). And marketing, well, it's that Gowers journal thing, remember?</p>
<p>So this all looks great. Got the goods, can compete.</p>
<p>Except there are a few things that I think are terrible flaws; in no way fatal flaws (quite possibly the opposite) but ones with negative side effects that worry me.</p>
<p>To start with, overlay journals do the silly extreme libertarian thing of pretending the infrastructure they use doesn't cost anything. Even if the costs of the current technology might be very small, overlay journals will have to stick to the cheapest available tech, ignoring (let alone helping) the transformation of scientific communication.</p>
<p>A more important problem is: can this scale? I don't think it can (not much anyway). Research quality obviously doesn't scale well -- if everyone is a top journal, nobody is. Regarding production quality in &quot;lesser&quot; journals, I don't think authors will invest much in their manuscripts and reviewers will be less likely to have the skills or invest extra time. It still might work if journals started to rely on a more iterative process where post-publication feedback leads to revisions. (I mean, traditionally published journal articles can be awful piles of unedited crap, why expect more from an overlay journal, amiright?) But on the one hand, the community would have to accept that, i.e., it would require a much more significant change in scientific culture, and on the other hand people would have to, well, read papers and give feedback -- where the average number of readers for a math research paper is probably less than 1. Seems unlikely. So we might get elite journals that can get away with this model commercially but anyone else is screwed; not a fan.</p>
<p>The third problem I see is more severe as it relates to the structure of scientific communities: who watches the watchers? <a href="https://www.peterkrautzberger.org/0118/#a-democratization-of-the-communities">Years ago</a> I wrote that my biggest problem with academic communities (and the greatest strength of its publishing system) lies in its power structure: the key to power lies with editorial boards which are predominantly  aristocratic. Society-driven journals actually have democratic oversight for their editorial boards (as mild as its effect might be) and even commercial publishers have shareholder oversight, as &quot;unscientific&quot; as their interest may be. But overlay journals have nobody watching them. You might argue the free market will take care of it but it might just be that <a href="http://cameronneylon.net/blog/the-goods-in-the-scholarly-marketplace/">journals are clubs</a> and that <a href="http://cameronneylon.net/blog/scholarly-communications-less-of-a-market-more-like-general-taxation/">scholarly communication is more like general taxation</a>.</p>
<p>And that combination worries me. The unique ability of elite overlay journals to succeed commercially (as in: providing a valuable product) combined with a lack of checks and balances might lead to an imbalance that cannot be corrected.</p>
<p>But what do I know. Maybe such journals will realize the risk associated with their success and take responsibility for their actions and their effect on the community at large. And then maye they will focus on innovation and on reproducibility of their model for average (&quot;mediocre&quot;) journals that the majority of researchers publish in. I've seen crazier things.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Got jobs?]]></title>
        <id>http://karagila.org/2017/got-jobs/</id>
        <link href="http://karagila.org/2017/got-jobs/">
        </link>
        <updated>2017-02-19T15:42:56Z</updated>
        <summary type="html"><![CDATA[<p>Good news! I'm about to finish my dissertation. Hopefully, come summer I will be Dr. Asaf Karagila.</p>

<p>So the next order of business is finding a position for next year. So far nothing came up. But I'm open to hearing from the few readers of my blog if they know about something, or have some offers that might be suitable for me. <a href="http://karagila.org/2017/got-jobs/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Registration for the 2017 SUnMaRC now open]]></title>
        <id>http://dcernst.github.io/sunmarc-2017-open/</id>
        <link href="http://dcernst.github.io/sunmarc-2017-open/">
        </link>
        <updated>2017-02-12T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><img src="/images/SUnMaRCLogoLarge.jpg" class="img-responsive img-rounded" width="100%" img="" style="margin-bottom: 10px" /></p>

<p>Registration for the <a href="https://naumathstat.github.io/sunmarc2017/">2017 Southwestern Undergraduate Mathematics Research Conference</a> (aka SUnMaRC) is now open!  <a href="http://nau.edu">Northern Arizona University</a> is hosting this year’s conference on March 31-April 2, 2017.  We are excited to announce Kathryn Bryant (Colorado College), <a href="http://www.segerman.org">Henry Segerman</a> (Oklahoma State University), and Steve Wilson (NAU, emeritus) as our <a href="https://naumathstat.github.io/sunmarc2017/speakers/">invited speakers</a>.</p>

<p>The goal of the conference is to welcome undergraduates to the wonderful world of mathematics research, to develop and foster a rich social network between the mathematics students and faculty throughout the great Southwest, and to celebrate the accomplishments of our undergraduate students. We encourage undergraduate students from all years of study to participate and give presentations in any area of mathematics, including applications to other disciplines.  However, while we do recommend giving a talk, it is not a requirement for conference participation. To register for the conference and to submit a title and abstract for a student presentation, visit the <a href="https://naumathstat.github.io/sunmarc2017/registration/">2017 SunMaRC Registration page</a>.</p>

<p>The conference began in 2004 as the Arizona Mathematics Undergraduate Conference.  In 2008, the conference changed to SUnMaRC to recognize the participation of institutions throughout the southwest.</p>

<p>If you have any questions about this year’s SUnMaRC, please contact one of the conference organizers:</p>

<ul>
  <li><a href="mailto:jeffrey.rushall@nau.edu">Jeff Rushall</a></li>
  <li><a href="mailto:dana.ernst@nau.edu">Dana Ernst</a></li>
  <li><a href="mailto:Nellie.Gopaul@nau.edu">Nellie Gopaul</a></li>
  <li><a href="mailto:Tiffany.Lenhart@nau.edu">Tiffany Lenhart</a></li>
</ul>]]></summary>
        <author>
            <name>Dana C. Ernst</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Farewell, Matti]]></title>
        <id>http://karagila.org/2017/farewell-matti/</id>
        <link href="http://karagila.org/2017/farewell-matti/">
        </link>
        <updated>2017-02-06T19:06:00Z</updated>
        <summary type="html"><![CDATA[<p>My mentor, teacher, mathematical confidant and generally good friend, Matti Rubin passed away this morning. Many of the readers here know him for his mathematical work, many knew him as a friend as well, or as a teacher.</p>

<p>Matti was a kind teacher, even if sometimes over-pedantic. <a href="http://karagila.org/2017/farewell-matti/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[My Mathematics Genealogy]]></title>
        <id>http://dcernst.github.io/my-mathematics-genealogy/</id>
        <link href="http://dcernst.github.io/my-mathematics-genealogy/">
        </link>
        <updated>2017-01-04T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>The mission of the <a href="https://www.genealogy.math.ndsu.nodak.edu/index.php">Mathematics Genealogy Project</a> (MGP) is to compile information about all  mathematicians, living and dead, to create family trees based on advisor-student relationships. The MGP database contains over 200,000 entries.  A complete entry for a mathematician in the database lists the mathematician’s name, year and title of their dissertation, graduating institution, list of their PhD students, and their PhD advisor(s).  Occasionally, some of this information is missing.  You can find my record <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=125763">here</a>. Since finishing my PhD in 2008, I’ve poked around the MGP and always thought it would be cool to <a href="https://www.genealogy.math.ndsu.nodak.edu/posters.php">get a poster made</a> that displays my mathematical genealogy, but I just haven’t gotten around to it.</p>

<p>One of my former students, Andrew Lebovitz, recently posted a link on Facebook to a <a href="http://www.nature.com/news/majority-of-mathematicians-hail-from-just-24-scientific-families-1.20491#/b1">Nature article</a> that summarizes a paper, titled <a href="http://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-016-0088-y">The classical origin of modern mathematics</a>, which completed a comprehensive analysis of the MGP database.  One of the interesting findings was that the individuals in the database fall into 84 distinct family trees with two-thirds of the world’s mathematicians concentrated in just 24 of them.</p>

<p>After reading the Nature article, I was motivated to see if I could figure out whether I belonged to one of the 24 families. It wasn’t obvious to me how I would do this without manually clicking on my advisor (<a href="https://math.colorado.edu/~rmg/">Richard M. Green</a>), then my advisor’s advisor, etc. This was slightly more complicated than I expected because there were quite a few ancestors with 2 advisors, so I had to navigate down multiple paths.   As I clicked around, I drew out my family tree in a notebook.</p>

<p>Here is what I discovered.  My longest branch goes back to <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=136514">Nicolo Fontana Tartaglia</a> (currently 14,428 descendants).  My tree includes <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=74313">Isaac Newton</a>, <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=134975">Galileo Galilei</a>, and <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=125434">Marin Mersenne</a> (who <a href="https://en.wikipedia.org/wiki/Mersenne_prime">Mersenne primes</a> were named after). Interestingly, no one on this path belongs to one of the 24 families mentioned in <a href="http://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-016-0088-y">The classical origin of modern mathematics</a>.  Also, I was disappointed to find out that I wasn’t related to <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=38586">Leonhard Euler</a>. However, I am a descendant of <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=129422">Henry Bracken</a>, who is the head of one of the 24 families.</p>

<p>I posted some of this information on Facebook and asked if anyone knew how to automatically create a nice visualization of the directed graph corresponding to my family tree. <a href="https://math.depaul.edu/cdrupies/">Chris Drupieski</a> replied and pointed out a program called <a href="http://www.davidalber.net/geneagrapher/">Geneagrapher</a>, which was built to do exactly what I was looking for. In particular, Geneagrapher gathers information for building math genealogy trees from the MGP, which is then stored in dot file format. This data can then be passed to <a href="http://www.graphviz.org">Graphviz</a> to generate a directed graph.</p>

<p>Here are the steps that I completed to get Geneagrapher up and running on my computer running MacOS 10.11.  The Geneagrapher website suggests using <code>easy_install</code> via Terminal, but this didn’t immediately work for me.  It often seems that doing anything with Python on my Mac requires a few extra steps.  After doing a little searching around, I found a <a href="http://stackoverflow.com/questions/6012246/why-is-python-easy-install-not-working-on-my-mac">post on Stack Overflow</a> that solved my issue.  At the command line, I typed the following:</p>

<pre><code>sudo chown -R &lt;your_user&gt;:wheel /Library/Python/2.7/site-packages/</code></pre>

<p>Of course, you should replace <code>&lt;your_user&gt;</code> with your username.  Note that using <code>sudo</code> requires you to enter your password.  Next, I installed Geneagrapher using the following:</p>

<pre><code>easy_install http://www.davidalber.net/dist/geneagrapher/Geneagrapher-0.2.1-r2.tar.gz</code></pre>

<p>In order to use Geneagrapher, you need to input a record number from MGP.  Mine is 125763.  At the command line, I typed:</p>

<pre><code>ggrapher -f ernst.dot -a 125763</code></pre>

<p>You can replace <code>ernst</code> with whatever you’d like the output file to be called. The next step is to pass the dot file to Graphviz.  If you don’t already have Graphviz installed, you can do so using <a href="http://brew.sh">Homebrew</a> (which is also easy to install):</p>

<pre><code>brew install graphviz</code></pre>

<p>Following the Geneagrapher instructions, I typed the following to generate my family tree:</p>

<pre><code>dot -Tpng ernst.dot &gt; ernst.png</code></pre>

<p>Maybe it is worth mentioning that unless you specify otherwise, the dot and png files will be stored in your home directory.  Below is my mathematical family tree created using Geneagrapher. As you can see, it took a while for my ancestors to leave the <a href="https://www.cam.ac.uk">University of Cambridge</a>.</p>

<p><img src="/images/FamilyTree.png" class="img-responsive" width="100%" img="" style="margin-bottom: 10px" /></p>]]></summary>
        <author>
            <name>Dana C. Ernst</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Applying teaching skills to business]]></title>
        <id>http://normanspace.org/2016/12/28/applying-teaching-skills-to-business/</id>
        <link href="http://normanspace.org/2016/12/28/applying-teaching-skills-to-business/">
        </link>
        <updated>2016-12-29T00:10:22Z</updated>
        <summary type="html"><![CDATA[<p>I&#8217;ve really been happy to see how much my teaching skills have transferred to a business context. Employees are in some ways a lot like students. You need to teach them certain skills, motivate them to practice the things you teach them, and ideally, help them learn to be self-sufficient and improve themselves. When we have a new policy that we want to implement it, simply recognizing the implementation as a teaching-related challenge is a big step already. Then I try to use my teaching skills that I learned at LaGuardia and elsewhere to train employees, and even to help some employees learn how to train other employees.</p>]]></summary>
        <author>
            <name>Norman Lewis Perlmutter</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mathematical philosophy on YouTube!]]></title>
        <id>http://karagila.org/2016/mathematical-philosophy-on-youtube/</id>
        <link href="http://karagila.org/2016/mathematical-philosophy-on-youtube/">
        </link>
        <updated>2016-12-23T10:07:05Z</updated>
        <summary type="html"><![CDATA[<p>If you follow my blog, you probably know that I am a big fan of Michael Stevens from the VSauce channel, who in the recent year or so released several very good videos about mathematics, and about infinity in particular. Not being a trained mathematician, Michael is doing an incredible task.</p>

<p>Non-mathematicians often tend to be Platonists &quot;by default&quot;, so they will assume that every question has an answer and sometimes it's just that we don't know that answer. But it's out there. It's a fine approach, but it can somewhat fly in the face of independence if you are not trained to think about the difference between true and provable. <a href="http://karagila.org/2016/mathematical-philosophy-on-youtube/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dual Ramsey, an introduction – Ramsey DocCourse Prague 2016]]></title>
        <id>https://mikepawliuk.ca/2016/12/12/dual-ramsey-an-introduction-ramsey-doccourse-prague-2016/</id>
        <link href="https://mikepawliuk.ca/2016/12/12/dual-ramsey-an-introduction-ramsey-doccourse-prague-2016/">
        </link>
        <updated>2016-12-13T00:02:28Z</updated>
        <summary type="html"><![CDATA[<p>The following notes are from the <a href="http://iuuk.mff.cuni.cz/events/doccourse/">Ramsey DocCourse in Prague 2016</a>. The notes are taken by me and I have edited them. In the process I may have introduced some errors; email me or comment below and I will happily fix them.</p>
<div class="summary">
<p style="padding-left:30px;"><strong>Title</strong>: Dual Ramsey, the Gurarij space and the Poulsen simplex 1 (of 3).</p>
<p style="padding-left:30px;"><strong>Lecturer</strong>: Dana Bartošová.</p>
<p style="padding-left:30px;"><strong>Date</strong>:  December 12, 2016.</p>
<p style="padding-left:30px;"><strong>Main Topics</strong>: Comparison of various Fraïssé settings, metric Fraïssé definitions and properties, KPT of metric structures, Thick sets </p>
<p style="padding-left:30px;"><strong>Definitions:</strong> continuous logic, metric Fraïssé properties, NAP (near amalgamation property), PP (Polish Property), ARP (Approximate Ramsey Property), Thick, Thick partition regular. </p>
</div>
<p>Lecture 1 &#8211; Lecture 2 &#8211; Lecture 3</p>
<p><a href="http://boolesrings.org/mpawliuk/ramsey-doccourse-2016/">Ramsey DocCourse Prague 2016 Index of lectures.</a></p>
<p><span id="more-1516"></span></p>
<hr />
<h2>Introduction</h2>
<p>Throughout the DocCourse we have primarily focused on Fraïssé limits of finite structures. As we saw in Solecki&#8217;s first lecture (not posted yet), it makes sense, and is useful, to consider Fraïssé limits in a broader context. Today we will discuss those other contexts.</p>
<p>Solecki&#8217;s first lecture discussed how to take <em>projective</em> Fraïssé limits. Panagiotopolous&#8217; lecture (not posted yet) looked at a specific application of these projective limits. We will see how to take <em>metric</em> (direct) Fraïssé limits.</p>
<h2>Overview</h2>
<table class="tg">
<tr>
<th class="tg-9hbo"></th>
<th class="tg-e3zv">Discrete</th>
<th class="tg-e3zv">Compact</th>
<th class="tg-e3zv">Metric Structure</th>
</tr>
<tr>
<td class="tg-9hbo">Size</td>
<td class="tg-031e">Countable</td>
<td class="tg-031e">Separable</td>
<td class="tg-031e">Separable, complete</td>
</tr>
<tr>
<td class="tg-9hbo">Limit</td>
<td class="tg-031e">Fraïssé limit</td>
<td class="tg-031e">Quotient of the projective limit</td>
<td class="tg-031e">(direct or projective) Metric Fraïssé limit</td>
</tr>
<tr>
<td class="tg-9hbo">Homogeneity</td>
<td class="tg-031e">(ultra)homogeneity</td>
<td class="tg-031e">Projective approximate homogeneity</td>
<td class="tg-031e">Approximate homogeneity (*)</td>
</tr>
<tr>
<td class="tg-9hbo">Automorphism group</td>
<td class="tg-031e">non-archimedian groups (closed subgroups of <img src="https://s0.wp.com/latex.php?latex=S%5E%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="S^&#92;infty " title="S^&#92;infty " class="latex" /></td>
<td class="tg-031e">homeomorphism groups</td>
<td class="tg-031e">Polish Groups</td>
</tr>
<tr>
<td class="tg-9hbo">KPT, extremely amenable iff</td>
<td class="tg-yw4l">RP</td>
<td class="tg-yw4l">Dual Ramsey</td>
<td class="tg-yw4l">Approximate RP (**)</td>
</tr>
<tr>
<td class="tg-9hbo">Metrizability of UMF iff</td>
<td class="tg-yw4l">finite Ramsey degree</td>
<td class="tg-yw4l">(***)</td>
<td class="tg-yw4l">(Open) Compact RP?</td>
</tr>
<tr>
<td class="tg-9hbo">Where we&#8217;ve seen these</td>
<td class="tg-yw4l">Classical</td>
<td class="tg-yw4l">Solecki&#8217;s lectures</td>
<td class="tg-yw4l">These lectures</td>
</tr>
</table>
<p>(*) &#8211; Exact homogeneity is often not possible.<br />
(**) &#8211; In the projective setting this is fairly unexplored. These proofs are usually via direct (discrete) Ramsey, or through concentration of measure.<br />
(***) &#8211; You have KPT before you take the quotient, but lose it after taking the quotient. e.g. UMF(pre-pseudo arc) is not metrizable (through RP). A question of Uspenskij asks about the UMF(pseudo arc).</p>
<h2>Continuous Logic definitions</h2>
<p>In the context of Banach spaces, it makes sense to use continuous logic. This is where we instead of the usual <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;{0,1&#92;} " title="&#92;{0,1&#92;} " class="latex" />-valued logic we allow sentences to take on values in the interval <img src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="[0,1] " title="[0,1] " class="latex" />. We also suitably adjust the logical constructives.</p>
<table class="tg">
<tr>
<th class="tg-e3zv">Classical logic</th>
<th class="tg-e3zv">Continuous logic</th>
</tr>
<tr>
<td class="tg-031e">True</td>
<td class="tg-031e">0</td>
</tr>
<tr>
<td class="tg-031e">False</td>
<td class="tg-031e">1</td>
</tr>
<tr>
<td class="tg-yw4l"><img src="https://s0.wp.com/latex.php?latex=%3D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="= " title="= " class="latex" /></td>
<td class="tg-yw4l"><img src="https://s0.wp.com/latex.php?latex=d+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="d " title="d " class="latex" /></td>
</tr>
<tr>
<td class="tg-031e"><img src="https://s0.wp.com/latex.php?latex=x+%5Cvee+y+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x &#92;vee y " title="x &#92;vee y " class="latex" /></td>
<td class="tg-031e"><img src="https://s0.wp.com/latex.php?latex=%5Cmin%5C%7Bx%2Cy%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;min&#92;{x,y&#92;} " title="&#92;min&#92;{x,y&#92;} " class="latex" /></td>
</tr>
<tr>
<td class="tg-031e"><img src="https://s0.wp.com/latex.php?latex=x+%5Cwedge+y+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x &#92;wedge y " title="x &#92;wedge y " class="latex" /></td>
<td class="tg-031e"><img src="https://s0.wp.com/latex.php?latex=%5Cmax%5C%7Bx%2Cy%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;max&#92;{x,y&#92;} " title="&#92;max&#92;{x,y&#92;} " class="latex" /></td>
</tr>
<tr>
<td class="tg-031e"><img src="https://s0.wp.com/latex.php?latex=%5Cneg+x+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;neg x " title="&#92;neg x " class="latex" /></td>
<td class="tg-031e"><img src="https://s0.wp.com/latex.php?latex=1-x+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="1-x " title="1-x " class="latex" /></td>
</tr>
<tr>
<td class="tg-031e"><img src="https://s0.wp.com/latex.php?latex=x+%5CRightarrow+y+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x &#92;Rightarrow y " title="x &#92;Rightarrow y " class="latex" /></td>
<td class="tg-031e"><img src="https://s0.wp.com/latex.php?latex=%28x-y%29+%5Cvee+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(x-y) &#92;vee 0 " title="(x-y) &#92;vee 0 " class="latex" /></td>
</tr>
<tr>
<td class="tg-yw4l"><img src="https://s0.wp.com/latex.php?latex=%5Cforall+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;forall " title="&#92;forall " class="latex" /></td>
<td class="tg-yw4l"><img src="https://s0.wp.com/latex.php?latex=%5Csup+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;sup " title="&#92;sup " class="latex" /></td>
</tr>
<tr>
<td class="tg-yw4l"><img src="https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;exists " title="&#92;exists " class="latex" /></td>
<td class="tg-yw4l"><img src="https://s0.wp.com/latex.php?latex=%5Cinf+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;inf " title="&#92;inf " class="latex" /></td>
</tr>
</table>
<p>Now we define functions and relations. Let <img src="https://s0.wp.com/latex.php?latex=%28A%2Cd%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(A,d) " title="(A,d) " class="latex" /> be a complete metric space. So <img src="https://s0.wp.com/latex.php?latex=%28A%5En%2C+d%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(A^n, d) " title="(A^n, d) " class="latex" /> will be given the sup metric.</p>
<ul>
<li><img src="https://s0.wp.com/latex.php?latex=F%3A+A%5En+%5Crightarrow+A+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="F: A^n &#92;rightarrow A " title="F: A^n &#92;rightarrow A " class="latex" /> comes with a Lipschitz constant.</li>
<li><img src="https://s0.wp.com/latex.php?latex=R%3A+A%5En+%5Crightarrow+%5B0%2C1%5D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="R: A^n &#92;rightarrow [0,1] " title="R: A^n &#92;rightarrow [0,1] " class="latex" /> comes with a Lipschitz constant.</li>
</ul>
<p>Then functions and relations must satisfy the usual things that functions and relations satisfy in classical logic.</p>
<h3>Examples</h3>
<table class="tg">
<tr>
<th class="tg-031e"></th>
<th class="tg-e3zv">Finitely generated substructures</th>
<th class="tg-9hbo">Limit</th>
<th class="tg-9hbo">maps</th>
<th class="tg-9hbo">Language</th>
</tr>
<tr>
<td class="tg-e3zv">Separable metric spaces</td>
<td class="tg-031e">finite metric spaces</td>
<td class="tg-yw4l">Separable Urysohn space</td>
<td class="tg-yw4l">isometric embedding</td>
<td class="tg-yw4l">just the distance</td>
</tr>
<tr>
<td class="tg-e3zv">Separable Banach spaces</td>
<td class="tg-031e">finite dimensional Banach spaces (**)</td>
<td class="tg-yw4l">Gurarij space</td>
<td class="tg-yw4l">isometric linear embedding</td>
<td class="tg-yw4l"><img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%7C+%5Ccdot+%7C%7C%2C+%2B%2C+%28%5Ccdot+%5Clambda%29_%7B%5Clambda+%5Cin+%5Cmathbb%7BQ%7D%7D%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;{|| &#92;cdot ||, +, (&#92;cdot &#92;lambda)_{&#92;lambda &#92;in &#92;mathbb{Q}}&#92;} " title="&#92;{|| &#92;cdot ||, +, (&#92;cdot &#92;lambda)_{&#92;lambda &#92;in &#92;mathbb{Q}}&#92;} " class="latex" /></td>
</tr>
<tr>
<td class="tg-e3zv">Separable Choquet spaces</td>
<td class="tg-031e">finite dimensional simplices</td>
<td class="tg-yw4l">Poulsen simplex</td>
<td class="tg-yw4l">affine homeomorphisms (*)</td>
<td class="tg-yw4l">Something that captures the convex structure</td>
</tr>
</table>
<p>(*) &#8211; An affine homeomorphism sends <img src="https://s0.wp.com/latex.php?latex=S_0+%5Crightarrow+S_1+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="S_0 &#92;rightarrow S_1 " title="S_0 &#92;rightarrow S_1 " class="latex" /> and sends extreme points to extreme points, then is extended affinely to the rest of the simplex. The metric here is not canonical.<br />
(**) &#8211; Similar to the discrete case, to take a limit you only need a cofinal sequence. In this case we take <img src="https://s0.wp.com/latex.php?latex=%5Cell%5En_%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;ell^n_&#92;infty " title="&#92;ell^n_&#92;infty " class="latex" />.</p>
<h3>Morphisms between models</h3>
<p>In continuous logic the maps between models are isometric embeddings that preserves functions and relations.</p>
<h2>Properties of the finitely generated substructures</h2>
<p>In the classical Fraïssé setting we looked at homogeneity, HP, JEP and AP. These notions have suitable generalizations in the metric Fraïssé setting.</p>
<div class="defn"><strong>Definition</strong>. Let <img src="https://s0.wp.com/latex.php?latex=%28A%2Cd%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(A,d) " title="(A,d) " class="latex" /> be a metric structure. We describe finitely generated substructures in <img src="https://s0.wp.com/latex.php?latex=%28A%2Cd%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(A,d) " title="(A,d) " class="latex" /> by <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cvec%7Ba%7D+%5Crangle+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;langle &#92;vec{a} &#92;rangle " title="&#92;langle &#92;vec{a} &#92;rangle " class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=%5Cvec%7Ba%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;vec{a} " title="&#92;vec{a} " class="latex" /> is an <img src="https://s0.wp.com/latex.php?latex=n+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="n " title="n " class="latex" />-tuple in <img src="https://s0.wp.com/latex.php?latex=A+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="A " title="A " class="latex" />.</p>
<p>We say that <img src="https://s0.wp.com/latex.php?latex=%28A%2Cd%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(A,d) " title="(A,d) " class="latex" /> is <strong>approximately ultrahomogeneous (AUH)</strong> if <img src="https://s0.wp.com/latex.php?latex=%5Cforall+%5Cvec%7Ba%7D+%5Cin+A%5En%2C+%28%5Cforall+n%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;forall &#92;vec{a} &#92;in A^n, (&#92;forall n) " title="&#92;forall &#92;vec{a} &#92;in A^n, (&#92;forall n) " class="latex" /> and for every <img src="https://s0.wp.com/latex.php?latex=%5Cphi%3A+%5Clangle+%5Cvec%7Ba%7D+%5Crangle+%5Crightarrow+A+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;phi: &#92;langle &#92;vec{a} &#92;rangle &#92;rightarrow A " title="&#92;phi: &#92;langle &#92;vec{a} &#92;rangle &#92;rightarrow A " class="latex" /> morphism, and for all <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;epsilon &gt;0 " title="&#92;epsilon &gt;0 " class="latex" />, there is a <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cphi%7D+%5Cin+%5Ctext%7BAut%7D%28A%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;hat{&#92;phi} &#92;in &#92;text{Aut}(A) " title="&#92;hat{&#92;phi} &#92;in &#92;text{Aut}(A) " class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=d%28%5Cphi%28%5Cvec%7Ba%7D%29%2C+%5Chat%7B%5Cphi%7D%28%5Cvec%7Ba%7D%29%29%3C%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="d(&#92;phi(&#92;vec{a}), &#92;hat{&#92;phi}(&#92;vec{a}))&lt;&#92;epsilon " title="d(&#92;phi(&#92;vec{a}), &#92;hat{&#92;phi}(&#92;vec{a}))&lt;&#92;epsilon " class="latex" />.</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BAge%7D%28A%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Age}(A) " title="&#92;text{Age}(A) " class="latex" /> is the collection of finitely generated substructures of <img src="https://s0.wp.com/latex.php?latex=A+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="A " title="A " class="latex" />.
</div>
<div class="thm"><strong>Lemma</strong>. If <img src="https://s0.wp.com/latex.php?latex=A+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="A " title="A " class="latex" /> is AUH and separable, then <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BAge%7D%28A%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Age}(A) " title="&#92;text{Age}(A) " class="latex" /> has</p>
<ul>
<li>HP,</li>
<li>JEP,</li>
<li>NAP (the Near Amalgamation Property),</li>
<li>PP (the Polish Property, an analogue of countability).</li>
</ul>
</div>
<p>We now explain NAP and PP. The NAP is a striaghtforward generalization of AP.</p>
<div class="defn"><strong>Definition</strong>. Let <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BK%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;mathcal{K} " title="&#92;mathcal{K} " class="latex" /> be a collection of finitely generated metric structures. We say that <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BK%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;mathcal{K} " title="&#92;mathcal{K} " class="latex" /> satisfies <strong>NAP</strong> if when <img src="https://s0.wp.com/latex.php?latex=f_i+%3A+A+%5Crightarrow+B_i+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="f_i : A &#92;rightarrow B_i " title="f_i : A &#92;rightarrow B_i " class="latex" /> are embeddings, then</p>
<p> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+%5Cepsilon+%3E+0%2C+%5Cforall+%5Cvec%7Ba%7D+%5Cin+A%5En%2C+%28%5Cforall+n%29%2C+%5Cexists+C+%5Cin+%5Cmathcal%7BK%7D%2C+%5Cexists+g_i+%3A+B_i+%5Crightarrow+C++&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle  &#92;forall &#92;epsilon &gt; 0, &#92;forall &#92;vec{a} &#92;in A^n, (&#92;forall n), &#92;exists C &#92;in &#92;mathcal{K}, &#92;exists g_i : B_i &#92;rightarrow C  " title="&#92;displaystyle  &#92;forall &#92;epsilon &gt; 0, &#92;forall &#92;vec{a} &#92;in A^n, (&#92;forall n), &#92;exists C &#92;in &#92;mathcal{K}, &#92;exists g_i : B_i &#92;rightarrow C  " class="latex" /> <br />
such that<br />
<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d_C+%28g_1+f_1+%28%5Cvec%7Ba%7D%29%2C+g_2+f_2+%28%5Cvec%7Ba%7D%29+%3C+%5Cepsilon.++&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle  d_C (g_1 f_1 (&#92;vec{a}), g_2 f_2 (&#92;vec{a}) &lt; &#92;epsilon.  " title="&#92;displaystyle  d_C (g_1 f_1 (&#92;vec{a}), g_2 f_2 (&#92;vec{a}) &lt; &#92;epsilon.  " class="latex" /> 
</div>
<p>The PP measures how closely you can embed two metric spaces.</p>
<div class="defn"><strong>Definition</strong>. Let <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BK%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;mathcal{K} " title="&#92;mathcal{K} " class="latex" /> be a collection of finitely generated metric structures with JEP. Define <img src="https://s0.wp.com/latex.php?latex=K_n+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="K_n " title="K_n " class="latex" /> to be all pairs <img src="https://s0.wp.com/latex.php?latex=%28%5Cvec%7Ba%7D%2C+A%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(&#92;vec{a}, A) " title="(&#92;vec{a}, A) " class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%5Cvec%7Ba%7D+%5Cin+A%5En+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;vec{a} &#92;in A^n " title="&#92;vec{a} &#92;in A^n " class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cvec%7Ba%7D%5Crangle+%3D+A+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;langle &#92;vec{a}&#92;rangle = A " title="&#92;langle &#92;vec{a}&#92;rangle = A " class="latex" />. Define <img src="https://s0.wp.com/latex.php?latex=d_n+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="d_n " title="d_n " class="latex" />, a pseudometric on <img src="https://s0.wp.com/latex.php?latex=K_n+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="K_n " title="K_n " class="latex" /> by<br />
<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d_n%28%28%5Cvec%7Ba%7D%2C+A%29%2C+%28%5Cvec%7Bb%7D%2C+B%29%29+%3A%3D+%5Cinf%5C%7Bd_c%28f%28%5Cvec%7Ba%7D%2C+g%28%5Cvec%7Bb%7D%29%29%5C%7D%2C++&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle  d_n((&#92;vec{a}, A), (&#92;vec{b}, B)) := &#92;inf&#92;{d_c(f(&#92;vec{a}, g(&#92;vec{b}))&#92;},  " title="&#92;displaystyle  d_n((&#92;vec{a}, A), (&#92;vec{b}, B)) := &#92;inf&#92;{d_c(f(&#92;vec{a}, g(&#92;vec{b}))&#92;},  " class="latex" /> <br />
where this is taken over al <img src="https://s0.wp.com/latex.php?latex=C+%5Cin+%5Cmathcal%7BK%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="C &#92;in &#92;mathcal{K} " title="C &#92;in &#92;mathcal{K} " class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=A%2CB+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="A,B " title="A,B " class="latex" /> embed in <img src="https://s0.wp.com/latex.php?latex=C+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="C " title="C " class="latex" />, and all embeddings <img src="https://s0.wp.com/latex.php?latex=f%3A+A+%5Crightarrow+C+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="f: A &#92;rightarrow C " title="f: A &#92;rightarrow C " class="latex" />, <img src="https://s0.wp.com/latex.php?latex=g%3A+B+%5Crightarrow+C+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="g: B &#92;rightarrow C " title="g: B &#92;rightarrow C " class="latex" />.</p>
<p>We say <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BK%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;mathcal{K} " title="&#92;mathcal{K} " class="latex" /> satisfies the <strong>Polish Property (PP)</strong> if <img src="https://s0.wp.com/latex.php?latex=%28K_n%2C+d_n%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(K_n, d_n) " title="(K_n, d_n) " class="latex" /> is separable for all <img src="https://s0.wp.com/latex.php?latex=n+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="n " title="n " class="latex" />.
</div>
<p>This gives us the following Fraïssé theorem for metric structures.</p>
<div class="thm"><strong>Theorem (K. Schonetsonitis, I. BenYaacov)</strong>. Let <img src="https://s0.wp.com/latex.php?latex=A+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="A " title="A " class="latex" /> be a Polish structure. TFAE</p>
<ol>
<li><img src="https://s0.wp.com/latex.php?latex=A+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="A " title="A " class="latex" /> is AUH.</li>
<li><img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BAge%7D%28A%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Age}(A) " title="&#92;text{Age}(A) " class="latex" /> satisfies HP, JEP, NAP and PP.</li>
</ol>
</div>
<h2>The Urysohn space</h2>
<p>Recall that <img src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb%7BU%7D%2C+d%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(&#92;mathbb{U}, d) " title="(&#92;mathbb{U}, d) " class="latex" /> is the separable Urysohn space. It is the (unique) complete, separable metric space, universal for separable metric spaces and (exactly) ultrahomogeneous with respect to finite metric spaces.</p>
<p>Its age is the collection of finite metric spaces. It is a metric Fraïssé class.</p>
<p>Its automorphism group has a similar universal property.</p>
<div class="thm"><strong>Theorem (Uspenskij)</strong>. <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BIso%7D%28%5Cmathbb%7BU%7D%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Iso}(&#92;mathbb{U}) " title="&#92;text{Iso}(&#92;mathbb{U}) " class="latex" /> is universal with respect to second countable topological groups.
</div>
<p><a href="http://boolesrings.org/mpawliuk/2012/03/06/facts-about-the-urysohn-space-some-useful-some-cool/">See these notes</a> for more information.</p>
<h2>Automorphism groups</h2>
<p>Recall the following fact about (classical) Fraïssé structures.</p>
<div class="thm"><strong>Theorem</strong>. Every  closed subgroup of <img src="https://s0.wp.com/latex.php?latex=S%5E%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="S^&#92;infty " title="S^&#92;infty " class="latex" /> can be represented as the automorphism group of a classical Fraïssé structure.
</div>
<p>The following observation of Melleray is the corresponding fact for metric structures. It has a similar proof to the classical fact.</p>
<div class="thm"><strong>Theorem(Melleray)</strong>. Every Polish group <img src="https://s0.wp.com/latex.php?latex=G+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="G " title="G " class="latex" /> can be represented as an automorphism group of an AUH relational Polish structure.
</div>
<div class="proof"><strong>Proof</strong>. By a theorem of Uspenskij, <img src="https://s0.wp.com/latex.php?latex=G+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="G " title="G " class="latex" /> is a closed subgroup of <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BIso%7D%28%5Cmathbb%7BU%7D%2C+d%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Iso}(&#92;mathbb{U}, d) " title="&#92;text{Iso}(&#92;mathbb{U}, d) " class="latex" />. <img src="https://s0.wp.com/latex.php?latex=G+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="G " title="G " class="latex" /> acts on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BU%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;mathbb{U} " title="&#92;mathbb{U} " class="latex" /> by isometries, so for all <img src="https://s0.wp.com/latex.php?latex=n+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="n " title="n " class="latex" />, <img src="https://s0.wp.com/latex.php?latex=G+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="G " title="G " class="latex" /> acts on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BU%7D%5En+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;mathbb{U}^n " title="&#92;mathbb{U}^n " class="latex" /> by the diagonal action.</p>
<p>For every orbit closure in <img src="https://s0.wp.com/latex.php?latex=G+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="G " title="G " class="latex" /> of a point <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5Cmathbb%7BU%7D%5En+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x &#92;in &#92;mathbb{U}^n " title="x &#92;in &#92;mathbb{U}^n " class="latex" /> add a relational symbol <img src="https://s0.wp.com/latex.php?latex=C+%3D+%5Coverline%7BG+%5Ccdot+c%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="C = &#92;overline{G &#92;cdot c} " title="C = &#92;overline{G &#92;cdot c} " class="latex" /> called <img src="https://s0.wp.com/latex.php?latex=R_C+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="R_C " title="R_C " class="latex" />.
</div>
<h2>Extreme amenability</h2>
<p>The first relevant result is the following:</p>
<div class="thm"><strong>Theorem (Pestov 2002)</strong>. <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BIso%7D%28%5Cmathbb%7BU%7D%2C+d%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Iso}(&#92;mathbb{U}, d) " title="&#92;text{Iso}(&#92;mathbb{U}, d) " class="latex" /> is extremely amenable.
</div>
<p>This proof uses the finite Ramsey theorem and concentration of measure.</p>
<div class="thm"><strong>Theorem (KPT 2005)</strong>. <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BIso%7D%28%5Cmathbb%7BU%7D_%5Cmathbb%7BQ%7D%2C+d%2C+%5Cleq%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Iso}(&#92;mathbb{U}_&#92;mathbb{Q}, d, &#92;leq) " title="&#92;text{Iso}(&#92;mathbb{U}_&#92;mathbb{Q}, d, &#92;leq) " class="latex" /> is extremely amenable and <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BIso%7D%28%5Cmathbb%7BU%7D%2C+d%29+%3D+%5Coverline%7B%5Ctext%7BIso%7D%28%5Cmathbb%7BU%7D_%5Cmathbb%7BQ%7D%2C+d%29%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Iso}(&#92;mathbb{U}, d) = &#92;overline{&#92;text{Iso}(&#92;mathbb{U}_&#92;mathbb{Q}, d)} " title="&#92;text{Iso}(&#92;mathbb{U}, d) = &#92;overline{&#92;text{Iso}(&#92;mathbb{U}_&#92;mathbb{Q}, d)} " class="latex" />.
</div>
<p>The KPT theorem for metric structures is given by the following.</p>
<div class="thm"><strong>Theorem (Melleray, Tsankov)</strong>. Let <img src="https://s0.wp.com/latex.php?latex=A+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="A " title="A " class="latex" /> be AUH. TFAE:</p>
<ol>
<li><img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BAut%7D%28A%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Aut}(A) " title="&#92;text{Aut}(A) " class="latex" /> is extremely amenable.</li>
<li><img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BAge%7D%28A%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Age}(A) " title="&#92;text{Age}(A) " class="latex" /> satisfies ARP.</li>
</ol>
</div>
<p>We define the approximate Ramsey Property.</p>
<div class="defn"><strong>Definition</strong>. Let <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BK%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;mathcal{K} " title="&#92;mathcal{K} " class="latex" /> be a collection of finitely generated metric structures. For <img src="https://s0.wp.com/latex.php?latex=A%2CB+%5Cin+%5Cmathcal%7BK%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="A,B &#92;in &#92;mathcal{K} " title="A,B &#92;in &#92;mathcal{K} " class="latex" />, <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BEmb%7D%28A%2CB%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Emb}(A,B) " title="&#92;text{Emb}(A,B) " class="latex" /> is the collection of all morphisms from <img src="https://s0.wp.com/latex.php?latex=A+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="A " title="A " class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=B+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="B " title="B " class="latex" />. There is a suitable distance between embeddings which we will not define here (in the special case of Banach spaces it is the operator norm).</p>
<p>(<strong>ARP</strong>):<br />
<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+A%2CB+%5Cin+%5Cmathcal%7BK%7D%2C+%5Cforall+r+%5Cgeq+2%2C+%5Cforall+%5Cepsilon+%3E0%2C+%5Cforall+F+%5Cin+%5B%5Ctext%7BEmb%7D%28A%2CB%29%5D%5E%7B%3C%5Comega%7D%2C++&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle  &#92;forall A,B &#92;in &#92;mathcal{K}, &#92;forall r &#92;geq 2, &#92;forall &#92;epsilon &gt;0, &#92;forall F &#92;in [&#92;text{Emb}(A,B)]^{&lt;&#92;omega},  " title="&#92;displaystyle  &#92;forall A,B &#92;in &#92;mathcal{K}, &#92;forall r &#92;geq 2, &#92;forall &#92;epsilon &gt;0, &#92;forall F &#92;in [&#92;text{Emb}(A,B)]^{&lt;&#92;omega},  " class="latex" /> <br />
there is a <img src="https://s0.wp.com/latex.php?latex=C+%5Cin+%5Cmathcal%7BK%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="C &#92;in &#92;mathcal{K} " title="C &#92;in &#92;mathcal{K} " class="latex" /> such that<br />
<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+c%3A+%5Ctext%7BEmb%7D%28A%2CC%29+%5Crightarrow+%5Br%5D%2C+%5Cexists+%5Cphi+%5Cin+%5Ctext%7BEmb%7D%28B%2CC%29%2C+%5Cexists+i+%5Cin+%5Br%5D++&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle  &#92;forall c: &#92;text{Emb}(A,C) &#92;rightarrow [r], &#92;exists &#92;phi &#92;in &#92;text{Emb}(B,C), &#92;exists i &#92;in [r]  " title="&#92;displaystyle  &#92;forall c: &#92;text{Emb}(A,C) &#92;rightarrow [r], &#92;exists &#92;phi &#92;in &#92;text{Emb}(B,C), &#92;exists i &#92;in [r]  " class="latex" /> <br />
such that<br />
<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7Bf+%5Ccirc+%5Cphi+%3A+f+%5Cin+F%5C%7D+%5Csubseteq+%28c%5E%7B-1%7D%28i%29%29_%5Cepsilon.++&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle  &#92;{f &#92;circ &#92;phi : f &#92;in F&#92;} &#92;subseteq (c^{-1}(i))_&#92;epsilon.  " title="&#92;displaystyle  &#92;{f &#92;circ &#92;phi : f &#92;in F&#92;} &#92;subseteq (c^{-1}(i))_&#92;epsilon.  " class="latex" /> <br />
Here <img src="https://s0.wp.com/latex.php?latex=%28X%29_%5Cepsilon+%5Csubset+%5Ctext%7BEmb%7D%28A%2CC%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(X)_&#92;epsilon &#92;subset &#92;text{Emb}(A,C) " title="(X)_&#92;epsilon &#92;subset &#92;text{Emb}(A,C) " class="latex" />, and the <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;epsilon " title="&#92;epsilon " class="latex" />-fattening is using the embedding distance (which we haven&#039;t defined).
</div>
<p>Recall that in the infinite case, rigidity was needed to have the embedding RP. That is why in finite metric spaces we added linear orders to get the RP. However, metric spaces do satisfy the ARP (by Pestov from extreme amenabilty of <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BIso%7D%28%5Cmathbb%7BU%7D%2Cd%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Iso}(&#92;mathbb{U},d) " title="&#92;text{Iso}(&#92;mathbb{U},d) " class="latex" />, without needing to add linear orders.</p>
<p>Also, by using the usual compactness arguments, we can assume that the witness <img src="https://s0.wp.com/latex.php?latex=C+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="C " title="C " class="latex" /> to ARP is the full Fraïssé limit.</p>
<h2>The stabilizer equivalence</h2>
<p>In the KPT correspondence, we saw a useful connection between the stabilizer of a set and collections of finite structures. See <a href="https://boolesrings.org/mpawliuk/2016/11/16/topological-dynamics-and-ramsey-classes-ramsey-doccourse-prague-2016/">Lionel Ngyuen van The&#8217;s first DocCourse lecture</a>.</p>
<p>Here we mention an analogous connection.</p>
<div class="defn"><strong>Definition</strong>. Let <img src="https://s0.wp.com/latex.php?latex=G+%3D+%5Ctext%7BIso%7D%28%5Cmathbb%7BU%7D%2Cd%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="G = &#92;text{Iso}(&#92;mathbb{U},d) " title="G = &#92;text{Iso}(&#92;mathbb{U},d) " class="latex" />. The neighbourhood given by <img src="https://s0.wp.com/latex.php?latex=X+%5Cin+%5B%5Cmathbb%7BU%7D%5D%5E%7B+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="X &#92;in [&#92;mathbb{U}]^{ 0 " title="X &#92;in [&#92;mathbb{U}]^{ 0 " class="latex" /> is denoted by<br />
<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++V_X%5E%5Cepsilon+%3A%3D+%5C%7B%5Cphi+%5Cin+%5Ctext%7BIso%7D%28%5Cmathbb%7BU%7D%2Cd%29+%3A+d%28%5Cphi%28x%29%2Cx%29+%3C+%5Cepsilon%2C+%5Cforall+x+%5Cin+X%5C%7D.++&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle  V_X^&#92;epsilon := &#92;{&#92;phi &#92;in &#92;text{Iso}(&#92;mathbb{U},d) : d(&#92;phi(x),x) &lt; &#92;epsilon, &#92;forall x &#92;in X&#92;}.  " title="&#92;displaystyle  V_X^&#92;epsilon := &#92;{&#92;phi &#92;in &#92;text{Iso}(&#92;mathbb{U},d) : d(&#92;phi(x),x) &lt; &#92;epsilon, &#92;forall x &#92;in X&#92;}.  " class="latex" /> <br />
The pointwise stabilizer is<br />
<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctext%7BStab%7D%28X%29+%3A%3D+%5C%7B%5Cphi+%5Cin+%5Ctext%7BIso%7D%28%5Cmathbb%7BU%7D%2Cd%29+%3A+%5Cphi%28x%29+%3D+x%2C+%5Cforall+x+%5Cin+X%5C%7D.++&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle  &#92;text{Stab}(X) := &#92;{&#92;phi &#92;in &#92;text{Iso}(&#92;mathbb{U},d) : &#92;phi(x) = x, &#92;forall x &#92;in X&#92;}.  " title="&#92;displaystyle  &#92;text{Stab}(X) := &#92;{&#92;phi &#92;in &#92;text{Iso}(&#92;mathbb{U},d) : &#92;phi(x) = x, &#92;forall x &#92;in X&#92;}.  " class="latex" /> <br />
The embedding distance, for <img src="https://s0.wp.com/latex.php?latex=f%2Cg+%5Cin+%5Ctext%7BEmb%7D%28X%2C+%5Cmathbb%7BU%7D%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="f,g &#92;in &#92;text{Emb}(X, &#92;mathbb{U}) " title="f,g &#92;in &#92;text{Emb}(X, &#92;mathbb{U}) " class="latex" /> is<br />
<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d%28f%2Cg%29+%3D+%5Cmax_%7Bx+%5Cin+X%7D+%5C%7Bd%28f%28x%29%2C+g%28x%29%5C%7D.++&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle  d(f,g) = &#92;max_{x &#92;in X} &#92;{d(f(x), g(x)&#92;}.  " title="&#92;displaystyle  d(f,g) = &#92;max_{x &#92;in X} &#92;{d(f(x), g(x)&#92;}.  " class="latex" /> 
</div>
<div class="thm"><strong>Correspondence</strong>. <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BEmb%7D%28X%2C+%5Cmathbb%7BU%7D%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Emb}(X, &#92;mathbb{U}) " title="&#92;text{Emb}(X, &#92;mathbb{U}) " class="latex" /> can be identified with <img src="https://s0.wp.com/latex.php?latex=G+%2F+%5Ctext%7BStab%7D%28X%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="G / &#92;text{Stab}(X) " title="G / &#92;text{Stab}(X) " class="latex" />.
</div>
<div class="proof"><strong>Proof</strong>. If <img src="https://s0.wp.com/latex.php?latex=f+%5Cin+G+%2F+%5Ctext%7BStab%7D%28X%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="f &#92;in G / &#92;text{Stab}(X) " title="f &#92;in G / &#92;text{Stab}(X) " class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=f+%3A+%5Cmathbb%7BU%7D+%5Crightarrow+%5Cmathbb%7BU%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="f : &#92;mathbb{U} &#92;rightarrow &#92;mathbb{U} " title="f : &#92;mathbb{U} &#92;rightarrow &#92;mathbb{U} " class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=f+%5Cupharpoonright+X+%5Cin+%5Ctext%7BEmb%7D%28X%2C+%5Cmathbb%7BU%7D%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="f &#92;upharpoonright X &#92;in &#92;text{Emb}(X, &#92;mathbb{U}) " title="f &#92;upharpoonright X &#92;in &#92;text{Emb}(X, &#92;mathbb{U}) " class="latex" />.
</div>
<p>So we can reword the ARP for finite metric spaces, by transfering the colouring <img src="https://s0.wp.com/latex.php?latex=c%3A+%5Ctext%7BEmb%7D%28A%2C%5Cmathbb%7BU%7D%29+%5Crightarrow+%5Br%5D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="c: &#92;text{Emb}(A,&#92;mathbb{U}) &#92;rightarrow [r] " title="c: &#92;text{Emb}(A,&#92;mathbb{U}) &#92;rightarrow [r] " class="latex" /> to a colouring <img src="https://s0.wp.com/latex.php?latex=%5Chat%7Bc%7D+%3A+G+%2F+%5Ctext%7BStab%7D%28A%29+%5Crightarrow+%5Br%5D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;hat{c} : G / &#92;text{Stab}(A) &#92;rightarrow [r] " title="&#92;hat{c} : G / &#92;text{Stab}(A) &#92;rightarrow [r] " class="latex" />.</p>
<h2>Thick sets</h2>
<p>Thickness is a group property that captures some Ramsey properties. This is desirable because we would like to be able to detect Ramsey type phenomena from the group itself, without having to know the underlying Fraïssé limit.</p>
<div class="defn"><strong>Definition</strong>. (<img src="https://s0.wp.com/latex.php?latex=G+%3D+%5Ctext%7BIso%7D%28%5Cmathbb%7BU%7D%2Cd%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="G = &#92;text{Iso}(&#92;mathbb{U},d) " title="G = &#92;text{Iso}(&#92;mathbb{U},d) " class="latex" />). <img src="https://s0.wp.com/latex.php?latex=T+%5Csubseteq+G+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="T &#92;subseteq G " title="T &#92;subseteq G " class="latex" /> is <strong>thick</strong> iff <br /> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+V_X%5E%5Cepsilon%2C+%5C%7Bg+V_X%5E%5Cepsilon+T+%3A+g+%5Cin+G%5C%7D+%5Ctext%7B+has+the+finite+intersection+property.%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;displaystyle  &#92;forall V_X^&#92;epsilon, &#92;{g V_X^&#92;epsilon T : g &#92;in G&#92;} &#92;text{ has the finite intersection property.}  " title="&#92;displaystyle  &#92;forall V_X^&#92;epsilon, &#92;{g V_X^&#92;epsilon T : g &#92;in G&#92;} &#92;text{ has the finite intersection property.}  " class="latex" /> </p>
<p><img src="https://s0.wp.com/latex.php?latex=G+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="G " title="G " class="latex" /> is <strong>thick partition regular</strong> iff <img src="https://s0.wp.com/latex.php?latex=%5Cforall+V_X%5E%5Cepsilon%2C+%5Cforall+G+%2F+%5Ctext%7BStab%7D%28x%29+%3D+%5Cbigcup_%7Bi%3D1%7D%5En+%3D+P_i+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;forall V_X^&#92;epsilon, &#92;forall G / &#92;text{Stab}(x) = &#92;bigcup_{i=1}^n = P_i " title="&#92;forall V_X^&#92;epsilon, &#92;forall G / &#92;text{Stab}(x) = &#92;bigcup_{i=1}^n = P_i " class="latex" /> there is a <img src="https://s0.wp.com/latex.php?latex=P_%7Bi_0%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="P_{i_0} " title="P_{i_0} " class="latex" /> that is thick.
</div>
<div class="thm"><strong>Theorem</strong>. <img src="https://s0.wp.com/latex.php?latex=G+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="G " title="G " class="latex" /> is thick partition regular iff <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BAge%7D%28%5Cmathbb%7BU%7D%2C+d%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;text{Age}(&#92;mathbb{U}, d) " title="&#92;text{Age}(&#92;mathbb{U}, d) " class="latex" /> satisfies ARP.
</div>
<p>This is really just unwinding definitions. Then by general topological dynamics abstract nonsense we get:</p>
<div class="thm"><strong>Theorem</strong>. If <img src="https://s0.wp.com/latex.php?latex=G+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="G " title="G " class="latex" /> is thick partition regular then <img src="https://s0.wp.com/latex.php?latex=G+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="G " title="G " class="latex" /> is extremely amenable.
</div>
<p>Note that this is a theorem just about groups. This doesn&#8217;t use much of the structure of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BU%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;mathbb{U} " title="&#92;mathbb{U} " class="latex" />. Our goal is to prove extreme amenability without having to first prove Ramsey theorems.</p>
<h2>Next lectures</h2>
<p>In the next lectures we will examine the Gurarij space and prove the ARP for <img src="https://s0.wp.com/latex.php?latex=%5Cell_%5Cinfty%5En+&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;ell_&#92;infty^n " title="&#92;ell_&#92;infty^n " class="latex" /> (i.e. Banach spaces).</p>
<h2>References</h2>
<p>(This is incomplete &#8211; Mike)</p>
<ul>
<li>Kechris, Pestov, Todorcevic. <a href="http://www.ams.org/mathscinet-getitem?mr=2140630">&#8220;Fraïssé limits, Ramsey theory, and topological dynamics of automorphism groups&#8221;</a>. 2005.</li>
<li>Pestov. <a href="http://www.ams.org/mathscinet-getitem?mr=2277969">&#8220;Dynamics of infinite-dimensional groups. The Ramsey-Dvoretzky-Milman phenomenon.&#8221;</a>. 2006.</li>
</ul>]]></summary>
        <author>
            <name>Mike Pawliuk – Mathematics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Talk: Survey of mathematically applied computability theory]]></title>
        <id>http://m6c.org/w/2016/11/survey-of-mathematically-applied-computability/</id>
        <link href="http://m6c.org/w/2016/11/survey-of-mathematically-applied-computability/">
        </link>
        <updated>2016-11-19T20:36:43Z</updated>
        <summary type="html"><![CDATA[Despite being relatively small, my department has three faculty in finite combinatorics, in addition to having me in logic. I recently gave a series of two talks in our seminar to present a broad overview of classical computability theory, and &#8230; <a href="http://m6c.org/w/2016/11/survey-of-mathematically-applied-computability/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Carl Mummert</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some thoughts about teaching advanced set theory]]></title>
        <id>http://karagila.org/2016/some-thoughts-about-teaching-advanced-set-theory/</id>
        <link href="http://karagila.org/2016/some-thoughts-about-teaching-advanced-set-theory/">
        </link>
        <updated>2016-11-14T00:14:40Z</updated>
        <summary type="html"><![CDATA[<p>I've been given the chance to teach the course in axiomatic set theory in Jerusalem this semester. Today I gave my first lecture as a teacher. It went fine, I even covered more than I expected to, which is good, I guess. I am also preparing lecture notes, which I will probably post here when the semester ends. These predicated on some rudimentary understanding in logic and basic set theory, so there might be holes there to people unfamiliar with the basic course (at least the one that I gave with Azriel Levy for the past three years).</p>

<p>Yesterday, however, I spent most of my day thinking about how we---as a collective of set theorists---teach axiomatic set theory. About that usual course: axioms, ordinals, induction, well-founded sets, reflection, \(V=L\) and the consistency of \(\GCH\) and \(\AC\), some basic combinatorics (clubs, Fodor's lemma, maybe Solovay or even Silver's theorem). Up to some rudimentary permutation. <a href="http://karagila.org/2016/some-thoughts-about-teaching-advanced-set-theory/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enjoying new business job]]></title>
        <id>http://normanspace.org/2016/11/11/enjoying-new-business-job/</id>
        <link href="http://normanspace.org/2016/11/11/enjoying-new-business-job/">
        </link>
        <updated>2016-11-11T18:43:30Z</updated>
        <summary type="html"><![CDATA[<p>Hi Everybody.</p>
<p>I&#8217;ve been really enjoying my new job at Time Service in Toledo. I&#8217;m about to finish my third month here, and I expect I&#8217;ll be staying with this job for quite a while. I find that working in business gives me a variety of interesting problems to solve, and although they&#8217;re not deep and abstract in the same way as math research problems, they still require a lot of creative thinking and give me challenges to work on over time and puzzles to chew on as I drift off to sleep, in my morning shower, etc., just like math research did. The whole operation of helping to run a business feels like a big optimization problem &#8212; how do I figure out the best way to use all of our company&#8217;s resources to the greatest effect?</p>
<p>I hope all my friends in the New York Logic community are doing well. Please keep in touch!</p>]]></summary>
        <author>
            <name>Norman Lewis Perlmutter</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Zornian Functional Analysis or: How I Learned to Stop Worrying and Love the Axiom of Choice]]></title>
        <id>http://karagila.org/2016/zornian-functional-analysis-or-how-i-learned-to-stop-worrying-and-love-the-axiom-of-choice/</id>
        <link href="http://karagila.org/2016/zornian-functional-analysis-or-how-i-learned-to-stop-worrying-and-love-the-axiom-of-choice/">
        </link>
        <updated>2016-10-10T18:34:33Z</updated>
        <summary type="html"><![CDATA[<p>Back in the fall semester of 2015-2016 I had taken a course in functional analysis. One of the reasons I wanted to take that course (other than needing the credits to finish my Ph.D.) is that I was always curious about the functional analytic results related to the axiom of choice, and my functional analysis wasn't strong enough to sift through these papers.</p>

<p>I was very happy when the professor, Matania Ben-Artzi, allowed me to write a final paper about the usage of the axiom of choice in the course, instead of taking an exam. <a href="http://karagila.org/2016/zornian-functional-analysis-or-how-i-learned-to-stop-worrying-and-love-the-axiom-of-choice/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fifteen fun problems]]></title>
        <id>http://dcernst.github.io/fifteen-fun-problems/</id>
        <link href="http://dcernst.github.io/fifteen-fun-problems/">
        </link>
        <updated>2016-09-29T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>It’s day 4 of the <a href="https://twitter.com/hashtag/loveyourmath?src=hash">#loveyourmath</a> campaign! One of the things I enjoy about doing mathematics is working on interesting problems that require a bit of creativity and/or cleverness.  I especially like problems that don’t require you to know very much in advance.  A few semesters ago we launched a course for mathematics majors, called <a href="http://teaching.danaernst.com/mat220s15/">MAT 220: Introduction to Mathematical Reasoning</a>, whose main objective is to make students wrestle with exactly the types of problems I love. In particular, the focus of the course is on reasoning and communication through problem solving and written mathematical arguments in order to provide students with more experience and training early in their university studies. The goal is for the students to work on interesting yet challenging multi-step problems that require almost zero background knowledge. The hope is that students will develop (or at least move in the direction of) the habits of mind of a mathematician. The problem solving of the type in this course is a fundamental component of mathematics that receives little focused attention elsewhere in most mathematics programs.</p>

<p>Below are 15 problems from the course.  Originally I was only going to list 5, but it was hard enough to only pick 15. I attempted to showcase a variety of problems that utilize different ways of thinking.  I’m intentionally not providing any solutions.  Some of these problems are classics or variations on classics.  Have fun playing!</p>

<ol>
  <li>I have 10 sticks in my bag. The length of each stick is an integer. No matter which 3 sticks I try to use, I cannot make a triangle out of those sticks. What is the minimum length of the longest stick?</li>
  <li>A mouse eats his way through a 3 by 3 by 3 cube of cheese by tunneling through all 27 of the 1 by 1 by 1 sub-cubes. If she starts at one corner and always moves to an uneaten sub cube, can she finish at the center of the cube?</li>
  <li>We have two strings of pyrotechnic fuse. The strings do not look homogeneous in thickness but both of them have a label saying 4 minutes. So we can assume that it takes 4 minutes to burn through either of these fuses. How can we measure a one minute interval?</li>
  <li>Show that in any group of 6 students there are 3 students who know each other or 3 students who do not know each other.</li>
  <li>Suppose someone draws 20 random lines in the plane. What is the maximum number of intersections of these lines?</li>
  <li>Suppose you have 12 coins, all identical in appearance and weight except for one that is either heavier or lighter than the other 11 coins. What is the minimum number of weighing one must do with a two-pan scale in order to identify the counterfeit?</li>
  <li>Suppose you have 9 coins, all identical in appearance and weight except for one that <em>we know is heavier</em> than the other 8 coins. What is the minimum number of weighing one must do with a two-pan scale in order to identify the counterfeit?</li>
  <li>Four prisoners are making plans to escape from jail. Their current plan requires them to cross a narrow bridge in the dark that has no handrail. In order to successfully cross the bridge, they must use a flashlight.  However, they only have a single flashlight.  To complicate matters, at most two people can be on the bridge at the same time.  So, they will need to make multiple trips across the bridge, returning the flashlight back to the first side of the bridge by having someone walk it back.  Unfortunately, they can’t throw the flashlight.  It takes 1, 2, 5, and 10 minutes for prisoner A, prisoner B, prisoner C, and prisoner D to cross the bridge and when two prisoners are walking together with the flashlight, it takes the time of the slower prisoner.  What is the minimum total amount of time it takes all four prisoners to get across the bridge?</li>
  <li>How many ways can 110 be written as the sum of 14 different positive integers?</li>
  <li>Consider the following problem. An overfull prison has decided to terminate some prisoners. The jailer comes up with a game for selecting who gets terminated. Here is his scheme. 10 prisoners are to be lined up all facing the same direction. On the back of each prisoner’s head, the jailer places either a black or a red dot. Each prisoner can only see the color of the dot for all of the prisoners in front of them and the prisoners do not know how many of each color there are. The jailer may use all black dots, or perhaps he uses 3 red and 7 black, but the prisoners do not know. The jailer tells the prisoners that if a prisoner can guess the color of the dot on the back of their head, they will live, but if they guess incorrectly, they will be terminated. The jailer will call on them in order starting at the back of the line. Before lining up the prisoners and placing the dots, the jailer allows the prisoners 5 minutes to come up with a plan that will maximize their survival. What plan can the prisoners devise that will maximize the number of prisoners that survive? Some more info: each prisoner can hear the answer of the prisoner behind them and they will know whether the prisoner behind them has lived or died. Also, each prisoner can only respond with the word “black” or “red.”</li>
  <li>In the senate of the Klingon home world no senator has more than three enemies. Show that the senate can be separated into two houses so that nobody has more than one enemy in the same house.</li>
  <li>100 prisoners are isolated in individual jail cells with no way to communicate. They are currently serving life sentences.  Due to an overcrowded prison, the jailer decides to offer the prisoners the following deal. There is a a room with nothing in it except a light switch (that starts in the off position). At random, the jailer will escort a single prisoner into the room with the light switch. After 5 seconds, the jailer will escort the prisoner back to his/her jail cell. The jailer will repeat this over and over again.  He tells each of the prisoners that if one of the prisoners can indicate when every prisoner has been in the room with the light switch at least once, he will let all the prisoners go.  However, if a prisoner erroneously states that each prisoner has been in the room with the light switch, then all the prisoners will be executed.  Before beginning, the jailer gets all 100 prisoners together and gives them 5 minutes to come up with a plan.  What should their plan be?  It’s important to note that the jailer is choosing prisoners at random to take in the room.  That is, by chance, the same prisoner may be escorted to the room several times in a row.  Also, your task is to devise a scheme for the prisoners to communicate with the light switch.  You shouldn’t bother searching for other ways for the prisoners to communicate.</li>
  <li>Three boxes, one with black, one with white, and one with black and white balls.  Each of the boxes is labeled B, W, and BW, but unfortunately, <em>all</em> the boxes are labeled incorrectly.  Moreover, you cannot see inside each of the boxes, but you can reach in and pull a ball out.  What is the minimum number of balls that need to be pulled before you can relabel all the boxes correctly?</li>
  <li>Imagine you have 25 pebbles, each occupying one square on a 5 by 5 chess board. Suppose that each pebble must move to an adjacent square by only moving up, down, left, or right. Is it possible to do this if every pebble must move and each square is only occupied by a single pebble after all pebbles have moved?  If so, find a solution.  If not, explain why.</li>
  <li>Show that in any set of seven different positive integers there are three numbers such that the greatest common divisor of any two of them leaves the same remainder when divided by three.</li>
</ol>

<p>If you want to see more problems from the course, go <a href="http://teaching.danaernst.com/files/spring2015/mat220/220ProblemCollection.pdf">here</a>.</p>

<p><em>Note:</em> The <a href="https://twitter.com/hashtag/loveyourmath?src=hash">#loveyourmath</a> 5-day campaign is sponsored by the <a href="http:maa.org">Mathematical Association of America</a>.  The goal of the campaign is to engage a general audience across a broad representation of mathematics, whether it is biology, patterns, textbooks, art, or puzzles.</p>]]></summary>
        <author>
            <name>Dana C. Ernst</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The 5 groups of order 8]]></title>
        <id>http://dcernst.github.io/the-5-groups-of-order-8/</id>
        <link href="http://dcernst.github.io/the-5-groups-of-order-8/">
        </link>
        <updated>2016-09-28T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>It’s day 3 of the <a href="https://twitter.com/hashtag/loveyourmath?src=hash">#loveyourmath</a> campaign!  For this post, I wanted to share some pictures of some quilts that one of my former students made for me when I was at <a href="http://plymouth.edu">Plymouth State University</a>.</p>

<p>It turns out that up to isomorphism, there are exactly 5 groups of order 8.  Below are representatives from each isomorphism class:</p>

<ul>
  <li>$\mathbb{Z}_8$ (<a href="https://en.wikipedia.org/wiki/Cyclic_group">cyclic group</a> of order 8)</li>
  <li>$\mathbb{Z}_4\times \mathbb{Z}_2$</li>
  <li>$\mathbb{Z}_2\times \mathbb{Z}_2\times \mathbb{Z}_2$</li>
  <li>$D_4$ (<a href="https://en.wikipedia.org/wiki/Dihedral_group">dihedral group</a> of order 8)</li>
  <li>$Q_8$ (<a href="https://en.wikipedia.org/wiki/Quaternion_group">quaternion group</a>)</li>
</ul>

<p>The first three groups listed above are abelian while the last two are not.  It’s a fairly straightforward exercise to prove that none of these groups are isomorphic to each other.  It’s a bit more work to prove that the list is complete.  <a href="https://en.wikipedia.org/wiki/Finitely_generated_abelian_group#Classification">The Fundamental Theorem of Finitely Generated Abelian Groups</a> guarantees that we haven’t omitted any abelian groups of order 8.  Handling the non-abelian case is trickier.  If you want to know more about to prove that the classification above is correct, check out the Mathematics Stack Exchange post <a href="http://math.stackexchange.com/questions/64406/how-can-you-show-there-are-only-2-nonabelian-groups-of-order-8">here</a>, the <a href="http://groupprops.subwiki.org/wiki/Main_Page">GroupProps </a> wiki page about <a href="http://groupprops.subwiki.org/wiki/Groups_of_order_8">groups of order 8</a>, and the nice classification of all groups of order less or equal to 8 that is located <a href="http://www2.lawrence.edu/fast/corrys/Math300/8Groups.pdf">here</a>.</p>

<p>Since groups have binary operations at their core, we can represent a finite group using a table, called a group table.  In order to help out minds recognize patterns in the table, we can color the entries in the table according to which group element occurs.  Of course, if we rearrange the column and row headings of the table, we have to rearrange or recolor the entries of the table accordingly.  Doing so may make some patterns more or less visually recognizable.  Similar to the book <a href="http://web.bentley.edu/empl/c/ncarter/vgt/">Visual Group Theory</a> by <a href="http://web.bentley.edu/empl/c/ncarter/">Nathan Carter</a> (Bentley University), I utilize colored group tables in several chapters of <a href="http://dcernst.github.io/IBL-AbstractAlgebra/">An Inquiry-Based Approach to Abstract Algebra</a>, which is an open-source abstract algebra book that I wrote to be used with an <a href="http://maamathedmatters.blogspot.com/2013/05/what-heck-is-ibl.html">IBL approach</a> to the subject.</p>

<p>While I was teaching out of Carter’s book during the summer of 2009, one of my students (Michelle Reagan) made five quilts that correspond to colored group tables for the five groups of order 8.  Here are pictures of the quilts.</p>

<div class="row">
<center>
<div><img src="/images/Quilt1.JPG" width="80%" class="img-responsive" img="" style="margin-bottom: 15px" /></div>
<div><img src="/images/Quilt2.JPG" width="80%" class="img-responsive" img="" style="margin-bottom: 15px" /></div>
<div><img src="/images/Quilt3.JPG" width="80%" class="img-responsive" img="" style="margin-bottom: 15px" /></div>
<div><img src="/images/Quilt4.JPG" width="80%" class="img-responsive" img="" style="margin-bottom: 15px" /></div>
<div><img src="/images/Quilt5.JPG" width="80%" class="img-responsive" img="" style="margin-bottom: 15px" /></div>
</center>
</div>

<p>It’s a fun exercise to figure out which quilt corresponds to which group.  I’ll leave it to you to think about.</p>

<p><em>Note:</em> The <a href="https://twitter.com/hashtag/loveyourmath?src=hash">#loveyourmath</a> 5-day campaign is sponsored by the <a href="http:maa.org">Mathematical Association of America</a>.  The goal of the campaign is to engage a general audience across a broad representation of mathematics, whether it is biology, patterns, textbooks, art, or puzzles.</p>]]></summary>
        <author>
            <name>Dana C. Ernst</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A (new) favorite math book]]></title>
        <id>http://dcernst.github.io/a-new-favorite-math-book/</id>
        <link href="http://dcernst.github.io/a-new-favorite-math-book/">
        </link>
        <updated>2016-09-27T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>As part of day two of the <a href="https://twitter.com/hashtag/loveyourmath?src=hash">#loveyourmath</a> campaign, I wanted to share a math book that has recently become one of my favorites, namely <a href="http://math.depaul.edu/tpeter21/Eulerian.html">Eulerian Numbers</a> by <a href="http://math.depaul.edu/tpeter21/index.html">T. Kyle Petersen</a> (DePaul University). The book was published in late 2015.  According <a href="http://www.springer.com/us/book/9781493930906">Springer</a>:</p>

<blockquote>
<p>This text presents the Eulerian numbers in the context of modern enumerative, algebraic, and geometric combinatorics. The book first studies Eulerian numbers from a purely combinatorial point of view, then embarks on a tour of how these numbers arise in the study of hyperplane arrangements, polytopes, and simplicial complexes. Some topics include a thorough discussion of gamma-nonnegativity and real-rootedness for Eulerian polynomials, as well as the weak order and the shard intersection order of the symmetric group.</p>

<p>The book also includes a parallel story of Catalan combinatorics, wherein the Eulerian numbers are replaced with Narayana numbers. Again there is a progression from combinatorics to geometry, including discussion of the associahedron and the lattice of noncrossing partitions.</p>

<p>The final chapters discuss how both the Eulerian and Narayana numbers have analogues in any finite Coxeter group, with many of the same enumerative and geometric properties. There are four supplemental chapters throughout, which survey more advanced topics, including some open problems in combinatorial topology.</p>

<p>This textbook will serve a resource for experts in the field as well as for graduate students and others hoping to learn about these topics for the first time.​</p>
</blockquote>

<p>Generally speaking, most of my research in pure mathematics falls in the category of algebraic combinatorics.  However, I’ve had very little formal training in combinatorics.  It turns out that I know quite a bit about Catalan combinatorics, but again, it’s not a subject that I’ve explicitly studied.  Prior to opening the book, I knew next to nothing about <a href="https://en.wikipedia.org/wiki/Eulerian_number">Eulerian numbers</a>, let alone <a href="https://en.wikipedia.org/wiki/Narayana_number">Narayana numbers</a>.</p>

<p><img src="/images/EulerianNumbers.jpg" align="left" width="150" img="" style="margin-right: 15px" /> Right around the time I found out I would be teaching our graduate combinatorics class during the Fall 2016 semester, I learned about Kyle’s book.  I was really looking forward to teaching the class because I figured that one of the best ways to fill in my lack of formal training in combinatorics was to teach a class about it.  After thumbing through Kyle’s book (and thinking, “wow, I don’t really know any of this stuff!”), I decided that I could run the class as a sort of “topics course” focusing on Eulerian numbers and Catalan combinatorics while hitting many of the core ideas of enumerative combinatorics along the way.  As a bonus, I would be forced to learn lots of cool things that relate to my research interests, many of which I probably should have know more about anyway.</p>

<p>I’m currently in week 5 of my <a href="https://dcernst.github.io/teaching/mat526f16/">Topics in Combinatorics</a> graduate course in which we are closely following Kyle’s book.  Despite the fact that we’ve barely covered two chapters, I’m absolutely in love with the book and the content.  It’s so much fun!  I have to admit that I don’t always know which specific topics are key ideas and which are just fun side stories, but I think that’s mostly true every time one teaches a course for the first time. One of the things I really like about the themes in the book is that connects with cutting edge research topics.  We’re learning about “current events” in algebraic/enumerative combinatorics.</p>

<p>My only minor complaint is that I wish Kyle provided less detail in the hints/solutions for the exercises in the back of the book.  On the other hand, there have been a couple times where I’ve thought, “geez, there’s no way I would have ever come up with that argument without significant guidance.”</p>

<p><em>Note:</em> The <a href="https://twitter.com/hashtag/loveyourmath?src=hash">#loveyourmath</a> 5-day campaign is sponsored by the <a href="http:maa.org">Mathematical Association of America</a>.  The goal of the campaign is to engage a general audience across a broad representation of mathematics, whether it is biology, patterns, textbooks, art, or puzzles.</p>]]></summary>
        <author>
            <name>Dana C. Ernst</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Resigning from LaGuardia]]></title>
        <id>http://normanspace.org/2016/08/02/resigning-from-laguardia/</id>
        <link href="http://normanspace.org/2016/08/02/resigning-from-laguardia/">
        </link>
        <updated>2016-08-02T05:16:05Z</updated>
        <summary type="html"><![CDATA[<p>I have resigned my position at LaGuardia Community College effective the beginning of the fall semester. I will be moving back to my birth town of Toledo, Ohio in a few days, where I will help to manage a medium-sized business started by my great-grandfather. It&#8217;s a watch repair business, with departments across the country. I&#8217;ll get to work closely with my father, who is the President of the company. I&#8217;m really looking forward to the opportunity to try out a completely different career.</p>
<p>As a side project, I hope to find some time to do a bit of research for MIRI. I&#8217;ve discussed MIRI research in a couple of recent posts here. I plan to continue updating this blog with stuff on MIRI research and other updates on my life. I&#8217;ll miss my colleagues in New York, and I hope we keep in touch. My students are welcome to keep in touch as well.</p>]]></summary>
        <author>
            <name>Norman Lewis Perlmutter</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Two agent mild optimization]]></title>
        <id>http://normanspace.org/2016/08/01/two-agent-mild-optimization/</id>
        <link href="http://normanspace.org/2016/08/01/two-agent-mild-optimization/">
        </link>
        <updated>2016-08-02T01:42:23Z</updated>
        <summary type="html"><![CDATA[<p><a href="http://box5203.temp.domains/~normansp/wp-content/uploads/2016/08/2FactorMildOptimization.pdf">Here is a paper</a> that came out of the MIRI Summer Fellows Program research workshop that I attended in June. The LaTeX code is <a href="http://boolesrings.org/perlmutter/files/2016/08/2FactorMildOptimization.tex">here</a>.</p>
<p>Quantilization is a form of mild optimization where you tell an AI to choose something at random from (for instance) the top 10% of best solutions, rather than taking the best solution. This helps to get around the problem of an agent whose values are mostly aligned with yours but that does pathological things when it takes its values to the extreme. In this paper, we examine a similar process, but involving two (or more) agents rather than one.</p>
<p>For those of you who were also at the MSFP, you can read some additional discussion of the paper <a href="https://groups.google.com/forum/?utm_medium=email&amp;utm_source=footer#!msg/miri-summer-fellows-program-2016/YJpzUjLXcos/AwrBt2fsBQAJ">here</a>. The main idea is that Connor is working on a simulation to help test the ideas in the paper. If you&#8217;re interested in helping with the simulation but don&#8217;t have access to the forum post linked above, get in touch with me.</p>]]></summary>
        <author>
            <name>Norman Lewis Perlmutter</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine Intelligence Research Institute]]></title>
        <id>http://normanspace.org/2016/08/01/machine-intelligence-research-institute/</id>
        <link href="http://normanspace.org/2016/08/01/machine-intelligence-research-institute/">
        </link>
        <updated>2016-08-02T01:18:37Z</updated>
        <summary type="html"><![CDATA[<p>In June, I attended a two-week workshop in Northern California, combining technical research and personal growth. The workshop was run by the Machine Intelligence Research Institute (<a href="https://intelligence.org/">MIRI</a>) and the Center For Applied Rationality (<a href="http://rationality.org/">CFAR</a>) in Northern California. The goal of MIRI is to lay the multidisciplinary theoretical foundations (in math, philosophy, computer science, and decision theory, among other fields) to try to insure friendly artificial intelligence, that is to say, to make it so that when artificial intelligence becomes smarter than humans, its interests are aligned with ours.</p>
<p>Their research has a fair amount of overlap with mathematical logic. I&#8217;d encourage any logicians who are interested in these sort of things to get involved. It&#8217;s a very good and important cause; the future of humanity is at stake. Unaligned artificial intelligence could destroy us all in a way that makes nuclear war and global warming seem tame in comparison.<br />
 Their <a href="https://intelligence.org/2014/12/23/new-technical-research-agenda-overview/">technical research agenda </a> is a good place to start for a technical perspective. The book <i> Superintelligence </i> by Nick Bostrom is a good starting point for a less technical introduction and to help understand why MIRI&#8217;s agenda is important and nontrivial.</p>
<p>One area of MIRI research that I find particularly interesting has to do with a version of Prisoner&#8217;s Dilemma played by computer programs that are allowed to read each others&#8217; source code. This work makes use of a bounded version of Löb&#8217;s theorem. Actually, a fair bit of MIRI research relates to Löb&#8217;s theorem. <a href="http://intelligence.org/files/lob-notes-IAFF.pdf#subsection.7.2">Here</a> is a good introduction.</p>
<p>Feel free to contact me if you&#8217;d like to know more about how to get involved with MIRI research. Or you can contact MIRI directly.</p>]]></summary>
        <author>
            <name>Norman Lewis Perlmutter</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[In praise of some history]]></title>
        <id>http://karagila.org/2016/in-praise-of-some-history/</id>
        <link href="http://karagila.org/2016/in-praise-of-some-history/">
        </link>
        <updated>2016-07-10T00:19:44Z</updated>
        <summary type="html"><![CDATA[<p>Teaching pure mathematics is not a trivial thing. You have to overcome the several barriers that were constructed by the K12 education that mathematics is a bunch of &quot;fit this problem into that mold&quot;.</p>

<p>I recently had a chat with James Cummings about teaching. He said something that I knew long before, that being a good teacher requires a bit of theatricality. My best teacher from undergrad, Uri Onn, had told me when I started teaching, that being a good teacher is the same as being a good storyteller: you need to be able and mesmerize your audience and keep them on the edge of their seats, wanting more. <a href="http://karagila.org/2016/in-praise-of-some-history/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Constructive proof that large cardinals are consistent]]></title>
        <id>http://karagila.org/2016/constructive-proof-that-large-cardinals-are-consistent/</id>
        <link href="http://karagila.org/2016/constructive-proof-that-large-cardinals-are-consistent/">
        </link>
        <updated>2016-07-06T12:30:15Z</updated>
        <summary type="html"><![CDATA[<p>I am not a Platonist, as I keep pointing out. Existence, even not in mathematics, is relative and confusing to begin with, so I don't pretend to try and understand it in a meaningful way. </p>

<p>However, we have a proof, a constructive proof that large cardinals are consistent. And they exist in an inner model of our universe. <a href="http://karagila.org/2016/constructive-proof-that-large-cardinals-are-consistent/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some thoughts about "automated theorem searching"]]></title>
        <id>http://karagila.org/2016/some-thoughts-about-automated-theorem-searching/</id>
        <link href="http://karagila.org/2016/some-thoughts-about-automated-theorem-searching/">
        </link>
        <updated>2016-06-27T00:02:26Z</updated>
        <summary type="html"><![CDATA[<p>Let me begin by giving a spoiler warning. If you haven't watched &quot;The Prisoner&quot; you might be spoiled about one of the episodes. Not that matters, for a show from nearly 40 years ago, but you <strong>should</strong> definitely watch it. It is a wonderful show. And even if you haven't watched it, it's just one episode, not the whole show. So you can keep on reading.</p>

<p>So, I'm fashionably late to the party (with some good excuse, see my previous post), but after the recent 200 terabytes proof for the coloring of Pythagorean triples, the same old questions are raised about whether or not at some point computers will be better than us in finding new theorems, and proving them too. <a href="http://karagila.org/2016/some-thoughts-about-automated-theorem-searching/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Iterating Symmetric Extensions]]></title>
        <id>http://karagila.org/2016/iterating-symmetric-extensions/</id>
        <link href="http://karagila.org/2016/iterating-symmetric-extensions/">
        </link>
        <updated>2016-06-22T06:43:40Z</updated>
        <summary type="html"><![CDATA[<p>I don't usually like to write about new papers. I mean, it's a paper, you can read it, you can email me and ask about it if you'd like. It's there. And indeed, for my previous papers, I didn't even mention them being posted on arXiv/submitted/accepted/published. This paper is a bit different; but don't worry, this is not your typical &quot;new paper&quot; post.</p>

<p>If you don't follow arXiv very closely, I have posted a paper titled &quot;<a href="http://arxiv.org/abs/1606.06718">Iterating Symmetric Extensions</a>&quot;. This is going to be the first part of my dissertation. The paper is concerned with developing a general framework for iterating symmetric extensions, which oddly enough, is something that we didn't really know how to do until now. There is a refinement of the general framework to something I call &quot;productive iterations&quot; which impose some additional requirements, but allow greater freedom in the choice of filters used to interpret the names. There is an example of a class-length iteration, which effectively takes everything that was done in the paper and uses it to produce a class-length iteration—and thus a class length sequence of models—where slowly, but surely, Kinna-Wagner Principles fail more and more. This means that we are forcing &quot;diagonally&quot; away from the ordinals. So the models produced there will not be defined by their set of ordinals, and sets of sets of ordinals, and so on. <a href="http://karagila.org/2016/iterating-symmetric-extensions/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Syntactic T-Rex: Irregularized]]></title>
        <id>http://karagila.org/2016/syntactic-t-rex-irregularized/</id>
        <link href="http://karagila.org/2016/syntactic-t-rex-irregularized/">
        </link>
        <updated>2016-06-20T19:39:12Z</updated>
        <summary type="html"><![CDATA[<p>One of my huge pet peeves is with people who think that writing \(1+2+3+\ldots=-\frac1{12}\) is a reasonable thing without context. Convention dictates that when no context is set, we interpret infinite summation as the usual convergence of a series, namely the limit of the partial sums, if it exists (and of course that \(1+2+3+\ldots\) does not converge to any real number). However, a lot of people who are [probably] not mathematicians per se, insist that just because you <em>can</em> set up a context in which the above equality holds, e.g., Ramanujan summation or zeta regularization, then it is automatically perfectly fine to write this out of nowhere without context and being treated as wrong.</p>

<p>But those people forget that \(0=1\) is also very true in the ring with a single element; or you know, just in any structure for a language including the two constant symbols \(0\) and \(1\), where both constants are interpreted to be the same object. And hey, who even said that \(0\) and \(1\) have to denote constants? Why not ternary relations, or some other thing? <a href="http://karagila.org/2016/syntactic-t-rex-irregularized/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A media query for MathML is pointless]]></title>
        <id>https://www.peterkrautzberger.org/0190/</id>
        <link href="https://www.peterkrautzberger.org/0190/">
        </link>
        <updated>2016-06-16T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>So I attended <a href="https://www.w3.org/2016/09/TPAC/">TPAC</a> for the first time. TPAC has that oddly familiar conference feeling -- a bunch of specialists crowded in a relatively small space, most of them pretty weird people (and slightly more diverse than a math conference, not that that's a compliment). But it also had a very unfamiliar feeling: web standards invariably mean politics more directly.</p>
<p>Anyway.</p>
<h2>O to be a query...</h2>
<p>There was a joint meeting of CSSWG and DPUB IG on Monday and I was running late (discussing math-on-web things with Daniel Marques actually), so I missed the first 15 minutes. My mind was blown when, within 2 minutes of me sitting down, a motion was accepted to task Florian with spec'ing (specing? speccing?) out a media query for MathML support (as well as an API to flip it). I didn't feel I was in a position to speak up, so I just sat there wondering what just happened.</p>
<p>The motivation seems rather natural, I suppose. As long as there's no universal browser support for MathML, people are still stuck with providing fallbacks. In situation where they cannot load a JS library themselves (e.g., in ebooks), they have to use a fallback even if they could provide MathML.</p>
<p>If there was a media query, people could add both fallbacks and MathML in a standardized fashion, hiding one or the other depending on the result of that media query. In addition, an API would enable JS libraries to leverage a universal way to progressively enhance content; it wasn't quite clear in the end, but some people seemed to hope that API could additionally be triggered by assistive technology.</p>
<p>This discussion started (I think) on the epub3 end, where the IDPF is currently discussing epub 3.1 and best practices; as usual, MathML features in a painfully prominent role. In epub land, the dream seems to be: you create an epub3 file once and some day down the line, when a user's reading system finally picks up MathML support, the old content will magically improve -- progressive enhancements so to speak.</p>
<p>Naturally, <code>@supports</code> is already very helpful in all sorts of ways today which probably made it a no-brainer (and thus the quick decision). Unfortunately, I think a &quot;media query for MathML&quot; does not solve a single problem.</p>
<p>I was so late to the meeting so when the question for &quot;any objections&quot; came out, I did not feel I was in a position to do so. Still, in a breakout meeting later that day (about epub specifically), I voiced my criticisms to both epub, accessibility, and CSS people.</p>
<p>So this is, if you will, the written version of my opinion. (In case you missed that you are on my personal website, please note the use of &quot;my&quot; here.)</p>
<h2>... of silkworm size</h2>
<p>A single media query for MathML won't help me as content provider (author, publisher, technology specialist); I also find it generally unhelpful for the web as a whole.</p>
<p>The problem with a single query is simple: when would a browser respond positively? When should a browser legitimately claim to have MathML support? I honestly don't know.</p>
<p>MathML is a huge (and pretty vague) spec. There's not a single browser or library that could claim complete support. MathJax is the <a href="https://www.w3.org/Math/testsuite/results/tests.html">top scorer with 85%</a> on the MathML test suite (since MathPlayer was kicked out by IE) but that's not saying much since the test suite is highly biased -- whoever feels like it can submit the data, and in MathJax's case that was me (who is obviously biased).</p>
<p>I can't see how a single media query for all of MathML could provide people with any kind of reliable information on the front-end. Most likely, Gecko and WebKit implementations will immediately turn it on which does not help one bit -- people will still have to test their content on those engines in detail.</p>
<p>Personally, I have already done that too many times (and keep a close eye on them) and I always come to the same conclusion: I cannot recommend using them to anyone since they are too unreliable. So I'm still stuck the same way I was before. Similarly, any publicly available crawler data I've seen indicates that nobody is using native MathML on Gecko and WebKit in the wild, so my position does not seem to be unique.</p>
<h2>... or immense</h2>
<p>Of course, the CSSWG might spec out a whole set of individual media queries for every single MathML features. As unlikely as that seems, we'd just end up deeper in the rabbit hole: MathML is still extremely vague so few features are specified in enough detail (compared to CSS or SVG anyway). To take a simple example, while Gecko and WebKit might claim support for <code>mfrac</code> (fractions), it's not helping me if those fractions are laid out badly as soon as I put something mildly complex in them. So again, I'll end up not using it.</p>
<p>In terms of accessibility, it seemed an API that assitive technology could trigger would not be as easy to implement in browsers (yet &quot;easy&quot; seemed a pre-requisite given the comments from browser reps in the CSSWG). Since AT tends not to inject scripts (JAWS craziness notwithstanding), they'd need a more sophisticated feature (which is, I think, also being discussed by CSSWG, but considered much harder, i.e., unlikely).</p>
<p>Besides, this assumes that MathML significantly benefits accessibility. After MathJax getting deeply involved in building a suitable tool, I find this argument questionable. Talking to a11y folks, it usually comes down to &quot;but MathPlayer!&quot; and while MathPlayer was pretty good (albeit dead in the water now) it didn't actually use MathML but a proprietary internal format representing the result of semantic heuristics; this makes it kind of hard to use it as an example for how great MathML is for accessibility.</p>
<p>I think it's unrealistic to expect every single assistive technology to invest as much in a niche like math. I'd estimate that, at any one point in time over the past 18 years, the number of actively maintained accessibility tools with MathML support was 1 (no, neither JAWS nor VoiceOver count as &quot;maintained&quot; when it comes to MathML).</p>
<p>Further, not a single tool has ever used MathML as an internal format because it is <em>simply insufficient</em> -- it is a XML document language for layout and is grossly unsemantic (and don't say &quot;but ContentMathML&quot; now).</p>
<p>If people feel like exposing MathML to AT, then they can use one of the many standard tricks to ARIA-hide the fallback content and visually hide the MathML. Again, in my opinion, that's a disservice for your readers, but nobody stops you.</p>
<h2>the 800 pound query</h2>
<p>For me, the weirdest thing about this whole decision was its speed: that the CSSWG signed off on this idea in under 20 minutes just makes me a teeny tiny bit skeptical. It feels a lot like one big &quot;whatevs&quot; -- browsers don't really care but, hey, a media query is little work and if it keeps these math people off our backs, all the more reason.</p>
<p>The real problem remains with or without a media query: where is MathML going? As Romain commented on twitter:</p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr"><a href="https://twitter.com/pkrautz">@pkrautz</a> it&#39;s real progress going on<br>1999 → hope MathML gets implemented<br>2016 → hope a declaration of non-implementation gets implemented</p>&mdash; Romain Deltour (@rdeltour) <a href="https://twitter.com/rdeltour/status/777895491719852033">September 19, 2016</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Browser vendors have never worked on MathML support, MathML is no longer maintained as a spec, the MathWG is no more (<a href="https://www.peterkrautzberger.org/0186/">did you notice?</a>), and MathML is a bad web standard for both layout (another post) and <a href="https://www.peterkrautzberger.org/0185/">accessibility</a>.</p>
<h3>fool me once, shame on you.</h3>
<p>I think it's time to realize that after 18 years of not succeeding on the web, the problem might just lie with MathML itself. We don't need it on the web (CSS and SVG are better for layout and ARIA better for accessibility) and we should stop giving browser vendors an excuse not to do anything that actually helps those developers who realize math on the web in its myriad forms today. (And the XML document world, where MathML succeeded, would be better off as well.)</p>
<p>Don't get me wrong, there are many problems left for math on the web but MathML is not a silver bullet, in fact, it solves none of them. Even if it was implemented widely, we'd still need CSS and ARIA features to match. Instead of waiting for others (i.e., browsers) to solve their problems by magic, the few people with an interest (and the resources to match) will have to solve this niche problems on their own and in a way that moves the web forward as a whole.</p>
<p>Either way, a media query for MathML is pointless.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Written elsewhere]]></title>
        <id>https://www.peterkrautzberger.org/0189/</id>
        <link href="https://www.peterkrautzberger.org/0189/">
        </link>
        <updated>2016-06-16T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>As has been established a number of times, I write better elsewhere. So for the n<sup>th</sup> time, here are some cross-postings of things I wrote elsewhere.</p>
<h2>math formats for the web</h2>
<p>Somebody <a href="https://groups.google.com/d/msg/mathjax-users/UR9Cz66QIxQ/d4zLFxdDDQAJ">asked on the MathJax user group</a></p>
<blockquote>
<p>To my understanding MathJax supports these input formats: LaTeX, MathML, and AsciiMath. If I'm making a website and I can choose to use any of the three formats, what are some advantages of choosing each?</p>
</blockquote>
<p>Since I've answered this so many times, I thought it might be worth copying here:</p>
<img alt="Admiral Akhbar: It's a trap! (Star Wars Return of the Jedi), meme)" src="https://imgflip.com/readImage?iid=14854991">
<p>&quot;That's a tricky (trick?) question.</p>
<p>MathML is MathJax's internal format  (essentially anyway) so anything that can be done in MathJax is done through our MathML support, cf <a href="http://docs.mathjax.org/en/latest/mathml.html">http://docs.mathjax.org/en/latest/mathml.html</a>. While MathML is quite good for such an internal purpose, it can be difficult to create. It's rarely written manually (much like HTML or CSS) and tools can have trouble producing high-quality MathML (converters can fail, editors might produce overcomplicated MathML). MathML is the dominant format used in professional publishing workflows and thus comes with a rich toolchain out of XML-land.</p>
<p>MathJax's LaTeX-like input provides a faithful implementation of the most common math-mode LaTeX commands as well as other standard packages and a few non-standard features, cf. <a href="http://docs.mathjax.org/en/latest/tex.html">http://docs.mathjax.org/en/latest/tex.html</a>. LaTeX is much easier to author by hand than MathML and provides the typical LaTeX advantages such as custom macros (for even easier authoring). It also has the benefit of a large community thanks to the wide adoption of TeX as a programming language for print layout in academic writing. LaTeX is probably the most popular format when people have a choice, so MathJax's TeX-like input has a wide community out there. From a real TeX perspective, MathJax restricts LaTeX input to math-mode since it converts internally into MathML. Due to LaTeX's print heritage, some constructions are hard to do (e.g., equal-width columns are trivial in MathML but not doable with the default LaTeX macros).</p>
<p>AsciiMath is a lightweight markup language designed to convert well to MathML. I sometimes like comparing it to markdown -- not as powerful but much more sensible to write. It does not have the expressive power of MathML but it is very easy to learn because it was designed by Peter Jipsen specifically for high-school- and college-level students. It is less frequently used but if it's expressive power is sufficient, I tend to recommend it.</p>
<p>In summary, MathML is MathJax's internal format so anything you can do with MathJax you can do with its MathML input. LaTeX is virtually as powerful (with some edge cases), is easier to author by hand, and has a large community both from real TeX-land and MathJax's community. AsciiMath is the little brother of both MathML and LaTeX and provides a good compromise between expressive strength and human readability.</p>
<p>If you look beyond MathJax there are even more options, of course.&quot;</p>
<hr>
<p>Moving on.</p>
<h3>math accessibility vs machine readability</h3>
<p>On the &quot;Getting Math Onto Web Pages&quot; community group, <a href="https://lists.w3.org/Archives/Public/public-mathonwebpages/2016May/0022.html">Tzivya raised a big topic</a> regarding accessibility:</p>
<blockquote>
<p>I would love it the world would come to understand that accessibility is a subset of machine readability. Accessibility APIs are a specialized kind of machine. If we are working on machine readable math, we need to make sure that those specialized machines can read the math too. Otherwise we will do the work twice.</p>
</blockquote>
<p>I found myself disagreeing with Tzivya (which means I'm probably wrong because she is <strong>awesome</strong>). This disagreement is mostly influenced by our work at MathJax for the past year or so, <a href="https://www.mathjax.org/mathjax-accessibility-extensions-v1-now-available/">making math rendering accessible via MathJax</a>. But the point is an important one to me because, as I expected (feared?), a few discussion on the Community Group have already brought up the problem of looking for the right™ solution instead of the realistic one.</p>
<p>For me, what we have now is the right solution: HTML, CSS, ARIA, SVG etc, several competing math rendering/computation/etc implementations based on these, lots of tools tangential to them. An excellent kind of mess without standards beyond what works ok for each project out there. It's not the right™ solution but it has the potential of becoming better and better. It's really just another part of web development; nothing else needed.</p>
<p>Anyway, so <a href="https://lists.w3.org/Archives/Public/public-mathonwebpages/2016May/0026.html">I wrote</a>:</p>
<hr>
<p>&quot;I do dream that eventually (maybe 10 years from now?) we'll have a thorough a11y API mapping for mathematics. At the moment, I don't think mathematics (as a culture / language) is ready for this (though web technology probably would be).</p>
<p>Regarding general machine readability vs accessibility, one important difference I see is that machine readability can benefit from partial results whereas accessibility cannot.</p>
<p>A typical example for this might be units. If we can find a way to make units machine readable, I think we'd have a major improvement for STEM on the web. But it won't help accessibility (much) to know that there are units in an expression if it is otherwise unintelligible.</p>
<p>Of course, we currently don't have any standard or best practice for exposing units on the web. The MathWG had a very old note on units  (from 2003) which suggested class='MathML-Unit' on MathML elements; I don't think that's viable approach today. Perhaps schema is a better starting point considering how successful search engines can leverage units in recipes (I could imagine lab protocols and engineering might benefit from similar methods).</p>
<p>For some tools it's extremely easy to generate markup for units, e.g., Jos de Jong's MathJS has a rich interface for handling units and could probably easily expose them in a visual output. TeX has a rich history with the physics and siunitx packages (which are, for example, partially available in MathJax as third party extensions) and heuristics seem feasible to enrich formats in general (again, MathJax can do some of that via the speechruleengine).</p>
<p>I think for humans we have to change our expectations. Otherwise, we'll just end up repeating the mistakes of the past. I'll post some thoughts on the accessibility thread later.&quot;</p>
<hr>
<p>And I then <a href="https://lists.w3.org/Archives/Public/public-mathonwebpages/2016May/0027.html">also wrote</a> on the related thread:</p>
<hr>
<p>&quot;Today the most<br>
reliable method is still to use binary images with alt text: static images<br>
are the most reliable in terms of cross browser/platform/network conditions<br>
for visual rendering and alt-text is the only way to guarantee at least<br>
some alternative rendering (e.g. aural and braille) -- no matter how poor<br>
the results may be.</p>
<p>Don't get me wrong, in many specific situation, there will be better ways.<br>
If you have simple content, then you can get decent visual results with<br>
HTML tags with nested aria-labels. If you know you can rely on webfonts<br>
(e.g., many ebook situations) then you can use CSS with webfonts for<br>
rendering (and again nested labels). If you don't need IE8 (sigh) then you<br>
can use SVG etc.</p>
<p>But in generality, binary images with alt-text are still the most robust<br>
way -- and that's an extremely sorry state. I'm pretty sure we can do<br>
better but we need to identify what users need and what tools can<br>
realistically achieve today.</p>
<p>My first guess would be: some form of speech text, potentially enabling<br>
some level of exploration through nesting (and perhaps full exploration via<br>
JS). That's not as bad as it sounds. SVGs with aria-labels are already a<br>
close second in terms of usability (pending the ultimate demise of IE8),<br>
and like HTML they open up the opportunity of deep-labels and thus already<br>
get a certain level of exploration.</p>
<p>But there are other aspects. For example in the US, MathSpeak has a long<br>
history and many users of aural rendering are trained to its way of<br>
describing the visual structure of an equation. I've heard enough anecdotal<br>
evidence to take this very seriously -- after all, that's how visual users<br>
do it. Still, a few months ago I learned that in Germany, on the other<br>
hand, blind students might learn TeX syntax early in school (most likely<br>
because there is no tradition like MathSpeak which, after all, precedes the<br>
web by decades).</p>
<p>I also expect much overlap with SVG accessibility, where the challenges of<br>
summary information at a top level and exploration of details are very<br>
similar to mathematics.&quot;</p>
<hr>
<h2>Barrierefreiheit</h2>
<p>Oh, I gave a talk for Global Accessibility Awareness Day 2016 at the FernUni Hagen -- in German (it's been a while). The slides are <a href="https://pkra.github.io/slides-gaad16/">on GitHub Pages</a>. It's already somewhat outdated because Wikipedia now serves mainly SVGs (generate with <a href="https://github.com/mathjax/MathJax-node">mathjax-node</a>).</p>
<p>Anyway, the core summary stays true:</p>
<blockquote>
<p>Why is it difficult to make formulas accessible?</p>
<ol>
<li>Formulas compress information (extremely)</li>
<li>Formulas are often visual</li>
<li>Formulas are context-dependent</li>
<li>Formulas are poorly authored</li>
</ol>
</blockquote>
<p>In other words, math accessibility sucks bad. And no solution will really help you there. But <a href="https://www.mathjax.org/mathjax-accessibility-extensions-v1-now-available/">MathJax now does its best to make it suck less</a>.</p>
<p>Oh, speaking of accessibility, I'm extremely disappointed that I won't make it to <a href="http://www.roledrinks.nl/">role=drinks</a> after all -- but if you're close by, why don't you drop by?</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MM70: YouTube links!]]></title>
        <id>http://karagila.org/2016/mm70-youtube-links/</id>
        <link href="http://karagila.org/2016/mm70-youtube-links/">
        </link>
        <updated>2016-06-14T14:46:45Z</updated>
        <summary type="html"><![CDATA[<p>During the first day of the conference we realized that it might be a good idea to get the lectured videoed, so we quickly set up the videos for the second and third day. With the exception of one speaker who asked not to be videoed, you can find all the lectures from the second and third day of the conference in this <a href="https://www.youtube.com/playlist?list=PLT-roSWIpp1Hvj2GNhztmfNIJ0Shtu2P8" target="_blank">YouTube Playlist</a>.</p>

<p>Enjoy! <a href="http://karagila.org/2016/mm70-youtube-links/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quick update from Norwich]]></title>
        <id>http://karagila.org/2016/quick-update-from-norwich/</id>
        <link href="http://karagila.org/2016/quick-update-from-norwich/">
        </link>
        <updated>2016-06-11T03:03:38Z</updated>
        <summary type="html"><![CDATA[<p>It's been a while, quite a while, since I last posted anything. Even a blurb.</p>

<p>I'm visiting David Asperó in Norwich at the moment, and on Sunday, the 12th, I will return home. It seems that the pattern is that you work most of the day, then head for a few drinks and dinner. Mathematics is eligible for the first two beers, philosophy of mathematics for the next two, and mathematical education for the fifth beer. Then it's probably a good idea to stop. Also it is usually last call, so you kinda have to stop. <a href="http://karagila.org/2016/quick-update-from-norwich/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The size and topology of quasi-Fatou components of quasiregular maps]]></title>
        <id>https://sixsmith2017.wordpress.com/2016/06/07/the-size-and-topology-of-quasi-fatou-components-of-quasiregular-maps/</id>
        <link href="https://sixsmith2017.wordpress.com/2016/06/07/the-size-and-topology-of-quasi-fatou-components-of-quasiregular-maps/">
        </link>
        <updated>2016-06-07T11:23:12Z</updated>
        <summary type="html"><![CDATA[<p><a href="http://www.ams.org.liverpool.idm.oclc.org/journals/proc/2017-145-02/S0002-9939-2016-13253-X/">Proc. Amer. Math. Soc. 145 (2017), no. 2, 749–763. </a>Also available on the <a href="https://arxiv.org/abs/1601.03308">arXiv</a>. This is a joint work with <a href="http://arxiv.org/find/math/1/au:+Nicks_D/0/1/0/all/0/1">Dan Nicks</a>.<span id="more-164"></span></p>
<p>We consider the iteration of quasiregular maps of transcendental type from <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Ed&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="&#92;mathbb{R}^d" title="&#92;mathbb{R}^d" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Ed&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="&#92;mathbb{R}^d" title="&#92;mathbb{R}^d" class="latex" />. In particular we study quasi-Fatou components, whichare defined as the connected components of the complement of the Julia set.</p>
<p>Many authors have studied the components of the Fatou set of a transcendental entire function, and our goal in this paper is to generalise some of these results to quasi-Fatou components. First, we study the number of complementary components of quasi-Fatou components, generalising, and slightly strengthening, a result of Kisaka and Shishikura. Second, we study the size of quasi-Fatou components that are bounded and have a bounded complementary component. We obtain results analogous to those of Zheng, and of Bergweiler, Rippon and Stallard. These are obtained using techniques which may be of interest even in the case of transcendental entire functions.</p>]]></summary>
        <author>
            <name>Dave Sixsmith – I am a mathematician, not a calculator</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Escaping sets of continuous functions]]></title>
        <id>https://sixsmith2017.wordpress.com/2016/06/07/escaping-sets-of-continuous-functions/</id>
        <link href="https://sixsmith2017.wordpress.com/2016/06/07/escaping-sets-of-continuous-functions/">
        </link>
        <updated>2016-06-07T11:11:25Z</updated>
        <summary type="html"><![CDATA[<p>Accepted for publication by the <em>Journal d&#8217;Analyse Mathematique.</em> Available on the <a href="http://arxiv.org/abs/1601.04010">arXiv</a>. This is a joint work with <a href="http://arxiv.org/find/math/1/au:+Short_I/0/1/0/all/0/1">Ian Short</a>.<span id="more-157"></span></p>
<p>Our objective is to determine which subsets of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Ed&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="&#92;mathbb{R}^d" title="&#92;mathbb{R}^d" class="latex" /> arise as escaping sets of continuous functions from <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Ed&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="&#92;mathbb{R}^d" title="&#92;mathbb{R}^d" class="latex" /> to itself. We obtain partial answers to this problem, particularly in one dimension, and in the case of open sets. We give a number of examples to show that the situation in one dimension is quite different from the situation in higher dimensions. Our results demonstrate that this problem is both interesting and perhaps surprisingly complicated.</p>]]></summary>
        <author>
            <name>Dave Sixsmith – I am a mathematician, not a calculator</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On permutable meromorphic functions]]></title>
        <id>https://sixsmith2017.wordpress.com/2016/06/07/on-permutable-meromorphic-functions/</id>
        <link href="https://sixsmith2017.wordpress.com/2016/06/07/on-permutable-meromorphic-functions/">
        </link>
        <updated>2016-06-07T11:04:13Z</updated>
        <summary type="html"><![CDATA[<p><a href="http://link.springer.com.liverpool.idm.oclc.org/article/10.1007%2Fs00010-016-0426-y">Aequationes Math. 90 (2016), no. 5, 1025–1034<em>.</em></a> Also available on the <a href="http://arxiv.org/abs/1603.07497">arXiv</a>. This is a joint work with <a href="http://arxiv.org/find/math/1/au:+Osborne_J/0/1/0/all/0/1">John Osborne</a>.<span id="more-152"></span></p>
<p>We study the class <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="&#92;mathcal{M}" title="&#92;mathcal{M}" class="latex" /> of functions meromorphic outside a countable closed set of essential singularities. We show that if a function in <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="&#92;mathcal{M}" title="&#92;mathcal{M}" class="latex" />, with at least one essential singularity, permutes with a non-constant rational map <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="g" title="g" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="g" title="g" class="latex" /> is a Möbius map that is not conjugate to an irrational rotation.  For a given function <img src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BM%7D&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="f &#92;in &#92;mathcal{M}" title="f &#92;in &#92;mathcal{M}" class="latex" /> which is not a Möbius map, we show that the set of functions in <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="&#92;mathcal{M}" title="&#92;mathcal{M}" class="latex" /> that permute with <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="f" title="f" class="latex" /> is countably infinite. Finally, we show that there exist transcendental meromorphic functions <img src="https://s0.wp.com/latex.php?latex=f%3A+%5Cmathbb%7BC%7D+%5Cto+%5Cmathbb%7BC%7D&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="f: &#92;mathbb{C} &#92;to &#92;mathbb{C}" title="f: &#92;mathbb{C} &#92;to &#92;mathbb{C}" class="latex" /> such that, among functions meromorphic in the plane, <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=111111&#038;s=0" alt="f" title="f" class="latex" /> permutes only with itself and with the identity map.</p>]]></summary>
        <author>
            <name>Dave Sixsmith – I am a mathematician, not a calculator</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reverse Mathematics of Matroids]]></title>
        <id>http://m6c.org/w/2016/04/reverse-mathematics-of-matroids/</id>
        <link href="http://m6c.org/w/2016/04/reverse-mathematics-of-matroids/">
        </link>
        <updated>2016-04-22T15:27:10Z</updated>
        <summary type="html"><![CDATA[This post is about the paper Reverse Mathematics of Matroids by Jeff Hirst and me. We look at basis theorems for countable vector spaces, countable graphs, and countable enumerated matroids. These three kinds of structures turn out to be extremely &#8230; <a href="http://m6c.org/w/2016/04/reverse-mathematics-of-matroids/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Carl Mummert</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An example with Dedekind cuts]]></title>
        <id>http://m6c.org/w/2016/04/an-example-with-dedekind-cuts/</id>
        <link href="http://m6c.org/w/2016/04/an-example-with-dedekind-cuts/">
        </link>
        <updated>2016-04-19T19:07:48Z</updated>
        <summary type="html"><![CDATA[In this post, I will briefly describe an example in computability theory that is well known, but not easy to find in the literature. It gives one reason why Dedekind cuts are difficult to work with computationally. Theorem. There is &#8230; <a href="http://m6c.org/w/2016/04/an-example-with-dedekind-cuts/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Carl Mummert</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Math on the web; time to step up!]]></title>
        <id>https://www.peterkrautzberger.org/0188/</id>
        <link href="https://www.peterkrautzberger.org/0188/">
        </link>
        <updated>2016-04-18T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>You may have seen <a href="https://www.peterkrautzberger.org/0186/">my previous post</a> on why MathML is a failed web standard and, how, for better or worse, I think the focus needs to be on helping the tools that work on the web today.</p>
<p>The obvious problem is: how should that work? How do we get this small, disparate, and sometimes divided community of math tools for the web to inform web standards and, ultimately, browser development?</p>
<p>Well, it's time to find out.</p>
<p>A couple of people have been working towards a new effort and we've now formed a W3C Community Group. The name may sound funny but it's what this group is after: <a href="https://www.w3.org/community/mathonwebpages">Getting Math onto Web Pages</a>. No fuss, no drama, no limitations. The focus is on how we do this today and how we can make it easier.</p>
<p>So now it's up to us.</p>
<p>If you're a developer of a tool that makes math work on the web today and want to help shape the future, then it's time to step up. I know your resources are probably tight, in fact most projects out there are run by idealists, as side-projects or chronically under-funded. I hear you.</p>
<p>But you built a tool because nothing was getting the job done. Standards? Same thing. We need to <a href="https://discourse.wicg.io/t/welcome-to-specifiction/6">learn about the process</a>, understand what we want to do and what we can do, and ultimately, help build standards that work for everyone. Otherwise, the job won't get done.</p>
<p>So <strong><a href="https://www.w3.org/community/mathonwebpages">join the Community Group</a></strong> and work together to <a href="http://movethewebforward.org/">move the web forward</a> for mathematics and beyond.</p>
<p>Need more information? Here's the initial description from the <a href="https://www.w3.org/community/mathonwebpages">CG homepage</a>:</p>
<blockquote>
<p>There are many technical issues in presenting mathematics in today's<br>
Open Web Platform, which has lead to the poor access to Mathematics in<br>
Web Pages. This is in spite of the existing de jure or de facto<br>
standards for authoring mathematics, like MathML, LaTeX, or asciimath,<br>
which have been around for a very long time and are widely used by the<br>
mathematical and technical communities.</p>
<p>While MathML was supposed to solve the problem of rendering mathematics<br>
on the web it lacks in both implementations and general interest from<br>
browser vendors.</p>
<p>However, in the past decade, many math rendering tools have been pushing<br>
math on the web forward using HTML/CSS and SVG.</p>
<p>One of the identified issues is that, while browser manufacturers have<br>
continually improved and extended their HTML and CSS layout engines, the<br>
approaches to render mathematics have not been able to align with these<br>
improvements. In fact, the current approaches to math layout could be<br>
considered  to be largely disjoint from the other technologies of OWP.</p>
<p>Another key issue, is that exposing (and thus leveraging) semantic<br>
information of mathematical and scientific content on the web needs to<br>
move towards modern practices and standards instead of being limited to<br>
a single solution (MathML). Such information is critical for<br>
accessibility, machine-readability, and re-use of mathematical content.</p>
<p>This Community Group intends to look at the problems of math on the web<br>
in a very bottom-up manner.</p>
<p>Experts in this group should identify how the core OWP layout engines,<br>
centered around HTML, SVG, and CSS, can be re-used for the purpose of<br>
mathematical layout by mapping mathematical entities on top of these,<br>
thereby ensuring a much more efficient result, and making use of current<br>
and future OWP optimization possibilities.  Similarly, experts should<br>
work to identify best practices for semantics from the point of view of<br>
today's successful solutions.</p>
</blockquote>
<p>This work should also reveal where the shortcomings are, from the<br>
mathematical layout point of view, in the details of these OWP<br>
technologies, and propose improvements and possible additions to these,<br>
with the ultimate goal of reaching out to the responsible W3C Working<br>
Groups to make these changes. This work may also reveal new technology<br>
areas that should be specified and standardized on their own right, for<br>
example in the area of Web Accessibility.</p>
<blockquote>
<p>The ultimate goal is to pave the way for a standard, highly optimized<br>
implementation architecture, on top of which mathematical syntaxes, like<br>
LaTeX or MathML, may be mapped to provide an efficient display of<br>
mathematical formulae.</p>
<p>Note that, although this community group will concentrate on<br>
mathematics, many other areas, e.g., science and engineering, will<br>
benefit from (and factor into) the approach and from the core<br>
architecture.</p>
</blockquote>
<p>PS: We've also applied for a CG slot at <a href="https://www.w3.org/2016/09/TPAC/">TPAC 2016</a> in Lisbon for a face-to-face of the CG as well as the opportunity to talk to other groups. Fingers crossed!</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Infinite chess position of game value $\omega^4$]]></title>
        <id>http://normanspace.org/2016/04/14/infinite-chess-position-of-game-value-omega4/</id>
        <link href="http://normanspace.org/2016/04/14/infinite-chess-position-of-game-value-omega4/">
        </link>
        <updated>2016-04-15T03:32:30Z</updated>
        <summary type="html"><![CDATA[<p>We submitted the infinite chess paper for publication a while back, but I forgot to post it.<br />
The link below connects to a page that Joel wrote summarizing the key ideas, which also contains a link to the ArXiv for the full paper.</p>
<p><a href="http://jdh.hamkins.org/tag/infinite-chess/">http://jdh.hamkins.org/tag/infinite-chess/</a></p>]]></summary>
        <author>
            <name>Norman Lewis Perlmutter</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vsauce on cardinals and ordinals]]></title>
        <id>http://karagila.org/2016/vsauce-on-cardinals-and-ordinals/</id>
        <link href="http://karagila.org/2016/vsauce-on-cardinals-and-ordinals/">
        </link>
        <updated>2016-04-09T20:11:11Z</updated>
        <summary type="html"><![CDATA[<p>To the readers of my blog, it should come as no surprise that I have a lot of appreciation to what Michael Stevens is doing in Vsauce. In the past Michael, who is not a mathematician, created an excellent video about the Banach-Tarski paradox, as well another one on supertasks. And now he tackled infinite cardinals and ordinals.</p>

<p>You can find the video here: <a href="http://karagila.org/2016/vsauce-on-cardinals-and-ordinals/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responses to "MathML is a failed web standard".]]></title>
        <id>https://www.peterkrautzberger.org/0187/</id>
        <link href="https://www.peterkrautzberger.org/0187/">
        </link>
        <updated>2016-04-07T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>This blog doesn't see a lot of traffic (funny how that works when you post every  6 months) but I was surprised to see how few responses there have been to &quot;MathML is a failed web standard&quot;, especially from the MathML enthusiasts.</p>
<p>I don't have any analytics on this site beyond what CloudFlare collects passively. There was spike of ~800 unique visitors and then higher-than-usual traffic afterwards, it might not be completely unreasonable to guess that 1000 people opened the post back then -- until somebody posted it to Hacker News today (no link to save your sanity from reading HN comments) so now it's more like 20,000 people have clicked a link to that piece.  Of course, few of those will have read it, fewer still will have carefully read it. My best guess is: 3 people have read it. Does that sound about right?</p>
<p>Most responses were basically &quot;meh&quot; (especially on <a href="https://twitter.com/search?q=mathml">the twitters</a>). <a href="https://twitter.com/stevefaulkner">Steve Faulkner</a> is, of course, to blame for much of that twitter attention (thanks Steve!). I also received a few kind emails with responses, thanks for those. Elsewhere, <a href="http://jessecmckeown.tumblr.com/post/141734737315/musings-on-web-mathml-and-some-of-our">Jesse McKeown</a> wrote a short tumblr; as a former mathematician I'll formally (get it?) object to the use of Gödel's work.</p>
<p><a href="https://medium.com/@PaulTopping/response-to-peter-krautzberger-s-mathml-is-a-failed-web-standard-179ab8ffa24b">Paul Topping's &quot;response&quot;</a> was mostly focused on his own ideas which have little to do with what I wrote. Let me respond to those few points that were about my piece. Let's do this inline.</p>
<blockquote>
<p>The first thing to note in his post is that he says that MathML is a failed <strong>web</strong> standard. By this, I believe he is only saying that it has failed as a language supported by browsers.</p>
</blockquote>
<p>I had hoped my glorious <code>&lt;s&gt;</code> tag was making the point clear. But I guess not.</p>
<blockquote>
<p>He acknowledges that it is in heavy use in education, publishing, and elsewhere but I wish he’d made this distinction a bit more strongly.</p>
</blockquote>
<p>Ignoring the point that I didn't actually mention education (or &quot;elsewhere&quot;), I thought I had fulfilled this &quot;wish&quot; when I wrote: <q>It’s also clearly a success in the XML publishing world, serving an important role in standards such as JATS and BITS. The problem is: MathML has failed on the web.</q>.</p>
<p>I'm not sure how much clearer I can make that distinction -- success here, failure there.</p>
<blockquote>
<p>The browser makers ignore MathML so getting rid of it won’t affect them much. Perhaps Peter is directing his message to the MathML community itself.</p>
</blockquote>
<p>For what it's worth (and before anyone needs to speculate), my piece was very broadly directed at the web community. I was probably looking for readers who follow current trends in browser standards and their development. (Shout out to Chaals!)</p>
<blockquote>
<p>This one’s easy. MathML isn’t implemented in most browsers so its not used.</p>
</blockquote>
<p>That argument seems rather simplistic to me. Looking at any successful new web standard out there today (e.g., picture, flexbox, grid, animation), even a partial, behind-a-flag implementation does not mean the standard is not being used. Instead, there's a positive feedback loop with (often seemingly small groups of) developers. Even at the best of times (e.g., Dave Barton pushing WebKit forward for a year, Fred Wang's crowd-funded months), developer feedback for MathML was (and is) non-existent (cf. my example of serious bugs not even being reported).</p>
<blockquote>
<p>Sure but imagine if MathML specified layout to the level that TeX does.</p>
</blockquote>
<p>This is a) ignoring how badly Presentation MathML does not specify layout (in particular, compared to CSS) and b) a red herring (TeX).</p>
<blockquote>
<p>This might well be the case but what’s the point here? If CSS now has what math layout needs, we’re done, right?</p>
</blockquote>
<p>Yes. That's the main point, actually.</p>
<blockquote>
<p>Perhaps, but even if Presentation MathML provided sufficient semantics, most authors wouldn’t add them. The fact is MathML already provides recommended markup patterns for expressing a lot of math semantics but authors aren’t interested in adding such patterns to their math. Authors generally stop tweaking their math as soon as it looks right and can be read by a fellow human. I don’t think this will change. Even publishers are less and less interested in spending resources on marking up math with the required level of semantics. This won’t change even if MathML added missing semantics constructs and the necessary editing tools were available. Instead, everyone is moving in the opposite direction, spending less and less time and money on careful authoring.</p>
</blockquote>
<p>An elegant straw man argument is still a straw man argument. I did not write about authoring or extending MathML. Good points though.</p>
<blockquote>
<p>Peter acknowledges Neil Soiffer’s work on algorithmically extracting semantic information from Presentation MathML but seems to think it has hit a brick wall.</p>
</blockquote>
<p>Another case of putting words in my mouth. A bit far-fetched this time, since MathJax is actively doing research in this area.</p>
<blockquote>
<p>In technology, when someone has a better idea how to do something they should just do it and let the market decide whether their solution is really an improvement.</p>
</blockquote>
<p>To quote myself:</p>
<ul>
<li><q>Today, lots of tools will let you render mathematics using CSS.</q></li>
<li><q>It’s possible to generate HTML+CSS or SVG that renders any MathML content [...] on the server.</q> [And obviously on the client as well.]</li>
<li><q>Since layout is practically solved [...]</q>.</li>
</ul>
<p>I tried to make a point that CSS and SVG already provide various solutions today. I also tried to make a point that MathML is not used significantly in the wild (except by conversion to HTML/CSS or SVG of course). So it seems to me that I argued that &quot;the market&quot; has chosen these solutions over MathML.</p>
<p>But I guess I wasn't clear enough. Oh well.</p>
<blockquote>
<p>No problem but a lot of work needs to be done first.</p>
</blockquote>
<p>No, see above.</p>
<blockquote>
<p>Peter claims MathML’s mere existence is blocking discussions. What discussions did it block?</p>
</blockquote>
<p>That's a good point even though Paul's piece is a nice example of the point I was trying to make. Calling on the community (who is that again?) to magically fix MathML after 10 years without development instead of making room for successful solutions? That is an elegant block.</p>
<p>Anyway, one problem for me is that many discussions I have in mind happened privately, especially with web standards experts. But that's no excuse for not spending a few minutes thinking about public examples; for some reasons, this example <a href="https://groups.google.com/forum/#!topic/mozilla.dev.platform/96dZw1jXTvM">the discussion on mozilla.dev.platform</a> is the first to come to mind (man, I was feeling righteous back then).</p>
<p>Another example are the specs themselves. The ARIA spec basically has <a href="https://www.w3.org/TR/wai-aria-1.1/#math">a big glaring hole where math should be</a>. Similarly, take a look at the suggestions in the <a href="https://www.w3.org/TR/wai-aria-practices/#math">ARIA best practices</a> spec and the <a href="http://www.idpf.org/epub/301/spec/epub-contentdocs.html#sec-xhtml-mathml-alt">epub3 spec</a>. All of them focus entirely on MathML-based solutions without any reflection on whether these actually work in real life. The ARIA practices spec even discourages working solutions like HTML-math using dubious arguments about the semantics of Presentation MathML. Moving on.</p>
<p>Paul goes on to write about generating semantic information. It's not quite a straw man but nevertheless has little to do with my concerns about exposing semantic information on the web.</p>
<p>To wrap up.</p>
<blockquote>
<p>Of course, Peter doesn’t believe automated semantics recognition can do the job.</p>
</blockquote>
<p>See above.</p>
<blockquote>
<p>Do we want that math to look identically in every browser? I believe the answer is generally “no”.</p>
</blockquote>
<p>I have the impression people generally expect consistent rendering across browsers. But anecdotal evidence is, well, anecdotal.</p>
<p>And that's all folks. I'll add more as they come along.</p>
<hr>
<p>And stay tuned for more.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li>
<p><strong>Don Stolee</strong>, 2016-04-14</p>
<p>Totally agree with your points raised and must admit don't understand all of it.</p>
<p>We are XML publishers out of Australia and use MathML within our markup. We then publish the XML content to our HTML5 eReader (tekReader) and use MathJax to assist with the rendering.</p>
<p>Example here: <a href="http://tekreader.eglootech.com/book/tekReader-Guide#part22#pt22-1-1-h3">http://tekreader.eglootech.com/book/tekReader-Guide#part22#pt22-1-1-h3</a></p>
<p>It seems to work well on modern browsers found on desktops, tablets and smartphones and we have a University in Canada using our reader.</p>
<p>I would hope the XML world does not drop the standard and browsers continue to support, somewhat.</p>
<ul>
<li>
<p><strong>Peter</strong>, 2016-04-14</p>
<p>Thanks for your comment. Tekreader looks very nice.</p>
<p>MathML is clearly a success in the XML world so I don't see it disappearing. I'm not suggesting that anyone should drop MathML if it works for them.</p>
<p>The point I was trying to make was entirely about its role on the web where other tools have made it obsolete (in the sense that it is no longer necessary to have native MathML browser implementations). Since most XML markup is converted to HTML for web delivery (e.g. OASIS tables), I don't see a huge problem in converting MathML to HTML as well.</p>
<p>Does that make sense?</p>
</li>
<li>
<p><strong>Don</strong> 2016-04-14</p>
<p>All good Peter. Thanks for getting back to me. If I may add. I've been providing XML publishing systems since the early 90's (SGML back then). All very monolithic and complex. With the advent of tablets and smartphones I see a trend in marking down XML (I call it dummy down) to HTML5. In fact my business now advocates markup using HTML5 (now with semantics) and do away with all the complexity downstream. Most of the rich markup is never used anyway (aka S1000D).</p>
</li>
<li>
<p><strong>Peter</strong> 2016-04-14</p>
<p>Thanks for the additional comment, Don. I'm far from your level of experience obviously, but I've also heard about this trend. In that context, I often point to <a href="https://www.youtube.com/watch?v=bh2WyI_6c_k">John Maxwell's BiB 2012 talk</a>.</p>
</li>
<li>
<p><strong>Don</strong> 2016-04-14<br>
Awesome! Thanks for sharing. At least I know I am not crazy!</p>
</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What I realized recently]]></title>
        <id>http://karagila.org/2016/what-i-realized-recently/</id>
        <link href="http://karagila.org/2016/what-i-realized-recently/">
        </link>
        <updated>2016-03-30T17:04:42Z</updated>
        <summary type="html"><![CDATA[<p>I recently learned that diamonds are cut and polished with the dust of other diamonds. And I recently realized that success is cut and polished with the dust of failures.</p>

<p>In particular a successful mathematical idea is polished with the dust of the many failed ideas that preceded it. <a href="http://karagila.org/2016/what-i-realized-recently/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MathML is a failed web standard]]></title>
        <id>https://www.peterkrautzberger.org/0186/</id>
        <link href="https://www.peterkrautzberger.org/0186/">
        </link>
        <updated>2016-03-26T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Since I'm expecting more than my <s>1</s> 2 regular readers to read this, let me add a preface. I've been managing the MathJax project for 4 years now. In the last two years, I've also been consulting for publishers regarding math-related workflows, in particular TeX-to-XML and XML-to-web, both on the back and front-end. Not that it says much, but I'm an invited expert on the W3C Digital Publishing Interest Group (shoutout to Jean and Tzviya!) and I also recently left the W3C Math Working Group (to which David had invited me in late 2014). MathML is a big (positive) part of my professional life.</p>
<p>I recently posted a terse -- uhm, shall we say summary? -- of my thoughts on MathML on <a href="https://gitter.im/w3c/a11ySlackers?at=56d6c6ad0bdb886502f6a83b">a11ySlackers</a>; and I promised a blog post. There's now a 6000 word thingie sitting in my drafts which would take months to whip into shape. So I tried again and it now feels both too long and too short; oh well, maybe it leads somewhere, maybe it doesn't.</p>
<p>Needless to say, opinions posted on my personal website are my personal opinions (funny how that works). In particular, they do not reflect the opinions of any of my clients, let alone the team at MathJax. I think they don't particularly help anything or anyone specifically except, perhaps, in encouraging a more open and realistic discussion.</p>
<h2>The gist of it</h2>
<p>MathML is a failed web standard.<sup>*</sup></p>
<p>We can do better, we deserve better.</p>
<p>MathML-in-HTML5 is in the way of that.</p>
<p><small><sup>*</sup>Some people might prefer &quot;browser standard&quot;, as in &quot;a web standard to be implemented natively in the browser&quot; since some web standards do not rely on browser implementations. Also, &quot;natively&quot; as opposed to some web-components hack shipped in a browser.</small></p>
<h2>MathML is a failed web standard</h2>
<p>It doesn't matter whether or not MathML is a good XML language. Personally, I think it's quite alright. It's also clearly a success in the XML publishing world, serving an important role in standards such as JATS and BITS.</p>
<p>The problem is: MathML has failed on the web.</p>
<p>Luckily, many technologies have succeeded and today MathML is neither necessary but also no longer sufficient for math on the web. Instead of one monolithic solution, we have many. We should acknowledge this and move forward towards several newer and smaller standards that actually help developers.</p>
<p>Here are a few reasons that make me say these things.</p>
<h5>1. MathML has not been significantly supported by browser vendors, neither on the spec level nor on the implementation level.</h5>
<p>You might easily think they do (Office! ChromeVox! VoiceOver!) but the browser vendors actually don't. The partial MathML implementations in Gecko and WebKit are entirely the work of volunteers. Largely unpaid, largely unsupervised, largely unaccountable.</p>
<p>Not a single browser vendor has stated an intent to work on the code, not a single browser developer has been seen on the MathWG. After 18 years, not a single browser vendor is willing to dedicate even a small percentage of a developer to MathML.</p>
<p>This is where the story should end, really. But sadly it doesn't. MathML's success in the XML world has kept it alive, but not for the benefit of anyone on the web.</p>
<p>MathML is a poor web standard and it would be better to remove it from HTML 5.</p>
<h5>2. Browser implementations of MathML are not used.</h5>
<p>If you look at publicly <a href="http://webdevdata.org/">available</a> crawler <a href="https://search.nerdydata.com/">data</a>, you'll notice that it's hard to find examples of MathML that aren't behind paywalls. If you look further, you'll hardly find an example where people providing MathML content rely on native MathML implementations; even on Gecko and WebKit they use MathML-to-HTML5 converters. Another indicator is that, despite implementations having subtly deteriorated in the past two years, people aren't even complaining (I mean, WebKit stopped drawing surds (<a href="http://jsbin.com/muhuwuqepo/2/edit?html,output">try this in Safari 8</a>) but apparently nobody cared enough to even file a bug). Actual developer problems are so extreme you can't seriously develop anything slightly advanced with MathML (e.g., Gecko has non-existent or incomplete support for basic APIs such as style, dataset, or event handlers for MathML elements).</p>
<h5>3. Content MathML has failed to provide usable semantics.</h5>
<p>Ok, truth be told, I don't know. The problem is: it's nearly impossible to generate good Content MathML (except with massive manual labor). As far as I know there is not a single significant collection of mathematics encoded in Content MathML out there. It's mainly ephemeral research projects and some hand-crafted projects. That's fine, we need research after all, but that is not a standard fit for the web.</p>
<h5>4. Presentation MathML fails front-end developers because it unnecessarily binds layout features to MathML elements instead of providing a usable set of CSS features.</h5>
<p>Now <code>&lt;mstyle&gt;</code>, <code>&lt;mspace&gt;</code>, <code>&lt;mpadded&gt;</code>, <code>&lt;mphantom&gt;</code>, <code>&lt;menclose&gt;</code>, <code>&lt;mfenced&gt;</code>, <code>&lt;mtable&gt;</code>, <code>&lt;mstack&gt;</code> might sound funny to a web developer but it's a serious problem. The web has found a productive separation of concern. MathML is incompatible with this approach.</p>
<h5>5. MathML fails because it does not specify layout sufficiently.</h5>
<p>MathML assumes an implementor would know or care about the intricacies and traditions of math layout. How do you draw a surd? Not specified. How do you draw a fraction? Not specified. How do you space things? Not specified. [But yes, dear implementor, you should support arcane mathematical layout features like movable limits, operator dictionaries, the subtle spacing and layout difference of inline- and display-style and so forth; you know why they're important, right? RIGHT? And also make sure to implement 5 different approaches to vertical stacking, because, reasons -- kthx, xxo.]</p>
<h5>6. Presentation MathML fails because CSS is slowly implementing all layout features that mathematical layout needs, making it obsolete.</h5>
<p>Today, lots of tools will let you render mathematics using CSS. It's messy but it works everywhere (ok, dear IE7 user, not for you, I'm sorry). The time when MathML implementations would have significantly enhanced web layout features are past.</p>
<h5>7. Presentation MathML fails to provide sufficient semantics.</h5>
<p>Neil Soiffer wrote ingenious heuristics for MathPlayer which makes most people think that Presentation MathML makes mathematics accessible. That's about as accurate as saying OCR means all images with text are actually accessible.</p>
<p>The reality is that even for school-level math you need both high-quality Presentation MathML (which is rare in itself) combined with powerful (but inevitably fallible) heuristics to extract meaningful semantic information; that's acceptable in the short run but not a real solution for mathematical semantics on the web.</p>
<h5>8. The MathML spec is not actively developed.</h5>
<p>MathML has seen no significant activity <a href="https://www.w3.org/standards/history/MathML3">in almost a decade</a>. In the industrial XML world, MathML is a success and people want more features but improvements are not even brought up. It seems nobody wants to jeopardize an adoption on the web. MathML being a web standard is negatively affecting even those users who actually embrace it because MathML is stuck in maintenance mode.</p>
<p>Did you know the MathWG's charter is running out this month? Would you notice if it wasn't renewed and the WG would cease existing? Would you notice if WebKit and Gecko ripped out their MathML implementation tomorrow? I'm not sure many people would.</p>
<h2>What to do next.</h2>
<h5>A) MathML needs to be dropped from HTML 5.</h5>
<p>Many people I've met have the mistaken impression that browser manufacturers have declared an intent to implement everything in the set of standards usually called HTML 5. They have not (even if HTML 5 as a &quot;spec&quot; may strive for that).</p>
<p>I think as long as MathML is in that set of standards, the lame duck argument (&quot;it's a standard!&quot;) will continue to prevent alternative developments that help the actually working solutions for mathematics on the web.</p>
<p>At this point, MathML is effectively preventing mathematics from aligning with today's and tomorrow's web. This is hurting everyone. We need to drop MathML to make room for better standards.</p>
<h5>B) Math layout can and should be done in CSS and SVG. Let's improve them incrementally to make it simpler.</h5>
<p>It's possible to generate HTML+CSS or SVG that renders any MathML content -- on the server, mind you, no client-side JS required (but of course possible). The resulting markup is arguably crap -- it's span soup at its worst and some use cases are difficult to realize. But we've been there with HTML and CSS; people know how to solve this. It got us standards like flexbox and css-grid; it's worth pursuing improvements to those standards that work instead of waiting for Godot.</p>
<p>It's also difficult to write your own math rendering tool. But we need more ideas, not less! It shouldn't be harder to write a simple math renderer in CSS or SVG than it is to write a RWD framework or a vector graphics library.</p>
<p>We don't need Presentation MathML for this even if many projects (like MathJax) use it as an internal format. MathML's failure as a web standard is hurting the web because it is blocking discussions about improving existing standards to help existing mathematics tools on the promise that eventually &quot;MathML will solve everything (tm)&quot;.</p>
<p>I can't see a native MathML approach help to fill these final gaps. What existing rendering solutions need has little to do with what MathML implementations need. We don't need underspecified layout features tied to MathML elements, we need flexible CSS features that are integrated into existing CSS. Most importantly, existing solutions can iterate on partial improvements to ensure that these help layout on the web more generally, not just the needs of one specific mathematical markup language.</p>
<p>We don't need one true approach to math layout, we need flexibility for developers to be innovative and pursue new ways of solving layout problems and expressing mathematical thought on the web.</p>
<p>We need to get together with CSSWG/Houdini TF/etc to work out solutions that help those developers who actually solve the problem of math on the web.</p>
<p>To give a rough idea -- From a MathJax point of view, three areas are difficult in CSS right now (and probably universally for math layout tools on the web):</p>
<ul>
<li>vertical stacking (although flexbox is probably already enough to fix that and CSS Ruby might also be interesting to look at for synergies)</li>
<li>stretchy characters and enclosures (this is the BIG one -- but they're really just fancy borders)</li>
<li>tight character bounding boxes (math layout has stronger requirements on typography than most forms of text but even <a href="https://bocoup.com/weblog/text-rendering">existing technology is problematic</a>)</li>
</ul>
<p>Stretchy things are by far the biggest layout question, if only because they once <a href="http://web.archive.org/web/20150224234431/http://ojanvafai.com/post/mathml-in-webkit">led Ojan Vafai to call</a> math layout fundamentally incompatible with CSS layout. As much as I respect his expertise, that cannot be the answer. It seems unlikely that we can't incrementally reduce the complexity for existing rendering solutions; in any case, it has little to do with MathML.</p>
<h5>C) We need a new approach for exposing semantics.</h5>
<p>Since layout is practically solved (or at least achievable), we really need to solve the semantics. Presentation MathML is not sufficient, Content MathML is just not relevant.</p>
<p>We need to look where the web handles semantics today -- that's ARIA and HTML but also microdata, rdfa etc. Especially ARIA is an extremely urgent problem because it currently ties mathematics entirely to Presentation MathML elements (where it fails) instead of providing a way to enrich all mathematical rendering on the web.</p>
<p>We also need to look beyond the semantics of mathematics into the semantics of mathematics in its applications, e.g., mathematical notation out of physics (units etc), chemistry (isotopes, reactions etc) and biology (trees, graphs etc). We need to find ways to expose this information to assistive technologies, search and other tools.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Talk on Reverse Mathematics and Ramsey Theory]]></title>
        <id>http://m6c.org/w/2016/03/talk-on-reverse-mathematics-and-ramsey-theory/</id>
        <link href="http://m6c.org/w/2016/03/talk-on-reverse-mathematics-and-ramsey-theory/">
        </link>
        <updated>2016-03-18T15:25:34Z</updated>
        <summary type="html"><![CDATA[This is a copy of my notes from a two-hour talk I gave at our local combinatorics seminar about Reverse Mathematics and Ramsey Theory. The audience consisted of our combinatorialists, who are not logicians, and so the talk is intended &#8230; <a href="http://m6c.org/w/2016/03/talk-on-reverse-mathematics-and-ramsey-theory/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Carl Mummert</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Five WH's of Set Theory]]></title>
        <id>http://karagila.org/2016/the-five-whs-of-set-theory/</id>
        <link href="http://karagila.org/2016/the-five-whs-of-set-theory/">
        </link>
        <updated>2016-01-23T11:11:56Z</updated>
        <summary type="html"><![CDATA[<p>I was asked to write a short introduction to set theory for the <a href="https://ests.wordpress.com/">European Set Theory Society</a> website. I attempted to give a short answer to what is set theory, why study it, when and how to study it and where to find resources.</p>

<p>You can find the article on the ESTS' website <a href="https://ests.wordpress.com/resources/">&quot;Resources&quot;</a> page, or in the Papers section of my website. <a href="http://karagila.org/2016/the-five-whs-of-set-theory/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MM70: Travel Grants for Students!]]></title>
        <id>http://karagila.org/2015/mm70-travel-grants-for-students/</id>
        <link href="http://karagila.org/2015/mm70-travel-grants-for-students/">
        </link>
        <updated>2015-12-30T23:17:30Z</updated>
        <summary type="html"><![CDATA[<p>The registration to Menachem Magidor's 70th Birthday Conference is still open!</p>

<p>If you happen to be a student and a member of the Association for Symbolic Logic, you can apply for an ASL travel award. For more information as to how, <a href="http://ma.huji.ac.il/~mm70/#support" target=_blank>please see here</a>. There's just enough time to still submit your request! <a href="http://karagila.org/2015/mm70-travel-grants-for-students/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Goodbye, Oren.]]></title>
        <id>http://karagila.org/2015/goodbye-oren/</id>
        <link href="http://karagila.org/2015/goodbye-oren/">
        </link>
        <updated>2015-12-28T01:04:11Z</updated>
        <summary type="html"><![CDATA[<p>I recently heard the news that Oren Kolman passed away a couple of weeks ago.</p>

<p>Some of you may have known him through MathOverflow as &quot;Avshalom&quot; where he often appeared in the comments with generally useful references, and some of you may have known him in real life as a teacher or a colleague, or a student. Some of you may have even knew him as Eoin Coleman. <a href="http://karagila.org/2015/goodbye-oren/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Michael, you're awesome.]]></title>
        <id>http://karagila.org/2015/michael-youre-awesome/</id>
        <link href="http://karagila.org/2015/michael-youre-awesome/">
        </link>
        <updated>2015-12-09T00:13:05Z</updated>
        <summary type="html"><![CDATA[<p>After so many terrible YouTube videos about math, about four months ago Michael Stevens made a really nice video about the Banach-Tarski (Banach-T-Rex) paradox. This video was made surprisingly well by someone who has little to none formal mathematical education, but certainly the desire and [at least basic] prowess to understand that perhaps things are not as simple in mathematics - especially when infinite objects are involved - and perhaps you can't just drop something on your audience in hope they view you as a magician. Instead, Michael tried to educate the viewers, in a fairly reasonable way, about infinite objects and the preliminaries needed for the Banach-Tarski paradox.</p>

<p>You can find that video right here: <iframe height="315" width="560" src="https://youtube.com/embed/s86-Z-CbaHA" frameborder="0" allowfullscreen></iframe> <a href="http://karagila.org/2015/michael-youre-awesome/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MM70: Registration is now open!]]></title>
        <id>http://karagila.org/2015/mm70-registration-is-now-open/</id>
        <link href="http://karagila.org/2015/mm70-registration-is-now-open/">
        </link>
        <updated>2015-12-02T19:01:29Z</updated>
        <summary type="html"><![CDATA[<p>I am happy to announce, on behalf of the organizing committee, that the registration for Menachem Magidor's 70th Birthday Conference is now open!</p>

<p><a href="http://ma.huji.ac.il/~mm70/#registration"><img src="http://ma.huji.ac.il/~mm70/poster-small.jpg" alt="MM70 Poster"></a> <a href="http://karagila.org/2015/mm70-registration-is-now-open/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cofinality and the axiom of choice]]></title>
        <id>http://karagila.org/2015/cofinality-and-the-axiom-of-choice/</id>
        <link href="http://karagila.org/2015/cofinality-and-the-axiom-of-choice/">
        </link>
        <updated>2015-11-29T22:35:41Z</updated>
        <summary type="html"><![CDATA[<p>What is cofinality of a[n infinite] cardinal? If we think about the cardinals as ordinals, as we should in the case the axiom of choice holds, then the cofinality of a cardinal is just the smallest cardinality of an unbounded set. It can be thought of as the least ordinal from which there is an unbounded function into our cardinal. Or it could be thought as the smallest cardinality of a partition whose parts are all &quot;small&quot;.</p>

<p>Not assuming the axiom of choice the definition of cofinality remains the same, if we restrict ourselves to ordinals and \(\aleph\) numbers. But why should we? There is a rich world out there, new colors that were not on the choice-y rainbow from before. So anything which is inherently based on the ordering properties of the ordinals should not be considered as <em>the</em> definition of an ordinal. So first let's recall the two ways we can order cardinals without choice. <a href="http://karagila.org/2015/cofinality-and-the-axiom-of-choice/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is MathML accessible?]]></title>
        <id>https://www.peterkrautzberger.org/0185/</id>
        <link href="https://www.peterkrautzberger.org/0185/">
        </link>
        <updated>2015-11-15T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Last week I attended an excellent <a href="http://www.studentenwerke.de/de/content/ibs-fachtagung">conference on accessibility in higher education</a>. It was great to get a some insight into where things stand with the German higher-ed community. It also reminded me of something that keeps bugging me this year.</p>
<p>MathML is often presented as the single solution to all math accessibility problems. For example, the <a href="http://w3c.github.io/aria/aria/aria.html#math">ARIA spec</a> says &quot;Browsers that support native implementations of MathML are able to provide a more robust, accessible math experience than can be accomplished with plain text approximations of math&quot;, the <a href="http://www.idpf.org/accessibility/guidelines/">IDPF accessibility guidelines</a> says &quot;[...] a benefit of native MathML support [...] is the ability to provide voicing based on the markup [...]&quot; (ok, they do suggest fallback speech text later only to go on and tell you that annotation-xml will work without, you know, some level of MathML support), even <a href="http://www.aiim.org/Research-and-Publications/standards/committees/PDFUA/Technical-Implementation-Guide">PDF/UA suggests MathML</a>.</p>
<p>While this might seem plausible for authors, I can't shake the feeling that saying &quot;just use MathML&quot; is a bit of a cheat, especially on the web.</p>
<p>On the one hand, there's the reality of the technology landscape. I'm not going to criticize browsers yet again but accessibility happens to include visual rendering (duh!); without it accessibility of mathematics on the web is fundamentally broken. Even more so since ARIA fall short in terms of enabling HTML or SVG rendering of mathematics to be accessible.</p>
<p>On the other, while a growing number of screenreaders happily tout MathML support, there are (please correct me) really just three solutions out there: The new kids are VoiceOver and ChromeVox whose quality might be summarized with &quot;meh&quot; (not terrible but really not yet great in terms of math support or, for that matter, active development of math support). The grand old lady of math accessibility is of course MathPlayer which, I'm guessing, is the origin of the &quot;just use MathML&quot; (&quot;just use MathPlayer&quot;?) attitude for accessibility both because of its quality and because it is what many screenreaders leverage (JAWS, NVDA, Texthelp etc). However, with MathPlayer being pushed out of IE and into the status of a third party library (and integration into screenreaders sometimes lacking) that line of argument is a thing of the past. Practically speaking, there is no real, productive competition today and thus no resources for improvements.</p>
<p>Anyway, the question I've been pondering is: why do most screenreaders rely on external tools rather than implement MathML support themselves?</p>
<p>I suspect the answer is the same as with browsers: because it is too hard to render MathML accessibly. That is, while building on MathML is much better than alternatives (I'm looking at you, TeX), it's still an awful lot of trouble to write a decent (let alone good) MathML accessibility solution. Too much work, too much of a niche, too many other things to do, yadayadayada.</p>
<p>Of course with MathML I mean Presentation MathML since Content MathML is too rare in the wild. Presentation MathML is a very good XML format to canonically represent most traditional (read: print) formula layout and is universally appreciated as an archival format. But Presentation MathML is not &quot;trivially&quot; accessible. Unlike, say, ARIA roles, there is no straight-forward process that will tell you how to, e.g., voice, sensibly explore or highlight a well-written MathML expression (let alone a shoddily-written one). Instead, existing tools end up guessing both the mathematical structure of an expression as well as its semantics.</p>
<p>On the one hand, there's the fundamental problem of context (e.g., to tell whether (a,b) describes an open interval, a point in the plane, or an inner product) and of compression (<a href="http://worrydream.com/KillMath/">Kill Math</a> anyone?). But what's even more confusing about &quot;just use MathML&quot; is that, in fact, Presentation MathML can be pretty semantic -- with elements like <code>mfrac</code>, <code>mroot</code>, or <code>mlongdiv</code>, and things like <code>menclose</code> notation, fences, or the operator dictionary, all of which carry semantics despite Presentation MathML being &quot;just&quot; about layout.</p>
<p>So you might think that's not so bad after all. However, that's only half true. Besides the obvious problem of virtually everything missing in terms of notation, Presentation MathML is somewhat lacking in genuinely neutral layout features. So as an author, you'll have to use those semantic-but-really-layout elements. This way you end up finding suggestions in <a href="http://www.w3.org/Math/draft-spec/mathml.html#chapter3_id.3.3.2.2">the spec itself</a> to use <code>mfrac</code> with <code>linethickness=&quot;0&quot;</code> to represent a binomial coefficient.</p>
<math display="block">
  <mo>(</mo>
  <mfrac linethickness="0">
    <mi>n</mi>
    <mi>k</mi>
  </mfrac>
  <mo>)</mo>
</math>
<p>Which is visually rather similar to doing a construction using an <code>mtable</code> (which might in turn be used to convey a vector/matrix).</p>
<math display="block">
  <mrow>
      <mo>(</mo>
        <mtable>
          <mtr><mtd><mi>n</mi></mtd></mtr>
          <mtr><mtd><mi>k</mi></mtd></mtr>
        </mtable>
      <mo>)</mo>
  </mrow>
</math>
<p>And then you could also hack something together using <code>mstack</code> which might sound like a fundamental math layout element (a vertical stack) but unfortunately is designed only for written addition, multiplication, and division.</p>
<p>As an accessibility tool you need to build in something that allows you to guess the semantic structure. And just to stress this again: not for the horribly broken markup you'll inevitably run into but for <em>high quality, spec-suggested markup</em>.</p>
<p>Don't get me wrong. It's great that such heuristics are actually not impossible for Presentation MathML (as opposed to handling a programming language like TeX) so you can at least cover the educational use cases pretty well. But we're a long way making math accessibility being an average task for screenreaders (which is what it should be, just like visual rendering should be a simple task for a browser). MathML is a step forward for math accessibility but it is, ultimately, a tiny step given the practical problems, especially on the web. Endlessly repeating &quot;just use MathML&quot; is not helping.</p>
<hr>
<p>I feel like I should add a <strong>Disclaimer</strong> to this one. We're currently building an accessibility solution for MathJax based on improvements to ChromeVox's math engine so obviously I'm terribly biased and a horrible person. But you already knew that.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Don't worry about it]]></title>
        <id>http://karagila.org/2015/dont-worry-about-it/</id>
        <link href="http://karagila.org/2015/dont-worry-about-it/">
        </link>
        <updated>2015-11-09T16:37:02Z</updated>
        <summary type="html"><![CDATA[<p>In a recent Math.SE question about the foundations of category theory without set theory, someone made a claim that \(\ZF\) makes it hard to learn mathematics, because in \(\ZF\) the questions &quot;is \(\RR\subseteq\pi\)?&quot; and &quot;is \(\RR\in\pi\)?&quot; can be phrased. They continued to argue that there are questions like whether or not hom-sets are disjoint or not, which are hard to explain to people who are &quot;drunk on ZF's kool-aid&quot;.</p>

<p>So I raised a question in the comment, and got replies from two other people who kept repeating the age old silly arguments of what are the elements of \(\RR\times\RR\) or what are these or that elements. And supposedly the correct pedagogical answer is &quot;It does not matter what are the elements of \(\RR\times\RR\).&quot; With that I strongly agree, and when I taught my students about ordered pairs on the very first class of the semester, I made it very clear that there are other ways to define ordered pairs and that we only do that because we want to show that there is at least one way in which ordered pairs can be realized as sets; but ultimately we couldn't care less about what way they encode ordered pairs into sets, as long it is a &quot;legal&quot; way. <a href="http://karagila.org/2015/dont-worry-about-it/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How do you read a paper?]]></title>
        <id>http://karagila.org/2015/how-do-you-read-a-paper/</id>
        <link href="http://karagila.org/2015/how-do-you-read-a-paper/">
        </link>
        <updated>2015-11-01T10:29:27Z</updated>
        <summary type="html"><![CDATA[<p>Some time ago I was talking to some people about how they read a paper. And I learned that I am somewhat significantly different from a lot of people. I spent some time thinking about it, and I arrived at some interesting conclusions.</p>

<p>So here is how I read a paper, and I'd like to ask you to think about how you read a paper, and why you read it this way. <a href="http://karagila.org/2015/how-do-you-read-a-paper/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The curious invisibility of MathML]]></title>
        <id>https://www.peterkrautzberger.org/0184/</id>
        <link href="https://www.peterkrautzberger.org/0184/">
        </link>
        <updated>2015-10-27T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>By now, my <del>one</del> two readers might consider me a huge flip-flop when it comes to MathML. It's great, it's terrible, it's great, it's terrible etc. Thankfully, nobody reads this so that's not a huge issue that I was recently reminded of a couple of things that keep making me doubt MathML's future on the web. One of them is its invisibility as a web standard.</p>
<p>Around the time when I first came to grips with the part of my job for MathJax which can only be called something horrible like &quot;technology evangelist&quot;, <a href="https://www.webplatform.org/">webplatform.org</a> launched. For a newbie like me this seemed like a big thing. All the big companies involved, supposedly working together, pushing the Open Web Platform, bringing together the best of existing devloper docs (Mozilla, Google, Microsoft etc), creating documentation hackathons etc. This is huge! (No it wasn't.)</p>
<p>So as a new MathJax and thus MathML &quot;evangelist&quot; I was dismayed that MathML was not mentioned in the &quot;hot topics&quot; list on the frontpage (cf. <a href="https://web.archive.org/web/20121008212425/http://webplatform.org/">the Wayback Machine</a>). I remember trying to raise the issue and getting a response literally years later (2014) pointing me to where I should have tried to start a discussion. Recently, I visited the site again, and since <a href="https://web.archive.org/web/20140331033358/http://www.webplatform.org/">its redesign last year</a>, it's a bit clearer where things stand, but still MathML is hard to find.</p>
<p>In fact, I can't find any link to MathML while browsing <a href="http://webplatforms.org/">webplatforms.org</a>. Only the search finally yields a link to the base page for MathML (and the content you'll find starting form there seems to be copied from MDN (which is obviously fine)). But don't worry, even here you'll find <a href="https://docs.webplatform.org/wiki/guides/lesser-known_semantic_elements#Superscript_and_subscript">a little bit of MathML bashing</a>.</p>
<p>So as I came upon <a href="http://webplatform.org/">webplatform.org</a> again recently, I started to wonder why I had given up on approaching such sites. And it's pretty simple: if you look around, it's pretty much the same thing everywhere.</p>
<p>Whether it's the html5-is-cool sites like <a href="http://html5rocks.com/">html5rocks</a> or <a href="http://html5please.com/">html5please</a>, MathML just doesn't show up. General web development sites? Oh look, Smashing Magazine has <a href="http://www.smashingmagazine.com/search-results/?q=mathml&amp;cx=partner-pub-6779860845561969%3A5884617103&amp;cof=FORID%3A10&amp;ie=UTF-8">no mention since 2009</a> and A List Apart has <a href="http://alistapart.com/search?keywords=mathml">one comment in 2013 and even that 2009 article comes with snark.</a>.</p>
<p>I'd give you that <a href="http://caniuse.com/">caniuse</a> lists MathML but even if you can bear the pain of looking at all that red, take a look at its frontpage which lists MathML under &quot;other&quot;, a miraculous category with anything from EOT to strict mode to ShadowDOM; not exactly prime real estate.</p>
<p>Then you cast your net wider and go to <a href="https://www.google.com/alerts">Google Web Alerts</a> and your register to get an alert for MathML, you set it to its widest setting – and what you'll get is almost exclusively a long lists of MathML snippets produced by Springer OA journals, with maybe some MathJax or StackOverflow sprinkled in. Speaking of which, don't go <a href="http://stackoverflow.com/questions/tagged/mathml">search for mathml on StackOverflow</a> because you will only see questions that have next to nothing to do with the web (except that really nice and difficult one that obviously has to have negative votes – yay SO community...).</p>
<p>But maybe you are also interested in other things. Like regular web technologies (you know, the ones that get implemented by browser vendors) or other niche web ecosystems. And then you might just notice some really cool resources in those areas. Can you even imagine something like <a href="https://github.com/philipwalton/flexbugs">flexbugs</a> or <a href="https://github.com/sindresorhus/awesome">an awesome-style GitHub list</a> or the incredible <a href="https://github.com/dvschultz/99problems">99problems</a> for MathML? I admit I can't.</p>
<p>Let's stop here.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Banach-Tarski Banach-T-Rex]]></title>
        <id>http://karagila.org/2015/banach-tarski-banach-t-rex/</id>
        <link href="http://karagila.org/2015/banach-tarski-banach-t-rex/">
        </link>
        <updated>2015-10-21T00:10:16Z</updated>
        <summary type="html"><![CDATA[<p>I had already written about <a href="../../2014/anti-anti-banach-tarski-arguments/">anti-anti-Banach-Tarski</a> arguments. But now the Mathematical T-Rex has something to say too.</p>

<p><a href="../../wp-content/uploads/2015/10/LM-BT.png"><img src="../../wp-content/uploads/2015/10/LM-BT.png" alt="LM-BT"></a> <a href="http://karagila.org/2015/banach-tarski-banach-t-rex/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MathJax font matching and pairing.]]></title>
        <id>https://www.peterkrautzberger.org/0183/</id>
        <link href="https://www.peterkrautzberger.org/0183/">
        </link>
        <updated>2015-09-30T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>In the age old tradition of cross-posting stuff I've written elsewhere.</p>
<p>A while back Tim Arnold, the awesome person behind projects like <a href="https://github.com/tiarno/plastex">plastex</a> and <a href="https://www.npmjs.com/package/mathjax-server">mathjax-server</a> asked the following question on the <a href="https://groups.google.com/forum/#!topic/mathjax-users/Ze2XsPXWz2Q">MathJax User Group</a>.</p>
<blockquote>
<p>I am trying to decide what font to use for MathJax. The TeX font is the default, but I think I remember that the STIX-Web fonts have the best glyph coverage.</p>
<p>I have a lot of math to support on all kinds of browsers. What factors should I consider when choosing the best font to use in MathJax?</p>
</blockquote>
<p>Soon thereafter, fellow Booles' Ringer <a href="http://dcernst.github.io/">Dana Ernst</a> asked me the very same thing. At that point, I was hooked and started this post. It only took me a month to actually get around to finishing it because I wanted to include a basic demo.</p>
<p><strong>tl;dr.</strong> Font pairing is an art, is a pain, is an art. I've cooked up a small example on CodePen that allows you to test Google fonts with various MathJax fonts. Just grab a font name from Google Fonts, paste it in and check out how the available math fonts pair up. For screen-real-estate reasons you might want to head over to CodePen. Easy as that.</p>
<p data-height="268" data-theme-id="0" data-slug-hash="pjzVej" data-default-tab="result" data-user="pkra" class="codepen">See the Pen <a href="http://codepen.io/pkra/pen/pjzVej/">MathJax Font lab</a> by Peter Krautzberger (<a href="http://codepen.io/pkra">@pkra</a>) on <a href="http://codepen.io/">CodePen</a>.</p>
<script async="" src="https://assets.codepen.io/assets/embed/ei.js"></script>
<hr>
<p>It is a complex question because, essentially, font pairing is an art. If you <a href="https://css-tricks.com/sites-for-browsing-type-pairings/">simply look at existing sites that try to help you with this</a>, it's clear that many people are looking for solutions while fully realizing that this is highly arcane design knowledge. Alas, I have no such knowledge. What I can add is that it's also a compromise between overall design and the effects on MathJax functionality. So let me summarize some of the important details.</p>
<p>The biggest limitation is obviously that MathJax only supports a handful of fonts. That's a bummer and we hope to add support for more fonts so if you're savvy and interested in helping out, reach out!</p>
<p>The next thing worth pointing out is that MathJax already goes a long way by matching the ex-height and em-width of the surrounding font, that is the height of <code>x</code> and width <code>m</code>. That's simply best practice but more work on the web.</p>
<p>However, it's usually still important to pair the math font with the surrounding font carefully to avoid disrupting the reader's flow between math and non-math (because ex-height/em-width are often not enough matching, especially for upper case letters). Of course, you could use the math font for the surrounding text to avoid that but most people strongly favor their options for text more (and rightly so, mathematics should always serve the text in my opinion).</p>
<p>(<strong>Edit, 2015-10-01</strong> Davide Cervone had to correct me there. originally this had <em>em-height</em>, <em>height of <code>x</code> and <code>m</code></em>, <em>ex/em-height</em>; D'oh...)</p>
<p>The next important thing is usually another piece of font functionality. That is, most people like to weigh their options with respect to font coverage, i.e., which Unicode points are covered by glyphs in the fonts. For that it's important to consider what happens if MathJax encounters a Unicode point that's not in the glyphs of the configured fonts.</p>
<p>For the default MathJax &quot;TeX&quot; fonts (for historic reasons), there's an additional feature: MathJax supports a wider range of Unicode than the fonts themselves might tell you upon inspection of their glyphs. That's because MathJax builds some characters on the fly (e.g., the TeX fonts do not include a quadruple integral but build it out of two double integrals; similarly for &quot;negated&quot; characters). If I recall correctly, we only do this for the &quot;TeX&quot; fonts (the release that added the additional webfonts was simply sub-par for various unfortunate reasons, I'm afraid, and we never got around fixing it).</p>
<p>Next, MathJax will run through a (pretty complex) fallback chain within the configure fonts (e.g., upright Greek will be substituted with italic Greek because we think that's better).</p>
<p>Next, MathJax will ask the browser for a glyph, i.e, fallback to system fonts. Side fact: this also triggers reflows as MathJax has to measure the actual glyph as best it can (for the configured fonts, we generate the relevant data during production and load them on the fly but there are no browser APIs to get the relevant metrics for unknown fonts/glyphs).</p>
<p>The lack of exact information about an unknown glyph means that the layout can't be as precise as it is with our supported fonts. However, in many situations this is not a huge issue as such glyphs are usually rare and not part of complex layout situations. Then again, e.g., placing sub/supscripts can be affected so your mileage may vary.</p>
<p>The bigger issue (speaking from the complaints we get) is the randomness of the system font. You can control that via the <code>undefinedFamily</code> configuration option of each MathJax output processor. You might then also add a separate webfont for that fallback (well, if you can find one that helps with your content and both fonts for math and text; a tall order usually).</p>
<p>Finally, by testing / pre-processing your content via MathJax-node (for QA or for actual output), you can gather up the information on the missing glyphs for your content.</p>
<p>In the future, we are hoping to find the resources to expand the fallback cascade. The idea is to enable you to specify other supported fonts before the system fonts are used (e.g., use TeX fonts but then be able to fallback to Latin Modern or STIX). This would resolve the problem of measurements / layout quality but adds load (both webfonts and fontmetric data). In that context, we would probably work on simplifying our dev tools so that developers can build their own cascade. Finally, we would also hope to simplify our tools for generating the fontmetrics data, i.e., enable developers to modify a copy of MathJax to use their own in-house fonts. But there are some technical requirements to the fonts and considerations for a smart fallback chain so that's highly non-trivial to set up.</p>
<p>In any case, you can play around with the pen and let me know what you think, either here or on CodePen.</p>
<p data-height="268" data-theme-id="0" data-slug-hash="pjzVej" data-default-tab="result" data-user="pkra" class="codepen">See the Pen <a href="http://codepen.io/pkra/pen/pjzVej/">MathJax Font lab</a> by Peter Krautzberger (<a href="http://codepen.io/pkra">@pkra</a>) on <a href="http://codepen.io/">CodePen</a>.</p>
<script async="" src="https://assets.codepen.io/assets/embed/ei.js"></script>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Thing Explainer Challenge]]></title>
        <id>http://karagila.org/2015/the-thing-explainer-challenge/</id>
        <link href="http://karagila.org/2015/the-thing-explainer-challenge/">
        </link>
        <updated>2015-09-24T18:51:47Z</updated>
        <summary type="html"><![CDATA[<p>Randall Munroe of the xkcd fame has a new book coming up where he explains various concepts using a small repository of &quot;simple&quot; words (this is based on <a href="http://xkcd.com/1133/" target="_blank">this xkcd comic</a>). He recently posted <a href="http://blog.xkcd.com/2015/09/22/a-thing-explainer-word-checker/" target="_blank">this blog post</a>, where he reveals a word checker program that he wrote to help him with the task.</p>

<p>So I figured, why not use this for explaining mathematical theorems. <a href="http://karagila.org/2015/the-thing-explainer-challenge/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Talk on the existence of connected components of graphs]]></title>
        <id>http://m6c.org/w/2015/09/talk-on-the-existence-of-connected-components-of-graphs/</id>
        <link href="http://m6c.org/w/2015/09/talk-on-the-existence-of-connected-components-of-graphs/">
        </link>
        <updated>2015-09-23T21:25:59Z</updated>
        <summary type="html"><![CDATA[This week I am attending a seminar at Dagstuhl on Measuring the Complexity of Computational Content: Weihrauch Reducibility and Reverse Analysis. This post has slides from my talk and some blog-only remarks to expand on them. As the title suggests, &#8230; <a href="http://m6c.org/w/2015/09/talk-on-the-existence-of-connected-components-of-graphs/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Carl Mummert</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Name that number]]></title>
        <id>http://karagila.org/2015/name-that-number/</id>
        <link href="http://karagila.org/2015/name-that-number/">
        </link>
        <updated>2015-09-21T04:21:06Z</updated>
        <summary type="html"><![CDATA[<p>In the best TV show ever produced, Patrick McGoohan plays the mysterious No. Six. He lives in The Village, where former spies are held. The people there are essentially captive, and they all have numbers instead of names. But he is <em>not a number</em>! He is a free man!</p>

<p>We find a similar concept in Zelda's poem &quot;Every man has a name&quot; (לכל איש יש שם), which in Israel is closely associated with the Holocaust and with assigning numbers to people. But alas, we are all numbers in some database. Our ID numbers, employer number, the index under which you appear in the database. You are your phone number, and your bank account number. You are the aggregation of all these numbers. And more. <a href="http://karagila.org/2015/name-that-number/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to solve your problems]]></title>
        <id>http://karagila.org/2015/how-to-solve-your-problems/</id>
        <link href="http://karagila.org/2015/how-to-solve-your-problems/">
        </link>
        <updated>2015-09-05T00:46:48Z</updated>
        <summary type="html"><![CDATA[<p>Anyone who peruses mathematical Q&amp;A sites, or had students come to office hours or send questions via other means (email, designated forums, carrier pigeons, or written on a note tied to a brick tossed into your office) knows the following statement: &quot;I don't know where to begin&quot;, or at least one of its variants.</p>

<p>Richard Feynman, who was this awesome guy who did a lot of cool things (and also some physics (but I won't hold it against him today)), has a famous three-steps algorithm for solving any problem.
<ol>
<li> Write the problem down.</li>
<li> Think. <em>Real</em>. Hard.</li>
<li> Write the solution down.</li>
</ol> <a href="http://karagila.org/2015/how-to-solve-your-problems/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mathematical T-Rex]]></title>
        <id>http://karagila.org/2015/mathematical-t-rex/</id>
        <link href="http://karagila.org/2015/mathematical-t-rex/">
        </link>
        <updated>2015-08-28T21:53:52Z</updated>
        <summary type="html"><![CDATA[<p>Ever explained to a &quot;working mathematician&quot; about the undecidability of the continuum hypothesis? I bet you too had felt like this T-Rex.</p>

<p><a href="../../wp-content/uploads/2015/08/Cohen-CH.png"><img src="../../wp-content/uploads/2015/08/Cohen-CH.png" alt="T-Rex: CH"></a> <a href="http://karagila.org/2015/mathematical-t-rex/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Even closer to the origin!]]></title>
        <id>http://www.dorais.org/news/2015-08-25-even-closer-to-the-origin.html</id>
        <link href="http://www.dorais.org/news/2015-08-25-even-closer-to-the-origin.html">
        </link>
        <updated>2015-08-25T02:44:06Z</updated>
        <summary type="html"><![CDATA[<p>Roughly three years ago, I wrote <a href="/news/2012-06-30-back-to-the-origin.html">Back to the origin</a>, when I came back to Hanover, New Hampshire. I’ve now moved to Burlington, Vermont, which is roughly half way between Hanover and Montréal, Québec, which is my true origin. I’m very happy to start a new position at the <a href="http://uvm.edu">University of Vermont</a>!</p>]]></summary>
        <author>
            <name>François G. Dorais</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some thoughts on Native MathML]]></title>
        <id>https://www.peterkrautzberger.org/0182/</id>
        <link href="https://www.peterkrautzberger.org/0182/">
        </link>
        <updated>2015-08-09T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Do not worry about your difficulties with MathML; I can assure you that mine are still greater.</p>
<p>— <a href="http://en.wikiquote.org/wiki/Albert_Einstein#1940s">not Albert Einstein</a>.</p>
</blockquote>
<p>I have written about why <a href="https://www.peterkrautzberger.org/0175/">I care about MathML</a> and why I care about <a href="https://www.peterkrautzberger.org/0176/">Native MathML</a>. Time to talk about some of the problems I see.</p>
<p>This piece reflects my personal opinion and is not indicative of the position of any project I might work on. It is meant as a conversation starter.</p>
<p>I care very much about MathML and in particular the mission of the W3C Math Working Group <a href="http://www.w3.org/Math/Documents/Charter2006.html">to facilitate and promote the use of the Web for mathematical and scientific communication</a>. Yet, while MathML has succeeded everywhere else, it struggles on the web. That worries me.</p>
<h2>The rise and fall of MathML</h2>
<p>MathML did not start out as an XML language but as the <code>&lt;math&gt;</code> tag in HTML3. It was the browser vendors (Microsoft, Netscape) who rejected it; as a result, <code>&lt;math&gt;</code> went into XML &quot;exile&quot; (where it was immensely successful) and returned to HTML in HTML5.</p>
<p>Still, all OWP technologies stand and fall with the support and adoption from browser vendors. It does not matter how good (or bad) a web standard is or how well it works elsewhere. Browser vendor adoption is the only relevant measure.</p>
<h2>No news is not good news</h2>
<p>It's been two years since I started to write <a href="http://radar.oreilly.com/2013/11/mathml-forges-on.html">&quot;MathML forges on&quot;</a>.</p>
<p>Back then, native browser support seemed to be on the tipping point. Dave Barton had done amazing work on improving Alex Milowski's WebKit code, the deactivation in Chrome seemed to be a hiccup due to one single bug (that already had a fix). It seemed, with a little luck, Gecko/Firefox and WebKit/Safari would have made it to the 80/20 point within a year, hopefully in turn get the Blink/Chrome team to re-enable MathML; then we'd watch as Trident/IE (now Edge) would hurry to integrate the math support from LineServices.</p>
<p>Two years later, Gecko has moved sideways, WebKit has barely moved, Trident/Edge remains a mystery, and Blink is &quot;the villain&quot; (for dropping the WebKit MathML code). MathML is still the only viable markup language for mathematics (recently reaffirmed by its ISO standardization), and yet, native browser support seems just as far away as ever.</p>
<p>Why?</p>
<h2>Who implements native MathML support?</h2>
<p>Gecko's and WebKit's (still quite partial) support has been almost exclusively implemented by volunteer contributors (and mostly unpaid volunteers at that).</p>
<p>Effectively, no browser vendor has ever worked on MathML support in their browser. (Yes, that's a bit unfair to Mozilla devs who are great -- sorry. There are also good people at Apple, Google, Microsoft; still, the companies all fail to invest in MathML browser support.)</p>
<p>The volunteers, on the other hand, come and go. Nobody is able to find significant funding and development is, once again, effectively dead.</p>
<p>At this point, I don't see how we can ever get sufficient native MathML support in browsers; the volunteer method does not work and the vendors remain uninterested.</p>
<h2>Where could we go instead?</h2>
<p>The fact that browser vendors do not implement MathML says virtually nothing about MathML. Studying past discussions, it's clear that there isn't a lot of knowledge about the spec or the requirements of mathematical layout. (Again, this is a little unfair to some Mozilla devs.)</p>
<p>So I see no reason to give up on MathML, let alone math and science notation on the web. Because one thing has not changed: it's still the best markup for math -- and education, industry, and research need a good markup that works on the web.</p>
<p>While I don't think native browser implementations is a realistic goal at this point, I think MathML can still be a trail blazer, especially for scientific notation. It is, after all, a long standing W3C standard and we know it works very well in a browser context (even if you need polyfills).</p>
<p>I think there are two problems we can focus on that are just as useful to move scientific markup (and the web in general) forward:</p>
<ol>
<li>how to do mathematical layout using the web standards that are widely implemented (and how to improve both)</li>
<li>how to expose the underlying markup to all tools that understand it</li>
</ol>
<p>As opposed to native browser support for MathML, both of these are extremely feasible.</p>
<p>For the first, it recently became clear to that modern browsers (IE9+) are actually good enough for layout; that is, you can write converters from MathML to HTML or SVG markup so that the result is stable, i.e., provides the same layout on all browsers (comparable to TeX quality but naturally integrated into the page context). To be clear, this is not (just) about client-side rendering like MathJax (in fact, MathJax does not provide this yet).</p>
<p>The biggest problem is that the necessary markup itself is messy, making it hard to generate (just look at the spans-spans-spans that MathJax currently generates).</p>
<p>But is this unusual? I think this situation is not unlike how grids using Bootstrap or Foundation are overly complicated compared to grids using css-grid layout. Or how doing flexbox-like layout is horribly complicated without flexbox.</p>
<p>I think we should focus on widely implemented standards and work on improving them so that the markup you need for good math layout becomes cleaner and thus easier to generate (both in terms of structure/semantics and performance).</p>
<p>For the second point, looking at the developments of the semantic web, it's obviously not being realized in terms of mandated HTML tags or CSS properties. It is being realized via ARIA roles, RDFa, microdata etc. I'm not saying these approaches work for the semantic structure of MathML (let alone STEM in general) but something along those lines seems achievable.</p>
<p>Frankly, I'm a bit tired of waiting for <del>Godot</del> native browser support for MathML. MathML is frozen because we're all waiting for browsers to catch up. It is simply not happening. Let's look for ways to move forward.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li>
<p><strong>gimsieke</strong>, 2015-08-10</p>
<blockquote>
<p>Nobody is able to find significant funding</p>
</blockquote>
<p>MathJax has managed to attract a significant network of donors. Why don’t they either encourage their “investors” to also invest in native math rendering, or why don’t they use the proceeds to fund native development directly? This shouldn’t be beyond their bylaws.</p>
<ul>
<li>
<p><strong>Peter</strong>, 2015-08-10</p>
<blockquote>
<p>Why don’t they either encourage their “investors” to also invest in native math rendering,</p>
</blockquote>
<p>The &quot;nobody&quot; includes MathJax. Of course, the fact that we failed does not say much. The fact that everybody failed so far, might.</p>
<blockquote>
<p>why don’t they use the proceeds to fund native development directly</p>
</blockquote>
<p>Because then we wouldn't be able to develop MathJax itself.</p>
<blockquote>
<p>This shouldn’t be beyond their bylaws.</p>
</blockquote>
<p>Sure. Neither would be curing cancer.</p>
</li>
</ul>
</li>
<li>
<p><strong>Bruce Miller</strong>, 2015-08-10</p>
<p>Interesting blog post!  I've two comments to make.</p>
<p>Easy one first: I feel like you are unnecessarily harsh on the quality of Gecko's MathML support.  While I understand your pride in MathJax, I'd still put Gecko at 90/10 or better rather than 80/20 or below.  It certainly can use improvement and is more variable, depending on system fonts, etc, and I'd definitely appreciate more official support from Mozilla. But it gets all the essentials and with the right fonts looks virtually as good as MathJax --- and it's blindingly fast in comparison.</p>
<p>This is more than a fanboy stance: I think there's a psychological factor to this as well, when the message seems to be that no matter what is done, it's never good enough.</p>
<p>The second issue is a bit more subtle. On the one hand, you  advocate strongly for MathML; on the other, you propose to focus on &quot;widely implemented standards&quot; for doing mathematical layout. There seems a big ambiguity there: Are you suggesting that authors should create &amp; serve MathML in their web pages and that the way forward is in improving and using the better supported standards as a way of rendering the MathML?  Or are you suggesting using whatever technology is available to render something that looks like math, whether or not the representation is MathML? I suspect the former, hope for it, but whichever stance you take, I'd prefer to see it more explicit.  The ambiguity just feeds the suspicions about MathJax in some and provides an excuse to abandon MathML in others.</p>
<p>Thanks for the thought provoking article;<br>
bruce</p>
<ul>
<li>
<p><strong>Peter</strong>, 2015-08-11</p>
<blockquote>
<p>While I understand your pride in MathJax, [...]</p>
</blockquote>
<p>This post is really not about MathJax. In many ways, the opposite. But the only ones who could claim pride in MathJax would be Davide and Robert; certainly not me.</p>
<blockquote>
<p>I'd still put Gecko at 90/10 or better rather than 80/20 or below</p>
</blockquote>
<p>I've often described Gecko as the baseline for MathML feature support. If you can't make your MathML work in Gecko, you probably shouldn't be using it.</p>
<p>But I also understand why people disagree with that. In my experience, you need to be quite knowledgeable about Gecko's implementation (at least from the outside) to avoid running into layout quirks or missing features; watching the MediaWiki math extension feedback is a good example for this.</p>
<p>Of course, this is nothing special, the same is true about MathJax. But the problem is that no large scale MathML adopter I've ever talked to is willing or able to spend the resource on optimizing their content for Firefox.</p>
<blockquote>
<p>[...] depending on system fonts [...]</p>
</blockquote>
<p>That's not a minor issue though. The switch to MATH tables has brought quite a few problems in terms of layout and more importantly developer burden.</p>
<p>While MATH tables seem to be the way to go, they can only be leveraged by native implementations (and there aren't exactly many fonts with MATH tables, nor would I expect that expensive niche to grow much soon).</p>
<p>This adds to the burden of front end developers who would have to provide two sets of webfonts -- one for Gecko and one for everyone else (i.e., polyfills). It's another case of a good standard being useless because it's not widely implemented. But it's made worse because polyfills cannot leverage it so there's no positive feedback loop.</p>
<blockquote>
<p>it's blindingly fast in comparison.</p>
</blockquote>
<p>Sure. That's why I'm not talking about client-side rendering here but for the generation of HTML with CSS. This includes tools like LaTeXML or pandoc or any XML workflow tool.</p>
<p>(But fun fact: we've seen edge cases of client-side MathJax outperforming Firefox by a clear margin. I got lucky and was able to mention it to Rob O'Callahan personally and <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1139709">Gecko got improvements</a>.)</p>
<blockquote>
<p>I think there's a psychological factor to this as well, when the message seems to be that no matter what is done, it's never good enough.</p>
</blockquote>
<p>I don't think the problem is &quot;never good enough&quot;. MathJax is certainly not &quot;good enough&quot; for many people (in particular in terms of performance, but also layout, feature support etc).</p>
<p>I think the problem is rather &quot;no chance of getting better&quot;. There is no interest from the browser companies; that's what would have to change.</p>
<p>I think even a limited implementation would be interesting if developers had the promise that bugs will get fixed and implementations moved forward. This is not some kind of chicken-and-egg problem, it's simply a failure of browser vendors (and just to repeat myself: not of individual browser developers!).</p>
<blockquote>
<p>Are you suggesting that authors should create &amp; serve MathML in their web pages and that the way forward is in improving and using the better supported standards as a way of rendering the MathML?<br>
Or are you suggesting using whatever technology is available to render something that looks like math, whether or not the representation is MathML?</p>
</blockquote>
<p>Neither and both. Authors should use whatever works for them. If that's asciimath during authoring or even in the final page, that's fine; I don't lose sleep over it. (Just like nobody loses sleep over somebody converting markdown in the page.) I do think that authoring tools and converters should <em>not</em> stop at MathML but think further because waiting for MathML support to come around is not helping.</p>
<p>I would like to see those tools move MathML forward by making it the best markup for rendering math on the OWP. But I'm not thinking of something that &quot;just&quot; looks like math but about HTML or SVG markup that is enriched to be just as powerful as its underlying MathML. That's currently not possible for lack of, e.g., aria roles. But I think wecould quickly get to a point where a fully equivalent &quot;interpretation&quot; (or &quot;transpilation&quot; to use a fashionable term) in HTML or SVG does not require client-side rendering.</p>
<blockquote>
<p>The ambiguity just feeds the suspicions about MathJax in some and provides an excuse to abandon MathML in others.</p>
</blockquote>
<p>This reads like FUD to me.</p>
<p>My piece opens with &quot;This piece reflects my personal opinion and is not indicative of the position of any project I might work on.&quot; This obviously includes MathJax.</p>
<p>MathJax is a MathML rendering engine. I'm proposing to something based on MathML and my hope is to move MathML forward despite the lack of interest from browser vendors.</p>
<p>But if somebody needs an excuse to &quot;abandon&quot; MathML, I'd prefer to convince them by showing them how great MathML is rather than saying &quot;oh, just wait a few more years and browser vendors will finally get it and implement it&quot;. MathML deserves better!</p>
</li>
<li>
<p><strong>Bruce</strong>, 2015-08-12</p>
<blockquote>
<p>This post is really not about MathJax.</p>
</blockquote>
<p>Understood. But really my point was that both Gecko &amp; MathJax, while both imperfect, do pretty decent math typography, at least by the measure of web typography generally.</p>
<blockquote>
<p>Sure. That's why I'm not talking about client-side rendering here but for the generation of HTML with CSS. This includes tools like LaTeXML or pandoc or any XML workflow tool.</p>
</blockquote>
<p>... and ...</p>
<blockquote>
<p>I would like to see those tools move MathML forward by making it the best markup for rendering math on the OWP. But I'm not thinking of something that &quot;just&quot; looks like math but about HTML or SVG markup that is enriched to be just as powerful as its underlying MathML. That's currently not possible for lack of, e.g., aria roles. But I think we could quickly get to a point where a fully equivalent &quot;interpretation&quot; (or &quot;transpilation&quot; to use a fashionable term) in HTML or SVG does not require client-side rendering.</p>
</blockquote>
<p>...</p>
<blockquote>
<blockquote>
<p>The ambiguity just feeds the suspicions about MathJax in some and provides an excuse to abandon MathML in others.</p>
</blockquote>
</blockquote>
<blockquote>
<p>This reads like FUD to me.</p>
</blockquote>
<p>FUD? Perhaps, but the fact that I'm paranoid, doesn't mean that I'm not being followed. :&gt;</p>
<p>MathML offers a representation of math in such a form as to enable: high-quality rendering; accessibility; reuse (especially content). One would have hoped for gradual adoption &amp; implementation of MathML, starting with the aspects that are both &quot;easiest&quot; and most in demand: rendering first; increasing support for accessibility; and eventually support for reuse. That seems to me a critical evolutionary path if true accessibility and reuse of mathematics will ever be achieved.</p>
<p>Alas, math is a niche; generating good MathML and rendering it is non-trivial, content moreso. And, as you point out, browser support seems stalled, at best.</p>
<p>While your proposed solution of improving HTML+CSS, RDF and aria seems practical and innocent, without a strong and simultaneous call for continued improvement of native MathML support in browsers and its generation by authors as well as the actual serving of MathML, there's the danger of undermining that evolutionary path of MathML support. I don't believe that's your intention, but the implication that authors need only serve HTML+CSS for rendering, imagining they'll someday add aria annotation, eliminates the most pressing reasons for wanting MathML in the first place. Reuse of mathematics, or even truly useful accessibility remain mere pipe-dreams.</p>
<p>...</p>
<blockquote>
<p>But if somebody needs an excuse to &quot;abandon&quot; MathML, I'd prefer to convince them by showing them how great MathML is rather than saying &quot;oh, just wait a few more years and browser vendors will finally get it and implement it&quot;. MathML deserves better!</p>
</blockquote>
<p>Thanks; That's what I was hoping to hear. I just want to make sure that message doesn't get lost in the shuffle. If we give the impression that rendering and a modicum of accessibility is &quot;good enough&quot;, we may as well just leverage the browser's improvements in image rescaling, attach little tape-recordings to the images, and call it done.</p>
</li>
<li>
<p><strong>Peter</strong>, 2015-08-12</p>
<p>Thanks, Bruce.</p>
<blockquote>
<p>While your proposed solution of improving HTML+CSS, RDF and aria seems practical and innocent, without a strong and simultaneous call for continued improvement of native MathML support in browsers and its generation by authors as well as the actual serving of MathML, there's the danger of undermining that evolutionary path of MathML support.</p>
</blockquote>
<p>I disagree. As I wrote, I don't see any practical interest from vendors towards implementing MathML. So calling for improvements is pointless -- they are not doing anything.</p>
<p>I'd be thrilled to be wrong and see browser vendors dedicate the necessary resources to MathML development (and maybe join the MathWG to help move the spec forward).</p>
<p>But if I'm not wrong, then &quot;Waiting for Improvements&quot; will be worthy of Beckett.</p>
<p>As much as I care about MathML, I care even more about mathematics on the web. Since native MathML support is not happening, I think MathML needs to evolve into something that can be native. My suggestion voiced here is that it should evolve towards HTML and CSS.</p>
<blockquote>
<p>but the implication that authors need only serve HTML+CSS for rendering, imagining they'll someday add aria annotation, eliminates the most pressing reasons for wanting MathML in the first place.</p>
</blockquote>
<p>I think &quot;eliminates&quot; is misleading. First, I disagree because you cannot &quot;eliminate&quot; what's not there. MathML is not usable on the web (without polyfills) because browser vendors are not supporting it.</p>
<p>Secondly, I disagree because I believe that only MathML will allow us to move towards &quot;HTML as powerful as MathML&quot;.</p>
<p>That's the whole point of this piece, really: imho browser support will not happen, so let's think about ways how the spec (and maybe even the MathWG) can evolve to fulfill its mission.</p>
<p>And I obviously and strongly believe that MathML is the best basis for doing so.</p>
<p>But unless somebody can get browser vendors to dedicate the necessary resources, then I find it unhelpful to sit around and pretend like MathML is working out on the web. Instead, we should think hard about how it can be made to help math and science on the web (without native MathML implementations).</p>
<blockquote>
<p>Reuse of mathematics, or even truly useful accessibility remain mere pipe-dreams.</p>
</blockquote>
<p>Again, I disagree. On the one hand, it is really pretty easy to achieve exposure of the underlying MathML -- just look at what ChromeVox did already years ago with MathJax, leveraging the internal MathML to enable fully accessible exploration of the visual output.</p>
<p>On the other hand, I think &quot;reuse of mathematics&quot; is too broad. I think quite a few use cases that people hope for are unrealistic (e.g., copy&amp;paste has so many challenges on the web, with or without MathML). And the realistic ones (e.g., accessibility, search) can be achieved in HTMLified-MathML (pretty easily, I think).</p>
<p>As much as I care about MathML, I care even more about mathematics on the web. Since native MathML support is not happening, I think MathML needs to evolve into something that can be native. My suggestion voiced here is that it should evolve towards HTML and CSS.</p>
</li>
<li>
<p><strong>Bruce</strong>, 2015-08-12</p>
<blockquote>
<p>As much as I care about MathML, I care even more about mathematics on the web. Since native MathML support is not happening, I think MathML needs to evolve into something that can be native. My suggestion voiced here is that it should evolve towards HTML and CSS.</p>
</blockquote>
<p>Just to be sure I understand, you're suggesting that rather than</p>
<p><code>&lt;mfrac&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mfrac&gt;</code></p>
<p>the &quot;New MathML&quot; would be</p>
<p><code>&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;mi&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;b&lt;/span&gt;&lt;/span&gt;</code></p>
<p>with perhaps a few `style=&quot;...&quot;`` thrown in?<br>
thanks;<br>
bruce</p>
</li>
<li>
<p><strong>Peter</strong>, 2015-08-02</p>
<p>No. But probably for very different reasons than you might think.</p>
<p>But I'm not very interested in discussing technical details here. This is a conversation starter, not a technical document. If MathWG wants to consider this direction, then I think we need to bring together practitioners first. And that's practitioners who deal with rendering MathML in a web context; that's not exactly a strong suit of the WG today.</p>
<p>I also need to slightly correct (or extend) my previous comment to include what I mentioned in the post: I might prefer HTML but I also think SVG should be an equal target. For example, your LaTeXML can already generate SVGs for MathML; why make it less useful than it could be if you already have good underlying data in the form of MathML?</p>
</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is the Continuum Hypothesis a definite problem?]]></title>
        <id>http://karagila.org/2015/is-the-continuum-hypothesis-a-definite-problem/</id>
        <link href="http://karagila.org/2015/is-the-continuum-hypothesis-a-definite-problem/">
        </link>
        <updated>2015-08-07T03:44:55Z</updated>
        <summary type="html"><![CDATA[<p>I am not a Platonist.</p>

<p>In general, while I do find it entertaining to think about god, afterlife, or a concrete mathematical universe, I find more comfort in the uncertainty of existence than I do in the likelihood that my belief is wrong, or in the terrifying conviction that comes along with believing in something (and everyone else is wrong). <a href="http://karagila.org/2015/is-the-continuum-hypothesis-a-definite-problem/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[So that took a while]]></title>
        <id>https://www.peterkrautzberger.org/0181/</id>
        <link href="https://www.peterkrautzberger.org/0181/">
        </link>
        <updated>2015-07-31T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I finally completed the blog migration I started a few months ago. Moving away from WordPress forced me to re-think a few parts and re-work a lot of content by hand. This was tedious but forced a worthwhile bit of introspection.</p>
<h2>Permalinks</h2>
<p>Oh, permalinks. The name is so clean and yet so misleading. WordPress is so forgiving to both admins, authors and visitors. But leaving that paradise is fun, too. At one point I had renamed all posts in a way which led to a site with zero posts; hilarious.</p>
<p>I've switched to the simplest permalink structure -- enumeration. But then the question was: how many digits (I like my numbers to be the same string length)? I ended up with four digits. This is No.181 after 5 years of writing on the web, so it seems rather unlikely I'll reach 9999 in my life time. And if I do, I'd be happy to revisit this (@future self: sorry! it'll be a pain!).</p>
<h2>Comments.</h2>
<p>I've been discussing the changes with Sam over the past few months. The biggest point of disagreement has been comments. Jekyll can't provide comments (obviously) and I am not interested in going back to Disqus (for various reasons). I also had the impression that comments were not doing it for me anymore. The ratio spam / useful comment was about 1000 to 1. Sure, Akismet took care of this and Disqus could, too. In addition, I'd get comments from other places (twitter, g+ or plain email) and since <del>I'm not a cool indieweb dev</del> it's never that many, I manually added them to posts.</p>
<p>In other words, I started to feel like comments are just not that useful anymore (caveat lector: see below) and that having a special technology for it seems overkill.</p>
<p>So for now, I'm going with comments-by-email, with a simple link at the end of each post, prepped with a subject line for you. Comments will then be added by myself. I'm hoping anybody willing to comment is willing to send me an email (anonymous or not). Maybe I'm wrong. I'll also pull in comments from other places (e.g., twitter). There's currently a <a href="http://hypothes.is/">hypothes.is</a> opt-in as well. Not sure if I'll keep it though. Feedback would be nice.</p>
<p>As always, <a href="http://xkcd.com/1357/">xkcd.com/1357</a> applies. If you really feel the need to comment, please do it on your own site.</p>
<h2>Reviewing my content</h2>
<p>Having to do a lot of manual editing of my own work was a healthy experience. Yes, it drained time and varied from cringeworthy to depressing. But it also showed me that, once in a while, I still like my old writing. It also showed me some horrible crap, including one troll post which I'm keeping to remind me never to troll again. I hope it's the only one 😞.</p>
<p>I was surprised about the number of comments. One reason to go with email comments was the general lack of comments. Why keep extra technology on the site when I only get spam comments? But I admit I was surprised by the many (real) comments I have from my postdoc days and especially from other Booles' Ringers and mathblogging folks. You people are the best!</p>
<p>Oh, and it took me a while to realize that I had actually been on Jekyll before moving to WordPress. Guess that means I'm going back to WordPress in a few years. (@future self: again, very sorry! Let's wait until we hit 9999 posts, ok?) One thing I regret losing is the post-specific history from WordPress; couldn't get that to survive this migration (but will back the database up for myself). Hopefully git will improve this (with some auto-committing).</p>
<h2>Broken links</h2>
<p>With Jekyll I switched on <a href="https://travis-ci.org/pkra/peterkrautzberger.org">some basic CI</a> (thanks, Travis CI!), including html-proofer. With ~1000 links right now, it's no surprise that some of them are dead. Fixing the internal ones along the way of my review was easy enough. And for the rest (but not that many), I used the <a href="https://archive.org/web/web.php">Wayback Machine</a>; a handful are actually lost forever.</p>
<p>What was surprising to me was which links needed the Wayback Machine. It's not surprising that some random app on appspot goes down. But something on <a href="http://harvard.edu/">Harvard.edu</a> or <a href="http://publishers.org/">publishers.org</a>? That's somewhat funny (and painful). Small niche blogs? They were solid. You are all awesome!</p>
<h2>What's next</h2>
<p>Being on such a long hiatus (also caused by having other writing projects that bled me out), I want to get back into writing here. Since this site is now a git repo, you can file bugs on the <a href="https://github.com/pkra/peterkrautzberger.org">GitHub copy</a> but also fin ideas for posts I put down as issues.</p>
<p>I was thinking about some technical posts on math on the web. And there's one post that's been in the works for months; I should finish that one. Or give it a few more months maybe; you know how these things go.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Blurbs!]]></title>
        <id>http://karagila.org/2015/blurbs/</id>
        <link href="http://karagila.org/2015/blurbs/">
        </link>
        <updated>2015-07-29T21:08:59Z</updated>
        <summary type="html"><![CDATA[<p>I don't like social media very much. I never really subscribed to the whole Friendster, MySpace, Facebook, Twitter, Google Wave, Google+, and what have you social network sort of approach that you need to have &quot;friends&quot; and &quot;followers&quot; and &quot;follow&quot; other people.</p>

<p>I always preferred to be the master of my domain. The king of my castle. But literally, not the Seinfeld euphemisms sense. In any case. I've been thinking about a page where I can post short thoughts about math, life and otherwise. The blog is not suitable, since I'm not going to add a post each time I have a new thought. So instead I've started a blurbs page. Each blurb has a number, and an anchored link that you can use in case you want to share it. <a href="http://karagila.org/2015/blurbs/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Young Set Theory 2015]]></title>
        <id>http://karagila.org/2015/young-set-theory-2015/</id>
        <link href="http://karagila.org/2015/young-set-theory-2015/">
        </link>
        <updated>2015-07-20T00:34:17Z</updated>
        <summary type="html"><![CDATA[<p>Have you heard? Young Set Theory 2015 will take place in Jerusalem! How exciting is that?
Tomorrow (Monday, July 20th) is the last day for registration. This means that you have only a few hours to get yourself together and send an application!</p>

<p>If you are not <a href="http://settheory.mathtalks.org/yst2015/">on this list</a>, you better hurry up to <a href="http://www.as.huji.ac.il/schools/math19/application">this application form</a> and register! Come on, what are you waiting for??? <a href="http://karagila.org/2015/young-set-theory-2015/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The rules of research]]></title>
        <id>http://karagila.org/2015/the-rules-of-research/</id>
        <link href="http://karagila.org/2015/the-rules-of-research/">
        </link>
        <updated>2015-07-08T02:27:49Z</updated>
        <summary type="html"><![CDATA[<p>Here are the rules of research. Feel free to add your own.</p>

<p><ol>
    <li>If it seems obvious, it's probably false as stated.</li>
    <li>If it seems obvious and true, it's probably false without additional hypotheses.</li>
    <li>If you think that you wrote a proof, you probably missed something obvious. See (1) and/or (2).</li>
    <li>You missed something obvious, see (1).</li>
    <li>When you go to see your advisor, suddenly all your thoughts align, and you find the solution.</li>
    <li>Two hours after finally talking with your advisor, you realize that your solution is obvious, therefore (1) or (2) apply.</li>
    <li>If you use forcing to prove the argument, then you probably missed some object being encoded generically.</li>
    <li>If you use forcing, and you didn't miss some crucial object, then you missed some other crucial object not being coded by the generic.</li>
    <li>When the truth is found to be lies, and all the joy within you dies...</li>
    <li>It's not false if you can force it.</li>
    <li>It's not true if you used the axiom of choice more than three times in the proof.</li>
    <li>It's not cheating if you asked a visitor to the university whose visit did not span longer than two weeks from the moment you asked them.</li>
    <li>If your question was about inner models, you may extend the above timespan to a month. Equally, if the question is about the axiom of choice, it should be shortened to a week.</li>
    <li>It's not considered unethical to make sacrifice in order to appease Mayan and Aztec gods. Just in case we got it wrong, and they're in charge of the mathematical universe.</li>
    <li>If it still seems obvious, you're probably right. It's still false, though.</li>
    <li>If you need six technical lemmas, whose proof is reduced to a single line (or just one lemma with an actual proof), then it's probably obvious. Unfortunately, see (1) and (2).</li>
    <li>If by some chance something is obvious, but you wrote out the proof, and it checks out, then it wasn't obvious at all.</li>
    <li>Remember what the dormouse said: feed your head.</li>
    <li>If you haven't watched Futurama in a while, then you're doing something wrong.</li>
    <li>Whatever happens, it's the other guy's fault. Also, see (1).</li>
    <li>I just work here, you know? I don't.</li>
    <li>Rolling a D20 die to determine the truth value of a statement is the original algorithm behind proof verification software.</li>
    <li>When you hit the wall, and you're about to give up and decide that whatever you're trying to prove is false, see (4).</li>
    <li>The only proofs that write themselves are obvious proofs. If your proof is obvious, see (2) and (3).</li>
    <li>To be honest, it needs more cowbell.</li>
    <li>Seriously, you're gonna want that cowbell in your proof.</li>
    <li>See (1), (2) and (4).</li>
</ol> <a href="http://karagila.org/2015/the-rules-of-research/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When the box means nothing]]></title>
        <id>http://karagila.org/2015/when-the-box-means-nothing/</id>
        <link href="http://karagila.org/2015/when-the-box-means-nothing/">
        </link>
        <updated>2015-05-26T09:44:43Z</updated>
        <summary type="html"><![CDATA[<p>When assuming the axiom of choice the product topology and box the topology are quite different when considering infinite products. For example the Tychonoff product of countably many sets of three elements is compact, metrizable an all in all a very nice space. On the other hand, the box product is not separable or second countable at all.</p>

<p>But without the axiom of choice the world is indeed a strange place. This was posted as answer <a href="http://math.stackexchange.com/a/1299027/622">on math.SE</a> earlier today. <a href="http://karagila.org/2015/when-the-box-means-nothing/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[I need your help!]]></title>
        <id>http://karagila.org/2015/i-need-your-help/</id>
        <link href="http://karagila.org/2015/i-need-your-help/">
        </link>
        <updated>2015-05-08T14:51:39Z</updated>
        <summary type="html"><![CDATA[<p>The account has been suspended, I'd like to thank everyone who helped! I have removed the comments posted by &quot;Isa Bria&quot; after the real Isa Bria has contacted me and asked to remove them.</p>

<p>We have verified, in the meantime, that the same person impersonating me on Quora is the one who used Isa's name in those comments. <a href="http://karagila.org/2015/i-need-your-help/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A problem and a possible solution]]></title>
        <id>http://karagila.org/2015/a-problem-and-a-possible-solution/</id>
        <link href="http://karagila.org/2015/a-problem-and-a-possible-solution/">
        </link>
        <updated>2015-05-06T08:41:26Z</updated>
        <summary type="html"><![CDATA[<p>So closing in on my third year, and in theory I should finish my dissertation by next summer. This means that I should probably start the writing process around April (I'm a fast writer, what with having a quality keyboard and knowing LaTeX quite well).</p>

<p>But if I want to be sure that I can finish next year, I should probably omit one of the problems I originally wanted to solve; and keep that for later, unless it turns out to be particularly simple when I finish the rest. <a href="http://karagila.org/2015/a-problem-and-a-possible-solution/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Torture of Mathematical Research]]></title>
        <id>http://karagila.org/2015/the-torture-of-mathematical-research/</id>
        <link href="http://karagila.org/2015/the-torture-of-mathematical-research/">
        </link>
        <updated>2015-04-22T07:12:02Z</updated>
        <summary type="html"><![CDATA[<p>In a manner more befitting to Edgar Allan Poe, Mathematics is a cruel and unforgiving mistress.</p>

<p>Mathematics will often dangle in front of you some ideas, and you will work them out, to find a mistake. Then you will go back to the beginning, find new ideas that she had in store, work those out and proceed only to find a mistake much later. Then you go back to the beginning, and you find yet another minor idea that was missing, and now when everything works you continue. But then you find another gap, and you have to go back to the beginning and hope to find yet another idea. And don't get me started on those ideas that you find not to work during all these searches. <a href="http://karagila.org/2015/the-torture-of-mathematical-research/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Here we go again]]></title>
        <id>https://www.peterkrautzberger.org/0180/</id>
        <link href="https://www.peterkrautzberger.org/0180/">
        </link>
        <updated>2015-04-21T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Oh well. What can I say. New site, yadayada. It had to happen some time.</p>
<p>Switching back to a static site generator. Jekyll, which took me a while to decide on. In the end, <a href="http://partiallyattended.com/2015/02/04/the-70-90-rule/">Ian Mulvany</a> rang true. Jekyll is trivial to set up (I'm using <a href="http://getpoole.com/">Poole</a>/<a href="http://lanyon.getpoole.com/">Lanyon</a>), hosting on GitHub pages, some simple CI via Travis).</p>
<p>I thought about exploring other static-site generators (in particular JS-based ones) but, in the end, Jekyll is <em>the</em> static-site generator so it's easy to switch to and from if I need to.</p>
<p>I'm not yet going to switch the old site over since I have yet to properly import the older content, set up redirects etc.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Talking, really, about work]]></title>
        <id>https://www.peterkrautzberger.org/0179/</id>
        <link href="https://www.peterkrautzberger.org/0179/">
        </link>
        <updated>2015-04-12T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Yesterday I was driving up to Northeim to pick up some Sandkastensand (because people had actually cleaned out the other store's 150 25kg packs -- are you kidding me). While in my car, I was listening to <a href="http://www.deutschlandfunk.de/schriftstellerin-susan-kreller-die-kinder-nicht-alleine.1202.de.html?dram:article_id=316765">this conversation on DLF</a>, featuring a writer notable for her children's books. I didn't know her though I'll try to get my hands on her collection of new translations of English poems (for children).</p>
<p>What struck me about the conversation was the nature of the discussion. I suppose a good example was a ever so slightly sharp turn in the conversation when it came to the translation of a Lewis Carroll poem which, in its new translation, featured a Porsche -- an anachronism that met criticism from the host.</p>
<p>What caught my ear was how these two talked eye-to-eye, the host displaying in-depth knowledge not only of literature in general but the guest's work in particular. This allowed them to discuss how the writer worked, the real essence of her work, the challenges, the modus operandi. (What also made me wonder was the precarity of the writer; the collection came out of her PhD work, the first book seemed only a success in so far as it landed her some prize/stipend that allowed her to write the second book. Literary careers always sound like scientific research careers, yet we keep things separated.)</p>
<hr>
<p>I've always yearned for the equivalent of an art critic (which the host evidently provided) but for math and science. One of my first blog posts ever was about mediocrity and, in may ways, critics are the perfect example of why mediocrity is [pun not averted] critical. Instead of pretending to pursue &quot;high&quot; art/science/math a critic is helping their field by providing constructive (and when necessary destructive) review. In public. We do not have this for STEM. Yet the discussion between those two was as esoteric to me as a discussion about forcing axioms or JavaScript libraries would be to them. Of course, German Feuilleton (oh my, I had no idea about <a href="https://en.wikipedia.org/wiki/Feuilleton">contemporary meaning in French</a>) assumes none of its work is esoteric but features 0% of real science criticism (let alone math).</p>
<hr>
<p>Skip back a few years. My only comment left on <a href="http://carta.info/">Carta.info</a> (no link because I can't find it and because carta has become quite strange) was a foolish, troll-like comment (confirming <a href="https://en.wikipedia.org/wiki/Hanlon%27s_razor">Hanlon's razor</a>, it was out of stupidity) where I wondered why <a href="http://www.deutschlandfunk.de/aktuelle-presseschau.354.de.html">DLF's Presseschau</a> never included quotes from blogs, since I clearly had (and have) the impression political bloggers are on par with those strange, small-town newspapers that make it into that selection of op eds. (IIRC, there's now some minor tech segment on DLF that features some blog posts; oh well.)</p>
<hr>
<p>Over the past year I started to listen to more and more podcasts, primarily about web technology, i.e., work (it all started with the excellent <a href="http://shoptalkshow.com/">Shoptalkshow</a>). Listening to the conversation on DLF, I realized two things. First, technology podcasts provide just that criticism for web technology. While it's often infantile, it's equally often profoundly useful. As usual, web tech is trying to skip an old medium; a loss for both sides.</p>
<p>Still, during the DLF conversation yesterday I realized that I need to look for another kind of technology podcast: one about actual code. That is, where developers talk about their approach to programming, problem solving, how various tools do their job, and who knows, maybe even actively review code. In other words, a podcast that does for web tech what the DLF piece yesterday might do for writers. Maybe streaming things like <a href="http://twitch.tv/">twitch.tv</a> (and perhaps <a href="http://livecoding.tv/">livecoding.tv</a> if it ever goes [pun not averted] live) will fill the gap naturally. Still, I'll have to hunt around some time.</p>
<p>Thinking back to mathematics, the podcasts I tried do not fill that gap. There are really good ones out there but they are not on the level of that DLF conversation or on the level of technology podcasts. They always seemed to be more interested in news, puzzles etc rather than challenging the listeners and the experts alike. Which reminds me, I should try to pick up Vilani's book.</p>
<hr>
<p>Later it smelled like Sommerregen. And everything was well.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Turning Green!]]></title>
        <id>http://karagila.org/2015/turning-green/</id>
        <link href="http://karagila.org/2015/turning-green/">
        </link>
        <updated>2015-03-17T00:16:14Z</updated>
        <summary type="html"><![CDATA[<p>Well, it's that special day of the year again. The holiest of days. The day we celebrate the patron of alcohol enthusiasts, Saint Patrick. 
So raise your whiskey glasses (my recommendation is Jameson 12 for those with deep pockets; Kilbeggan for those with shallow pockets), your Guinness pints, and wear green. Because tomorrow is all about soaking your brains in ethanol while listening to Irish folk songs, Irish punk rock (Thin Lizzy and Flogging Molly, for example) and other drinking songs. <a href="http://karagila.org/2015/turning-green/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Existentialism II, like Colonel Kurtz]]></title>
        <id>http://karagila.org/2015/existentialism-ii-like-colonel-kurtz/</id>
        <link href="http://karagila.org/2015/existentialism-ii-like-colonel-kurtz/">
        </link>
        <updated>2015-03-11T00:34:48Z</updated>
        <summary type="html"><![CDATA[<p>Last night I posted a strange story about a gecko and a moth.</p>

<p>It occurred to me today that this is a very Kurtzian story, if we take the Brando interpretation of Mistah Kurtz (he dead) in Apocalypse Now! (the Redux version is one of my favorite movies, I guess). In the movie Harrison Ford plays a tape where Kurtz is describing a snail crawling along the straight edge of a razor, crawling slithering, this is his dream, this is his nightmare. <a href="http://karagila.org/2015/existentialism-ii-like-colonel-kurtz/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Existentialism]]></title>
        <id>http://karagila.org/2015/post-post-modern-existentialism/</id>
        <link href="http://karagila.org/2015/post-post-modern-existentialism/">
        </link>
        <updated>2015-03-10T00:34:26Z</updated>
        <summary type="html"><![CDATA[<p>Spring has begun in Israel.</p>

<p>Yesterday was the first day where you could say that the weather is characteristically spring; and today (as well tomorrow) we are expected for a daytime heatwave and a nighttime cold weather (e.g. Beer-Sheva is expecting a whopping 31 degrees centigrade during the day, and 13 during the night). <a href="http://karagila.org/2015/post-post-modern-existentialism/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Excited after the first day of teaching]]></title>
        <id>http://normanspace.org/2015/03/04/excited-after-the-first-day-of-teaching/</id>
        <link href="http://normanspace.org/2015/03/04/excited-after-the-first-day-of-teaching/">
        </link>
        <updated>2015-03-04T19:45:06Z</updated>
        <summary type="html"><![CDATA[<p>Today was my first day of teaching for the spring semester. I have a very different schedule this semester from last semester. Last semester, I had three courses, and I had requested that they be restricted to two days per week so that I wouldn&#8217;t have to come in as many days. In previous years at other institutions, that strategy had worked well to help me organize my time. However, I never taught more than two courses at once. Here at LaGuardia, teaching three long classes on the same day proved to be overwhelming, especially considering that I had to move my office hours to a third day and often ended up coming in a fourth day anyway to attend meetings, grade, prepare course materials, or do administrative work. </p>
<p>So I am happy that I have only one course each day this semester. I am teaching two courses this semester. Precalculus (Math 200) meets on Tuesdays and Thursdays at 8AM, and Elementary Algebra (Math 96) meets on Mondays and Wednesdays at 9:15 AM. (Each class meets with me a total of five hours per week.) Then on Fridays I have the set theory seminar at 10AM at the Graduate Center, or occasionally a faculty seminar at LaGuardia at 9AM where we will prepare to teach a seminar for first year LaGuardia students. I think that will be cool, because I really enjoyed my first year seminar as an undergraduate student at Grinnell. </p>
<p>This morning schedule is a big change for me; I have been a total night owl for the last seven years at least, rarely getting up much before noon. But I think it will be good for my health to wake up more with the sun. It might be a rough adjustment period, but it will be worthwhile. As a bonus, if all goes well, I can leave work by mid to late afternoon most days and be able to go out in the city some weekday evenings for dinner or a show. (If all doesn&#8217;t go well, I&#8217;ll be buried in grading, course preparation, administrative work, etc. and rarely get out of here until late anyway. But I am optimistic that it will be better than that.) Another nice benefit to the schedule is that I can conveniently make myself available for 45 minutes worth of office hours four days per week, so that students have a better opportunity to see me.</p>
<p>The elementary algebra students seem like a good group. They really seemed to appreciate the activity of sharing their feelings towards math and their expectations for the course. The videos didn&#8217;t seem to be as effective; only a few students commented on them, but the initial discussion before the videos was quite fruitful. A few students told me that they hate math, but many, I think a majority though I didn&#8217;t count, came in with positive attitudes towards math. Now it is my responsibility to help them to maintain these positive attitudes and to work hard and succeed in the class. I&#8217;m up for the challenge. </p>]]></summary>
        <author>
            <name>Norman Lewis Perlmutter</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[catch my post at the Wiley Exchanges blog]]></title>
        <id>https://www.peterkrautzberger.org/0178/</id>
        <link href="https://www.peterkrautzberger.org/0178/">
        </link>
        <updated>2015-03-02T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>It's been quiet around here -- too much work behind the scenes -- BUT you can still read some of my usual incessant babbling over at the <a href="http://exchanges.wiley.com/blog/">Wiley Exchanges Blog</a> where I write about MathML and its role in <a href="http://exchanges.wiley.com/blog/2015/03/02/making-math-and-science-first-class-citizens-on-the-web/">Making math and science first class citizen's on the web</a>.</p>
<hr>
<blockquote>
<p>For posterity, here's the version I submitted, including typos</p>
</blockquote>
<h1>Making math&amp;science first-class citizens on the web</h1>
<figure>
  <a href="http://www.keepcalm-o-matic.co.uk/p/keep-calm-and-love-math-and-science-2/">
    <img alt="Keep Calm and Love Math and Science" src="https://www.peterkrautzberger.org/assets/2015/keep-calm-and-love-math-and-science-2.png">
  </a>
  <figcaption>
     © keepcalm-o-matic.co.uk
  </figcaption>
</figure>
<blockquote>
<p>Without mathematics, there's nothing you can do. Everything around you is mathematics.<br>
<a href="https://en.wikipedia.org/wiki/Shakuntala_Devi">Shakuntala Devi</a></p>
</blockquote>
<p>It has always surprised me a little that the web -- created at CERN by a trained physicist turned computer scientist -- was born without much consideration for math and science. Of course, it isn't all that surprising since the original HTML lacked more basic things (such as support for tables or images). Either way, people did see the need early on and in 1995 <a href="http://www.w3.org/MarkUp/html3/maths.html">the draft of HTML 3 proposed a <code>&lt;math&gt;</code> tag</a>, adding basic math support in HTML. Unfortunately, HTML 3 was rejected by browser vendors, and its more fortunate successor, HTML 3.2, <a href="http://en.wikipedia.org/wiki/HTML#HTML_versions_timeline">dropped the <code>&lt;math&gt;</code> tag</a> (among other things). As was the fashion of the time, the <code>&lt;math&gt;</code> tag was turned into a separate XML specification and within a year <a href="http://www.w3.org/TR/1998/REC-MathML-19980407/">MathML was born</a>. Problem solved? Not quite.</p>
<p>MathML did turn out to be hugely successful in the XML world. Authoring and conversion tools quickly made MathML easy to create and edit while publishers adopted MathML in their XML workflows. The main reason was that MathML provided a robust, exchangeable, and reusable format for rendering and archiving equational content. However, XML did not succeed as much on the open web and the XML legacy made it difficult to use MathML in HTML itself. This meant that mathematics (and in extension scientific notation) remained a second-class citizen. Surprisingly, MathML did not simply fade away like other web standards but made a comeback in HTML 5, where we can now use like any other tag. Problem solved? Not quite.</p>
<p>Despite its success, its rich ecosystem, and its importance for research and education, MathML continues to struggle on the most critical front: browser adoption. So far, not a single browser vendor has actively developed their MathML implementation. While Internet Explorer and Chrome lack MathML support entirely, Firefox and Safari at least accepted code contributed by volunteers (and in Mozilla's case actively supported the code base). To compensate, the <a href="http://www.mathjax.org/">MathJax</a> project (disclaimer: which I work for) developed an open-source JavaScript solution that authors and publishers can easily drop into their content. MathJax renders MathML on the fly, providing high-quality output that works everywhere out of the box, using only web standards such as HTML and CSS. A joint venture of the <a href="http://www.ams.org/">American Mathematical Society</a> and the <a href="http://www.siam.org/">Society for Industrial and Applied Mathematics</a> with the support from <a href="http://www.mathjax.org/#sponsors">numerous sponsors, including Wiley</a>, MathJax has become the gold standard for math on the web with our free CDN service alone registering 35 million daily visitors. Problem solved? Not quite.</p>
<p>While we are proud of our accomplishments at MathJax, we know that we can only provide half the solution: native browser support must be the goal. Only native browser support can make MathML universal, helping everyone and allowing people to push the envelope for math and science on the web further. I believe a crucial role lies with publishers. Taking a cue <a href="http://www.forbes.com/sites/techonomy/2011/11/30/now-every-company-is-a-software-company/">from Forbes</a>, now every publishing company is a web technology company. Not being involved in the development and implementation of web standards is a bit like printing books but not caring about literacy rates -- if you build it, they still can't come! When it comes to the development of the web, scientific publishers can become the bridge between authors and standards bodies and they can be instrumental in supporting the development of tools and processes that push everyone forward. Problem solved? Not quite but if you build <em>this</em>...</p>
<p>The re-integration of MathML into HTML5 was a huge step towards math and science becoming first class citizens on the web. MathML is not only a fully accessible exchange format for mathematics but it is also part of other scientific markup such as the <a href="https://en.wikipedia.org/wiki/Chemical_Markup_Language">Chemistry Markup Language</a> and the <a href="https://en.wikipedia.org/wiki/CellML">Cell Markup Language</a>. The future of MathML in browsers will determine the future of scientific markup on the open web. In the end, a chemical reaction or a data plot has no more reason to be a binary image than an equation -- we need markup that is alive in the page and can adapt to the needs of the users. Only this will allow us to develop new forms of expressing scientific thought, forms that are leveraging the full breadth of the open web platform, that are truly native to this amazing medium called the web. And that would be an exciting problem to have.</p>
<hr>
<blockquote>
<p>The comments were also interesting.</p>
</blockquote>
<ul>
<li>Kaveh Bazargan • 23 days ago</li>
</ul>
<p>Thank you Peter for your accurate and witty post, and thank you for MathJax which has served as a beautiful solution to math on the web. The lack of support from browsers has been pathetic and shameful, and you are right that the only real solution is that MathML (and other MLs) are supported natively supported as the definitive content. We should not really have to resort to &quot;tricks&quot; such as MathJax, however well executed those tricks might might be!</p>
<ul>
<li>Peter Krautzberger re Kaveh Bazargan • 23 days ago</li>
</ul>
<p>Thanks, Kaveh. As I wrote, Firefox and Safari do have some support for MathML and of course MathJax is also not yet complete in its implementation (there's only so much room in a non-technical post).</p>
<p>In my humble opinion, it's an achievable goal for a publisher to produce MathML that renders fine on Firefox's native support (while I don't think the same can be said about Safari at this point).</p>
<ul>
<li>Kaveh Bazargan Peter Krautzberger • 23 days ago</li>
</ul>
<p>Of course in practice we simply cannot restrict users to browsers these days, so until there is native support of MathML in all popular browsers, we'll continue with MathJax which <em>does</em> work on all. ;-)</p>
<ul>
<li>Peter Krautzberger Kaveh Bazargan • 23 days ago</li>
</ul>
<p>Here's hoping that one day, we won't have to. Wouldn't that be a nice problem to have?</p>
<ul>
<li>Robert O'Callahan • 23 days ago</li>
</ul>
<p>The best way to get all browsers to support MathML natively is to push math users to use Firefox for its native MathML support. That will get the attention of the other browser vendors. Unfortunately, even in this post you didn't clearly commend Firefox for being the only browser with native MathML.</p>
<ul>
<li>Peter Krautzberger re Robert O'Callahan • 23 days ago</li>
</ul>
<p>Thanks for the comment, Robert. I'm not sure who you have in mind with &quot;users&quot;. I would agree that authors should ensure that their MathML renders well on Firefox natively.</p>
<p>I wouldn't quite agree to call Gecko/Firefox the only browser with MathML support. WebKit/Safari made a lot of progress last year thanks to Fred Wang's work even if it's behind Firefox in its implementation.</p>
<ul>
<li>Robert O'Callahan re Peter Krautzberger • 23 days ago</li>
</ul>
<p>By &quot;users&quot; I mean people producing and viewing math content.</p>
<p>I'm glad Safari is making progress. Feel free to recommend it too. The important thing is to create market pressure for browser vendors to implement native MathML, and that means users/developers choosing one browser over another because of MathML.</p>
<p>As you probably realize, MathJax being so good has actually reduced that pressure; it's easy for browser vendors to say &quot;hey, MathJax works fine in our browser, so why bother investing in native MathML&quot;. Even in this post, you haven't clearly identified reasons why native MathML is better than MathJax fallback.</p>
<ul>
<li>Peter Krautzberger re Robert O'Callahan • 22 days ago</li>
</ul>
<p>I fully agree that users should choose browsers for their features and Firefox's MathML support is, to me, a huge factor, especially in an educational setting. (In fact, I just recently had an interesting situation where I helped a student struggling with a school project about HTML that required some math -- and naturally he chose MathML since they were using Firefox and he wasn't even aware of browser support issues -- bliss ;-) ).</p>
<p>I've encountered the &quot;MathJax is holding back browser implementations&quot; argument a couple of times now and it feels like a Catch-22 to me. Without MathJax (I think) there wouldn't be significant amounts of MathML on the open web and thus no incentive to implement MathML support natively. Now, with MathJax, there's lots of MathML, yet there's still no incentive. I suspect the reasons lie elsewhere. (And from speaking to Gecko, WebKit and Blink developers it does not lie with the developers).</p>
<p>The reason why I didn't go into technical details about why native support is so important is that it didn't fit in this forum (both in length and audience). But you're right that perhaps I should have tried better. Some basic notes can be found on my personal blog at <a href="http://boolesrings.org/krautzb">http://boolesrings.org/krautzb</a>...</p>
<ul>
<li>JonRimmer • 22 days ago</li>
</ul>
<p>You and others here say MathJax isn't an adequate solution. But you don't explain why? It seems like a very successful project, and a far better approach from an software engineering perspective than native browser support.</p>
<p>Adding MathML support into every browser requires duplication of development effort and places responsibility for maintenance in the hands of browser vendor employees for whom MathML is neither a priority nor an area of expertise. Each implementation will vary in its performance, bugs and feature-set, and authors will need to know these differences in order to produce content that is compatible across all browsers. Future versions of the MathML spec will require development and deployment across all browsers, increasing the cost and delay in making new features available.</p>
<p>In contrast, keeping MathML support within a library allows development to proceed at its own pace, handled by those for whom it is both a priority and an area of expertise, and removes the cross-browser compatibility burden. MathML users then only have to deal with a single set of features and bugs, and can upgrade to newer versions of the library as and when they need to, instead of being beholden to browser development and upgrade cycles.</p>
<p>It seems like browser vendors would be better off concentrating on providing powerful, general low-level APIs for things like parsing, layout and rendering, in order to help the implementation and use of libraries like MathJax. That way, the web can scale to support custom rendering of not just MathML, but also Chemistry ML, Cell ML, and the many other useful markup languages and formats, while reducing the centralisation of effort and complexity within the browsers themselves.</p>
<ul>
<li>Peter Krautzberger re JonRimmer • 22 days ago</li>
</ul>
<blockquote>
<p>But you don't explain why?</p>
</blockquote>
<p>See my other comments on this.</p>
<p>As for the other points your raise, they seem to apply to any newer web standard so I don't quite see how they're relevant to MathML specifically.</p>
<p>But yes, certain low-level APIs could make MathML polyfilling much easier; no surprise there. However, their implementation seems even less likely -- especially since some of them have been rejected in the past.</p>
<p>Besides, MathML is not rocket science. It adds a few basic constructs to HTML/CSS such as multiscripts, stretchy characters and better table alignments. If you look at Gecko and WebKit it's clear that it's not a huge burden to maintain.</p>
<ul>
<li>JonRimmer re Peter Krautzberger • 22 days ago</li>
</ul>
<p>I don't see any concrete technical reasons in any of your other comments for the inadequacy of MathJax. Could you be more specific about which comments you mean?</p>
<p>As for other new web standards, you are absolutely right that same points apply to them. The web has to get away from the situation where features must be implemented natively in the browser in order to avoid feeling second-class. That is the only way the web will be able to regain competitiveness with native platforms like iOS and Android. As it stands, the web is losing ground quickly to these platforms, because the need to implement features natively results in an unacceptable bottleneck in innovation.</p>
<p>Fortunately, while there may have been resistance in the past to making low-level capabilities available to library authors, that is changing. For example, there W3C CSS Working Group has recently created the Houdini Task Force [1] which aims to design low-level APIs for parsing, layout, content fragmentation and font metrics. I am certain that they and others would be very interested in hearing what APIs would help in implementing MathJax and equivalent libraries. The Extensible Web Manifesto [2] also covers similar ground.</p>
<p>[1] <a href="https://wiki.css-houdini.org/">https://wiki.css-houdini.org/</a><br>
[2] <a href="https://extensiblewebmanifesto/">https://extensiblewebmanifesto</a>...</p>
<p>−</p>
<ul>
<li>Peter Krautzberger re JonRimmer • 22 days ago</li>
</ul>
<p>Thanks, I'm well aware of Houdini and the extensible web manifesto and these are great initiatives with excellent people involved (such as Rob who commented here as well).</p>
<p>Personally, I think reports of the imminent death of the web are exaggerated. But even so, I'd argue that abandoning important and established web standards will do nothing but speed that up.</p>
<p>As for the technical issues, they are (again) nothing particular to MathML. Polyfilling a textual rendering component -- be it math or bidi or linebreaking -- always happens too late in the game, i.e., after the page renders because good layout will depend deeply on the surrounding context. Similarly, inserting large amounts of content fragments (easily in the thousands) into the DOM will always come with issues, especially performance.</p>
<p>More importantly, relying on a polyfill will prevent universal use. Developers will always have to make a conscious decision to add support, adding complexity and risking instability. In reality, we could never expect to be able to use mathematics in something as basic as a webmailer or a social network.</p>
<p>The thing is: the &quot;if&quot; is not even the problem. When you ask actual browser developers (be it Mozilla or Google or Apple or Microsoft) they in favor of MathML. The problem lies much more on the management side.</p>
<p>Ultimately, it comes down to how important mathematics is. (Why not kick bidi? SVG? flexbox? tables?)</p>
<p>The web is the most important medium for human communication and mathematics is one of the oldest and most universal forms of expression. Every school kid (worldwide) engages in mathematics (often for many years) and soon will do so in an HTML context. In particular, students will have to actively communicate (author, share, digest) mathematics and this will primarily happen on the web. To me, that makes it pretty important to have math natively on the web.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Infinite chess]]></title>
        <id>http://normanspace.org/2015/02/25/infinite-chess/</id>
        <link href="http://normanspace.org/2015/02/25/infinite-chess/">
        </link>
        <updated>2015-02-26T00:06:03Z</updated>
        <summary type="html"><![CDATA[<p>I recently started working with Joel Hamkins on a new project on infinite chess. We think that we will be able to improve on some results from his previous paper on transfinite game values in infinite chess to demonstrate a position with game value $\omega^4$. We made a lot of progress during January and February, as I was not teaching during that time. Teaching starts again for me next week. I hope that I will be able to find time to continue working on this project while I&#8217;m teaching during the spring semester. If not, then I will work on it more in the summer. Stay tuned to see a really cool infinite chess position <img src="https://s.w.org/images/core/emoji/12.0.0-1/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>]]></summary>
        <author>
            <name>Norman Lewis Perlmutter</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why learn math?]]></title>
        <id>http://normanspace.org/2015/02/18/why-learn-math/</id>
        <link href="http://normanspace.org/2015/02/18/why-learn-math/">
        </link>
        <updated>2015-02-18T07:01:01Z</updated>
        <summary type="html"><![CDATA[<p>Last fall, I noticed that a major problem for many of my students, especially my basic students, was a lack of motivation to study math. So I spent a few hours today looking for some motivational articles and videos on the topic. I plan to show this motivational material to students on the first day of class (the spring semester starts in the beginning of March at LaGuardia) and then have them discuss it. Here&#8217;s the best of what I found: two videos and one article. If any of my readers have additional suggestions for motivational material, I&#8217;d be very interested. I think it&#8217;s really important to get students feeling motivated from the beginning of the semester.</p>
<p>&nbsp;</p>
<p><a href="http://www.ctpost.com/news/article/Here-s-why-you-should-study-algebra-4710461.php">http://www.ctpost.com/news/article/Here-s-why-you-should-study-algebra-4710461.php</a></p>
<p>&nbsp;</p>
<p><iframe class='youtube-player' type='text/html' width='584' height='329' src='https://www.youtube.com/embed/VwCLitK69PU?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe></p>
<p><iframe class='youtube-player' type='text/html' width='584' height='329' src='https://www.youtube.com/embed/P0E-9uJgDZU?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe></p>]]></summary>
        <author>
            <name>Norman Lewis Perlmutter</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Much needed terminology, that isn't going to happen any time soon]]></title>
        <id>http://karagila.org/2015/much-needed-terminology-that-isnt-going-to-happen-any-time-soon/</id>
        <link href="http://karagila.org/2015/much-needed-terminology-that-isnt-going-to-happen-any-time-soon/">
        </link>
        <updated>2015-02-02T20:29:45Z</updated>
        <summary type="html"><![CDATA[<p>One of the reasons I love set theory so much, and specifically choice related research, is that this is an extremely fertile ground for amusing terminology. We have forcing, cardinals, collapsing, we have all sort of gems and rodents at our disposal... we even have a swamp thing.</p>

<p>Here are a few terminological ideas that I doubt are going to be developed by anyone. But if you plan on doing something similar (or if my terminology inspires some proof) feel free to use these terms, and please let me know! <a href="http://karagila.org/2015/much-needed-terminology-that-isnt-going-to-happen-any-time-soon/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Looking back at my tiny blogging challenge]]></title>
        <id>https://www.peterkrautzberger.org/0177/</id>
        <link href="https://www.peterkrautzberger.org/0177/">
        </link>
        <updated>2015-02-01T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>At the end of last year, I tried to motivate myself to write more so I set myself a <a href="http://boolesrings.org/krautzberger/2014/11/03/tiny-blogging-challenge/">tiny blogging challenge</a>: writeo one post each week for the remaining weeks of the year, don't spend more than for 30mins per post.</p>
<p>It didn't really work out but perhaps in a good way. Yes, I posted 7 out 8 weeks so that's close (still, Mike gets to name a charity of his choice). No, I most definitely did not spend just 30min per post (more like 1h, sometimes way more...). But those were means to an end which included a) try out something that gets me to write more regularly and b) make it interesting for my two readers, maybe add a third reader (crazy, I know!).</p>
<p>At the end of the year I was exhausted (so I had to take January off -- well, be kind enough to pretend I did that intentionally and not simply failed to write that one last post for week 8). In part this was due to me writing on a couple of other, work-related places. I suppose one could say the blogging challenge helped there; e.g., it motivated me to finish a couple of outstanding blog posts on <a href="http://mathjax.org/">mathjax.org</a>. But I think in reality it was the holidays and I had enough opportunity to write for a couple of hours (or sleep in to compensate).</p>
<p>As for the means, this exhaustion leaves me in doubt for the first one. Did I simply overdo it? Maybe I just need to pace myself better. We'll see (thanks to Asaf for bugging me to get back on the wagon).</p>
<p>As for the second one, I think that was a bit of a miss. At least in the sense that my posts seemed to cause a lot of confusion and irritation. Then again, that was somewhat intentional, I just wasn't happy with the <em>kind</em> of confusion, perhaps.</p>
<p>As for 2015, I will try to pace myself better. First target: finish that post from the original list of the tiny blogging challenge.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Asaf Karagila</strong>, 2015/02/01<br>
There. My one good deed for the year, I can get back to being an evil man once more (by forcing and tricking poor models of set theory to have no choice, of course).
<ul>
<li><strong>Peter</strong>, 2015/02/03<br>
What have I done!!!!1!!!!!11!!eleventy!!!!
<ul>
<li><strong>Asaf Karagila</strong>, 2015/02/04<br>
<a href="https://en.wikipedia.org/wiki/Elevenses">Elevenses</a>?
<ul>
<li><strong>Peter</strong>, 2015/02/05<br>
Hah. Funny. (fixed the link).</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>Asaf Karagila</strong>, 2015/02/01<br>
Also, how did Mike win the friendly wager? He didn’t post <em>anything</em> during that period. You should have won that after the first week, or second week.
<ul>
<li><strong>Peter</strong>, 2015/02/05<br>
True but I did say I’d take him on without his side of the bargain.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bonus round; Why I care about native MathML]]></title>
        <id>https://www.peterkrautzberger.org/0176/</id>
        <link href="https://www.peterkrautzberger.org/0176/">
        </link>
        <updated>2014-12-29T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>[This is week 7 of the challenge but really a post to make up for dropping the ball on week 5.]</p>
<iframe width="854" height="510" src="https://www.youtube.com/embed/-uZL3qqDVK8" frameborder="0" allowfullscreen=""></iframe>
<p><a href="https://www.peterkrautzberger.org/0175/">Last week</a> I wrote about why I care about MathML in general. Given that I work for a project that serves as a MathML polyfill, it's worth while to to point out why native implementations matter; they matter an entire alot of mattering.</p>
<p>A while back, <a href="http://www.milowski.com/">Alex Miłowski</a> asked me for some quotes about how native MathML implementations are important so luckily I can copy myself here.</p>
<h4>It's important.</h4>
<p>Some people say, &quot;few people on the web need MathML support.&quot; This is true. Just like saying &quot;few people need children's clothing&quot;.</p>
<p>Why is MathML important? Education, education, and education. Mathematics is a core skill and a vast amount of educational time and effort is spent on teaching children and adults to understand and apply math &amp; science. Very soon, HTML will be the dominating delivery method for educational content across the world. This means mathematics must be HTML, viz. MathML.</p>
<h4>HTML rendering should be native</h4>
<p>Where should HTML rendering be implemented? In the browser!</p>
<p>MathML has been HTML from its inception and after a (forced) XML-detour, MathML is back where it belongs: a part of HTML5. MathML layout is core HTML functionality, widely used in everything from web communities to professional publishers to educational startups. HTML and thus MathML rendering belongs in the browser.</p>
<h4>Performance</h4>
<p>While browser vendors show great interest in enabling polyfills to behave like native implementations, polyfills implementing layout standards (MathML, Flexbox etc), in the end, will not achieve native performance. The reason is simple: layout polyfills simply enter too late in the game -- after the browser layout is done, at a point where the user expects content, not additional rendering delays. Moore's Law helps a little but, ultimately, performance issues will prevent math and science from fulfilling their potential on the web.</p>
<h4>Robustness</h4>
<p>Even the most advanced polyfilling technology will remain a JavaScript solution. This increases the risk of problematic interactions with regular scripts for design, user interaction, and styling. Native support will always be more robust for web developers and consumers.</p>
<h4>Ubiquity</h4>
<p>Even the most ideal polyfill will require a conscious choice of the web developer to load it. This poses a grave restriction for end users and the emergence of new platforms for math and science on the web. From webmailer, to web based authoring, to social networks, all of these could turn out to be highly productive platforms -- but it's unlikely their developers will consider adding a polyfill for a perceived niche. With native MathML rendering, rendering MathML would be universal.</p>
<h4>The Future</h4>
<p>The web has revolutionized how we communicate. Not by magic but because thought leaders continually push the envelope, building new tools and platforms that transform how we work, speak, and think. These innovations feed back into standards development, enabling everyone to benefit and restarting the process, pushing us further.</p>
<p>MathML 3 captures traditional mathematical typography. Thanks to polyfills, we get a glimpse of how MathML might develop, how it can revolutionize the communication and dissemination of scientific knowledge. Yet without native implementations of MathML 3, we will never see MathML 4, 5, or 10, and the opportunities this will open up.</p>
<p>It took 50 years from Gutenberg's printing press to the first typeset mathematics book. We're 25 years into the web. Do we wait another 25 years or can browser vendors finally invest 1-2 developer years to get us there?</p>
<hr>
<p>Update.</p>
<p>First, I changed the embedded video; it was previously <a href="https://www.youtube.com/watch?feature=player_detailpage&amp;v=wHZHSt1CSgo#t=600">this one</a>.</p>
<p>Second, <a href="https://plus.google.com/u/0/+PeterKrautzberger/posts/3zdytApQw6N">over on Google+</a>, Harald Hanche-Olsen asked about the claim that MathML is a huge success. Here's what I responded with.</p>
<blockquote>
<p>Re success of MathML. Today, almost all equational content is stored as MathML. This is because almost all scientific (including mathematical) publishers have switched to XML workflows for production and archival where MathML fits in very naturally; similarly most technical writing (e.g., aerospace) is done in XML workflows.</p>
<p>For authoring, it's a bit more complicated. It is similar to, e.g., vector graphics where applications such as Adobe Illustrator have their own formats but when you save vector graphics for re-use you'll most likely export to SVG.</p>
<p>As I mentioned, there's definitely the need for a professional-grade, open source pure MathML editor (ideally HTML5). The only one I know of is MathFlow. But if you have ever used MathJax then you have authored MathML -- it's how MathJax works: convert any input to MathML and then leverage our MathML rendering engine.</p>
<p>Similarly, lots of other tools are able to output MathML -- besides converters from TeX (such as LaTeXML or tex4ht), Microsoft Word Equation editor can export to MathML, as does Open Office Math editor, MathType, MathMagic, the Windows Math Input Panel (handwriting recognition), MyScript (ditto), Maple, Mathematica and virtually any other tool you might have authored serious equational content in. (Oh well, I should've simply linked to <a href="http://www.w3.org/Math/wiki/Tools#Authoring_tools">http://www.w3.org/Math/wiki/Tools#Authoring_tools</a> which I recently set up.)</p>
<p>Of course, Word is the big reason why most scientific and educational content ends up providing MathML. I don't claim (or believe) that people are aware of most of this which was one of the reasons I wrote about it.</p>
</blockquote>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why I care about MathML]]></title>
        <id>https://www.peterkrautzberger.org/0175/</id>
        <link href="https://www.peterkrautzberger.org/0175/">
        </link>
        <updated>2014-12-26T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>[This is week 6~7? Mpf, I missed one (and a half?), bummer. I'll try to make up for it.]</p>
<p>When I started this writing challenge, I had listed a couple of potential blog post titles. One of them was &quot;Why you should care about MathML&quot;. I realized later that I really didn't want to pretend I could even try to tell my two readers what they should or should not care about. Instead, I want to jot down (remember: 30mins time limt) a few reasons why I started to care about MathML, <a href="http://hyperboleandahalf.blogspot.de/2010/04/alot-is-better-than-you-at-everything.html">alot</a>.</p>
<figure>
  <a href="http://hyperboleandahalf.blogspot.de/2010/04/alot-is-better-than-you-at-everything.html">
    <img alt="An Alot © Ellie Brosh" src="https://www.peterkrautzberger.org/assets/2014/ALOT2.png">
  </a>
  <figcaption>
    I care about this Alot. © Ellie Brosh
  </figcaption>
</figure>
<p>Unsurprisingly, it was in many ways a story of my education. Here are two quotes from yours truly.</p>
<blockquote>
<p>I think MathML is so far the best solution to present mathematical content on the web<br>
-- <a href="https://www.peterkrautzberger.org/0002/">actually me</a>, Dec. 2009</p>
</blockquote>
<p>Actually, more stuff wrong on my post; also, referencing Terry Tao's blog, weird.</p>
<blockquote>
<p>But mathml sucks [...]<br>
-- <a href="http://blogs.plos.org/mfenner/2011/01/23/beyond-the-pdf-is-epub/#comment-2489">also actually me</a>, Feb. 2011</p>
</blockquote>
<p>(In my defence, I probably meant authoring tools and browser support.)</p>
<p>So as you can see, I flip-flopped a bit there (and, in a fundamentally different way, I still do). So here are five short reasons why I care about MathML.</p>
<h3>a stable exchange format</h3>
<p>When I started using MathJax on a personal blog (thanks to the above quote I realize I started blogging <a href="http://thelazyscience.blogspot.de/2009/12/welcome.html">5 years ago this month</a>, (<a href="https://www.peterkrautzberger.org/0001/">local copy</a>), although I think I started to blog a year ealier on <a href="http://scivee.tv/">scivee.tv</a> (though this seems lost)), I was first annoyed and then very happy to not use macros. Obviously, you can use macros with MathJax but I started to avoid personalized macros at all costs. Ultimately, they prevented me from writing mathematics elsewhere and they limited re-use of my writing by other people (well, ok, that's more hope than reality I suppose).</p>
<p>MathML does not suffer any of these complications (well, technically Content MathML could if anyone used it). Instead, MathML provides a truly stable format for storing equational content while still allowing for re-use. Granted, it's not exactly easy to write by hand but neither are SVG or HTML/CSS (certainly not as soon as you want to express something more complex). Still, I'd encourage anyone to spend some time with it (e.g., try copy-editing a random piece of MathML and compare that to copy-editing some macro-filled LaTeX horror). In any case, creating MathML is straight forward, especially for those knowing LaTeX syntax (even if we could use a a good open-source MathML editor). Ultimately, MathML is more readable in isolation thanks to its nature of being actually a mark-up language and not a programming language.</p>
<h3>a focus beyond research</h3>
<p>What struck me early on was how successful MathML was outside of research. Research mathematicians (and scientists) tend to think their habits are vital for the longevity of mathematical writing. However, technical writing (such as industrial (think aerospace) documentation), engineering, and most importantly school-level mathematics are arguably more important -- and have benefited enormously from a mathematical markup that is easily handled by researchers and non-researchers alike. MathML has brought high quality rendering together with easy authoring to an incredibly wide and diverse community; a huge accomplishment.</p>
<h3>accessibility, for real</h3>
<p>What I also learned early on (in crass contrast to my 2009 self above) was that MathML has turned out to be critical for having truly accessible mathematics.</p>
<p>Of course, TV Raman's AsTeR voiced TeX/LaTeX long before MathPlayer, ChromeVox or VoiceOver voiced MathML. But besides the refinements (which later tools could so easily provide), the notion of accessibility stretches far beyond voicing and visually impaired users. Features like synchronized highlighting would be much harder in TeX (just think about identifying subexpressions in a complex TeX macro, let alone in poorly authored TeX) but they are critical for helping people with learning or physical disabilities. Even more advanced features like summarization and semantic analysis are much more straight forward in a markup language like MathML than in TeX. And so is search whose importance can hardly be overstated in times of ever increasing publication pressure; without search mathematical knowledge won't be accessible to us in the long run.</p>
<h3>the DOM (etc)</h3>
<p>The main reason why MathML is irreplaceable on the web is its compatibility with the DOM. This allows web developers to apply the full breadth of their tools to make mathematical content truly native instead of copying print-based layout. We cannot re-invent everything as Knuth did because web &quot;typography&quot; is far from finished and communicating on the web will probably change drastically every couple of years for the foreseeable future (just like communicating using the printing press did in another age). Having a naturally fitting technology allows mathematics to continually evolve its expression alongside other forms of expression on the web -- an incredible benefit (and challenge!).</p>
<h3>an open future to revolutionize how we &quot;speak&quot; mathematics</h3>
<p>This leads me straight to the last and probably main reason why I care for MathML. What the web has already done for regular language (all over the world), it can do for the language of mathematics: transform the way we communicate; expand, enhance, deepen, and lighten the way we express mathematical thought. You don't have to be Bret Victor to believe that in 30 years we will have developed new forms of expressions that truly leverage web technology and eliminate baroque limitations of black-and-white, print layout. We should strive to do so much better and I believe MathML is an important step in this direction.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Partition Principle]]></title>
        <id>http://karagila.org/2014/on-the-partition-principle/</id>
        <link href="http://karagila.org/2014/on-the-partition-principle/">
        </link>
        <updated>2014-12-20T20:45:25Z</updated>
        <summary type="html"><![CDATA[<p>Last Wednesday I gave a talk about the Partition Principle in our students seminar. This talk covered the historical background of the oldest open problem in set theory, and two proofs that for a long time I avoided learning. I promised to post a summary of the talk here. So here it is. The historical data was taken from the paper by Banaschewski and Moore, &quot;The dual Cantor-Bernstein theorem and the partition principle.&quot; (<a href="http://www.ams.org/mathscinet-getitem?mr=1072073">MR1072073</a>) as well Moore's wonderful book &quot;Zermelo’s Axiom of Choice&quot; (which has a Dover reprint!).</p>

<p><hr /> <a href="http://karagila.org/2014/on-the-partition-principle/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[#dotAstro FTW]]></title>
        <id>https://www.peterkrautzberger.org/0174/</id>
        <link href="https://www.peterkrautzberger.org/0174/">
        </link>
        <updated>2014-12-08T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>[This is week 4 of the challenge. woohoo.]</p>
<p>Today I only have ~15 min. This week, I happen to be in Chicago for <a href="http://dotastronomy.com/six">dotAstronomy 6</a>. This might be odd since I'm not an astronomer (nowhere near in fact). It is actually an immense privilege, though, since I'm part of a small group of invited interdisciplinary participants (also including biologists, climate scientists and library scientists). So my perspective is that of an outsider and I hate to admit it: it's what I suspected all along.</p>
<p>That is, ever since running into the dotAstronomy website a few years ago, I have been a little envious. I kept thinking &quot;This sounds incredibly fantastic. How could we do something like this for mathematics?&quot; Until today I could at least pretend that it couldn't actually be as great as it appears. Because nothing is, right?</p>
<p>My two readers won't be surprised to hear it: I was wrong. dotAstro is every bit as exciting, enlightening, creative, and savvy as I had hoped. A fantastic group of scientists from all walks of scientific life, including &quot;recovering&quot; researchers who have been led to non-standard careers while retaining a deep, nay fierce enthusiasm for their field as well as for the untapped potential offered to scientific communities by the web. This first day has been a perfect mix, starting with excellent talks, switching to amazing lightning talks, followed by an exhausting-because-engaging unconference sessions, and finally some great conversation at the pub (including perfectly greasy US bar food).</p>
<p>Luckily, I don't have to bore you with my notes but can simply point you to the <a href="http://dotastronomy.com/blog/2014/12/astro-6-live-blog-day-1/">live-blogging of the first day</a> by <a href="https://twitter.com/vrooje">@vrooje</a>. In case my notes go up in flames, I could probably reconstruct half of it from the Twitter hashtags of the unconference sessions I attended, i.e.,</p>
<ul>
<li><a href="https://twitter.com/hashtag/hackj?src=hash">#hackj</a> (hack the journal)</li>
<li><a href="https://twitter.com/hashtag/astrocult?src=hash">#astrocult</a> (identifying dotastro culture)</li>
<li><a href="https://twitter.com/hashtag/dotmuse?src=hash">#dotmu</a> (make science museums better)</li>
<li><a href="https://twitter.com/hashtag/dotall?src=hash">#dotall</a> (reach out to all audiences)</li>
</ul>
<p>Now I'm exhausted but excited for tomorrow's hack day.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>David Roberts</strong>, 2014/12/09<br>
Your link to dotastonomy six is not quite right…
<ul>
<li><strong>Peter</strong>, 2014/12/09<br>
Thanks. Should be fixed.</li>
</ul>
</li>
<li><strong>Asaf Karagila</strong>, 2014/12/10<br>
Two questions:
<ol>
<li>Did you only have 15 minutes because two weeks ago it took more than 30 minutes?</li>
<li>Do you think that the fact that two people have commented on the content of your blog means that this has exhausted your reader base? If so, what sort of Alot would you imagine is useful here?<br>
Finally, I agree that this could be great in math. But it could also end up being counterproductive. Since mathematics can be a very non-applied form of art, rather than science with basis and application to/from all sort of fields like astronomy (all types of physics, some chemistry, all sort of engineering), this means that we get quite a fragmented result. Sort of like having Kandinski paint one half of a picture, cover it all but one inch, and letting Gogen paint the other hand accordingly. It just won’t click most of the times, but when it does it will be awesome.<br>
What exactly do I mean? If you take someone working in differential geometry, there might not be much that they can say about combinatorial properties of successor of singular cardinals to a set theorist, and vice versa. So you’d have to work “in the middle of fields” where set theory and category theory meet, and differential geometry and constructive mathematics perhaps already wait for them. But now, since we’re talking about mathematics and mathematicians, we can’t expect everyone to be familiar with all the fields, or accept handwavy, sketchy arguments (because those will almost always fail when actually writing them down for the first time), so lengthy tutorial needs to be given first.<br>
Because mathematicians, and foremost Lady Mathematics, like precision and like accuracy. And you can’t just do that out of thin air.<br>
Of course, I’m not advocating against this idea. I think it’s great, if you can find the right people. Namely, a bunch of mathematicians from different fields which have a common core interest, and can either put the additional time in learning the basics of the other participants’ fields, or somehow be okay with handwaving until you slightly levitate, and of course have an open mind for these sort of things. Then sure, you can put them all together and let them talk about something, and almost surely something good can come out of it!<br>
(And it seems that I’ve mistaken the comment field for my own blog. ALOT! :-))</li>
</ol>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On reading and writing and silence]]></title>
        <id>https://www.peterkrautzberger.org/0173/</id>
        <link href="https://www.peterkrautzberger.org/0173/">
        </link>
        <updated>2014-12-02T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>[week 4 of the challenge. It's time for a quick post to catch up after last week's delay.]</p>
<p>As you know, this blogging challenge of mine is based on the observation that I would like to write more. And then Jeff Atwood reminds me in <a href="http://blog.codinghorror.com/because-reading-is-fundamental-2/">this interesting piece</a> that</p>
<blockquote>
<p>we badly need to incentivize listening</p>
</blockquote>
<p>which makes me wonder if my natural tendency to let things brew for ages might not be a good thing. This blogging challenge will invariably show if I'm actually able to write in decent quality under tighter constraints. (Right now, I'm not so sure.) So perhaps I will have to realize that silence is golden.</p>
<p>On a related note, in recent months, I was forced to think about my comment &quot;policy&quot;. This hadn't really come up before since I get very few comments and even fewer from strangers. But I think I should point out that nobody leaving a comment should expect said comment to be posted. Similary, nobody should expect a comment that has been posted to stay up (especially if gets posted automatically after I've allowed a comment in the past). Finally, nobody should expect me to reply to a comment even if I've replied to other comments and even if that happened in the same thread.</p>
<p>This policy has very little to do with trolling, actually, but more with off-topic comments and comments on ancient posts documenting how things have changed (I'm so surprised! not). It's also related to a different point: I'm probably switching off automated comments at some point next year (ooooooh, something will change, hint hint).</p>
<p>The number of worthwhile comments I get is roughly 1 per month (vs 5-10K of spam). So instead of a comment sytem, I'll figure out some way you can quickly send me a comment and then I will add it manually. This move is not just laziness about dealing with spam (it will be slightly more work, I suspect) but also reflects the fact that I consider your comments to be additions to the content, not separate from it. This does not mean that a comment needs to be serious, of course -- silly comments are just as (more?) (more!) relevant to me, so I hope people will keep'em coming.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Asaf Karagila</strong>, 2014/12/02<br>
Silly comments are my specialty. As are most form of off topic. I think that I would have managed to squeeze the 45 minutes I have to teach into an actual 45 minutes time frame if I would lay off the off topic comments and jokes to my classroom.<br>
However, I do feel that humor is an integral part of my teaching, so I won’t do that, and I’ll keep the usual five minutes overtime.<br>
Hey, look at that, I’m the first half of a soccer game! :)
<ul>
<li><strong>Peter</strong>, 2014/12/08<br>
This made me smile. <a href="http://hyperboleandahalf.blogspot.com/2010/04/alot-is-better-than-you-at-everything.html">Alot</a>.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Filter quantifiers]]></title>
        <id>http://m6c.org/w/2014/11/filter-quantifiers/</id>
        <link href="http://m6c.org/w/2014/11/filter-quantifiers/">
        </link>
        <updated>2014-11-30T18:18:16Z</updated>
        <summary type="html"><![CDATA[I have been supervising an undergraduate student in an independent study in topology this semester. We have just finished the Stone–Čech compactification, and the semester is ending, so I want to end with an ultrafilter based proof of Hindman&#8217;s theorem. &#8230; <a href="http://m6c.org/w/2014/11/filter-quantifiers/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Carl Mummert</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LaTeX Something Something Darkside]]></title>
        <id>https://www.peterkrautzberger.org/0172/</id>
        <link href="https://www.peterkrautzberger.org/0172/">
        </link>
        <updated>2014-11-28T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>[This is week 3 of the challenge. Ok, I'm stretching &quot;every week&quot; a bit here. I blame somebody's first cold or alternatively Turkeys. Also, I cheated; this took longer than 30mins.]</p>
<iframe width="625" height="382" src="https://www.youtube.com/embed/Wk2cd_x9Ta8" frameborder="0" allowfullscreen=""></iframe>
<blockquote>
<p>Darth Vader/Stewie: Oh, come on, Luke, come join the Dark Side! It's really cool!<br>
Luke/Chris: Well I don't know. Whose on it?<br>
Darth Vader/Stewie: Well um... there's me, the Emperor, this guy Scott. You'll like him, he's awesome...</p>
</blockquote>
<hr>
<p>Where my previous post was more about TeX-like syntax, this is about TeX/LaTeX proper. If you're a TeX/LaTeX enthusiast, don't go all crazy on me (I mean, have you seen my thesis?). This is about me feeling a growing awkwardness towards TeX/LaTeX. And this has little to do with TeX/LaTeX itself.</p>
<h3>If all you have is a hammer, everything looks like a nail</h3>
<p>TeX/LaTeX is a tool. It is a tool designed by Knuth to solve a problem in print layout. The trouble is: print is becoming less and less relevant and I think this holds for most TeX users (when was the last time you went to a library to look at the printed copy of a <em>current</em> journal issue?). What is not obsolete is PDF and TeX is, of course, very good when it comes to generating PDF.</p>
<p>However, this &quot;Portable Document Format&quot; is really quite useless in the one place where people consume more and more information: the web. (I admit I'm of the conviction that the web won't go away; crazy talk, I know.) And for the web, TeX/LaTeX is the wrong tool. Yes, there are about a gazillion projects out there that try to bridge that gap, try to create HTML out of LaTeX. But if you try them out you'll soon notice that you'll have to restrict yourself quite a bit to make conversion work.</p>
<p>Turn this around and you'll realize that the community as whole has a serious problem: almost nobody writes TeX/LaTeX that way which means almost all TeX/LaTeX will never convert to web formats well. To put it differently, there's a reason for a large market of blackbox vendors that specialize in TeX to XML/HTML conversion for professional publishers (and this often involves re-keying).</p>
<p>This is, of course, in no way a fault of TeX/LaTeX itself which was designed for print, in 1978. But it is a problem we are facing today.</p>
<h3>Everything is nothing</h3>
<p>Now TeX is Turing complete and this means we can do everything with TeX (even <a href="http://tex.blogoverflow.com/2012/10/i-tex-therefore-i-toast/">toast</a>). So a universal output for the web is theoretically possible. However, everything is nothing if we can't make it practical. Perhaps one day, we'll be lucky to find another Leslie Lamport who will give us &quot;HTMLTeX&quot;, i.e., a set of macros that work and rapidly become the de-facto standard for authors. I doubt it. (And not just because I know mathematicians who don't upload to the arXiv because their ancient TeX template won't compile there.)</p>
<p>I doubt it because there's no problem to solve here. Where Knuth (and Lamport) solved imminent problems, there is no problem when it comes to authoring for the web -- a gazillion tools do it, on every level of professionalism. TeX is neither needed for this nor does it help.</p>
<h3>Waste of resources</h3>
<blockquote>
<p>&quot;The best minds of my generation are thinking about how to write TeX packages.&quot;<br>
-- not Jeff Hammerbacher.</p>
</blockquote>
<p>Another part of my awkwardness towards TeX/LaTeX these days lies in the resources the community invests in it. It feels like every day, my filter bubble gives me a new post about somebody teaching their students LaTeX. These make me wonder. How many students will need LaTeX after leaving academia? How many would benefit from learning how to author for the web?</p>
<p>And then there's actual development. How many packages on CTAN are younger than 1/2/5 years? How many of those imitate the web by using computational software in the background or proprietary features such as JS-in-PDF (and who on earth writes a package like that)?</p>
<p>To me, this seems like an unfortunate waste of resources because we need people to move the web forward. If we remain stuck in PDF-first LaTeX-land, we miss a chance to create a web where math &amp; science are first class citizens, not just by name but by technology and adoption from its community.</p>
<p>If only a part of the TeX/LaTeX community would spend an effort on web technologies like IPython Notebook, BioJS (or even MathJax) it would make a huge impact.</p>
<h3>Professional?</h3>
<p>This brings me to my last awkward feeling about LaTeX for today which comes on strongly whenever somebody points out that LaTeX output is typographically superior.</p>
<p>I understand why somebody would say it but once again LaTeX is a merely tool. The reality of publishing is that almost all LaTeX documents are poorly authored, leading to poor typesetting. In addition, actual typographers will easily point out that good typography is not limited to Knuth's preferences enshrined in TeX.</p>
<p>So while I can understand why somebody would claim that their documents are well typeset, this is not very relevant. As long as we cannot enforce good practices (let alone best ones), the body of TeX/LaTeX documents will remain a barely usable mess (for anything but PDF generation).</p>
<p>On the other hand, publishers demonstrate every day that you can create beautiful print rendering out of XML workflows, no matter if you give them TeX or MS Word documents. Even MS Word has made huge progress in terms of rendering quality and nowadays ships with a very neat math input language, very decent handwriting recognition and other useful tools.</p>
<p>The web is typographically different. On the one hand, much of its standards (let alone browser implementations) is not on the level of established print practices. On the other hand, its typographic needs are very different from print for many reasons (reflow, reading on screens etc). And even though some of print's advantages will eventually be integrated, I suspect we will develop a different form of communication for STEM content on the web than we have in print because we have a much more powerful platform.</p>
<h2>Ultimately, PDFs have stopped looking professional to me. Instead, <a href="http://blog.felixbreuer.net/2014/11/20/geometry-of-restricted-partitions-talk-slides-threejs.html">Felix's recent slides</a>, <a href="http://bost.ocks.org/mike/algorithms/">Mike Bostock's &quot;Visualizing Algorithms&quot;</a>, and <a href="http://worrydream.com/Tangle/">Bret Victor's Tangle</a> are examples where you'll see my face light up, thinking about how we can build authoring tools to turn these experiments into tools for the average user.</h2>
<p><em>Comments</em></p>
<ul>
<li><strong>Stephen Brooks</strong>, 2014/11/28<br>
&quot;What is not obsolete is PDF [citation needed]&quot;<br>
I mean really they invented HTML with the idea of being displayed in a variable-sized digital window, and we’re still stuck with PDF more than ever, which emulated fixed-size paper pages. I roll my eyes when a conference says “your papers must be submitted on A4 or Letter”, the 20th century ended a while ago now.<br>
Also Tex/LaTeX is non-multithreadable because it’s essentially a single-thread computer program. A computer program is actually a hideous format for a *document*. It’s infinitely flexible of course, but it makes many document transformations (such as conversion to HTML without JavaScript) provably uncomputable.<br>
XML would have been a solution to this but they shot themselves in the foot with a bulky syntax that wasn’t as easy to type by human beings as TeX and abominable support for mathematics.<br>
So yes, I’m stuck using LaTeX and PDF for my papers because it’s the “de facto standard”, not because it’s the smart thing to do.</li>
<li><strong>Asaf Karagila</strong>, 2014/11/28<br>
I like LaTeX. I like the fact that I can compile to .pdf, and I like the fact that I have a very accurate control on how things are done.<br>
I like the fact that I can program macros, and that I can write my own language.<br>
I like the fact that I can make my thoughts about mathematics and my LaTeX language coincide, and type lectures in real time without any effort whatsoever, and require minimal rework (in terms of LaTeX) at the end. I don’t see this happening with XML, or with MS Word, or with HTML, or with anything. Because in order to have a macro language that is flexible enough for me to expand and modify it at will, I probably need something relatively flexible to begin with. Not a document, a program.<br>
But it is true that the majority of people have difficulties working properly with LaTeX. But then again, also with emails, smartphones, the internet, YouTube, and keychains. Whatever it is, many people will be using it wrong.<br>
I like my papers in PDF, and I like my documents written in LaTeX.
<ul>
<li><strong>Peter</strong>, 2014/12/02<br>
Thanks, Asaf, for pointing out how atttractive TeX’s power is to power users like yourself. I think the comparison to emails and smartphones is a bit unbalanced. E.g., LaTeX users usually have a university level education. LaTeX can be used well but I think most people overestimate their own ability. I ilke your description of TeX documents as compiled programs; it is the honest approach and I think it makes it clear how problematic the output is (much like you won’t expect source code from the 90s to compile or run today). Anyway, I’m sure we’ll have room to continue that discussion in other places on BR.</li>
</ul>
</li>
<li><strong>Kaveh</strong>, 2014/11/29<br>
Let me start by saying my views are mainly opposite to yours, but I promise not to go all crazy on you. 😉<br>
I will try and address the main points you make…<br>
Firstly, until around 2 years ago, I was helping to dig the grave for PDF, in order to prepare for more modern, interactive formats. But actually I have come to love the PDF again, and judging by usage, there is no sign of it dying. Humans like having “things”, and PDF is a thing. (In the perfect words of Steve Pettifer of UtopiaDocs, “it has edges”.) But what we need is to have PDF as one of many formats, so we have XML or HTML as the definitive content, and PDFs can be produced on the fly and with specs selected by the reader. TeX is the <em>only</em> program that can do this conversion without the output looking ugly, in the server and on the fly.<br>
So my view is let us not ditch the PDF but give it interactivity similar to HTML. This can be done and again TeX, using JavaScript, and the layers (OCGs) facility in PDF. As far as I know no other system can do this automatically.<br>
I agree that most tools to convert TeX/LaTeX to HTML are basic in their raw form, but with some major one-time work, clean LaTeX files can be converted to HTML (or XML) perfectly and fully automatically. (We have used TeX4HT, but with heavy configuration.)<br>
I agree that most black box vendors do not do a good job of converting TeX to HTML. I don’t think there is a lot of rekeying, but a lot of manual work is needed. The industry standard method, believe it or not, is to convert TeX to Word first, because the composition industry has invested heavily in tools to convert Word.<br>
You are right that TeX dates from 1978 and the core is largely unmodified, but that is what makes it so great. I have macros that I wrote 25 years ago that are guaranteed to work today. And if I can get my thesis off the 5 1/4″ floppies, they would work too, and give me a PDF. Try that with a 5 year old Word file!!<br>
There are 10,000s packages on CTAN, to do extraordinary tasks. You can look at Beamer (automatically create presentations from a text file) and Tikz (amazing graphics automatically generated from data).<br>
I do believe that the TeX engine has more control over typography than any other tool, including facilities like automatic stretching of spaces that designers are not even taught about because no one knows it is possible!! The only other engine that can match TeX is InDesign (which I love by the way), but that is because Adobe copied the TeX paragraph breaking mechanism!! I fully agree that most documents do not show the typographic quality because the class files are not taking advantage of it.<br>
I won’t bore you longer here, but my feeling is that if you dig deeper, you will find that TeX is becoming even more relevant today, because it is a pagination engine that works on mark-up. This means it can be used to produce output from HTML fully automatically, and unmatched by any other system. You only have to look at some XSL-FO output to realise that!<br>
LaTeX is not for everyone, but for documents with lots of math, there is still no better way of authoring. I fully agree that most people will never use LaTeX and never should and we need better authoring systems that are wysiwyg, but save in an exchangeable format.<br>
Peter, thanks for giving me the opportunity to get these off my chest!!</li>
<li><strong>Gerrit Imsieke</strong>, 2014/11/29<br>
At le-tex, we do a lot of LaTeX→XML conversion (yes, we’re one of these blackbox vendors, but we rarely re-key) and an increasing amount of XML→LaTeX conversion, since TeX is a fine rendering system. Our company is named after the typesetting system, so we should be somewhat “pro-TeX”. But I must admit that I share Peter’s original standpoint, rather than what the other distinguished people commenting here expressed. For one, the LaTeX→XML conversion is messy even for our own rather standardized LaTeX-first production lines, let alone for garden-variety author data. And I think we’re already using the most advanced tool around, which is <a href="http://dlmf.nist.gov/LaTeXML/" rel="nofollow">latexml</a> with its TeX-parser-mimicking processing approach that tries to expand author-defined macros until it reaches something that is defined as irreducible latexml constructs.<br>
Processing OOXML (.docx) documents is generally easier than processing LaTeX, despite the fact that most of the time they’re even less structured than LaTeX manuscripts. Even if they contain what is called “macros” in officeland, their content can be extracted without processing these macros, in contrast to TeX’s requirements.<br>
The more significant advantage though is that they may be accessed, processed and checked using XML tools (XPath 2, XSLT 2, Schematron), a fact that makes analysis and processing of a large amount of input much more determinist than parsing and processing the TeX input.<br>
We already don’t like <em>non-programmable</em> formats such as AsciiDoc or MarkDown because you need to successfully parse them prior to processing them. (XML-based formats, on the other hand, are parsable by default: if they’re not parsable, they’re just text and not XML.)<br>
What many authors have come to like and embrace about LaTeX, being able to use or define their domain-specific or individual vocabulary, is a curse to anyone who tries to make more sense of the content than a mere 2D graphics representation (e.g., PDF). And even creating a PDF can be hard because you can’t reliably, in an industrial-scale production environment, install and successfully run every package in its required version.<br>
I’m not against programmable documents – Excel has programmability (albeit not Turing complete) baked into its file format; I’ve done invoicing including VAT calculation and project scheduling including GANTT diagrams with LaTeX, and I’ve recently compiled a 330-pages PDF of a font coverage comparison table, generating HTML with XSLT 2 and printing it in the browser. But if you exchange data with others, you should avoid making the rendering depend on programs that have to be shipped with the content. I’d have the same objections against someone submitting their paper’s figures as JSON with an HTML page and D3 Javascript that renders their files. Or as CSV with a gnuplot settings file. Or, for that matter, requiring that an HTML page with MathML has to include a dedicated Javascript program in order to make sure that the math content may be rendered in all common Web browsers.<br>
The difference between someone including MathML and MathJax and someone using their own LaTeX macros is that 5 years from now, every widespread reading system will render the MathML in a sensible way, even without MathJax. Although the individual TeX macros <em>might</em> render the same way 30 years after, chances are that these macros rely on certain things that are taken for granted at write time, such as a certain font encoding or the presence of a dvips processor, and that it will just break with a future TeX distribution.<br>
For common TeX packages, longevity is not so much an issue. The currently available infrastructure of tools and publishers supports a certain number of common packages. They verify the compatiblity of input data with their configuration by attempting to render the input and see if it breaks. AMSMath content written on one system will most likely not break another installation that also supports AMSMath. But regarding input verification, we should demand more than a mere “it compiles” or “it renders ok” – provided that we don’t produce the content just for ourselves.<br>
I think this is what Peter’s after: It’s not about reproducing results with a similar setup (with the same tool, packages, fonts, …). It’s about shared vocabularies and syntaxes that render ok no matter what on current and future reading systems.<br>
In that regard, LaTeX is not an optimal format. But it certainly hits a sweet spot between terseness of input, individual and collaborative extensibility, and quality of output.<br>
On-the-fly conversion of LaTeX input to, and checking against, something more standardized – MathML etc. – in an environment such as <a href="https://www.sharelatex.com/" rel="nofollow">ShareLaTeX</a> might offer authors a smooth migration path. They’ll still be able to author and render it in the privacy of their homes or institutes, but by virtue of these online tools, they may also get realtime feedback on the processibility, renderabilty, and searchability in a wide range of environments. They should be made aware of that a potential reader will not receive the author’s own LaTeX→PDF rendering, but more likely a LaTeX→XML→HTML, LaTeX→HTML, LaTeX→HTML→EPUB, … rendering that is generated after automated input checks greenlighted it. So LaTeX will only be a front-end to something else, in a similar way as Word and its equation editor are. This something will be bigger in terms of ubiquity/exchangeability, but also more narrow in versatility (until content MathML and several other semantic languages become mainstream).
<ul>
<li><strong>Kaveh</strong>, 2014/11/30<br>
Hi Gerrit<br>
Thanks for detailed comments. Just to clarify, I am not suggesting LaTeX files are used for archiving, and agree that should be XML/MathML (or some other ML). So the long term stability of CTAN etc need not be a concern. The way I see it, TeX/LaTeX is useful in the following ways:<br>
— Authoring mathematical documents until something better comes along. Companies like WriteLatex and ShareLatex can help guide the author to write structured documents, so conversion to XML is easy.<br>
— Creating XML/MathML from those LaTeX documents (much better to use TeX than Perl, say).<br>
— Outputting XML to a PDF according to the user's requirements and on they fly.<br>
So in general I see TeX as a powerful engine to create XML, and to render XML to PDF.
<ul>
<li><strong>Gerrit Imsieke</strong>, 2014/11/30<br>
Hi Kaveh,<br>
Just a comment on the “creating XML with LaTex” part. Our first LaTeX→SGML converter dates back to 1996. It suffered from the Output SGML written to a DVI file and then extracting it with dvi2text (IIRC). We had issues with white space handling and line lengths, among others. Writing it to log or aux files didn’t seem a decent alternative because, IIRC, macro expansion worked differently when writing stuff to files than when writing it to the shipped page. And then we quickly would arrive in \expandafter\expandafter\expandafter\expandafter\expandafter hell, which in my view is sufficient justification for using another high-level programming language that may implement, but doesn’t rely on, macro expansion.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Douglas Carnall</strong>, 2014/11/29<br>
As George Bernard Shaw didn't say, all complexity is conspiracy against the laity. <a href="http://www.bmj.com/content/321/7262/711.2/rapid-responses" rel="nofollow">PDF was always the preferred format of the forces of reaction</a> to the web revolution. That there were free tools of mind-bending hardness-of-use to create them was always a feature, not a bug. (Seekers of ease could always pay that nice Mr. Adobe).<br>
Do not forget the sheer panic among publishers, conscious of the risk to their position as gatekeeper to the ziggurat of academic preferment, or bureaucrats anxious that their reports be considered &quot;influential,&quot; when, in, say, about 1997, they were confronted with a 10kB html file that would do about 97% of the job layout-wise, with a fraction of the resources of conventional typeset+print, and could instantly reach a global audience.<br>
Irrational as it may be, the hierarchy of visual prejudice that interprets &quot;typeset&quot; as &quot;quality&quot; runs deep, and there are a heap of folks out there whose entire economic interest is that you should fail.<br>
May I, nonetheless, wish your elbow every strength,<br>
D.</li>
<li><strong>David Farmer</strong>, 2014/12/01<br>
Asaf Karagila likes his papers in PDF.  Compared to what? Don't you think the following is a better way to read a paper on your computer screen?<br>
<a href="http://sl2x.aimath.org/development/sample/1402.3048/">Absolutely Choiceless Proofs</a>, by Asaf Karagila<br>
That version even looks good in a smart phone, which I doubt anyone would claim for PDF.<br>
This also illustrates Peter's point about re-keying. If you look at Section 4 in the link above, you will see a reference to &quot;Example 4&quot;.  But there is no example 4 in that version, because I set the theorems and examples to use two levels of numbering.  Likely the journal would do the same.  So the journal would pay someone to modify the LaTeX source by<br>
putting a <code>\label{...}</code> in the 4th example, and then <code>\ref{...}</code>  that label in Section 4.  This would also improve the PDF by allowing a link to the reference.<br>
The need to &quot;fix&quot; the LaTeX source before publication is a cost that most of us don't know about.  Maybe an awareness of that cost  (or a transfer of that cost to the author) could help motivate moving to a system which will end up with better documents on the web?</li>
<li><strong>William F. Hammond</strong>, 2014/12/01<br>
Experience with the best LaTeX-to-HTML converters shows that they require profiled LaTeX. Many well-written LaTeX documents conform to their profiles. For example, check out the processing of some LaTeX articles from <a href="http://arxiv.org/">arXiv.org</a> (in most cases without serious fussing in the source) here:<br>
<a href="http://www.albany.edu/~hammond/demos/Html5/arXiv/">http://www.albany.edu/~hammond/demos/Html5/arXiv/</a><br>
Formally profiled LaTeX brings in the discipline of SGML document types with matched XML shadows. Each workplace should have a few favorite profiles. One writes generalized LaTeX in the vocabulary of the profile. <code>\newcommand</code> is available, but its definitions must fully resolve in the vocabulary of the profile. The language of the profile should be sensible both for classical print and for HTML5. See my talk at the TUG meeting in 2010, <a href="http://www.albany.edu/~hammond/presentations/Tug2010/">http://www.albany.edu/~hammond/presentations/Tug2010/</a><br>
Profile-based systems like the GELLMU didactic production system, <a href="http://www.albany.edu/~hammond/gellmu/">http://www.albany.edu/~hammond/gellmu/</a>, are modular with processing components chained at the command line. They are easy to extend and modify. HTML5 output may be done with or without linking to something like MathJax. Moreover, someday if there is sufficient additional development of CSS, it could become reasonable for most browsers supporting CSS to render XML documents in the vocabulary of one’s LaTeX profile along the lines described in my TUG 2014 talk, <a href="http://www.albany.edu/~hammond/presentations/tug2014/">http://www.albany.edu/~hammond/presentations/tug2014/</a></li>
<li><strong>Peter</strong>, 2014/12/02<br>
Thanks to everyone for your thoughtful comments.</li>
<li><a href="http://mozillascience.org/mozilla-science-lab-week-in-review-december-1-7/">Pingback</a>, 2014/12/08</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LaTeX The Phantom Menace]]></title>
        <id>https://www.peterkrautzberger.org/0171/</id>
        <link href="https://www.peterkrautzberger.org/0171/">
        </link>
        <updated>2014-11-17T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><em>(Week 2 of the challenge.)</em></p>
<blockquote>
<p>LaTeX is the path to the dark side. LaTeX leads to TeX. TeX leads to DVI. DVI leads to suffering.<br>
-- not Yoda.</p>
</blockquote>
<p>Ever since joining MathJax, MathML has been a major part of my professional life. It's a slightly unhealthy relationship: wide-eyed enthusiasm and bottomless despair are frequent companions (although, I think, I'm becoming slightly more stable). Among the web standards of the W3C, MathML is, I think, unique and this is both good and bad (and topic for another post).</p>
<p>One thing that comes up regularly in discussions is how the use of LaTeX notation on the web is somehow evil. I believe this is a phantom menace.</p>
<h1>Five(-ish) reasons why TeX/LaTeX is no threat to MathML</h1>
<ul>
<li>Full TeX/LaTeX is so messy</li>
</ul>
<p>You might say that comparing full TeX/LaTeX and MathML is comparing apples and orange -- at most, I should be comparing math-mode TeX/LaTeX to MathML. But the problem is that the difference is tricky since mixing math and tex mode is all too common in the real world. Since TeX is a programming language and lacks enforceable best practices, there will never be a &quot;good&quot; subset of TeX/LaTeX that could provide reasonable markup constraints. The reality of how people use TeX/LaTeX is just too messy.</p>
<ul>
<li>on the web, &quot;LaTeX&quot; doesn't exist</li>
</ul>
<p>Quite literally, there is no such thing as &quot;LaTeX&quot; on the web. What is really being compared is a bunch of TeX-like input languages. If you think Markdown is bad off (yay CommonMark!) take a look at the number of easily incompatible TeX-like input on the web. MathJax's TeX-input vs Wikipedia's texvc vs iTeXMML vs pandoc vs ... -- they are all different on some level.</p>
<p>And even if you think: oh well, one day there'll be one standard LaTeX subset for the web (<a href="https://xkcd.com/927/">right?</a>), then there's still no threat here. Markdown, wikitext etc have never threatened HTML; raphaeljs, d3.js etc have never threatened SVG; threejs, pixi.js etc have never threatened WebGL. Instead, these tools pushed the use and thereby the standards forward. Pretending that TeX-like input (or asciimath or jqmath) has any other affect is a phantom.</p>
<ul>
<li>in the DOM, LaTeX does not make sense</li>
</ul>
<p>While you might still wish to speculate that LaTeX could somehow be coaxed into being playing nice with HTML, CSS etc, the story really ends at the DOM. LaTeX does not fit in the DOM; period.</p>
<ul>
<li>MathML is TeX for the web</li>
</ul>
<p>There is a reason why MathML is so damn good for mathematics -- it was created by people with a huge amount of experience, in particular in TeX and CAS. So in many ways, MathML is the natural continuation of the insights gained from TeX, applied to the web.</p>
<ul>
<li>MathML is better</li>
</ul>
<p>While at first sight MathML appears verbose (just like HTML or SVG might appear), it ultimately has one huge advantage over TeX: it is clean, self-contained, and stable. MathML provides a clear-cut presentation of equational content. It is infinitely easier to understand someone else's MathML than it is to understand someone else's TeX. (And you also cannot redefine <code>\relax</code> in MathML...)</p>
<ul>
<li>MathML has won already</li>
</ul>
<p>Fun fact: for roughly a decade, almost all new mathematics has been stored as MathML. Mathematicians are usually surprised by this -- doesn't every math journal accept TeX submissions? That's true and nobody would claim that the majority of mathematics is <em>authored</em> in MathML (come to think of it, that one probably goes to MS Word). But unless you publish with a very math-specific publisher (e.g., the AMS), your content is invariably converted into XML and your equational content into MathML. So even in pure math research (which is a miniscule amount of mathematics published compared to STEM in general) the authoritative format is MathML.</p>
<ul>
<li>If MathML failed because of math-mode LaTeX, that would be pathetic</li>
</ul>
<p>So LaTeX as a web standard is just not practical. Which brings me to my final point. If MathML fails because of a bunch math-mode LaTeX-like input thingies, then I think we deserve to fail. These are such a weak contender, MathML would have to be truly a miserable standard to loose out. By contraposition, the fact that MathML is far from miserable (as its success demonstrates every day) means it will not fail no matter how many web pages include TeX/LaTeX in their HTML.</p>
<h3>Where is this phantom menace coming from?</h3>
<p>The more interesting question for me is where this phantom originates from. I suspect this is really about the lack of browser implementations. It's always easier to look for a scapegoat. Making up a phantom like TeX will distract us from the important discussion: what's really holding back browser implementation? It's definitely not the math end where MathML simply rocks. And then the really interesting question can be: what could MathML 4 and MathML 5 look like?</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Asaf Karagila</strong>, 2014/11/17<br>
Join the dark side. We have cookies. Although in this context, it seems that you guys have cookies, to remember rendering preferences as needed. :-)<br>
I agree that the reality of LaTeX is messy. People are too used to MS Word and other “what you see” editors that they just want “something that works”, and learning the basic amount of LaTeX so the compilation is (1) without warnings, (2) looks professional to professionals is too much for most people.<br>
In other words: <a href="http://xkcd.com/1015/">http://xkcd.com/1015/</a> I did this to myself with LaTeX (and kerning).
<ul>
<li><strong>Peter</strong>, 2014/11/18<br>
Hm. You’re the second person now. It seems I have not been able to communicate this well (I blame the 30min time limit). This post is not a criticism of TeX/LaTeX, neither real TeX/LaTeX nor TeX-like stuff on the web. This is merely about the fact that TeX/LaTeX will never ever be a threat to any web standard, in particular MathML.
<ul>
<li><strong>Asaf Karagila</strong>, 2014/11/18<br>
I think that I understood that. I just felt the need to write that comment burning in my throat. Maybe it’s that cold I’ve got the past few days. My comment does feel as if I verbally sneezed on the page. :-)<br>
In either case, I see it as a case why MathML and web-based mathematics should be invested in, not as a replacement for LaTeX but as a companion. And I agree with that. But I felt the need to point out why LaTeX is still great, if you have a sensitive eye for these things. I don’t know, I’m just typing now into the comment box. Zoobitido. Blorgcups. I’ll stop. Now. Honestly! There, I stopped. :-)</li>
</ul>
</li>
</ul>
</li>
<li><strong>Paul Topping</strong>, 2014/11/18<br>
TeX (or LaTeX) is a perfectly fine input language, something that MathML is not and never was meant to be. It is always fine to keep around input language along with a representation generated from it so embedding TeX in a web page is fine too. As you say, Peter, the menace is phantom! MathML and TeX can live together in harmony but one cooks and the other does dishes.</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Welcome to Westdeutschland]]></title>
        <id>https://www.peterkrautzberger.org/0170/</id>
        <link href="https://www.peterkrautzberger.org/0170/">
        </link>
        <updated>2014-11-09T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>(<em>Week 1 of the challenge. Sorry for those looking for TeX/MathML related stuff. Sometimes, there are more urgent things, you know?</em>)</p>
<p>25 years ago today, <a href="https://en.wikipedia.org/wiki/Berlin_Wall#The_Fall">the wall fell</a> in Berlin, opening up Germany, opening up Europe. Admittedly, I don't remember much about that night; of course, I technically remember (and reconstructive memory is grand) but the event held little signficance to 10-year-old me. (Though arguably not zero signficance since I had actually visited Berlin for the first time that year, and I remember standing on a platform near the Brandenburger Tor, looking over the death strip to that iconic land mark and not really understanding things).</p>
<p>As you may have noticed, I recently moved back to Germany and most recently to Göttingen. This meant, after some 8+ years, I'm living in West Germany again. Admittedly, when I lived in Berlin while working on my PhD, I lived in a heavily gentrified (i.e., West-ernized) East Berlin quarter (fun fact 1: at the time, the percentage of foreign citizens in Prenzlauer Berg was precisely the city average, with the &quot;slight&quot; difference of almost all of those being from G8 countries...). Still, even that part of East Berlin (let alone other parts) remained structurally very different from, e.g., Bonn and Munich. A particular aspect for me was always the absence of the typical West German &quot;infrastructure&quot; of small shops and businesses (or ATMs for that matter). In any case, Prenzlberg still felt incredibly different from anything West German (though not as much as it did in the 90s or even early 2000s when I first fell in love with Berlin).</p>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/Gaussturm.jpg">
    <img alt="Gaussturm near Göttingen" src="https://www.peterkrautzberger.org/assets/2014/Gaussturm.jpg">
  </a>
  <figcaption>
    Gauss did not build this when <a href="https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss#Anecdotes">he was 9 years old</a>.
  </figcaption>
</figure>
<p>It has struck me how Göttingen, to me, seems like a perfect example of a West German city. I can't quite pinpoint this particular feeling. Maybe it is the beautiful 18th century city center (fun fact 2: supposedly Laplace urged Napoleon to spare Göttingen because Gauss might get hurt), maybe the lovely ring of late 19th century quarters surrounding it, perhaps the 50s Karstadt, the 70s Neues Rathaus, and the 90s malls. Certainly all of that a little. The city has also seen the typical post-WWII re-design towards cars as primary mobility solutions, which makes it a mess for the large number of bikes, pushing them to the sidewalks to collide with pedestrians (fun fact 3: I couldn't remember when I had last seen an atomkraft-nein-danke flag but I did see one on my first trip to Göttingen). Göttingen has this feel of wealthy-but-reluctant-to-admit-it (as so much of West Germany). It's filled with students making it appear modern and young and yet it's history weighs heavily in places (bizarro Bismarck adoration in the Bismarckturm does not compute). Göttingen is also surrounded by a beautiful countryside with a gazillion potential destinations for the weekend, many having been popular retreats at some point of the city's long history. Of course, for a mathematician, Göttingen is a particular attraction and yet it's hard to ignore <a href="https://de.wikipedia.org/wiki/Georg-August-Universit%C3%A4t_G%C3%B6ttingen#Vertreibung_und_Emigration">the great purge in 1933</a>.</p>
<p>Göttingen has this particular, everything-is-finished vibe (with a no-room-for-change beat) which I find so typical of West German cities. It's oddly appealing (especially after returning from SoCal) and yet slightly suffocating. If you want to live in a perfect example of West Germany, come stay in Göttingen. At the very least, you can stop by Gauss's grave and since it's a 5 minute walk from my home I expect you to stop by for a coffee after.</p>
<hr>
<p>Today, celebrations of the peaceful revolution of 1989 may be in focus. But on November 9 we always remember more. <a href="https://de.wikipedia.org/wiki/Novemberrevolution#Der_9._November_1918:_Das_Ende_der_Monarchie">1918</a>, <a href="https://en.wikipedia.org/wiki/Beer_Hall_Putsch">1923</a>, <a href="https://en.wikipedia.org/wiki/Kristallnacht">1938</a>, <a href="https://en.wikipedia.org/wiki/Berlin_Wall#The_Fall">1989</a>; I can't remember one without the other.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tiny blogging challenge]]></title>
        <id>https://www.peterkrautzberger.org/0169/</id>
        <link href="https://www.peterkrautzberger.org/0169/">
        </link>
        <updated>2014-11-03T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>This year hasn't exactly been great in terms of my blogging. Because life. After the Red Workbook concept tapered off I barely managed 1 post per month.</p>
<p>Still, I miss writing. So I'm setting myself a tiny blogging challenge for the few weeks remaining in 2014.</p>
<ul>
<li>write 1 post per week</li>
<li>and spend less than 30 minutes on a post</li>
</ul>
<h2>just one per week?</h2>
<p>Yes. I don't want to take on a 1-post-a-day challenge because, well, I'd simply fail. I'm no Cathy O'Neill. So most likely I'll write these posts on the weekend or possibly late at night.</p>
<p>One post per week seems reasonable. It's realistic, I've done it in the past yet it's far from what I'm currently able to do.</p>
<h2>30 minutes per post?</h2>
<p>Not a lot, I admit, but the averaging napping time of certain person. Given that my usual writing includes a procrastination phase of 5-6 months I'm expecting a change in quality. I'm just hoping for an improvement, given that more writing regularly should mean more practice.</p>
<h2>about what?</h2>
<p>I thought it might be prudent to have a couple of topics ready so that when I sit down (not unlikely on a Sunday at 11:30pm to make the deadline) I have a last resort for a topic to babble about.</p>
<ul>
<li>write a post about the blogging challenge (score!)</li>
<li>LaTeX The Phantom Menace</li>
<li>MathJax best practices: webfonts for text</li>
<li>LaTeX something something dark side</li>
<li>LaTeX the markdown for math</li>
<li>Why you should care about MathML</li>
<li>Why you shouldn't care about MathML</li>
</ul>
<p>Note that these are not actually related to drafts or even proper ideas. They are just ideas I jotted down over the past few weeks.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Asaf Karagila</strong>, 2014/11/03<br>
I dare you to sit and just type for 30 minutes straight. Real words, although syntax and grammar matter less here.<br>
Bonus points if it ends up a new and short proof of the equiconsistency between an inner model with a measurable and the existence of precipitous ideals.</li>
<li><strong>Micheal Pawliuk</strong>, 2014/11/04<br>
I would be interested in doing this too!<br>
Care to make it a little challenge? Along the lines of “the first person to go a week without posting donates some amount to the charity of the other’s choice?”<br>
Or are you all “talk” and no “walk”. :)
<ul>
<li><strong>Peter</strong>, 2014/11/09<br>
Hm… I would take on that challenge but I hesitate because I remember being very restricted financially as a grad student. I don’t want to add to that.</li>
</ul>
</li>
<li><a href="http://logic.dorais.org/archives/1593">Pingback</a>, 2014/11/09</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[It has not escaped our notice...]]></title>
        <id>https://www.peterkrautzberger.org/0168/</id>
        <link href="https://www.peterkrautzberger.org/0168/">
        </link>
        <updated>2014-10-26T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Just a quick post to show I'm still alive. One of the reasons why I haven't gotten to write recently is that we moved (yet again) to the final-for-oh-I-don't-know-who-knows-hopefully-a-few-or-more-years-that-would-be-nice-for-a-change destination.</p>
<p>And it seems my new neighborhood is trying to tell me something.</p>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/Goettingen21.jpg">
    <img alt="streetsign" src="https://www.peterkrautzberger.org/assets/2014/Goettingen21.jpg">
  </a>
  <figcaption>
    Street sign, Felix-Klein-Str., Göttingen
  </figcaption>
</figure>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/Goettingen11.jpg">
    <img alt="streetsign" src="https://www.peterkrautzberger.org/assets/2014/Goettingen11.jpg">
  </a>
  <figcaption>
    Street sign, Riemannstr., Göttingen
  </figcaption>
</figure>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/Goettingen3.jpg">
    <img alt="streetsign" src="https://www.peterkrautzberger.org/assets/2014/Goettingen11.jpg">
  </a>
  <figcaption>
    Street sign, Gaußstr., Göttingen
  </figcaption>
</figure>
<p>Oh well. I supposes that's what you get for moving to the town where these folks spent very productive years.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Becky</strong>, 2014/10/28<br>
Too cool, P.!</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[To Colloops a cardinal]]></title>
        <id>http://karagila.org/2014/to-colloops-a-cardinal/</id>
        <link href="http://karagila.org/2014/to-colloops-a-cardinal/">
        </link>
        <updated>2014-10-05T20:24:10Z</updated>
        <summary type="html"><![CDATA[<p>This is nothing new, but it's a choice-y way of thinking about it. Which is really what I enjoy doing.</p>

<p><strong>Definition.</strong> Let \(V\) be a model of \(\ZFC\), and \(\PP\in V\) be a notion of forcing. We say that a cardinal \(\kappa\) is &quot;colloopsed&quot; by \(\PP\) (to \(\mu\)) if every \(V\)-generic filter \(G\) adds a bijection from \(\mu\) onto \(\kappa\), but there is an intermediate \(N\subseteq V[G]\) satisfying \(\ZF\) in which there is no such bijection, but there is one for each \(\lambda\lt\kappa\). <a href="http://karagila.org/2014/to-colloops-a-cardinal/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Huge cardinals are huge!]]></title>
        <id>http://karagila.org/2014/huge-cardinals-are-huge/</id>
        <link href="http://karagila.org/2014/huge-cardinals-are-huge/">
        </link>
        <updated>2014-10-03T04:32:34Z</updated>
        <summary type="html"><![CDATA[<p>In <a title="Ramsey cardinals are large large small large cardinals" href="../../2014/ramsey-cardinals-are-large-large-small-large-cardinals/" target="_blank">a previous post</a>, I gave a humorous classification of large cardinals, dividing them to large large cardinals and small large cardinals, and so on. In particular huge cardinals were classified as large large large large large cardinals. But how large are they? Not surprisingly, very large.</p>

<p>In case you forgot, \(\kappa\) is a huge cardinal if there is an elementary embedding \(j\colon V\to M\), where \(M\) is a transitive class containing all the ordinals, with \(\kappa\) critical, and \(M\) is closed under sequences of length \(j(\kappa)\). <a href="http://karagila.org/2014/huge-cardinals-are-huge/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Anti-anti Banach-Tarski arguments]]></title>
        <id>http://karagila.org/2014/anti-anti-banach-tarski-arguments/</id>
        <link href="http://karagila.org/2014/anti-anti-banach-tarski-arguments/">
        </link>
        <updated>2014-09-22T12:31:38Z</updated>
        <summary type="html"><![CDATA[<p>Many people, more often than not these are people from <del>analysis or worse (read: physicists, which in general are not bad, but I am bothered when they think they have a say in how theoretical mathematics should be done),</del>  pseudo-mathematical, non-mathematical, philosophical communities, and from time to time actual mathematicians, would say ridiculous things like &quot;We need to omit the axiom of choice, and keep only Dependent Choice, since the axiom of choice is a source for constant bookkeeping in the form of non-measurable sets&quot;.</p>

<p>People often like to cite the paradoxical decomposition of the unit sphere given by Banach-Tarski. &quot;Yes, it doesn't make any sense, therefore the axiom of choice needs to be omitted&quot;. <a href="http://karagila.org/2014/anti-anti-banach-tarski-arguments/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ramsey cardinals are large large small large cardinals]]></title>
        <id>http://karagila.org/2014/ramsey-cardinals-are-large-large-small-large-cardinals/</id>
        <link href="http://karagila.org/2014/ramsey-cardinals-are-large-large-small-large-cardinals/">
        </link>
        <updated>2014-09-19T21:03:06Z</updated>
        <summary type="html"><![CDATA[<p>There is no well defined notion for what is a large cardinal. In some contexts those are inaccessibles, in others those are critical points of elementary embeddings, and sometimes \(\aleph_\omega\) is a large cardinal.</p>

<p>But we can clearly see some various degrees of largeness by how much structure the existence of the cardinal imposes. Inaccessible cardinals prove there is a model for second-order \(\ZFC\), and Ramsey cardinals imply \(V\neq L\). Strongly compact cardinals even imply that \(\forall A(V\neq L[A])\). <a href="http://karagila.org/2014/ramsey-cardinals-are-large-large-small-large-cardinals/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[My love-hate relationship with forcing]]></title>
        <id>http://karagila.org/2014/my-love-hate-relationship-with-forcing/</id>
        <link href="http://karagila.org/2014/my-love-hate-relationship-with-forcing/">
        </link>
        <updated>2014-09-10T07:27:39Z</updated>
        <summary type="html"><![CDATA[<p>Forcing is great. Forcing is an amazing method. If you can think about it, then you can probably force to make it happen. All it requires is some creativity and rudimentary understanding of the objects that you are working with.</p>

<p>Forcing is horrible. If you can think about it, you can encode it into generic objects. If you can't think about it, you can encode it into generic objects. If you think that you can't encode it into generic objects, then you are probably wrong, and you can still encode it into generic objects. <a href="http://karagila.org/2014/my-love-hate-relationship-with-forcing/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Fields Became "Nobel"]]></title>
        <id>http://karagila.org/2014/how-fields-became-nobel/</id>
        <link href="http://karagila.org/2014/how-fields-became-nobel/">
        </link>
        <updated>2014-08-13T10:18:23Z</updated>
        <summary type="html"><![CDATA[<p>Here is some interesting piece of mathematical history: How the Fields medal went from &quot;Soviet award&quot; to &quot;Mathematical Nobel&quot;.</p>

<p><a href="http://www.nytimes.com/2014/08/10/opinion/sunday/how-math-got-its-nobel-.html" target="_blank">How Math Got Its 'Nobel'</a>. <a href="http://karagila.org/2014/how-fields-became-nobel/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[This is not a blog post.]]></title>
        <id>http://karagila.org/2014/this-is-not-a-blog-post/</id>
        <link href="http://karagila.org/2014/this-is-not-a-blog-post/">
        </link>
        <updated>2014-08-12T07:35:06Z</updated>
        <summary type="html"><![CDATA[<p>This is not a blog post.</p>

<p>&nbsp; <a href="http://karagila.org/2014/this-is-not-a-blog-post/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ASCIIMathML to the rescue]]></title>
        <id>https://www.peterkrautzberger.org/0167/</id>
        <link href="https://www.peterkrautzberger.org/0167/">
        </link>
        <updated>2014-08-10T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Doug Schepers recently asked me for some advice for HTMLizing some mathematics. <a href="http://www.w3.org/People/Schepers/">Doug</a> is one of those exceptional people at the W3C who thrive in pushing the web and its standards forward. In this case, Doug was looking at <a href="http://www.musicdsp.org/files/Audio-EQ-Cookbook.txt">this bit of audio engineering</a> in the context of the <a href="http://www.w3.org/TR/webaudio/">Web Audio spec</a>.</p>
<p>As you can see, that text file has some beautiful ascii-art mathematics. Of course, Doug wanted to code this up properly for the web which means using MathML and the question was: what's the easiest way to do so?</p>
<p>It's not hard to see why I suggested <a href="http://www1.chapman.edu/~jipsen/mathml/asciimath.html">ASCIIMathML</a> (or asciimath). Asciimath was written by <a href="http://www1.chapman.edu/~jipsen/">Peter Jipsen</a> with whom I happen to have two lucky personal connections -- first, I luckily shared a room with Peter at BLAST 2010 (way before I got involved with MathJax, see <a href="http://boolesrings.org/krautzberger/tag/blast-2010/">these posts</a>), second I was lucky enough to enjoy his hospitality a couple of times while we lived in LA, including Peter taking me surfing for the first time in my life -- good times.</p>
<p>If I remember correctly, asciimath was born out of pure necessity -- finding a way for college students to write mathematics on the web. These kids were accustomed to graphing calculator style input, and Peter, of course, believed that MathML was the right way for an output on the web -- so in 2004 he started to write this beautiful JavaScript library to convert from one to the other.</p>
<p>Later on, <a href="http://dlippman.imathas.com/">David Lippman</a> wrote a nice MathJax addon, which was ultimately re-written by David Cervone, and so nowadays you can use asciimathml in any browser by combining it with MathJax.</p>
<h3>Why Asciimath is awesome</h3>
<p>First off, if you know some TeX I would probably describe asciimath as &quot;TeX without backslashes&quot;. Because, really, why not write <code>alpha</code> or <code>phi</code> for %alpha, phi%? Similarly, why not just write <code>sin</code> for %sin%? (Oh, and let's have <a href="https://github.com/mathjax/MathJax/issues/353">a fun discussion</a> about <code>phi</code> vs <code>varphi</code>, Unicode vs TeX. But not a problem, you can switch to whichever convention you like using MathJax.)</p>
<p>Second, if you know markdown, then I might describe asciimath as &quot;markdown for math&quot;. It's not TeX in all its (infamous) glory or even MathJax's TeX-like input with its many advantages for the web. It's much more restricted and that's by design -- much like markdown is.</p>
<p>Given its target (MathML) and its general webbiness, asciimath works smoothly with Unicode, which adds to its readability and usability (and internationalization). Everyone will probably appreciate that <code>-&gt;</code> and <code>→</code> work interchangeably (both of which seem much saner to me than anything LaTeX would suggest). So <code>f: A -&gt; B</code> and <code>f: A → B</code> produce identical MathML: %f: A -&gt; B% and %f: A → B%.</p>
<p>Similarly, asciimath's minimal approach does not need TeX's cumbersome <code>\begin{} \end{}</code> environments, but many important tools are available in much simpler ascii/computing notation, e.g., <code>((a,b),(c,d))</code> for matrices: %((a,b),(c,d))%.</p>
<h3>Making asciimath better</h3>
<p>Personally, I think asciimath probably deserves the title &quot;markdown for math&quot; although I think the title will go to TeX-like input after all (but that's another post).</p>
<p>What I'd really love to see is more people pushing asciimath further. The official <a href="https://github.com/mathjax/asciimathml">ASCIIMathML repository</a> is now hosted on MathJax's GitHub account and we even grabbed a nice domain at <a href="http://www.asciimath.org/">www.asciimath.org</a> to have an open page using Github pages for people to easily contribute enhancements to.</p>
<p>There's a lot of low hanging fruit in the form of improving the quality of the MathML (e.g., <code>a\\b</code> should probably produce <code>&lt;mfrac bevelled=&quot;true&quot;&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mfrac&gt;</code> instead of the problematic <code>&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;</code>) and of course asciimath by design should probably not strive to be feature complete (i.e., generate any kind of MathML) which means there should be situations where asciimath will simply fail and, much like markdown with HTML, it could perhaps gracefully mix MathML and asciimath.</p>
<p>But in any case, it's great to have this alternative to TeX-like inputs because TeX is ultimately holding math on the web back (but that's another post, for another time).</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Kasper Peulen</strong>, 2014/09/15<br>
I absolutely do agree that asciimath deserves the title “markdown for math”. However it seems that many mathematicians don't take anything serious that is ¬LaTeX.<br>
I'm really curious where your next blog post will be about. I do think that TeX is ultimately holding math on the web back. I think the web have seriously failed if in 10 year time, it is still the standard to use LaTeX code for a (good looking) mathematical chat. Or other forms of quick mathematical communcation on the web.<br>
But I'm not seeing ASCIIMath as the holy grail (yet). One reason that people may not take ASCIIMath seriously, is because it doesn't look the same as LaTeX. Not having a different mode for inline and display style math is something that arguably doesn't look so professional. I don't see people use ASCIIMath for writing a mathematical blog in this way.<br>
The lack of <code>\begin{align} \end{align}</code> like environements is also a downside of ASCIIMath. I use align environments all the time. I agree that ASCIIMathML aim shouldn't be to be feature complete. But I do think it should be able to generate 90 percent of what a mathematician uses. In other words 90 percent  of what is used at math.stackexchange for example.<br>
The last point I don't like about ASCIIMathML is its name. Being ASCII focussed is not what I envision for a future mathematical language. I think the language should be unicode focussed. Because unicode symbols are ultimately the easiest to read.<br>
For example take this LaTeX code:<br>
<code>\(W^{3\beta}_{\delta_1\rho_1\sigma_2}\)</code><br>
The ASCII variant:<br>
<code><code>W_(delta_1rho_1sigma_2)^(3beta}</code></code><br>
I think for the ultimate readable mathematical language, a hybrid of ASCIIMath and Murray Sargant's math language would be perfect: <a href="http://www.unicode.org/notes/tn28/UTN28-PlainTextMath-v3.pdf">http://www.unicode.org/notes/tn28/UTN28-PlainTextMath-v3.pdf</a><br>
In that language, you would have:<br>
<code>W_δ₁₂ρ₁σ₁^3β</code><br>
Which is the best readable of the three I think. (I see that ASCIIMathML does render some unicode symbols, but ₁ or ₂ or not rendered (what I would think is) correct.<br>
The problem of unicode symbols is of course that they are not easy to write in any plain html textarea input (or even ace editor). That is some real obstacle I try to battle with this little tool: <a href="http://kasperpeulen.github.io/PressAndHold/">http://kasperpeulen.github.io/PressAndHold/</a><br>
Ultimately, I think it should be possible to have unicode symbols be labeled &quot;easy to write&quot;. For example writing these unicode symbols <code>(W_δ₁₂ρ₁σ₁^3β)</code> in this comment box, was allmost trivial using that tool (which can be used as a bookmarklet script).<br>
Another way would be just mapping the ASCII macros already to their unicode symbols in the textarea element. Why should you convert beta to β only in the output? Why not converting it in the input while you are typing it ?<br>
I guess I want a language that could be described as &quot;ASCIIMathML with less ASCII&quot; Because, really, why not write α  or ϕ for alpha or phi ?</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Browsers should be commodities]]></title>
        <id>https://www.peterkrautzberger.org/0166/</id>
        <link href="https://www.peterkrautzberger.org/0166/">
        </link>
        <updated>2014-08-03T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>I think there is a world market for maybe five browsers<br>
-- not <a href="http://en.wikipedia.org/wiki/Thomas_J._Watson#Famous_misquote">Thomas J. Watson</a></p>
</blockquote>
<p>As my <del>one</del> two regular readers know, I work for <a href="http://www.mathjax.org/">a project</a> that's all about cross-browser support. It might, therefore, not come as a surprise that I use three browsers when working. That's mostly because I love incognito-modes; not just for the slightly increased privacy beyond ghostery/disconnect/abp but for the convenience of a clean, nowhere-logged-in browsing experience. However, a sense of realism forces me out of incognito-mode, so I spread things out.</p>
<p>On the desktop, I use Chrome for all Googly things (email, docs etc) and all social things (social networks, feed readers etc), Firefox (in privacy mode) for work things (Github etc) , and Chromium (in incognito mode) for other things (aka bouncing around the intertubez). I guess I also sometimes use &quot;Web&quot; (the Gnome browser; weird name) because it's WebKit and every so often I spin up one of Microsoft's testing VMs for IE. On my Android devices I use Chrome and Firefox mobile (I tried Opera and Dolphin as well but never felt like switching). &quot;Manual&quot; browsing I usually do in Chrome incognito tabs, links from other apps get opened in Firefox (because, trust). Maybe I should add the Wikipedia-beta app (which is so much better now) but I'm lucky to be on KitKat on all devices (no more horroribly-ancient-WebKit in apps) so browser-wise, I'm ok. And I feel the need to mention duckduckgo which is simply awesome (w00t! I just found out there's Android app. Gotta try that.)</p>
<p>But then there's an iPad in my home (where I'm only a guest). And of course, there are no choices for browsers: Safari is all you get. (In case you didn't know it already, all browsers on iOS have to use the underlying mobile Safari as a rendering engine because Apple's TOS forbid all browser engines in the app store). I think this needs to change.</p>
<hr>
<p>Somebody recently pointed out to me that after the convergence following the browser wars, we seem to be in a phase of (massive) divergence. And it's not going too well. Browser vendors are doing crazy stuff all over the place. Chrome gets a lot of heat (pulling MathML, CSS regions, threatening XSLT), though I find myself defending them more often than not because they are, at least, transparent (and they're also doing cool stuff like the earliest web components implementation, the CSS font loading API, the (failed) WebIntents etc). IE is like Chrome, just without the positive transparency. How crazy is it <a href="http://blogs.msdn.com/b/murrays/archive/2014/04/27/opentype-math-tables.aspx">to read over at Murray Sargent's blog</a> that IE is using a MathML-capable rendering system yet MathML is &quot;not planned&quot; in the <a href="http://status.modern.ie/">IE dashboard</a>? Then there's Apple which does things like happily touting MathML support when a) it's still enormously limited and b) it was all done by 3-4 volunteers (not together, mind you, all fighting by themselves, one following when the other burned out); or using the (non-standard) Pages engine in iBooks (only for iBooks Author books but still a heck of a bad practice).</p>
<p>Don't get me wrong, fundamentally, I think that's ok -- divergence needs to follow convergence. But I think it might take the same level of regulation that we saw in the browser wars to ensure we'll see convergence again. Currently, browsers are more like utilities, yet essentially unregulated. While desktop statistics are slightly better (but not actually good), mobile is an alarming monopoly. Safari on iOS, Chrome on Android; that's it. Sure, you can get Firefox for Android etc. but those browsers are at a massive disadvantage. Back in the day, Microsoft was forced to actively help users to install non-IE browsers (well, in the EU at least). The same should be done for all OSs, including mobile, and possibly even more in terms of apps/webview etc. (Granted, for FirefoxOS, this seems impossible; but just because Mozilla is mostly a positive force doesn't mean they can get a free pass.)</p>
<p>In the long run, I think, we need browsers to become commodities. For this they need to become easy to develop, to modify and recombine -- and with regulations to prevent abuse like we saw on Windows and we see on iOS. We need hundreds, maybe thousands of browsers, dozens of layout engines, modular, recombinable etc. I would love to be able to &quot;compile&quot; my own browser -- take some MathML support from one place, CSS modules from another, accessibility features from a third etc. pp. Not in the days-gone-by XML-dreams of modularization but in the &quot;hey, code-for-kids teaches you to write an HTML9 layout engine&quot; or in a <a href="https://github.com/breach/breach_core">breach</a>-but-for-real way (i.e., not just on top of Chromium), or (let's go crazy) write an HTML rendering engine in TeX or lolcode (what's the difference, really?).</p>
<p>Really, there simply has to be room for more than 5 browsers in the world.</p>
<hr>
<p>PS: Yes, this is mostly about &quot;layout engines&quot;, not &quot;browsers&quot;. To most people the distinction is meaningless.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Asaf</strong>, 2014/08/03<br>
You are <em>two</em> regular readers? Who’s the second one? :-)<br>
I agree that browsers should be more varied. I am surprised that you’re not using your own scripted Uzbl, instead of Chrome+Chromium (which are practically the same thing). I am also surprised that you’re not using Opera which uses its very own engine (unless I’m mistaken), where as Chrome, Chromium, Web and Safari all use the WebKit.<br>
But the reason is quite simple. Writing a modern browser engine is not a trivial task. It’s no longer a simple regex parser and a tcp socket. The more complex the web becomes, the harder it is to write a reliable rendering engine. So it’s only natural that a handful of competitors are left around.
<ul>
<li><strong>Peter</strong>, 2014/08/03<br>
I count as two readers 😉<br>
I don’t use uzbl out of the same sense of realism I mentioned above. I may have been writing confusingly / been confused (since the comments so far misunderstood what I was trying to say).<br>
First off, I wouldn’t mind using a single browser. That was not my point. Second, Chrome/Chromium and Safari/Web are now separate. Chrome forked WebKit into Blink last year and both sides have modified their end quite a bit since (especially ripping out components). Opera has given up on its Presto engine last year and is now based on Chromium (not just Blink as a rendering engine). Still, they are obviously quite close.<br>
Third, I’m aware how difficult writing a layout engine is (well, at least I’ve asked people who actually do that for a living). So is making cheese or building RAM modules; it does not make those products less of a commodity. But yes, my hope is that writing layout engines will eventually be much easier, perhaps easy enough for a typical “your first serious software project” kind of thing. (I’m also not saying this is a realistic hope.)
<ul>
<li><strong>Asaf Karagila</strong>, 2014/08/04<br>
Nice, taking cheap shots at an obvious typo. Of course I meant to ask “You have …” and of course you knew that!<br>
The comparison to cheese is wrong. Cheese is tasty, browser render engines are not. Also some cheese is left in a cave to grow mold, but then again I’m sure that the render engine of links, lynx, and friends are aged like fine scotch. :-)<br>
Thanks for the update on the world of rendering, I didn’t know all those news. Seems that a lot has been going on since I stopped caring about it. In either case, remember that Xul is the coolest engine of them all, since Xul is the gatekeeper for Gozer. (Okay, fine, it’s Zuul, but Xul has the same nice ring to it.)<br>
And speaking of Gozer, whenever you call a destructor of an object, you invoke Gozer. Egon is rolling in his early grave. (Need I also mention that a good browser engine should not cross streams? Alright, that’s my last Ghostbusters reference for this comment. I promise!)
<ul>
<li><strong>Peter</strong>, 2014/08/05<br>
Funny, I had missed your typo. I was really trying to joke that I count as two readers (crazy like that). Keep the Ghostbusters references coming!</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[No uniform ultrafilters]]></title>
        <id>http://karagila.org/2014/no-uniform-ultrafilters/</id>
        <link href="http://karagila.org/2014/no-uniform-ultrafilters/">
        </link>
        <updated>2014-07-24T10:48:23Z</updated>
        <summary type="html"><![CDATA[<p>Earlier this morning I received an email question from Yair Hayut. Is it consistent without the axiom of choice, of course, that there are free ultrafilters on the natural numbers but none on the real numbers?</p>

<p>Well, of course that the answer is negative. If \(\cal U\) is a free ultrafilter on \(\omega\) then \(\{X\subseteq\mathcal P(\omega)\mid X\cap\omega\in\cal U\}\) is a free ultrafilter on \(\mathcal P(\omega)\). But that doesn't mean that the question should be trivialized. What Yair asked was actually slightly subtler than that: is it consistent that there are free ultrafilters on \(\omega\), but no uniform ultrafilters on the real numbers? <a href="http://karagila.org/2014/no-uniform-ultrafilters/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why Carl Sagan was better than Neil deGrasse Tyson, and from the most of us too]]></title>
        <id>http://karagila.org/2014/why-carl-sagan-was-better-than-neil-degrasse-tyson-and-from-the-most-of-us-too/</id>
        <link href="http://karagila.org/2014/why-carl-sagan-was-better-than-neil-degrasse-tyson-and-from-the-most-of-us-too/">
        </link>
        <updated>2014-07-16T02:23:12Z</updated>
        <summary type="html"><![CDATA[<p>I've recently watched the finale of Cosmos, the new version, presented by Neil deGrasse Tyson. It was a very nice series which seem to push forward the fact that science is based on not knowing, rather than knowing, and the will to know. No, not will, the <em>need</em> to know. We need to know, and this is why we go on searching the answers to questions that haunt us.</p>

<p>Neil deGrasse Tyson pushed a lot on the point that we really push the planet to its limits, and we might be close to the point of no return from which there is only a terrible Venus-like fate to this planet. And that is an important issue, no doubt. <a href="http://karagila.org/2014/why-carl-sagan-was-better-than-neil-degrasse-tyson-and-from-the-most-of-us-too/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MathJax best practices; avoid display:none]]></title>
        <id>https://www.peterkrautzberger.org/0165/</id>
        <link href="https://www.peterkrautzberger.org/0165/">
        </link>
        <updated>2014-07-12T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>At MathJax we often get questions about specific examples of content / web design. Most of the time, people will show up on the <a href="https://groups.google.com/forum/#!forum/mathjax-users">MathJax User Group</a> (the preferred choice), <a href="http://stackoverflow.com/">StackOverflow</a> (semi-officially supported), and through our contact form on <a href="http://mathjax.org/">mathjax.org</a> (not the right choice but sometimes necessary for restricted users who can't post to either of the above).</p>
<p>Almost always, the problems are easy to track down (e.g., the infamous <a href="https://groups.google.com/forum/#!searchin/mathjax-users/15$20seconds/mathjax-users/iIvf2RkNdF4/Bi_TFDR3AsUJ">15s delay</a> if a custom configuration/extension/etc has an incorrect <code>loadComplete</code> call), sometimes they are bugs (e.g., the recent <a href="https://groups.google.com/forum/#!searchin/mathjax-users/chrome$20bold$20italic/mathjax-users/S5x-RQDPJrI/Tn31F4NjcTcJ">Chrome/WebKit webfont loading bug</a>), but of course every so often they hit on the subtleties that make what MathJax does so hard (ex/em matching, webfont detection etc.).</p>
<p>A surprising recent example for the latter revolves around the use of <code>display:none</code>. It usually comes up in reports of broken layout but the other day there was an interesting performance issue. To understand the second, it helps to understand the first.</p>
<h3>The layout trouble with <code>display:none</code></h3>
<p>The rendering issues sometimes seen for content which starts off with CSS <code>display:none</code> and later made visible stem from a simple problem: browser engines won't actually layout elements with <code>display:none</code>. MathJax on the other hand, needs to take a few vital measurements (basically widths and heights) to produce a correct layout -- and these measurements are not available when the content wasn't laid out by the browser.</p>
<p>To work around this predicament, we could just leave it to the author to work as if content with <code>display:none</code> was dynamically loaded content -- and force them to trigger a manual typeset when the content is revealed. But that's silly because the content is <em>there</em>, we should damn well use it.</p>
<p>So to work around <code>display:none</code>, MathJax does something quite simple: it moves the content into an invisible element that <strong>does</strong> get laid out -- using <code>visibility:hidden</code> with zero dimensions. Then MathJax can take the measurements, produce good rendering and put the rendered output back to the original location.</p>
<p>Now there's an obvious problem with that approach: where would you move the content to do the rendering? After all, just because something is <code>display:none</code> doesn't mean it has no context. It might be in a completely different CSS context (think: hints to a homework problem, sidebar content, menus), or the context might change once it becomes visible (think: popup footnotes/references, knowls). In other words, MathJax output in some other context might get screwed up when put back into the original context (e.g., matching font sizes correctly, dealing with inherited CSS). Of course, more often than not, this will work well but it is a general problem and should be avoided.</p>
<p>(Another way might be to use <a href="http://caniuse.com/#feat=mutationobserver">mutation observers</a>. Besides supported being limited, I think there's an argument to be made that layout should happen right away if possible. But it should probably become an option via an extension.)</p>
<h3>a surprising performance issue</h3>
<p>Recently, we saw a sample where all this magic had a very different side effect: serious performance issues. In that sample, hundreds of equations were hidden away with <code>display:none</code>. This meant that MathJax had to shift those around in the DOM -- and especially mobile browsers did not like that at all. What made matters worse was that the MathJax status messages gave no useful indication of what was going on, instead hanging at unrelated points -- because MathJax currently doesn't have a signal to catch a delay for such a &quot;simple&quot; action like laying out <code>display:none</code>. In the end, the sample (with 2000+ equations) left the user with the impression that their mobile browsers were hanging/crashing -- just because of all these necessary layout shenanigans! Darn!</p>
<h3>the moral</h3>
<p>The moral of the story is: use <code>visibility:hidden</code>, e.g., <code>position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;</code>), or tell MathJax to skip the content and <a href="http://docs.mathjax.org/en/latest/typeset.html">manually queue a typesetting call</a> when you reveal hidden content. If you want to put in some extra work, use <code>visibility:hidden</code>, let MathJax skip the hidden content and then queue a typesetting call for the hidden content after MathJax is loaded; that way the hidden content will be typeset only after the visible content is done (on MathJax's initial pass).</p>
<p>Any which way, don't get caught in bad layout or performance issues related to <code>display:none</code>!</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Carnival of Mathematics 111]]></title>
        <id>https://www.peterkrautzberger.org/0164/</id>
        <link href="https://www.peterkrautzberger.org/0164/">
        </link>
        <updated>2014-06-08T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>The math blogosphere is a friendly and relaxed placed. But there is one rule, I believe, we should all abide by: when <a href="http://aperiodical.com/">The Aperiodical</a> calls, you answer.</p>
<p>And so I'm honored to join the un-secret society of Carnival of Mathematics hosts. Indeed, the <a href="http://aperiodical.com/carnival-of-mathematics/">list of former and future hosts</a> over at The Aperiodical (who took over the organizational stress two years ago, stepping into the tremendously large footsteps of <a href="http://www.walkingrandomly.com/">Mike Croucher of Walking Randomly</a>), this list reads like a who-is-who of true math bloggers (the kind that cares for blogging as a community and art form). If you're not on it, do yourself a favor and <a href="mailto:katie@aperiodical.com">volunteer right now</a>. I'll wait. Honestly, I will. This post will still be here when you get back; I promise.</p>
<h3>Step closer, dear friend. Excitement awaits!</h3>
<p>In the time-honored tradition, let us remember that <a href="http://en.wikipedia.org/wiki/111_%28number%29">111</a> has many marvellous properties. However, if I were forced to name a favorite, I could not decide between the fact that the smallest magic square containing 1 and otherwise prime numbers, has a magical constant of 111, as well as the simple beauty of being a palindromic number.</p>
<ul>
<li>
<p>When you enter our attractions, you are almost unnaturally drawn to an oldie-but-goldie, an attraction worth a visit every time the carnival is in town: John Baez's <a href="http://www.math.ucr.edu/home/baez/roots/">Beauty of Roots</a>. As with Vincent Pantaloni (<a href="http://twitter.com/panlepan">@panlepan</a>) put it: &quot;The best math I stumbled upon this month is this visualisation of polynonmial roots&quot;.</p>
</li>
<li>
<p>Then stop by Antonio Sanchez Chinchon since he shares with us his <a href="http://aschinchon.wordpress.com/2014/05/08/the-mnemoneitor/">mnemoneitoR</a>, to translate numbers into easy-to-remember phrases inspired by books to generate funny mnemonic rules.</p>
</li>
<li>
<p>But don't stop there, wonders await as AP Goucher gives us <a href="http://cp4space.wordpress.com/2012/08/29/elliptic-curve-calculator/">the elliptic curve calculator</a>, a fixed page paper slide rule using elliptic curves.</p>
</li>
<li>
<p>And while you take a break, make sure to sit down and listen in on Alexandre Borovik's Math under the Microscope <a href="http://micromath.wordpress.com/2014/05/16/growing-neural-connections/">pointing us</a> to <a href="http://www.nytimes.com/2014/05/18/magazine/who-gets-to-graduate.html">this New York Times article</a> on a simple one-time exercise that might prevent community college students from dropping out of math classes.</p>
</li>
<li>
<p>But throw yourself back into the crowds of the carnival because when Colin Beveridge (of <a href="http://www.flyingcoloursmaths.co.uk/">Flying Colours Math</a>) was asked why he loves math, he wrote a <a href="http://www.flyingcoloursmaths.co.uk/student-asks-love-maths-much/">short and sweet post</a> to make his answer public. As luck will have it, a student asked Stephen Cavadino of <a href="http://cavmaths.wordpress.com/">cavmaths</a> the very same, and so we can enjoy <a href="http://cavmaths.wordpress.com/2014/05/16/whats-so-good-about-maths/">another answer</a> that might inspire future students to grow their own and personal passion for mathematics.</p>
</li>
<li>
<p>By now you're hungry and rightfully so. However, if you ever wondered where to place a hot dog stand, and how to adapt when the best customer moves into a motorhome, then fear not -- David Orden at <a href="http://mappingignorance.org/">Mapping Ignorance</a> will fill your stomach with <a href="http://mappingignorance.org/2014/05/14/place-business-one-customers-keeps-moving/">a great post</a>, taking you from Sylvester's original question back in 1857 all the way to today's cutting edge research.</p>
</li>
<li>
<p>With a full belly, let's head over to the Aperiodical, where <a href="http://aperiodical.com/author/paul/">Paul Taylor</a> tackled the mind-bending and subtle <a href="http://aperiodical.com/2014/05/the-hidden-maths-of-eurovision/">hidden maths of the Eurovision song contest</a> while <a href="http://aperiodical.com/author/katie/">Katie Steckles</a> provides us with a <a href="http://aperiodical.com/2014/05/matt-parker-talks-percentages/">recap of Matt Parker's appearance</a> on the BBC's consumer moanfest, Watchdog, where <a href="https://twitter.com/standupmaths">Matt</a> helped everyone get their percentages right.</p>
</li>
<li>
<p>And while you leave, why not trust him when the Aperiodical's <a href="http://checkmyworking.com/">Christian Perfect</a> points you in the direction of Nick Berry's excellent blog <a href="http://www.datagenetics.com/">DataGenetics</a>, with a post that will introduce you to the wonders of <a href="http://www.datagenetics.com/blog/may42014/index.html">Amidakuji</a>, bringing together braid theory and a very old arcade game.</p>
</li>
<li>
<p>Then go on and follow Katie Steckle to visit <a href="http://goadingtheitgeek.blogspot.co.uk/">Goading the IT geek</a>'s post on <a href="http://goadingtheitgeek.blogspot.co.uk/2014/05/blast-from-past.html">the deceivingly simple problem of calculating averages</a>.</p>
</li>
<li>
<p>And if you find yourself in a part of the Carnival you have already visited, why not take a chance and run into Stephen Cavadino's posts on <a href="http://cavmaths.wordpress.com/2014/05/04/the-maths-of-the-playground/">mathematics on children's playgrounds</a> and small <a href="http://cavmaths.wordpress.com/2014/05/25/833/">puzzle on the number 71</a>?</p>
</li>
<li>
<p>Back on the main road through the carnival, you'll see in the far end <a href="http://www.theguardian.com/science/alexs-adventures-in-numberland/">Alex's adventures in numberland</a>, where Alex Bellos has learned from Joseph Mazur <a href="http://www.theguardian.com/science/alexs-adventures-in-numberland/2014/may/21/notation-history-mathematical-symbols-joseph-mazur">how surprisingly new mathematical notation</a> is.</p>
</li>
<li>
<p>And if you like to gamble, dear friend, worry not. The BBC's Janet Ball can tell you a story that might encourage you, how the (in)famous <a href="http://www.bbc.co.uk/news/magazine-27519748">MIT blackjack team</a> won enormous amounts of money tackling the odds with their mathematical prowess.</p>
</li>
<li>
<p>Behold, the Mechanical Turk is nothing against our next mind-bending adventure as <a href="http://blog.andreahawksley.com/">Andrea Hawksley</a> takes you on a dive into <a href="http://blog.andreahawksley.com/non-euclidean-chess-part-2/">Non-Euclidean Chess</a>!</p>
</li>
<li>
<p>After his shocker, cool down a little and enjoy the talented <a href="http://mathtango.blogspot.com/">Shecky Riemann</a> sharing with us <a href="http://mathtango.blogspot.com/2014/05/fawn-nguyen-passion-personified.html">his interview with passionate math-ed blogger Fawn Nguyen</a>.</p>
</li>
<li>
<p>Nest step into the ghost house at Google+, where <a href="https://plus.google.com/app/basic/stream/z13ly3pi4x2ozv0dp22vejg4izrmdno34">Richard Green took everyone on a journey</a> from simply squaring prime numbers to monsters and moonshine and some of the most complex and arduous mathematics of the 20th century.</p>
</li>
<li>
<p>In our version of the house of mirros, behold: Nim and Fractals -- what could go better together? The amazing Tany Khovanova provides us with <a href="http://blog.tanyakhovanova.com/?p=496">the background on her latest paper</a> with one of her high school students in <a href="http://web.mit.edu/primes/">MIT's PRIMES project</a></p>
</li>
<li>
<p>But you obviously cannot get enough! Well, then, we dare you to follow The Aperiodical's <a href="http://aperiodical.com/author/peter/">Peter Rowlett</a> into the <a href="http://aperiodical.com/2014/05/podcasts-for-a-university-maths-student/">long, long list of podcasts for university math students</a>. Only the bravest have listened to them all!</p>
</li>
<li>
<p>As immortal challenges go, Chris Burke of <a href="http://mrburkemath.blogspot.com/">(x,why?)</a> celebrates overcoming one: the <a href="http://mrburkemath.blogspot.de/2014/04/day-1-30-posts-in-30-days-thats-problem.html">30 posts in 30 days blogging challenge</a> with a fine post on the <a href="http://mrburkemath.blogspot.com/2014/05/day-30-of-30-you-want-piece-of-this.html">struggle students face with piecewise functions</a>.</p>
</li>
<li>
<p>For the craziest ride of this carnival, be sure to stop by <a href="http://mathsball.blogspot.com.es/">Matifutbol</a> where, just in time for the start of the World Cup 2014 in Brazil, Herminio's post on <a href="http://mathsball.blogspot.com.es/2014/06/mathematical-binary-trees-estructure.html">trees and googols at the World Cup</a> will take you on a wild trip to all possible competitions, the Wedderburn-Etherington number and the very edge of the known universe, making you appreciate how simple life will be over the next 4 weeks.</p>
</li>
<li>
<p>If this is too wild, get your dose of World Cup math blogging at <a href="http://legavrik.blogspot.co.uk/">Matt Scroggs</a>'s who will tell you <a href="http://legavrik.blogspot.co.uk/2014/05/world-cup-stickers.html">how many Panini packages</a> you really need to buy to complete that Panini book you've been hiding under your bed all these years.</p>
</li>
<li>
<p>The strongest man in the world cannot resist the powers of set theoretical forcing. And <a href="https://www.peterkrautzberger.org/0164/%5Bhttp://boolesrings.org/asafk">Asaf Karagila</a> will make sure you won't wrongly use the analogy of field extensions to <a href="https://www.peterkrautzberger.org/0164/%5Bhttp://boolesrings.org/asafk/2014/forcing-this-has-to-stop/">explain forcing</a>.</p>
</li>
<li>
<p>And as you leave this Carnival behind, excited, exhausted, and content, you might still turn back for that one last ride, that one last attraction. So head over to Patrick Honner / <a href="http://mrhonner.com/">Mr Honner</a> as he takes on the The <a href="http://grantwiggins.wordpress.com/2014/04/23/conceptual-understanding-in-mathematics/">Grant Wiggins</a> Conceptual Understanding Challenge, allowing us, <a href="http://mrhonner.com/archives/13620">through his response</a>, a peek into that insightful brain of his.</p>
</li>
</ul>
<p>And so the Carnival comes to an end and we move on. As we must. Always.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><a href="http://aperiodical.com/2014/06/carnival-of-mathematics-111/">Pingback</a>, 2014/06/09</li>
<li><a href="https://web.archive.org/web/20140725153526/http://letsplaymath.net/2014/06/17/math-teachers-and-homeschool-bloggers-we-want-you-2/">Pingback [Wayback Machine]</a>, 2014/06/17</li>
<li><a href="http://cavmaths.wordpress.com/2014/06/27/maths-teachers-at-play-75/">Pingback</a>, 2014/06/27</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Forcing. This Has To Stop.]]></title>
        <id>http://karagila.org/2014/forcing-this-has-to-stop/</id>
        <link href="http://karagila.org/2014/forcing-this-has-to-stop/">
        </link>
        <updated>2014-06-07T02:36:04Z</updated>
        <summary type="html"><![CDATA[<p>Most, if not all, set theorists at one point or another were asked by a fellow mathematician to explain how forcing works. And many chose to give as an opening analogy field extensions. You can talk about how the construction of an algebraic closure is a bit similar, since the generic filter is a bit like the maximal ideal you use to make this construction; or you can talk about adding a transcendental number and the things that change as you add it.</p>

<p>But both these analogies would be wrong. They only take you so far, and not further. And if you wish to give a proper explanation to your listener, there will be no escape from the eventual logic and set theory of it all. I stopped, or at least I'm doing my best, using these analogies. I do, however, use the analogy of &quot;How many roots does \(x^{42}-2\) has?&quot; as an example for everyday independence (none in \(\mathbb Q\), two in \(\mathbb R\) and many in \(\mathbb C\)). But this is to motivate a different part of the explanation: the use of models of set theory (e.g. &quot;How can you add a real number??&quot;, well how can you add a root to a polynomial?) and the fact that we don't consider the universe per se. Of course, in a model of \(\ZFC\) we can always construct the rest of mathematics internally, but this is not the issue now. Just like we have a model of one theory, we can have a model for another. <a href="http://karagila.org/2014/forcing-this-has-to-stop/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Just when I thought I was out]]></title>
        <id>https://www.peterkrautzberger.org/0163/</id>
        <link href="https://www.peterkrautzberger.org/0163/">
        </link>
        <updated>2014-05-31T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I recently pondered whether I should stop reading the few remaining <a href="http://mathoverflow.net/">mathoverflow</a> and <a href="http://math.stackexchange.com/">math.stackexchange</a> feeds I keep in my feed reader (remember that archaic technology? I still use it heavily). Ever since I left research, I had dialed down the number of tags I was following on those wonderful sites, both because it was painful and because I lost interest (as contradictory as that may sound); in the end, all I kept were the [ultrafilter] tag on MO and the [set theory] tag on <a href="http://math.se/">math.SE</a>.</p>
<p>But I found myself brushing past even those few postings, so that yesterday I thought it was time to move on and remove them from my feed reader, de fact closing the &quot;math&quot; section of my feed reader, where all my research related feeds ended up. And then just as I am about to, I see <a href="http://math.stackexchange.com/a/814110">this question and answer</a> which, while neither spectacular or particular, reminded me why I once fell in love with set theory.</p>
<p>So, Asaf, I will call you Joey Zasa from now on.</p>
<iframe width="100%" height="510" src="https://www.youtube.com/embed/UneS2Uwc6xw" frameborder="0" allowfullscreen=""></iframe>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Asaf Karagila</strong>, 2014/05/31<br>
You’re welcome! :-)</li>
<li><strong>Ioanna</strong>, 2014/06/02<br>
Nice question and answers there! Set theory is fun Peter, it doesn’t have to be your job for you to play with it :)
<ul>
<li><strong>Peter</strong>, 2014/01/06<br>
Thanks, Ioanna. Well, when I left set theory, part of the reason was that it had stopped being fun. But I always thought our generation is lucky in the way the web helps us stay connected with our research area long after we left for other ventures (I even left a productive comment on a <a href="http://math.se/">math.SE</a> answer this year 😉 ).</li>
</ul>
</li>
<li><strong>Peter</strong>, 2014/06/05<br>
Bam! Math! \[ f: X \to Y \] And $ \sqrt{2} \le 2 $
<ul>
<li><strong>Asaf Karagila</strong>, 2014/06/06<br>
The first one is false in general, and the second one is false in \(\mathbb Q\) and \(\mathbb C\).<br>
😉
<ul>
<li><strong>Peter</strong>, 2014/06/09<br>
Indeed. It was just a test for MathJax rendering in the comments. I should be less careless 😉
<ul>
<li><strong>Asaf Karagila</strong><br>
Have you been dabbling with intuitionistic logic again?<br>
“Less careless” + Law of excluded middle = “More careful”.<br>
But he use of LEM is essential here! :-)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Debates About The Climate]]></title>
        <id>http://karagila.org/2014/debates-about-the-climate/</id>
        <link href="http://karagila.org/2014/debates-about-the-climate/">
        </link>
        <updated>2014-05-12T14:13:50Z</updated>
        <summary type="html"><![CDATA[<p>John Oliver (and his team of writers, I suppose) makes a particularly sharp point about the role of the media in the debate about climate changes.</p>

<p><iframe height="315" width="560" src="https://youtube.com/embed/cjuGCJJUGsg" frameborder="0" allowfullscreen></iframe> <a href="http://karagila.org/2014/debates-about-the-climate/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[HEAR YE, HEAR YE! The Carnival of Math is in town]]></title>
        <id>https://www.peterkrautzberger.org/0162/</id>
        <link href="https://www.peterkrautzberger.org/0162/">
        </link>
        <updated>2014-05-08T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Gee, it's been quiet around here! Between MathJax release work and diaper wrangling, blogging has been neglected. Inconceivable?</p>
<p>INCONCEIVABLE!</p>
<iframe width="100%" height="510" src="https://www.youtube.com/embed/D58LpHBnvsI" frameborder="0" allowfullscreen=""></iframe>
<p>The kind overlords of the math blogosphere to whom we are all but humble servants, yes, the one true and ever-so-periodical team at <a href="http://aperiodical.com/">The Aperiodical</a> have called upon yours truly to host a carnival. Not any carnival, but a blogging carnival of math.</p>
<p>So I invite to step into our tiny realm of mathblogging and help me host a grand show for all the world to see.</p>
<p><a href="http://aperiodical.com/carnival-of-mathematics">Bring me your posts, your rants, your poems.</a></p>
<p><a href="http://aperiodical.com/carnival-of-mathematics">Share idle idiosyncrasies, deranged derivations, cool calculations, and rash remarks.</a></p>
<p>Give it your best and your worst and your all. For the Carnival of Math is here and all creatures are welcome on its arena's floor.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p15]]></title>
        <id>https://www.peterkrautzberger.org/0161/</id>
        <link href="https://www.peterkrautzberger.org/0161/">
        </link>
        <updated>2014-04-08T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p15-1.jpg">
    <img alt="red workbook, p15-1" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p15-1.jpg">
  </a>
  <figcaption>
    Red Workbook, p.15, part 1
  </figcaption>
</figure>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p15-2.jpg">
    <img alt="red workbook, p15-2" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p15-2.jpg">
  </a>
  <figcaption>
    Red Workbook, p.15, part 2
  </figcaption>
</figure>
<h3>Transcript</h3>
<h4>Left page</h4>
<ul>
<li>Forcing möglich?</li>
<li>Für strongly summable? kaputtmachen???????</li>
<li>Bem (* [[circled]]) [[boxed]]</li>
</ul>
<h4>Right page</h4>
<ul>
<li>[4.] Eine &quot;elementare&quot; Charakterisierung von &quot;zentral&quot;</li>
<li>4.1 Def. \(A\subseteq S\) Setze
<ul>
<li>(a) \(T_ A = \{ (a_ 0, \ldots, a_ {n-1} ) \in S^{&lt; \omega} : FP(a_ i)_ {i=0}^{n-1} \subseteq A \}\)</li>
<li>\(T_A\) Teilbaum von \(S^{&lt; \omega}\).</li>
<li>Notiz:
<ul>
<li>\(A\) IP &lt;=&gt; \(T_A\) hat unendlichen Zweig</li>
<li>tatsaechlich bei konstruktion von IP-Menge zeigt man,</li>
<li>dass es sehr viele unendliche Zweige gibt</li>
<li>SK: sogar perfekter Baum</li>
</ul>
</li>
<li>(b) Fuer \(R \subseteq S^{&lt;\omega}\) Teilbaum, \(r \in R\) setze
<ul>
<li>\(N_r := N_r^R := \{ a \in S : r^a \in R \} (\subseteq S)\) [[a diagram: the tree \(R\) and the set of successors \(N_r\)]]</li>
</ul>
</li>
</ul>
</li>
<li>4.2 Satz [14.25 in HS]
<ul>
<li>Fuer \(A\subseteq S\) aequivalent: (a) \(A\) zentral
<ul>
<li>(b) \(\exists R \subseteq T(A)\) Teilbaum mit (2) \(\{ N_r^R: r \in R\}\) cwpws
<ul>
<li>(1) \(r\in R, a \in N_r \Rightarrow a\cdot N_{r \hat{} a} \subseteq N_r\)</li>
</ul>
</li>
<li>Solches \(R\) heisst \(\star\)-tree [in HS].</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>partial Translation</h3>
<h4>Left page</h4>
<ul>
<li>Forcing possible?</li>
<li>For strongly summable? destroying???????</li>
</ul>
<h4>Right page</h4>
<ul>
<li>[4.] An &quot;elementary&quot; Characterization of &quot;central&quot;</li>
<li>4.1 Definition. For \(A\subseteq S\) define:
<ul>
<li>(a) \(T_ A = \{ (a_ 0, \ldots, a_ {n-1} ) \in S^{&lt; \omega} : FP(a_i)_ {i=0}^{n-1} \subseteq A \}\)</li>
<li>\(T_A\) subtree of \(S^{&lt; \omega}\).</li>
<li>Note:
<ul>
<li>\(A\) IP &lt;=&gt; \(T_A\) includes an infinite branch</li>
<li>in fact, in the construction of IP-set one shows that there are many infinite branches</li>
<li>Sabine Koppelberg: in fact, a perfect subtree.</li>
</ul>
</li>
<li>(b) For \(R \subseteq S^{&lt;\omega}\) subtree, \(r \in R\) define
<ul>
<li>\(N_r := N_r^R := \{ a \in S : r^a \in R \} (\subseteq S)\) [[the successor set]]</li>
</ul>
</li>
</ul>
</li>
<li>4.2 Theorem [14.25 in HS]
<ul>
<li>For \(A\subseteq S\) TFAE:
<ul>
<li>(a) \(A\) central</li>
<li>(b) \(\exists R \subseteq T(A)\) subtree with
<ul>
<li>(2) \(\{ N_r^R: r \in R\}\) cwpws (collectionwise piecewise syndetic)</li>
<li>(1) \(r\in R, a \in N_r \Rightarrow a\cdot N_{r \hat{} a} \subseteq N_r\)</li>
</ul>
</li>
<li>Such \(R\) is called \(\star\)-tree [in HS].</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Notes</h3>
<p>We're getting to some serious results here. The &quot;tree characterization&quot; of centrality is, I think, not known (or not appreciated) widely enough. It might be a lot to wrap your mind around as a student but this might be one of the better ways of providing some insights into the notion of cwpws sets.</p>
<p>This page is very amusing. The random note on destroying strongly summable ultrafilters is what occupied a large part of my postdoctoral research. Apparently it took me a while to realize this is an interesting question. Come to think of it, Francois and I also spent quite a bit of time on the tree characterization; makes me want to skip ahead to a postdoc notebook...</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Downward Löwenheim-Skolem Theorems and Choice Principles]]></title>
        <id>http://karagila.org/2014/lowenheim-skolem-choice/</id>
        <link href="http://karagila.org/2014/lowenheim-skolem-choice/">
        </link>
        <updated>2014-03-31T03:00:47Z</updated>
        <summary type="html"><![CDATA[<p>I have posted a new note on the <a href="../../papers.html"><strong>Papers</strong></a> page.</p>

<p>It's a short little proof that the classic downward Löwenheim-Skolem theorem is equivalent to \(\DC\), and that for a well-ordered \(\kappa\), the downward Löwenheim-Skolem asserting the existence of models of cardinality \(\leq\kappa\) is in fact equivalent to the conjunction of \(\DC\) and \(\AC_\kappa\). <a href="http://karagila.org/2014/lowenheim-skolem-choice/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[...And we're back!]]></title>
        <id>http://karagila.org/2014/and-were-back/</id>
        <link href="http://karagila.org/2014/and-were-back/">
        </link>
        <updated>2014-03-31T00:12:27Z</updated>
        <summary type="html"><![CDATA[<p>Okay, I took the time to make some changes to my homepage.</p>

<p>Clearly, the theme is different now. I also changed the content of the Papers page. I removed the abstracts (for some reason I thought this is going to be a cool thing to have, but with time it grew to annoy me greatly). I will definitely post a few things there in the coming time, some notes and eventually some nice papers -- I hope! <a href="http://karagila.org/2014/and-were-back/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p14]]></title>
        <id>https://www.peterkrautzberger.org/0160/</id>
        <link href="https://www.peterkrautzberger.org/0160/">
        </link>
        <updated>2014-03-26T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p14.jpg">
    <img alt="red workbook, p14" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p14.jpg">
  </a>
  <figcaption>
    Red Workbook, p.14
  </figcaption>
</figure>
<h3>Transcript</h3>
<ul>
<li>Beweis: (a) =&gt; (b): \(\mathfrak{B} \subseteq q \Rightarrow \mathfrak{D} = \{ D_e : e \in [ \mathfrak{B} ]^{&lt; \omega} \} \subseteq q\)
<ul>
<li>Nimm \(g_e \in [S^{&lt; \omega}]\) mit \(\beta S \cdot q \subseteq \bigcup_{x \in g_e} \widehat{ x^{-1} D_e} = \widehat{C_e}\)</li>
<li>[ Verfeinerung von pws: \(A\) pws \(\in q \in K(\beta S) \Rightarrow \exists e \in [S^{&lt;\omega}]: \beta S \cdot q \subseteq \bigcup x^{-1} A\)]</li>
<li>$\Rightarrow \beta S \cdot q \subseteq \bigcap_{C \in \mathfrak{C}} \widehat{C_e} = Y_e \stackrel{3.3}{\Rightarrow} $ Beh.</li>
</ul>
</li>
<li>(b) =&gt; (a): seien \(g_e, C_e, \mathfrak{C}\) wie in (b).
<ul>
<li>Nimm \(p \in \beta S\) mit \(L := \beta S \cdot p \subseteq Y_{\mathfrak{C}}\) oBdA \(p\in K(\beta S)\).</li>
<li>\(\Rightarrow p\in L\).</li>
<li>Fuer \(e \in [\mathfrak{B}]^{&lt;\omega}: p \in \widehat{C_e} = \bigcup_{x\in g_e} \widehat{x^{-1} D_e}\)</li>
<li>\(\Rightarrow \exists x_e \in g_e: p \in \widehat{ x_e^{-1}D_e}\).</li>
</ul>
</li>
<li>((?) wieso eDe?) Nimm \(w\in \beta S\) mit \(S_e := \{ x_f : f \supseteq e, f \in [ \mathfrak{B}]^{&lt;\omega} \} \underset{?}{\in} \omega (\forall e \in \beta S)\)</li>
<li>Setze \(q = w \cdot p \Rightarrow q \in \beta S \cdot p \subseteq K(\beta S)\) und</li>
<li>es ist \(\mathfrak{B} \subseteq q\) [\(B\in \mathfrak{B}\) zeige: \(B\in q = w\cdot p\). Aber \(e:{B} \in [\mathfrak{B}]^{\omega}\)
<ul>
<li>\(D_e = B, S_e \in \omega\); Fuer alle \(f\supseteq e: x_f \cdot p \in \widehat{D_f}\)</li>
<li>\(\widehat{D_f} \subseteq \widehat{D_e} = \widehat{B} \Rightarrow S_e \cdot p \subseteq \widehat{B}\)</li>
<li>\(\Rightarrow w \cdot p \in \widehat{B}\)]</li>
</ul>
</li>
<li>Also folgt die Behauptung.□</li>
</ul>
<h3>partial Translation</h3>
<ul>
<li>Proof:</li>
<li>(a) =&gt; (b):
<ul>
<li>\(\mathfrak{B} \subseteq q \Rightarrow \mathfrak{D} = \{ D_e : e \in [ \mathfrak{B} ]^{&lt; \omega} \} \subseteq q\)</li>
<li>Take \(g_e \in [S^{&lt; \omega}]\) with \(\beta S \cdot q \subseteq \bigcup_{x \in g_e} \widehat{ x^{-1} D_e} = \widehat{C_e}\)
<ul>
<li>[\(A\) pws, \(A \in q \in K(\beta S) \Rightarrow \exists e \in [S^{&lt;\omega}]: \beta S \cdot q \subseteq \bigcup_{x\in e} x^{-1} A\)]</li>
</ul>
</li>
<li>$\Rightarrow \beta S \cdot q \subseteq \bigcap_{C \in \mathfrak{C}} \widehat{C_e} = Y_e \stackrel{3.3}{\Rightarrow} $ the claim.</li>
</ul>
</li>
<li>(b) =&gt; (a): let \(g_e, C_e, \mathfrak{C}\) as in (b).
<ul>
<li>Then take \(p \in \beta S\) mit \(L := \beta S \cdot p \subseteq Y_{\mathfrak{C}}\); without loss \(p\in K(\beta S)\).</li>
<li>\(\Rightarrow p\in L\).</li>
<li>For \(e \in [\mathfrak{B}]^{&lt;\omega}: p \in \widehat{C_e} = \bigcup_{x\in g_e} \widehat{x^{-1} D_e}\)</li>
<li>\(\Rightarrow \exists x_e \in g_e: p \in \widehat{ x_e^{-1}D_e}\).</li>
<li>Take \(w\in \beta S\) with \(S_e := \{ x_f : f \supseteq e, f \in [ \mathfrak{B}]^{&lt;\omega} \} \in \omega (\forall e \in \beta S)\)</li>
<li>Now define \(q = w \cdot p \Rightarrow q \in \beta S \cdot p \subseteq K(\beta S)\) and</li>
<li>since \(\mathfrak{B} \subseteq q\)
<ul>
<li>[\(B\in \mathfrak{B}\) show: \(B\in q = w\cdot p\). But \(e:{B} \in [\mathfrak{B}]^{\omega}\)</li>
<li>\(D_e = B, S_e \in \omega\); For all \(f\supseteq e: x_f \cdot p \in \widehat{D_f}\)</li>
<li>\(\widehat{D_f} \subseteq \widehat{D_e} = \widehat{B} \Rightarrow S_e \cdot p \subseteq \widehat{B}\)</li>
<li>\(\Rightarrow w \cdot p \in \widehat{B}\)]</li>
</ul>
</li>
<li>The claim follows.</li>
</ul>
</li>
</ul>
<h3>Notes</h3>
<p>This page contains the proof of Theorem 3.4 of the previous part (I guess I should've included that yesterday). I can't really make much of it. It's the dull of writing up a new notion. But if you look closer, you might stumble over a few details (as I did when I took these notes). Writing this up just now I find the choice of \(w\) quite striking.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p13]]></title>
        <id>https://www.peterkrautzberger.org/0159/</id>
        <link href="https://www.peterkrautzberger.org/0159/">
        </link>
        <updated>2014-03-25T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p13-1.jpg">
    <img alt="red workbook, p13-1" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p13-1.jpg">
  </a>
  <figcaption>
    Red Workbook, p.13, part 1
  </figcaption>
</figure>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p13-2.jpg">
    <img alt="red workbook, p13-2" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p13-2.jpg">
  </a>
  <figcaption>
    Red Workbook, p.13, part 2
  </figcaption>
</figure>
<h3>Transcript</h3>
<h4>First page</h4>
<ul>
<li><em>14. Sept. 2006</em></li>
<li>Fortsetzung Vortrag SK</li>
<li><em>3.</em> collectionwise thick (cwt, cwdick), collectionwise pws (cwpws)</li>
<li>3.2 Notation. \(\mathfrak{B} \subseteq \mathcal{P}(S), \mathfrak{V} := \{ D_e : e \in [\mathcal{B}]^{&lt;\omega} \}\)
<ul>
<li>\(\mathfrak{D}\) (-Suetterlin?), \(D_e = \bigcap_{B\in e} B\)</li>
<li>Also: \(\mathcal{B} \subseteq \mathfrak{V}\)</li>
</ul>
</li>
<li>3.1 Definition
<ul>
<li>Fuer \(\mathfrak{A} \subseteq \mathcal{P}(S): Y_ {\mathfrak{A}} = \bigcap_ {A\in\mathfrak{A}} \widehat{A} \subseteq \beta S\) abgeschlossen
<ul>
<li>[in 3.2, dann \(Y_ \mathfrak{B} = Y_ \mathfrak{D}\)]</li>
</ul>
</li>
</ul>
</li>
<li>3.3 Satz &amp; Def. Aequivalent:
<ul>
<li>(a) \(\exists q \in \beta S: \beta S \cdot q \subseteq Y_ \mathfrak{B}\) (natuerlich oBdA \(q\in K(\beta S)\))</li>
<li>(b) \(\forall D \in \mathfrak{D}\) \(D\) dick.</li>
<li>Dann: heisst \(\mathfrak{B}\) cwdick (cwd)</li>
</ul>
</li>
<li>Beweis
<ul>
<li>=&gt;: \(\beta S \cdot q \subseteq Y_ {\mathfrak{B}} = Y_ \mathfrak{D} \subseteq \widehat{D}\) fuer all \(D\in \mathfrak{D}\)</li>
<li>&lt;=: Fuer \(e\in [\mathfrak{B}]^{&lt;\omega}\) nimm \(q_ e \in \beta S, \beta S \cdot q_ e \subseteq \widehat{D_ e}\)
<ul>
<li>OBdA, \(q\in K(\beta S)\), (\(q_e \in \beta S \cdot q_e \in \widehat{D_e}\) gilt ✓)</li>
<li>Setze $ X_e := { q_f : e \subseteq f \in [ \mathfrak{B} ]^{&lt; \omega} } \subseteq \beta S$.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4>Second page</h4>
<ul>
<li>Damit \(X_e \subseteq \widehat{D_e}\) [ \(f\supseteq e \Rightarrow q_f \in \widehat{D_f} \subseteq \widehat{D_e}\)]</li>
<li>\(\{ X_e : e \in [\mathfrak{B}]^{&lt; \omega} \}\) hat eDE (? check)</li>
<li>nimm \(q\in \bigcap_{e \in [ \mathfrak{B} ]^{&lt;\omega}} cl_{\beta S}(X_e)\)</li>
<li>Beh. \(\forall D \in \mathfrak{D}: \beta S \cdot q \subseteq \widehat{D}\)
<ul>
<li>[ \(D = D_e, e\in [ \mathfrak{B}]^{&lt; \omega} \Rightarrow X_e \subseteq \widehat{D_e}, q\in cl(X_e) \Rightarrow q \in D_e\)</li>
<li>\(\forall S \in S, e \subseteq f, s\cdot q_f \underset{\beta S \cdot q_f \subseteq\widehat{D_f}}{\in} \widehat{D_f} \subseteq \widehat{D_e} \Rightarrow s\cdot X_e \subseteq \widehat{D_e}\)</li>
<li>\(\Rightarrow s\cdot q \in \widehat{D_e} \Rightarrow \beta S \cdot q \subseteq \widehat{D_e}\)]</li>
<li>Damit folgt die Behauptung □</li>
</ul>
</li>
<li>[&quot;Aufgabe&quot;: konstruiere \(q\) durch \(p\)-limiten?]</li>
<li>3.4 Satz &amp; Def. Aequivalent
<ul>
<li>(a) \(\exists q\in K(\beta S)\) mit \(\mathfrak{B} \subseteq q\)</li>
<li>(b) \(\forall e \in [\mathfrak{B} ]^{&lt;\omega} \exists g_e \in [S]^{&lt; \omega}\) mit \(\mathfrak{C} = { C_e: e \in [\mathfrak{B}]^{&lt;\omega} }\) cwdick; hierbei \(C_e = \bigcup_{x \in g_e x^{-1}} D_e\).</li>
<li>Nenne \(\mathfrak{B}\) dann cwpws.</li>
</ul>
</li>
</ul>
<h3>partial Translation</h3>
<h4>First page</h4>
<ul>
<li>September 14, 2006</li>
<li>Continuation: Talk by Sabine Koppelberg</li>
<li><em>3.</em> collectionwise thick (cwt), collectionwise piecewise syndetic (cwpws)</li>
<li>3.2 Notation. \(\mathfrak{B} \subseteq \mathcal{P}(S), \mathfrak{V} := \{ D_e : e \in [\mathcal{B}]^{&lt;\omega} \}\)
<ul>
<li>\(D_ e = \bigcap_ {B\in e} B\)</li>
<li>In particular, \(\mathcal{B} \subseteq \mathfrak{V}\)</li>
</ul>
</li>
<li>3.1 Definition
<ul>
<li>For \(\mathfrak{A} \subseteq \mathcal{P}(S)\) let \(Y_ {\mathfrak{A}} := \bigcap_ {A\in\mathfrak{A}} \widehat{A} \subseteq \beta S\) (closed)
<ul>
<li>[in the setup of 3.2, then \(Y_ \mathfrak{B} = Y_ \mathfrak{D}\)]</li>
</ul>
</li>
</ul>
</li>
<li>3.3 Theorem &amp; Definition. TFAE:
<ul>
<li>(a) \(\exists q \in \beta S: \beta S \cdot q \subseteq Y_ \mathfrak{B}\) (without loss of generality, \(q\in K(\beta S)\))</li>
<li>(b) \(\forall D \in \mathfrak{D}\) \(D\) thick.</li>
<li>We then call \(\mathfrak{B}\) collectionwise thick (cwthick, cwt)</li>
</ul>
</li>
<li>Proof:
<ul>
<li>=&gt;: \(\beta S \cdot q \subseteq Y_ {\mathfrak{B}} = Y_ \mathfrak{D} \subseteq \widehat{D}\) for any \(D\in \mathfrak{D}\)</li>
<li>&lt;=: For \(e\in [\mathfrak{B}]^{&lt;\omega}\) take \(q_e \in \beta S, \beta S \cdot q_e \subseteq \widehat{D_ e}\)
<ul>
<li>Without loss \(q\in K(\beta S)\),
<ul>
<li>(since \(q_ e \in \beta S \cdot q_ e \in \widehat{D_ e}\) holds ✓)</li>
</ul>
</li>
<li>Let $ X_ e := { q_ f : e \subseteq f \in [ \mathfrak{B} ]^{&lt; \omega} } \subseteq \beta S$.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4>Second page</h4>
<ul>
<li>Then \(X_ e \subseteq \widehat{D_ e}\)
<ul>
<li>[since \(f\supseteq e \Rightarrow q_ f \in \widehat{D_ f} \subseteq \widehat{D_ e}\)]</li>
</ul>
</li>
<li>\(\{ X_ e : e \in [\mathfrak{B}]^{&lt; \omega} \}\) has the finite intersection property.</li>
<li>So take \(q\in \bigcap_ {e \in [ \mathfrak{B} ]^{&lt;\omega}} cl_ {\beta S}(X_ e)\)</li>
<li>Claim: \(\forall D \in \mathfrak{D}: \beta S \cdot q \subseteq \widehat{D}\)
<ul>
<li>[proof]</li>
<li>\(D = D_ e, e\in [ \mathfrak{B}]^{&lt; \omega} \Rightarrow X_ e \subseteq \widehat{D_ e}, q\in cl(X_ e) \Rightarrow q \in D_ e\)</li>
<li>\(\forall S \in S, e \subseteq f, s\cdot q_ f \underset{\beta S \cdot q_ f \subseteq\widehat{D_ f}}{\in} \widehat{D_ f} \subseteq \widehat{D_ e} \Rightarrow s\cdot X_ e \subseteq \widehat{D_ e}\)</li>
<li>\(\Rightarrow s\cdot q \in \widehat{D_ e} \Rightarrow \beta S \cdot q \subseteq \widehat{D_ e}\)</li>
<li>The claim follows. □</li>
</ul>
</li>
<li>[&quot;Exercise&quot;: construct \(q\) as \(p\)-limit]</li>
<li>3.4 Theorem &amp; Definition. TFAE:
<ul>
<li>(a) \(\exists q\in K(\beta S)\) with \(\mathfrak{B} \subseteq q\)</li>
<li>(b) \(\forall e \in [\mathfrak{B} ]^{&lt;\omega} \exists g_ e \in [S]^{&lt; \omega}\) mit \(\mathfrak{C} = { C_ e: e \in [\mathfrak{B}]^{&lt;\omega} }\) cwthick; where \(C_ e = \bigcup_ {x \in g_ e x^{-1}} D_ e\).</li>
<li>We then call \(\mathfrak{B}\) collectionwise piecewise syndetic (cwpws).</li>
</ul>
</li>
</ul>
<h3>Notes</h3>
<p>We're back to Sabine Koppelberg's talks about basic \(\beta S\) results (with four more pages to come). This time, tackling the not-so-basic notions of collectionwise thick/pws sets. These notions are cricital for analysing sets the minimal ideal -- and equally elusive.</p>
<p>I'm not very happy with notation here; it seems to sacrifice accessibility over corrrectness. A sloppier notation might be helpful. In addition, &quot;collectionwise&quot; is a cumbersome prefix. I'd go for &quot;uniformly&quot; or &quot;coherently&quot; as they are often used in the context of filters (and this is what &quot;collectionwise&quot; is all about). But it probably wouldn't help to add yet another terminology.</p>
<p>Funny thing. I actually spent my last few weeks in Michigan thinking about these notions.</p>
<hr>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p12]]></title>
        <id>https://www.peterkrautzberger.org/0158/</id>
        <link href="https://www.peterkrautzberger.org/0158/">
        </link>
        <updated>2014-03-23T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p12.jpg">
    <img alt="red workbook, p12" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p12.jpg">
  </a>
  <figcaption>
    Red Workbook, p.12
  </figcaption>
</figure>
<h3>Transcript</h3>
<ul>
<li>WA \(\stackrel{p = q + r}{\Longrightarrow}\) (i) \(\forall k \in \mathbb{N}, W_ v \in r: \left\vert W_ v \cap W_ v+k\right\vert &lt; \omega\)</li>
<li>[struck through] (ii) \(\forall k \in \mathbb{N}: k \in V \rightarrow 2k \notin V\) (\(k\) und \(2k\) haben versch. \(W_ v\))</li>
<li>
<hr>
</li>
<li>Beweis: $ p = q+r$ beide in \(\mathbb{N}^*\), \(A\in p\).
<ul>
<li>=&gt; $ \displaystyle A = \bigcup_ {\underset{\in p}{v\in V}} v + \underset{\in r}{W_ v}$ =&gt; \(\exists v, k: v, v+k \in V\)
<ul>
<li>[ \(q \in \mathbb{N}^*\)]</li>
</ul>
</li>
<li>=&gt; \(W_ v \cap W_ {v+k} =: W \in r\), also unendlich</li>
<li>=&gt; \(\underbrace{v+W} ,v+k+W \in A\)
<ul>
<li>=&gt; \(v+k+W \in A+k\) =&gt; Beh.</li>
</ul>
</li>
</ul>
</li>
<li>Notiz: es gibt kofinal viele solche \(k\)'s! □</li>
<li>(2) Ein solches \(k\) liefert mit Aufzaehlung von \(A \cap A+k\)
<ul>
<li>eine kofinale Folge, so dass \(\left\vert a_ {n_ k} - a_ {n_ j -1}\right\vert \leq k\).</li>
<li>Also kann keine Aufzaehlung jede Schranke auf Endstuecken uebertrefeen.</li>
</ul>
</li>
<li>
<hr>
</li>
<li>Gilt &lt;= ? d.h. \(p\in \mathbb{N}^* \forall A\in p: \underset{\text{unendl}}{ \{ k: A \cap A+k \text{ unendl.} \}}\)
<ul>
<li>=&gt; \(p \in \mathbb{N}^* + \mathbb{N}^*\)</li>
</ul>
</li>
</ul>
<h3>partial Translation</h3>
<ul>
<li>Assume to the contrary. \(\stackrel{p = q + r}{\Longrightarrow}\) (i) \(\forall k \in \mathbb{N}, W_ v \in r: \left\vert W_ v \cap W_ v+k\right\vert &lt; \omega\)</li>
<li>[struck through] (uu) \(\forall k \in \mathbb{N}: k \in V \rightarrow 2k \notin V\) (\(k\) and \(2k\) have different. \(W_ v\))</li>
<li>
<hr>
</li>
<li>Proof: $ p = q+r$ both in \(\mathbb{N}^*\), \(A\in p\).
<ul>
<li>=&gt; $ \displaystyle A = \bigcup_ {\underset{\in p}{v\in V}} v + \underset{\in r}{W_ v}$ =&gt; \(\exists v, k: v, v+k \in V\) [[since]] \(q \in \mathbb{N}^*\) [[ \(V\) is infinite, thus contains two elements]]</li>
<li>=&gt; \(W_ v \cap W_ {v+k} =: W \in r\), hence infinite</li>
<li>=&gt; \(\underbrace{v+W} ,v+k+W \subseteq A\)
<ul>
<li>and \(v+k+W \in A+k\) =&gt; Claim.</li>
</ul>
</li>
</ul>
</li>
<li>Remark: there are cofinal many such \(k\)! □</li>
<li>(2) With such \(k\) we can find an enumeration \(A \cap A+k\) and some cofinal enumeration \(\left\vert a_ {n_ k} - a_ {n_ j -1}\right \vert \leq k\).
<ul>
<li>Hence no enumeration can exceed an arbitrary bound on end pieces</li>
</ul>
</li>
<li>
<hr>
</li>
<li>Does &lt;= hold? d.h. \(p\in \mathbb{N}^* \forall A\in p: \underbrace{ \{ k: A \cap A+k \text{ infinite}\}}_ {\text{infinite}}\)
<ul>
<li>=&gt; \(p \in \mathbb{N}^* + \mathbb{N}^*\)</li>
</ul>
</li>
</ul>
<h3>Notes</h3>
<p>This finishes the attempts to solve 4.1.7 from Hindman&amp;Strauss (successfully). Given the nice write up of the solution, I'm guessing I worked the proof out someplace else (blackboard, separate piece of paper etc). This reminds me that in the office I was working in at the time I found this wonderful stack of thick letter size paper (letter size! in Germany!). I loved writing on the paper for rough drafts, preparing talks/lecture notes etc. But it clashed with my desire to keep notebooks.</p>
<p>This page is extremely fascinating for me because of the final question. It's always easy to ask yourself if the reverse of a proposition holds; that's just standard. In this case, the answer should be a pretty straight forward &quot;no&quot;; however, I don't think I ever worked out a counterexample.</p>
<p>But that's not what makes this so fascinating for me. What is fascinating is that I spent a lot of time during my postdoc to solve a very similar problem (and failed) which I consider one of the most interesting questions about idempotent filters. Unfortunately, I was unable to solve the question. I don't want to go into detail here and it will take months until we get to that (a teaser never hurts, right?). It's fascinating to see that I was very nearly thinking about the very same problem this early in my PhD (and, not surprisingly, missed the actually interesting question at this point).</p>
<h3>Open questions</h3>
<ul>
<li>If $p\in \mathbb{N}^* $ and \(\forall A\in p: \underbrace{ \{ k: A \cap A+k \text{ infinite}\}}_ {\text{infinite}}\), does it follow that $p \in \mathbb{N}^* + \mathbb{N}^* $?
<ul>
<li>Probably no -- there needs to be more additive structure, in a coherent/filter fashion; just infinite seems too weak.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p11]]></title>
        <id>https://www.peterkrautzberger.org/0157/</id>
        <link href="https://www.peterkrautzberger.org/0157/">
        </link>
        <updated>2014-03-18T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p11-1.jpg">
    <img alt="red workbook, p11-1" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p11-1.jpg">
  </a>
  <figcaption>
    Red Workbook, p.11, part 1
  </figcaption>
</figure>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p11-2.jpg">
    <img alt="red workbook, p11-2" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p11-2.jpg">
  </a>
  <figcaption>
    Red Workbook, p.11, part 2
  </figcaption>
</figure>
<h3>Transcript</h3>
<h4>Left page</h4>
<ul>
<li>Bestanden bei: 60% Uebungen</li>
<li>Korrektur d. Klausur mit SK</li>
<li>Hindman &amp; Strauss:</li>
<li>4.1.7: $A \in p \in \mathbb{N}^* +\mathbb{N}^* $</li>
<li>=&gt; \(\exists k: \left\vert A \cap (A+k)\right\vert  = \omega\)</li>
<li>?=&gt; \(A\) kann nicht aufgezaehlt werden, so dass \(a_ {n+1} - a_ n \to \infty (n \to \infty)\)</li>
<li>vgl. van Douwen Artikel zu \(\beta \mathbb{N}\).</li>
</ul>
<h4>Right page</h4>
<ul>
<li>Aufgabe 4.1.7</li>
<li>\(p \in \mathbb{N}^* +\mathbb{N}^*  (\subseteq \mathbb{N}^* ), A\in p \Rightarrow \exists k \in \mathbb{N}: \left\vert A \cap (A+k)\right\vert  = \omega\)</li>
<li>WA: \(\forall k \in \mathbb{N}: \left\vert A \cap A+k\right\vert  &lt; \omega\)</li>
<li>[struck through: \(\underset{p \in \mathbb{N}^* }{\Rightarrow} \mathbb{N} \setminus A' \in p\)] \(\Rightarrow \mathbb{N} - (A+k) \in p\)</li>
<li>\(\Rightarrow \exists V^k, (W_ v^k)_ {v \in V^k}\) unendlich \(\bigcup_ {v\in V_ k} v+ W_ v^k \subseteq N - (A-k)\)</li>
<li>?? Nutzen? \(\bigcap V_ k\)? \(\bigcap W_ v^k\)?</li>
<li>\(\mathbb{N} \rightarrow \mathbb{Z}_ n \overset{\text{Homo}}{\rightarrow} \rightarrow \beta \mathbb{N} \rightarrow \mathbb{Z}_ n\) Homo</li>
<li>\(\Rightarrow p = q+r \Rightarrow p \bmod n = q \bmod n + r \bmod n\)</li>
<li>[struck out: [illegible] \(= -p +\bmod n \in \mathbb{Z}_ p = {0, \ldots, n-1}\)</li>
<li>\(A \in p \in \mathbb{N}^* +\mathbb{N}^*  \Rightarrow p = \overset{\overset{\mathbb{N}^* }{\ni \ \ \in}}{q+r} \Rightarrow A \supseteq \bigcup_ {v\in V \in q} v+ \overset{\in r}{W_ v}\)</li>
<li>[struck out: WA \(\forall k\ in \mathbb{N}: \left\vert A \cap A+k\right\vert  &lt; \omega \Rightarrow \forall k \in \mathbb{N}: k+p \notin \widehat{A}\)]</li>
<li>WA \(\forall k\ in \mathbb{N}: \left\vert A \cap A+k\right\vert  &lt; \omega \underset{p = q+r}{\Longrightarrow} \forall k \in \mathbb{N}: \left\vert k+W_ v \cap W_ v \right\vert  &lt; \omega\)</li>
<li>\(\Rightarrow \forall k \in \mathbb{N} k+r \notin \widehat{W_ v}\) [struckout: \(\Rightarrow: \forall k\in \mathbb{N}: k+r \notin \bigcup_ {v\in V} \widehat{W_ v}\)]</li>
<li>\(\Rightarrow q + r \notin \widehat{W_ v} \Rightarrow q+r \notin \bigcup \widehat{W_ v}\)</li>
</ul>
<h3>partial Translation</h3>
<h4>Left page</h4>
<ul>
<li>[some notes on grading a course]</li>
<li>Hindman &amp; Strauss:</li>
<li>4.1.7: $A \in p \in \mathbb{N}^* +\mathbb{N}^* $</li>
<li>=&gt; \(\exists k: \left\vert A \cap (A+k)\right\vert  = \omega\)</li>
<li>?=&gt; \(A\) can not be enumerated such that \(a_ {n+1} - a_ n \to \infty (n \to \infty)\)</li>
<li>cf. van Douwen article about \(\beta \mathbb{N}\).</li>
</ul>
<h4>Right page</h4>
<ul>
<li>Exercise 4.1.7</li>
<li>[first try] \(p \in \mathbb{N}^* +\mathbb{N}^*  (\subseteq \mathbb{N}^* ), A\in p \Rightarrow \exists k \in \mathbb{N}: \left\vert A \cap (A+k)\right\vert  = \omega\)</li>
<li>Assume to the contrary: \(\forall k \in \mathbb{N}: \left\vert A \cap A+k\right\vert  &lt; \omega\)</li>
<li>[struck through: \(\underset{p \in \mathbb{N}^* }{\Rightarrow} \mathbb{N} \setminus A' \in p\)] \(\Rightarrow \mathbb{N} - (A+k) \in p\)</li>
<li>\(\Rightarrow \exists V^k, (W_ v^k)_ {v \in V^k}\) infinite \(\bigcup_ {v\in V_ k} v+ W_ v^k \subseteq N - (A-k)\)</li>
<li>?? Useful? \(\bigcap V_ k\)? \(\bigcap W_ v^k\)?</li>
<li>[second try] \(\mathbb{N} \rightarrow \mathbb{Z}_ n \overset{\text{Homomorphism}}{\Longrightarrow} \beta \mathbb{N} \rightarrow \mathbb{Z}_ n\) Homomorphism</li>
<li>\(\Rightarrow p = q+r \Rightarrow p \bmod n = q \bmod n + r \bmod n\)</li>
<li>[struck out: [something illegible] \(= -p +\bmod n \in \mathbb{Z}_ p = {0, \ldots, n-1}\)</li>
<li>[third try] \(A \in p \in \mathbb{N}^* +\mathbb{N}^*  \Rightarrow p = q+r (\text{both in } \mathbb{N}^* ) \Rightarrow A \supseteq \bigcup_ {v\in V \in q} v+ \overset{\in r}{W_ v}\)</li>
<li>[struck out: Assume to the contrary \(\forall k\ in \mathbb{N}: \left\vert A \cap A+k\right\vert  &lt; \omega \Rightarrow \forall k \in \mathbb{N}: k+p \notin \widehat{A}\)]</li>
<li>[fourth try] Assume to the contrary \(\forall k\ in \mathbb{N}: \left\vert A \cap A+k\right\vert  &lt; \omega \underset{p = q+r}{\Longrightarrow} \forall k \in \mathbb{N}: \left\vert k+W_ v \cap W_ v \right\vert  &lt; \omega\)</li>
<li>\(\Rightarrow \forall k \in \mathbb{N} k+r \notin \widehat{W_ v}\) [struckout: \(\Rightarrow: \forall k\in \mathbb{N}: k+r \notin \bigcup_ {v\in V} \widehat{W_ v}\)]</li>
<li>\(\Rightarrow q + r \notin \widehat{W_ v} \Rightarrow q+r \notin \bigcup \widehat{W_ V}\)</li>
</ul>
<h3>Notes</h3>
<p>I find this double page (and the one following it) quite interesting. Mathematically speaking, there's very little going. If I recall correctly, it was Stefan Geschke (or else Sabine Koppelberg) who had mentioned the fact to me that sets in ultrafilters that are sums have too many small gaps, i.e., the size of gaps in their enumeration does not have an (improper) limit. So I found the exercise in Hindman&amp;Strauss and tried to solve it.</p>
<p>What's interesting is how I went about solving it. I would call this the &quot;formalist approach&quot;, i.e., by manipulation of symbols following simple logic since I have no intuition of the subject. Of course, I fail, repeatedly; the solution will be found on the next page.</p>
<p>By the way, the first two lines are about the grading of a set theory course (the previous page contains more but I did not reproduce it). I will skip a rant about how PhD students are often forced into TA duties without being paid; in a logical twist, they often &quot;cannot&quot; be paid because they are on grant money and most grants directly prohibit teaching duties.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p10]]></title>
        <id>https://www.peterkrautzberger.org/0156/</id>
        <link href="https://www.peterkrautzberger.org/0156/">
        </link>
        <updated>2014-03-17T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p10.jpg">
    <img alt="red workbook, p10" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p10.jpg">
  </a>
  <figcaption>
    Red Workbook, p.10
  </figcaption>
</figure>
<h3>Transcript</h3>
<ul>
<li>Notiz:
<ul>
<li>wieso \(\mathbb{Z} + p \subseteq \mathbb{N^* }\) fuer \(\mathbb{N^* } \ni p\) (evtl. min. id.pot.)</li>
<li>Kopie von \(\mathbb{Z}\)?</li>
<li>[this note was struck out by a check mark]</li>
</ul>
</li>
<li>Frage nicht standard PA-Modelle:
<ul>
<li>gibt es Eigenschaften, die sich reflektieren lassen?</li>
<li>Gibt es Reflektionsprinzip?</li>
<li>[the above two lines were struck out with as single line]</li>
<li>[illegible] Wenn es ein [struck out]</li>
<li>Idee: Wenn ein Nicht standard element</li>
<li>eine Eigenschaft hat</li>
<li>so haben unendlich viele Numerale</li>
<li>diese Eigenschsft, also</li>
<li>unendlich viele Nicht-Standard
<ul>
<li>[da elementare Substr]</li>
</ul>
</li>
<li>Richtig?</li>
<li>Was kann man damit machen?</li>
</ul>
</li>
</ul>
<h3>partial Translation</h3>
<ul>
<li>Note:
<ul>
<li>Why is \(\mathbb{Z} + p \subseteq \mathbb{N^* }\) for any \(\mathbb{N^* } \ni p\) (possibly just minimal idempotent)</li>
<li>Copy of \(\mathbb{Z}\)?</li>
<li>[this note was struck out by a check mark]</li>
</ul>
</li>
<li>Question about non-standard models of PA
<ul>
<li>are there properties that can be reflected?</li>
<li>Are there reflection principles?</li>
<li>[the above two lines were struck out with as single line]</li>
<li>Idea: If a non-standard element has some property, then infinitely many numerals have this property and therefore infinitely many non-standard elements have this property (as an elementary substructure).</li>
<li>Correct? What can you do with it?</li>
</ul>
</li>
</ul>
<h3>Notes</h3>
<p>The previous page is followed by another attempt of research ideas.</p>
<p>First there's a note on a basic but important observation for \(\beta \mathbb{N}\) -- it contains lots of copies of \(\mathbb{Z}\). I remember trying to figure this out and ending up asking Sabine Koppelberg -- and the solution took two second, leaving me miserably disappointed by my failure.</p>
<p>To understand the second part of the note, I should explain that my Diplom thesis was about large cardinals and reflection principles. The first few things I tried that summer came out of that perspective -- looking at cardinals (as a semingroup with ordinal addition/multiplication), hoping to connect with large cardinal theory. Nothing ever came of it but perhaps we'll encounter that later in this workbook.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p9]]></title>
        <id>https://www.peterkrautzberger.org/0155/</id>
        <link href="https://www.peterkrautzberger.org/0155/">
        </link>
        <updated>2014-03-13T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p9.jpg">
    <img alt="red workbook, p9" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p9.jpg">
  </a>
  <figcaption>
    Red Workbook, p.9
  </figcaption>
</figure>
<h3>Transcript</h3>
<ul>
<li>&quot;How far does a p-point travel?&quot;
<ul>
<li>\(\rightarrow\) Flaskova: p-Pkt ⋅ p-Pkt kein p-Pkt
<ul>
<li>\(\curvearrowright\) Wegen der Eigenschaft p-Pkt muesste nicht \(p+q\) in der Naehe von \(p\) bleiben?</li>
<li>\(\rightarrow\) wenn ja, wie ist die Bahn einese p-Pkt?</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>non-standards PA</li>
<li>\(\rightarrow\) als DS??</li>
</ul>
<h3>partial Translation</h3>
<ul>
<li>&quot;How far does a p-point travel?&quot;
<ul>
<li>\(\rightarrow\) Flašková: p-point ⋅ p-point (the product of two p-points) is not a p-point.
<ul>
<li>\(\curvearrowright\) Due to the properties of a p-point, shouldn't \(p+p\) somehow be &quot;close&quot; to \(p\)?</li>
<li>\(\rightarrow\) if so, what is the orbit of a p-point?</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>Can non-standard [models of] PA \(\rightarrow\) [be considered] as dynamical system?</li>
</ul>
<h3>Notes</h3>
<p>Finally, a first note that is not some lecture note but (almost) a note on research. Not that it's particularly meaningful or even sensible. In fact, it's rather mysterious to me. At first I thought the background lies at TOPOSYM (which I visited during the summer), where Jana Flašková talked about P-points. But looking back at my notes on her talk (in the red workbook but not published here), I don't think this really fits (but I might be wrong).</p>
<h3>Open Problems</h3>
<ul>
<li>What can we say about \(p+p\) for a P-point \(P\)?</li>
<li>What can we say about (the closure of) subsemigroup generated by \(p\)?</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p8]]></title>
        <id>https://www.peterkrautzberger.org/0154/</id>
        <link href="https://www.peterkrautzberger.org/0154/">
        </link>
        <updated>2014-03-11T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p8.jpg">
    <img alt="red workbook, p8" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p8.jpg">
  </a>
  <figcaption>
    Red Workbook, p.8
  </figcaption>
</figure>
<h3>Transcript</h3>
<ul>
<li><strong>Lemma</strong> \(A \subseteq S\) (a) \(A \in p \in K(\beta S)\) (also pws) =&gt; \(\exists g \subseteq_ e S: \stackrel{\stackrel{[unreadable]}{\downarrow}}{\beta S \cdot p} \subseteq \widehat{ \bigcup_ {x \in g} x^{-1} A }\)
<ul>
<li>(b) \(T := \bigcup_ {x \in g} x^{-1} A\) dick, \(g \subseteq_ e S\) (also \(A\) pws)
<ul>
<li>=&gt; \(\beta S \cdot q \subseteq \widehat{T}\) fuer ein \(q \in \beta S\)</li>
<li>=&gt; \(A \in x \cdot q\) fuer ein \(q\in \beta S\), ein \(x\in g\)</li>
</ul>
</li>
</ul>
</li>
<li><strong>Beweis</strong>
<ul>
<li>(b): \(q \in K(\beta S)\) mit \(\beta S \cdot q \subseteq \widehat{T}\) (Prop)
<ul>
<li>\(q \in \beta S \cdot q \subseteq \widehat{T} \Rightarrow \exists x \in g: x^{-1}A \in q \Rightarrow x \cdot q \in \widehat{A}\)</li>
</ul>
</li>
<li>(a) \(L := \beta S \cdot p\) min. LID , \(p \in L\).
<ul>
<li><strong>Beh</strong>: \(L \subseteq \bigcup_ {t \in S} \widehat{t^{-1}A }\) [ \(x \in L, p \in \beta S \cdot x = cl_ {\beta S} (s \cdot x)\)
<ul>
<li>da \(p\in \widehat{A}\) offen =&gt; \(\exists t \in S: t\cdot x \in \widehat{A} \Rightarrow x \in \widehat{t^{-1}A}\)]</li>
</ul>
</li>
<li>\(L\) kompakt, also \(\underset{\stackrel{=}{\beta S \cdot p} }{L} \subseteq \bigcup_ {t \in g} \widehat{ t^{-1}A}\) fuer ein \(g \subseteq_ e S\). □</li>
</ul>
</li>
</ul>
</li>
<li><strong>Prop</strong> \(A\subseteq S\); AeQ: (a) \(A\) pws (b) \(\exists y \in S: y^{-1}A\) zentral
<ul>
<li>(c) \(\exists D \subseteq S \text{ synd} \forall d \in D: d^{-1}A\) zentral</li>
</ul>
</li>
<li><strong>Beweis</strong>
<ul>
<li>(b) =&gt; (a): nimm \(\epsilon \in E_ \min(\beta S): y^{-1}A \in \epsilon \Rightarrow A \in y \cdot \epsilon \in K(\beta S)\)</li>
<li>(a) =&gt; (c): Sei \(e \subseteq_ e S\) mit \(\bigcup_ {t \in e} t^{-1}A = T\) dick;
<ul>
<li>sei \(L\subseteq \widehat{T}\) min LID, sei \(\epsilon \in L \cap E(\beta S)\)</li>
<li>Sei \(y\in \epsilon\) mit \(\epsilon \in \widehat{ y^{-1} A }\). Im DS \(\beta S\):</li>
<li>\(\epsilon\) uniform rekurrent, \(B = R(\epsilon, \widehat{ y^{-1}}A)\) syndetisch</li>
<li>\(D: y \cdot B\) (syndetisch! (Bem.)) und</li>
<li>\(\forall d\in D: d^{-1}A \in \epsilon\) (also zentral) [\(d = y\cdot b\) fuer ein \(b \in B\), \(b\epsilon \in y^{-1}A\)
<ul>
<li>\(y b \epsilon \in \widehat{A}, d\epsilon \in \widehat{A}, d^{-1}A \in \epsilon\)]</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>partial Translation</h3>
<ul>
<li><strong>Lemma</strong> \(A \subseteq S\)
<ul>
<li>(a) \(A \in p \in K(\beta S)\) (hence piecewise syndetic (pws)) =&gt; \(\exists g \subseteq_ e S: \beta S \cdot p \subseteq \widehat{ \bigcup_ {x \in g} x^{-1} A }\) [[so this union is thick!]]</li>
<li>(b) \(T := \bigcup_ {x \in g} x^{-1} A\) thick, \(g \subseteq S\) finite (so \(A\) is pws)
<ul>
<li>=&gt; \(\beta S \cdot q \subseteq \widehat{T}\) for some \(q \in \beta S\)</li>
<li>=&gt; \(A \in x \cdot q\) for some \(q\in \beta S\) and some \(x\in g\)</li>
</ul>
</li>
</ul>
</li>
<li><strong>Proof</strong>
<ul>
<li>(b): \(q \in K(\beta S)\) with \(\beta S \cdot q \subseteq \widehat{T}\) (by the previous proposition) [[workbook p 7]]
<ul>
<li>\(q \in \beta S \cdot q \subseteq \widehat{T} \Rightarrow \exists x \in g: x^{-1}A \in q \Rightarrow x \cdot q \in \widehat{A}\)</li>
</ul>
</li>
<li>(a) \(L := \beta S \cdot p\) minimal left ideal (LID) , \(p \in L\).
<ul>
<li><strong>Claim</strong>: \(L \subseteq \bigcup_ {t \in S} \widehat{t^{-1}A }\)
<ul>
<li>\(x \in L, p \in \beta S \cdot x = cl_ {\beta S} (s \cdot x)\) since \(p\in \widehat{A}\) open =&gt; \(\exists t \in S: t\cdot x \in \widehat{A} \Rightarrow x \in \widehat{t^{-1}A}\)]</li>
</ul>
</li>
<li>\(L\) compact, hence \(\underset{\stackrel{=}{\beta S \cdot p} }{L} \subseteq \bigcup_ {t \in g} \widehat{ t^{-1}A}\) for some finite \(g \subseteq S\). □</li>
</ul>
</li>
</ul>
</li>
<li><strong>Proposition</strong> \(A\subseteq S\); TFAE
<ul>
<li>(a) \(A\) pws</li>
<li>(b) \(\exists y \in S: y^{-1}A\) central</li>
<li>(c) \(\exists D \subseteq S \text{ syndetic} \forall d \in D: d^{-1}A\) central</li>
</ul>
</li>
<li><strong>Proof</strong>
<ul>
<li>(b) =&gt; (a): take \(\epsilon \in E_ \min(\beta S): y^{-1}A \in \epsilon \Rightarrow A \in y \cdot \epsilon \in K(\beta S)\)</li>
<li>(a) =&gt; (c): Let \(e \subseteq S\) finite with \(\bigcup_ {t \in e} t^{-1}A = T\) thick;
<ul>
<li>Let \(L\subseteq \widehat{T}\) min. LID, let \(\epsilon \in L \cap E(\beta S)\)</li>
<li>Let \(y\in \epsilon\) with \(\epsilon \in \widehat{ y^{-1} A }\). In the dynamical system \(\beta S\):</li>
<li>\(\epsilon\) is uniformly recurrent, \(B = R(\epsilon, \widehat{ y^{-1}}A)\) syndetic</li>
<li>\(D: y \cdot B\) (syndetic! (by the above remark.)) undand</li>
<li>\(\forall d\in D: d^{-1}A \in \epsilon\) (hence central)
<ul>
<li>[proof]: \(d = y\cdot b\) for some \(b \in B\), \(b\epsilon \in y^{-1}A\), \(y b \epsilon \in \widehat{A}, d\epsilon \in \widehat{A}, d^{-1}A \in \epsilon\)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Notes</h3>
<p>More wonderful stuff about thick, piecewise syndetics, and central sets.</p>
<p>The lemma tells us that pws could be called &quot;almost thick&quot; -- a finite set of translations is enough to make a pws set thick. The proposition on the other hand tells us that pws is surprisingly close to being central -- just one translation! (just keep in mind they are very much not the same notion). In addition, such a translation happens very, very frequently (a syndetic set!).</p>
<p>Somehow, I find this to be a lot of fun even if it's not particularly surprising -- minimal idempotent ultrafilters are just so incredibly rich.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p7]]></title>
        <id>https://www.peterkrautzberger.org/0153/</id>
        <link href="https://www.peterkrautzberger.org/0153/">
        </link>
        <updated>2014-03-09T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p7.jpg">
    <img alt="red workbook, p7" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p7.jpg">
  </a>
  <figcaption>
    Red Workbook, p.7
  </figcaption>
</figure>
<h3>Transcript</h3>
<ul>
<li><strong>Kapitel 2</strong> Dicke Teilmengen von \(S\)</li>
<li><strong>Def</strong>: \(T\subseteq S\) dick &lt;=&gt; \(\{ x^{-1}T : x\in S \}\) hat eDe</li>
<li><strong>Prop</strong>: Aeq: (a) \(T\) dick; (b) \(\forall e \subseteq_ e S \exists y \in S: ( y \in \bigcap_ {x\in e} x^{-1} T ) \Longleftrightarrow \stackrel{\stackrel{\text{punktweise}}{\downarrow}}{e \cdot y} \subseteq T)\)<br>
(c) ex. \(L \subseteq \widehat{T}\) (min) LID.
<ul>
<li>[proof]</li>
<li>a &lt;=&gt; c: \(x\in S, p\in \beta S: x^{-1} T \in p \stackrel{\text{Skript}}{\Leftrightarrow} T\in x\cdot p \Leftrightarrow x\cdot p \in \widehat{T}\)</li>
<li>also \(T \text{ dick} \Leftrightarrow \exists p \in \beta S: S\cdot p \subseteq \widehat{T} \stackrel{\text{stetig &amp; closed}}{\Longleftrightarrow} \exists p \in \beta S: \beta S \cdot p \subseteq \widehat{T} \Leftrightarrow \text{Beh.}\)</li>
</ul>
</li>
<li><strong>Bem.</strong> \(A\) dick =&gt; \(A\) zentral.
<ul>
<li>[\(A\) dick =&gt; \(\exists L \text{ min. LID} \subseteq \widehat{A} \Rightarrow \exists \epsilon: E_ \min \cap L \subseteq \widehat{A} \Rightarrow A \in \epsilon\).</li>
</ul>
</li>
<li><strong>Bem.</strong> (a) \(A \subseteq (\omega, +)\) dick &lt;=&gt; \(A\) enthaelt beliebig lange Intervalle
<ul>
<li>(b) dick \(\stackrel{\not \Rightarrow}{\not \Leftarrow}\) synd.</li>
<li>[proof]
<ul>
<li>Betrachte \(\omega = \bigcup_ {n \in \omega} I_ n\), \(\left\vert I_ n\right\vert  = n\), $0\in I_ 0 &lt;&lt; I_ 1 &lt;&lt; \ldots $</li>
<li>
<ol>
<li>\(A := \bigcup_ {2 \in \omega} I_ {2n}, B = \bigcup_ {n\in \omega} I_ {2n+1} \rightarrow A, B\) dick, nicht syndetisch.</li>
</ol>
</li>
<li>
<ol start="2">
<li>\(A = 2 \cdot \mathbb{N}\) synd, \(A\) nicht dick.</li>
</ol>
</li>
</ul>
</li>
<li>(c) \(A \subseteq \text{ pws} \Leftrightarrow \exists g \subseteq_ e S { t^{-1} \bigcup_ {x \in g} x^{-1}A : t \in S} \text{ eDE} \Leftrightarrow \exists g \subseteq_ e : \bigcup_ {x \in g} x^{-1}A \text{ dick.}\)</li>
<li>(d) \(A\) dick (pws, synd) =&gt; \(x^{-1} A\) dick (pws, synd)</li>
<li>\(A\) synd =&gt; \(x\cdot A\) synd.</li>
</ul>
</li>
</ul>
<h3>Translation</h3>
<ul>
<li><strong>Chapter 2</strong> Thick subsets of \(S\)</li>
<li><strong>Definition</strong>: \(T\subseteq S\) thick &lt;=&gt; $ { x^{-1}T : x\in S }$ has the finite intersection property (FIP)</li>
<li><strong>Proposition</strong>: TFAE
<ul>
<li>(a) \(T\) thick;</li>
<li>(b) \(\forall e \subseteq S \text{ finite } \exists y \in S: ( y \in \bigcap_ {x\in e} x^{-1} T) \Longleftrightarrow \stackrel{\stackrel{\text{pointwise}}{\downarrow}}{e \cdot y} \subseteq T)\)</li>
<li>(c) \(\exists L \subseteq \widehat{T}\) (minimal) left ideal (LID).</li>
<li>[proof of a &lt;=&gt; c]
<ul>
<li>note: \(x\in S, p\in \beta S: x^{-1} T \in p \Leftrightarrow T\in x\cdot p \Leftrightarrow x\cdot p \in \widehat{T}\)</li>
<li>therefore: \(T \text{ thick} \Leftrightarrow \exists p \in \beta S: S\cdot p \subseteq \widehat{T} \stackrel{\text{continuous &amp; closed}}{\Longleftrightarrow} \exists p \in \beta S: \beta S \cdot p \subseteq \widehat{T} \Leftrightarrow \text{ the claim}\).</li>
</ul>
</li>
</ul>
</li>
<li><strong>Remark</strong> \(A\) thick =&gt; \(A\) central.
<ul>
<li>proof. \(A\) central =&gt; \(\exists L \text{ min. LID} \subseteq \widehat{A} \Rightarrow \exists \epsilon: E_ \min \cap L \subseteq \widehat{A} \Rightarrow A \in \epsilon\).</li>
</ul>
</li>
<li><strong>Remark.</strong>
<ul>
<li>(a) \(A \subseteq (\omega, +)\) thick &lt;=&gt; \(A\) contains arbitrarily long intervals</li>
<li>(b) thick \(\not \Rightarrow\) syndetic, thick \(\not \Leftarrow\) syndetic.</li>
<li>[proof]
<ul>
<li>Consider a partition \(\omega = \bigcup_ {n \in \omega} I_ n\), \(\vert I_ n\vert  = n+1\) with $0\in I_ 0 &lt;&lt; I_ 1 &lt;&lt; \ldots $</li>
<li>
<ol>
<li>\(A := \bigcup_ {2 \in \omega} I_ {2n}, B = \bigcup_ {n\in \omega} I_ {2n+1} \rightarrow A, B\) thick, not syndetic.</li>
</ol>
</li>
<li>
<ol start="2">
<li>\(A = 2 \cdot \mathbb{N}\) syndetic, \(A\) not thick.</li>
</ol>
</li>
</ul>
</li>
<li>(c) \(A \subseteq \text{ piecewise syndetic (pws)} \Leftrightarrow \exists g \subseteq S \text{ finite } { t^{-1} \bigcup_ {x \in g} x^{-1}A : t \in S} \text{ eDE} \Leftrightarrow \exists g \subseteq S \text{ finite} : \bigcup_ {x \in g} x^{-1}A \text{ thick.}\)</li>
<li>(d) \(A\) thick (pws, synd) =&gt; \(x^{-1} A\) thick (pws, synd)</li>
<li>\(A\) synd =&gt; \(x\cdot A\) synd.</li>
</ul>
</li>
</ul>
<h3>Notes</h3>
<p>Same lecture, new chapter. This is the first of two pages on the basics of thick sets.</p>
<p>&quot;Thick&quot; is an odd notion. It always seems a little made up to me, something stated after the fact (after asking &quot;what does a set look like that covers a left ideal?&quot;). On the other hand, for \(\omega\), I can imagine that the notion &quot;a set that contains arbitrarily long intervals&quot; might actually come up independently of ultrafilters. However, I don't know the history of the notion, so I'm probably wrong here (if you know anything about this, please leave a comment).</p>
<p>A technical note. I realized that using the section heading &quot;partial translation&quot; was a bit misleading; as would be &quot;augmented/corrected translation&quot;. In fact, I do both -- leave some things out (negligible comments etc), clear up the layout, and add corrections (e.g. \(\vert I_ n\vert  = n+1\) instead of \(n\)). So I will just call it &quot;translation&quot; from now on.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p6]]></title>
        <id>https://www.peterkrautzberger.org/0152/</id>
        <link href="https://www.peterkrautzberger.org/0152/">
        </link>
        <updated>2014-03-05T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p6-1.jpg">
    <img alt="red workbook, p6-1" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p6-1.jpg">
  </a>
  <figcaption>
    Red Workbook, p.6, part 1
  </figcaption>
</figure>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p6-2.jpg">
    <img alt="red workbook, p6-2" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p6-2.jpg">
  </a>
  <figcaption>
    Red Workbook, p.6, part 2
  </figcaption>
</figure>
<h3>Transcript</h3>
<ul>
<li>
<p>Folgerung: Ann. \(1_S\) ex., \(X = 2^S\).</p>
<ul>
<li>Prop. \(C\subseteq x = \chi_C \in X\):
<ul>
<li>\(C\) zentral &lt;=&gt; ex \(y \in X: y\) prox. \(x\), unif. rek, \(y(1_S) = q\)
<ul>
<li>[&quot;=&gt;&quot; wie Satz/Beweis; &quot;&lt;=&quot; Setze \(U = { z: z(1_Q) = 1} \in y\)</li>
<li>\(\underset{Bsp.2}{\Rightarrow}\) \(R(x,U) = C \stackrel{\text{Def}}{\underset{\text{Satz}}{\Rightarrow}} C\) zentral]</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>\(S = (\omega, +)\)</p>
</li>
<li>
<p>Wir wissen</p>
<ul>
<li>(a) \(x,y \in X\) prox. &lt;=&gt; \(x,y\) stimmen auf bel. langen Int. von \(\omega\) ueberein</li>
<li>(b) \(y \in X\) unif. rekurrent \(\Longleftrightarrow \forall U \in \mathfrak{U}(y): R(y,U)\) synd.
<ul>
<li>\(\Longleftrightarrow \forall U_N \text{ (Basis offen) } R(y,U_n)\) syndetisch</li>
<li>\(\Longleftrightarrow \forall n \exists b \forall l \exists k (l \leq k \leq l+b \text{ und } y \upharpoonright [k,k+n] = y \upharpoonright n\)</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Fuer \(C \subseteq \omega\):</p>
<ul>
<li>\(C\) zentral \(\Leftrightarrow \exists y \in 2^\omega: y\) unif. rek. und \(y\) prox. $\chi_C $</li>
<li>und \(y(0)=1\)</li>
</ul>
</li>
<li>
<p><strong>Also zentrale Mengen analytisch!</strong></p>
</li>
<li>
<p>Frage: echt analytisch? SK: wahrscheinlich.</p>
</li>
<li>
<p>Notiz: Rand Oben: ?: Dieses DS in irgendeinem Sinn universell?</p>
</li>
<li>
<p>Notiz: gegenueberliegende Seite:</p>
<ul>
<li>anders: )offenbar ist) die eigetnlich Def. dadurch verbessert, dass klar wird, dass Obermengen wieder zentral sind</li>
<li>Frage: kann ich im selben DS bleiben, um die Def. fuer eine Obermenge zu verifizieren?
<ul>
<li>orig/anders: Laesst sich die Konstruktion in \(2^Q\) hinueberretten durch eine geeignete Abbildung?</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>partial Translation</h3>
<ul>
<li>
<p>Conclusion: Assume an identity \(1_S\) exists, \(X = 2^S\).</p>
<ul>
<li>(Side note: is this dynamical system universal in some sense?)</li>
<li>Proposition. \(C\subseteq x = \chi_C \in X\):
<ul>
<li>\(C\) central &lt;=&gt; ex \(y \in X: y\) proximal \(x\), uniformly recurrent, \(y(1_S) = q\)
<ul>
<li>[&quot;=&gt;&quot; as in the proof of the theorem; &quot;&lt;=&quot; Let \(U = { z: z(1_Q) = 1} \in y\)</li>
<li>\(\underset{Example 2}{\Rightarrow}\) \(R(x,U) = C \stackrel{\text{Definition}}{\underset{\text{Theorem}}{\Rightarrow}} C\) central]</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>\(S = (\omega, +)\)</p>
</li>
<li>
<p>We know</p>
<ul>
<li>(a) \(x,y \in X\) proximal &lt;=&gt; \(x,y\) agree on arbitrarily long Intervals of \(\omega\)</li>
<li>(b) \(y \in X\) unif. recurrent \(\Longleftrightarrow \forall U \in \mathfrak{U}(y): R(y,U)\) syndetic
<ul>
<li>\(\Longleftrightarrow \forall U_N \text{ (basic open) } R(y,U_n)\) syndetic</li>
<li>\(\Longleftrightarrow \forall n \exists b \forall l \exists k (l \leq k \leq l+b \text{ und } y \upharpoonright [k,k+n] = y \upharpoonright n\)</li>
</ul>
</li>
</ul>
</li>
<li>
<p>For \(C \subseteq \omega\):</p>
<ul>
<li>\(C\) central \(\Leftrightarrow \exists y \in 2^\omega: y\) unif. rec. and \(y\) prox. $\chi_C $</li>
<li>and \(y(0)=1\)</li>
</ul>
</li>
<li>
<p><strong>So central Sets are analytic!</strong></p>
</li>
<li>
<p>Question: properly analytic? Sabine Koppelberg: probably.</p>
</li>
<li>
<p>Note (across the page)</p>
<ul>
<li>to put it differenlty: this clearly improved the initial Definition as it is now clear that supersets of central sets are central.</li>
<li>Question: can we stay in the same dynamical system to verify that supersets of a central set are central?
<ul>
<li>to put it differently: can we find a map to transfer the constructions in \(2^Q\) over to an arbitrary DS?</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Notes</h3>
<p>This is a curious (double) page. I don't know why Sabine Koppelberg thought it was important to add the observation that the set of central sets of \(\omega\) is analytic (and I'm wondering if the question about &quot;properly analytic&quot; came from my PhD-sibling Gido Scharfenberger-Fabian). I don't think I've ever seen this fact used in the wild. It is a nice observation though and lets me add the first entry in this transcription project with the following subsection:</p>
<h3>Open problems</h3>
<ul>
<li>Is the set of central subsets of \(\omega\) properly analytic? (Sabine Koppelberg was apparently leaning towards &quot;yes!&quot;.)</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p5]]></title>
        <id>https://www.peterkrautzberger.org/0151/</id>
        <link href="https://www.peterkrautzberger.org/0151/">
        </link>
        <updated>2014-03-04T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p5.jpg">
    <img alt="red workbook, p5" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p5.jpg">
  </a>
  <figcaption>
    Red Workbook, p.5
  </figcaption>
</figure>
<h3>Transcript</h3>
<ul>
<li>
<p>Satz (Auslander-Ellis) \(X\) DS ueber \(S\), \(x\in X\) =&gt; \(\exists y \in X: x \text{ prox } y\) &amp; uniform rekurrent</p>
<ul>
<li>[Nimm \(\epsilon \in E_ \min(\beta S)\), setze \(y= \epsilon \cdot x \stackrel{\text{Cor.}}{\rightarrow}\) dies tut's.]</li>
</ul>
</li>
<li>
<p>Def. \(C\) dyn. zentral \(:\Leftrightarrow\) es ex. DS \(X\) ueber S, \(x,y \in X\), \(x\) prox \(y\), \(y\) unif. rek., und \(\exists U \in \mathfrak{U}(y): C = R(x,U)\).</p>
</li>
<li>
<p>Satz (Bergelson, Hindman etc) \(C \subseteq S\) zentral &lt;==&gt; \(C\) dyn. zentral.</p>
<ul>
<li>Beweis
<ul>
<li>&quot;&lt;=&quot;: $ C = R(x,U)$ (\(U\in \mathfrak{U}(y)\) etc)</li>
<li>\(\underset{\text{Cor. oben}}{\Rightarrow}\) ex. \(\epsilon \in E_ \min(\beta S): y = \epsilon \cdot x\) =&gt; \(\underbrace{R(x,U)}_ {=C} \in \epsilon\)</li>
<li>&quot;=&gt;&quot;: Setze \(Q := \begin{cases} S &amp; \text{ falls } 1_ S \text{ ex} \\\\ S \cup {1_ Q} &amp; \text{ sonst } 1_ Q \text( id.) \end{cases}\)</li>
<li>\(X = 2^Q\) (siehe Beispiel) etc, \(x = \chi_ C\) (da \(C \subseteq S \subseteq Q\))</li>
<li>Nach Vors. waehle \(\epsilon \in E_ \min(\beta S)\) mit \(C \in \epsilon\).</li>
<li>setze \(y:= \epsilon \cdot x\) =&gt; \(x\) prox. \(y\), \(y\) unif. rekurrent</li>
<li>Beh.: \(y(1_ Q) = 1\)
<ul>
<li>[sonst \(=0\), \(V
   :={ z : z(1_ Q) = 0} \in \mathfrak{U}(y)\)
<ul>
<li>\(y = \epsilon x\), also \(R(x,V) \in \epsilon\)</li>
</ul>
</li>
<li>=&gt; \(C \cap R(x,V) \neq \emptyset\), say \(s \in \ldots \cap \ldots\)</li>
<li>=&gt; \(0 = s \cdot x(1_ Q) \underset{\text{Def}}{=} x(1_ Q \cdot s ) = x(s) = 1\) ↯ ]</li>
</ul>
</li>
<li>Nimm \(U = { z \in X: z(1_ Q) = 1}\) clopen, \(\in \mathfrak{U}(y)\).</li>
<li>Nach Beispiel \(C = R(x,U)\). ☐</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>partial Translation</h3>
<ul>
<li>
<p>Theorem (Auslander-Ellis) \(X\) dynamical system over \(S\), \(x\in X\) =&gt; \(\exists y \in X: x \text{ proximal } y\) &amp; uniformly recurrent</p>
<ul>
<li>[Take \(\epsilon \in E_ \min(\beta S)\), and let \(y= \epsilon \cdot x \stackrel{\text{Corollary}}{\rightarrow}\) confirm that this works.]</li>
</ul>
</li>
<li>
<p>Definition. \(C\) dynanmically central \(:\Leftrightarrow\) there exists. dynamical system \(X\) over S, \(x,y \in X\), \(x\) proximal \(y\), \(y\) unif. recurrent, and \(\exists U \in \mathfrak{U}(y): C = R(x,U)\).</p>
</li>
<li>
<p>Theorem (Bergelson, Hindman etc) \(C \subseteq S\) central &lt;==&gt; \(C\) dyn. central.</p>
<ul>
<li>Proof.
<ul>
<li>&quot;&lt;=&quot;: $ C = R(x,U)$ (\(U\in \mathfrak{U}\) etc)</li>
<li>\(\underset{\text{Cor. above}}{\Rightarrow}\) there exists \(\epsilon \in E_ \min(\beta S): y = \epsilon \cdot x\) =&gt; \(\underbrace{R(x,U)}_ {=C} \in \epsilon\)</li>
<li>&quot;=&gt;&quot;: Let \(Q := \begin{cases} S &amp; \text{ if } 1_ S \text{ ex} \\\\ S \cup {1_ Q} &amp; \text{ else } 1_ Q \text( identity ) \end{cases}\)</li>
<li>\(X = 2^Q\) (see example earlier) etc, \(x = \chi_ C\) (since \(C \subseteq S \subseteq Q\))</li>
<li>By our assumptions choose \(\epsilon \in E_ \min(\beta S)\) with \(C \in \epsilon\).</li>
<li>let \(y:= \epsilon \cdot x\) =&gt; \(x\) proximal \(y\), \(y\) uniformly recurrent</li>
<li>Claim: \(y(1_ Q) = 1\)
<ul>
<li>[else \(=0\), \(V :={ z : z(1_ Q) = 0} \in \mathfrak{U}(y)\)
<ul>
<li>\(y = \epsilon x\), therefore \(R(x,V) \in \epsilon\)</li>
</ul>
</li>
<li>=&gt; \(C \cap R(x,V) \neq \emptyset\), say \(s \in \ldots \cap \ldots\)</li>
<li>=&gt; \(0 = s \cdot x(1_ Q) \underset{\text{Def}}{=} x(1_ Q \cdot s ) = x(s) = 1\) ↯ ]</li>
</ul>
</li>
<li>Take \(U = { z \in X: z(1_ Q) = 1}\) clopen, \(\in \mathfrak{U}(y)\).</li>
<li>As in the example: \(C = R(x,U)\). ☐</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Notes</h3>
<p>This is the continuation of lecture with notes on the previous pages and contains the next notes from the next lecture.</p>
<p>This lecture starts where the last one left off, reaping the rewards -- the famous theorem by Auslander-Ellis now looks almost distressingly easy, with a terribly arbitrary choice of \(\epsilon\).</p>
<p>The theorem by Hindman and Bergelson (citation needed) is less known perhaps. It greatly simplifies thinking about central sets and is really quite central (pardon the pun).</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p4]]></title>
        <id>https://www.peterkrautzberger.org/0150/</id>
        <link href="https://www.peterkrautzberger.org/0150/">
        </link>
        <updated>2014-03-01T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p4.jpg">
    <img alt="red workbook, p4" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p4.jpg">
  </a>
  <figcaption>
    Red Workbook, p.4
  </figcaption>
</figure>
<h3>Transcript</h3>
<ul>
<li>(a)=&gt; (b)
<ul>
<li>\(U\in \mathfrak{U}(y)\), \(R(y,U)\) synd, \(S = \bigcup_{t\in F_u} t^{-1}R(y,U)\)</li>
<li>Sei \(v\in L\) =&gt; \(\exists t_U: t_U^{-1} R(y,U) \in v \Rightarrow t_u \cdot v \in \widehat{R(y,U)}\)</li>
<li>Nimm \(p\in L\) Limes von \(\underbrace{ \{ t_U \cdot v: U\in \mathfrak{U}(y) \}}_{\text{Netz bzg} (\mathfrak{U}(y), \supseteq) \stackrel{L \text{ kompakt}}{\Rightarrow} \exists \text{ Limes}} \subseteq L\)</li>
<li>\(\Rightarrow p\cdot y = y\)
<ul>
<li>\(t_u \cdot v \cdot y \in U, t_u \cdot v \rightarrow p \Rightarrow p\cdot y = y\)</li>
</ul>
</li>
</ul>
</li>
<li>(f) =&gt; (a)
<ul>
<li>\(L \cdot y\) ist min. US [!] (abg. klar; US klar; jeder Orbit enhaelt \(y\))</li>
</ul>
</li>
<li>(e) =&gt; (a)
<ul>
<li>\(y\in M = \beta S \cdot y \text{ min., } y = p \cdot y \Rightarrow \exists L' \text{min. LID}: L' \cdot y \subseteq M \text{ US}\)</li>
<li>\(\Rightarrow L' = M \ni y \Rightarrow\) wie (b)=&gt;(e) die Beh.</li>
<li>[Rest einfach bis trivial]</li>
</ul>
</li>
<li>[<strong>Corollar</strong> \(x\) prox \(y\) =&gt; \(\exists L \text{ min LID} \forall p \in L: px = py\)
<ul>
<li>Bew: \(M = \{ p \in \beta S : px = py \} \neq \emptyset, MLID\) =&gt; Beh. ]</li>
</ul>
</li>
<li><strong>Corollar</strong> \(x\) prox \(y\), \(y\) unif. rek. =&gt; ex \(\epsilon \in E_{\min}(\beta S): \epsilon x = y (= \epsilon y)\)
<ul>
<li>&quot;&lt;=&quot; Cor &amp; Satz zuvor</li>
<li>&quot;=&gt;&quot; Cor -&gt; L -&gt; (Satz(e)) \(\epsilon\) wirkt wie \(id\) auf \(y\).</li>
</ul>
</li>
<li><strong>Corollar</strong>/Notiz: \(y\) unif. &lt;=&gt; \(\forall \epsilon \in E_{\min}(\beta S): \epsilon y = y\).</li>
<li>{Mittwoch 10 Uhr]</li>
</ul>
<h3>partial Translation</h3>
<ul>
<li>(a)=&gt; (b)
<ul>
<li>\(U\in \mathfrak{U}(y)\), \(R(y,U)\) syndetic =&gt; \(S = \bigcup_{t\in F_u} t^{-1}R(y,U)\)</li>
<li>Let \(v\in L\) =&gt; \(\exists t_U: t_U^{-1} R(y,U) \in v \Rightarrow t_u \cdot v \in \widehat{R(y,U)}\)</li>
<li>Let \(p\in L\) be the limit of \(\underbrace{ \{ t_U \cdot v: U\in \mathfrak{U}(y) \}}_{\text{ is a net with respect to} (\mathfrak{U}(y), \supseteq) \stackrel{L \text{ compact}}{\Rightarrow} \exists \text{ limit }} \subseteq L\)</li>
<li>\(\Rightarrow p\cdot y = y\)
<ul>
<li>\(t_u \cdot v \cdot y \in U, t_u \cdot v \rightarrow p \Rightarrow p\cdot y = y\)</li>
</ul>
</li>
</ul>
</li>
<li>(f) =&gt; (e)
<ul>
<li>\(L \cdot y\) is a minimal subsystem
<ul>
<li>obviously closed and a subsystem. Also, every orbit contains \(y\).</li>
</ul>
</li>
</ul>
</li>
<li>(e) =&gt; (a)
<ul>
<li>\(y\in M = \beta S \cdot y \text{ min.} => \exists p: y = p \cdot y \Rightarrow \exists L' \text{ minimal LID}: L' \cdot y \subseteq M \text{ subsystem}\)</li>
<li>\(\Rightarrow L' = M \ni y\)</li>
<li>now proceed as in (b)=&gt;(a).</li>
</ul>
</li>
<li>[<strong>Corollary</strong> \(x\) proximal to \(y\) =&gt; \(\exists L \text{ min. LID} \forall p \in L: px = py\)
<ul>
<li>Bew: \(M = \{ p \in \beta S : px = py \} \neq \emptyset, \text{ min. LID}\) =&gt; Claim. ]</li>
</ul>
</li>
<li><strong>Corollary</strong> \(x\) proximal to \(y\), \(y\) uniformly recurrent =&gt; ex \(\epsilon \in E_{\min}(\beta S): \epsilon x = y (= \epsilon y)\)
<ul>
<li>&quot;&lt;=&quot; by previous Corollary &amp; Theorem</li>
<li>&quot;=&gt;&quot; previous corollary yields min. LID L =&gt; (Theorem part (e)) =&gt; \(\epsilon\) operates like \(id\) on \(y\).</li>
</ul>
</li>
<li><strong>Corollary</strong>/Note: \(y\) unif. recurrent &lt;=&gt; \(\forall \epsilon \in E_{\min}(\beta S): \epsilon y = y\).</li>
</ul>
<h3>Notes</h3>
<p>Not much to say here; just finishing the proof of the theorem with some simple corollaries. The notes are very short on details but it seems to be all there.</p>
<p>This finishes the first lecture in the workbook (the next one was apparently scheduled for Wednesday, 10am).</p>
<p>In a sense it's a very &quot;normal&quot; proof in this field. That isn't to say it's easy but while the proof is a bit of a grind (a and b being the really only interesting part), the arguments are typical arguments that appear frequently; e.g., how to use syndeticity to build an ultrafilter (in this case using a net), the powerful properties of minimal left ideals (and their somewhat horrific lack of discernable structure).</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p3]]></title>
        <id>https://www.peterkrautzberger.org/0149/</id>
        <link href="https://www.peterkrautzberger.org/0149/">
        </link>
        <updated>2014-02-26T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p3.jpg">
    <img alt="red workbook, p3" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p3.jpg">
  </a>
  <figcaption>
    Red Workbook, p.3
  </figcaption>
</figure>
<h3>Transcript</h3>
<ul>
<li>Def.<br>
\begin{split} x,y \text{ proximal} &amp; \Leftrightarrow \forall V \in \mathfrak{U}(\overbrace{\Delta}^{\text{Diag. in $X\times X$}}) \exists s \in S: (sx, sy) \in V \\\\ &amp; \underbrace{\Leftrightarrow}_ {\text{topologie: diese Ueberd. bilden Umg.basis von $\Delta$ in $X^2$}} \forall (U_ i)_ {i=1}^m, \bigcup U_ i = X \text{ offen} \exists s \in S, i \leq m: sx, sy \in U_ i \end{split}</li>
<li>Satz
<ul>
<li>$ x,y \text{ prox.} \Leftrightarrow \exists p \in \beta S: px = py$.</li>
</ul>
</li>
<li>Bsp 2 (fortg)
<ul>
<li>Sei \(S\leq Q, 1_ Q \in Q\) mit \(1_ q \cdot s = s \cdot 1_ Q = s \forall s \in S\)</li>
<li>\(U: = { z \in X: z(1_ Q) = 1}\). Also \(U\subseteq X\) clopen [klar?]</li>
<li>Sei \(C\subseteq S: x:= \chi_ C\) (char. Fkt.)</li>
<li>Dann \(R(x,U) = C\)
<ul>
<li>[proof] \(s\in R(x,U) \Leftrightarrow s \cdot x \in U \Leftrightarrow s \cdot x (1_ Q) = 1 \Leftrightarrow x(1_ Q s) = 1 \Leftrightarrow x(s) = 1 \Leftrightarrow X \in C\)</li>
</ul>
</li>
<li>! Also: jede Teilmanege als Rueckkehrmenge darstellbar.</li>
</ul>
</li>
<li>Def. \(x\) unif. rekurrent \(\Leftrightarrow R(x,U) \text{ synd. } \forall U \in \mathfrak{U}\)</li>
<li>Satz. \(X\) DS ueber \(S\), \(y\in X\), \(L\subseteq \beta S\) min. LID<br>
a. \(y\) unif. rekurrent;<br>
b. \(\exists p \in L: p\cdot y = y\)<br>
c. \(\exists \epsilon \in L\cap E(\beta S): \epsilon \cdot y = y\)<br>
d. \(\exists \epsilon \in L \cap E(\beta S), x\in X: \epsilon \cdot x = y\)<br>
e. \(y\in \bigcup_ {M \text{min US}} M\)<br>
f. \(y \in L \cdot y\).</li>
<li>Beweis
<ul>
<li>c=&gt; a
<ul>
<li>$U \in \mathfrak{U}(y), V\subseteq \bar{V} \subseteq U \text{ offen}, A=R(y,V) \in \epsilon $ [\(\epsilon y = y\)]</li>
<li>\(B = {s: s\cdot \epsilon \in \hat{A}} \subseteq S \text{ syndetisch [HS 4.39]} \Rightarrow B \subseteq R(y,U)\) [\(s \epsilon \in \hat{A} \Rightarrow s\epsilon y = s y \in \bar{V} \subseteq U\)]</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>partial translation</h3>
<ul>
<li>Definition.\begin{split} x,y \text{ proximal} &amp; \Leftrightarrow \forall V \in \mathfrak{U}(\Delta) \exists s \in S: (sx, sy) \in V \\\\ &amp; \Leftrightarrow \forall (U_ i)_ {i=1}^m, \bigcup U_ i = X \text{ open} \exists s \in S, i \leq m: sx, sy \in U_ i \end{split}<br>
where \(\Delta\) is the diagonal in \(X\times X\); note that these coverings form a neighborhood basis of \(\Delta\) in \(X^2\)</li>
<li>Theorem
<ul>
<li>$ x,y \text{ proximal} \Leftrightarrow \exists p \in \beta S: px = py$.</li>
</ul>
</li>
<li>Example 2 (continued)
<ul>
<li>Let \(S\leq Q, 1_ Q \in Q\) with \(1_ q \cdot s = s \cdot 1_ Q = s \forall s \in S\)</li>
<li>\(U: = { z \in X: z(1_ Q) = 1}\). Then \(U\subseteq X\) is clopen</li>
<li>Let \(C\subseteq S: x:= \chi_ C\) (characteristic function)</li>
<li>Then \(R(x,U) = C\)
<ul>
<li>[proof] \(s\in R(x,U) \Leftrightarrow s \cdot x \in U \Leftrightarrow s \cdot x (1_ Q) = 1 \Leftrightarrow x(1_ Q s) = 1 \Leftrightarrow x(s) = 1 \Leftrightarrow X \in C\)</li>
</ul>
</li>
<li>! Therefore: every subset can be a return set</li>
</ul>
</li>
<li>Definition. \(x\) unif. recurrent \(\Leftrightarrow R(x,U) \text{ syndetic } \forall U \in \mathfrak{U}\)</li>
<li>Theorem. \(X\) dynamical system on \(S\), \(y\in X\), \(L\subseteq \beta S\) minimal left ideal. TFAE:<br>
a. \(y\) unif. recurrent;<br>
b. \(\exists p \in L: p\cdot y = y\)<br>
c. \(\exists \epsilon \in L\cap E(\beta S): \epsilon \cdot y = y\)<br>
d. \(\exists \epsilon \in L \cap E(\beta S), x\in X: \epsilon \cdot x = y\)<br>
e. \(y\in \bigcup_ {M \text{ minimal subsystem}} M\)<br>
f. \(y \in L \cdot y\).</li>
<li>Proof
<ul>
<li>c=&gt; a
<ul>
<li>$U \in \mathfrak{U}(y), V\subseteq \bar{V} \subseteq U \text{ offen}, A=R(y,V) \in \epsilon $ [\(\epsilon y = y\)]</li>
<li>\(B = {s: s\cdot \epsilon \in \hat{A}} \subseteq S \text{ syndetic [HS 4.39]} \Rightarrow B \subseteq R(y,U)\) [\(s \epsilon \in \hat{A} \Rightarrow s\epsilon y = s y \in \bar{V} \subseteq U\)]</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Notes</h3>
<p>The talk/lecture from the previous page continues, tackling proximality with its basic characterization in terms of \(\beta S\) and starting the proof of the characterization of uniform recurrence. That's fairly basic stuff (in the sense of necessary knowledge, not &quot;trivial&quot; or &quot;easy&quot;). The notes are a bit incomplete overall -- not sure if I was too lazy (likely) or if Sabine Koppelberg jumped a bit to get to the interesting bits.</p>
<p>The proof that begins at the bottom of the page is, for me, a typical cases of a proof that prevents one from learning; a picture perfect proof that throws elegant arguments around but keeps from its reader the beautiful messiness of coming up with it in the first place.</p>
<p>The reference [HS 4.39] is alomst certainly whatever is numbered 4.39 in Hindman &amp; Strauss, &quot;Algebra in the Stone–Čech compactification&quot;. (I can't check the actual detail since my copy of H&amp;S is still on route from LA.)</p>
<p>I forgot to mention in the first post that I substituted \mathfrak for Sutterlin in the transcription -- Sutterlin is too hard to come by (Sutterlin U is used to indicate the neighborhood filter).</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p2]]></title>
        <id>https://www.peterkrautzberger.org/0148/</id>
        <link href="https://www.peterkrautzberger.org/0148/">
        </link>
        <updated>2014-02-25T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p2.jpg">
    <img alt="red workbook, p2" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p2.jpg">
  </a>
  <figcaption>
    Red Workbook, p.2
  </figcaption>
</figure>
<h3>Transcript</h3>
<ul>
<li><strong>Koppelberg</strong> 20. Aug. 2006
<ul>
<li>Wied. \begin{split} C \subseteq S \text{ zentral} &amp; :\Longleftrightarrow &amp; \exists p \in E(\beta S) \cap K(\beta S): C \in p \\\\ &amp; \phantom{:}\Longleftrightarrow &amp; C \text{ IP-Menge &amp; PWS}\end{split}</li>
</ul>
</li>
<li><strong>1. Dyn. System</strong>
<ul>
<li>Ziel: zentral = dyn. zentral</li>
<li>Def.: DS \((X,\varphi)\) mit \(X\) kompatk, \(T_ 2\), \(\varphi\) Op. von S auf X (stetig in komp. \((S,X)\)), schreibe einfach \(s\cdot x\) statt \(\varphi(s,x)\).</li>
<li>Bsp:
<ol>
<li>\(W\) ($ \to t^n$), \(S \to \beta S\)</li>
<li>\(S\leq Q\), \(X=2^Q\) (Prod.raumder diskreten \({0,1}\)),</li>
</ol>
<ul>
<li>\(s\cdot x = x (q\cdot s) \forall s \in S, q\in Q, x\in X\)</li>
<li><strong>?</strong> stetig &amp; assoziativ (nachrechnen / klar)</li>
<li>[z.B. \(S=Q=W\), \(shift\) -&gt; Kap. 8 Skript]</li>
</ul>
</li>
<li>Def.
<ul>
<li>Untersystem, min US, \(\exists\) US min.</li>
<li>\(\beta S\) operiert auch auf \(X\) (wie immer)</li>
<li>aber <strong>nicht</strong> DS [Stetigkeit!)<br>
a. \(p\mapsto p \cdot x\) stetig, aber nicht \(x \mapsto p \cdot x\)!<br>
b. \((p \cdot q) \cdot x = p \cdot (q \cdot z)\) gilt. (i.A.)</li>
</ul>
</li>
<li>Bsp. \(Y\subseteq \beta S\) (als DS). \(Y \beta S\text{-invariant} \Leftrightarrow Y \text{ Linksid. von } \beta S\)</li>
<li>\(Y \text{ min. } US \Leftrightarrow Y \text{min. LID}\)</li>
</ul>
</li>
<li>[margin note, top]
<ul>
<li>Notizen: \(S_ 0={e_ 0}, e_ 0 \cdot e_ 0 = e_ 0\)</li>
<li>\(S_ {i+1} = S_ i \cup {e_ {i+1}}\) mit \(e_ {i+1}\) Identitaet dazu</li>
<li>[also immer Idenitaeten adjungieren] \(\Rightarrow \bigcup S_ i \equiv (\mathbb{N}, \vee)\) (sup)</li>
</ul>
</li>
<li>Hawaiian earring als DS =&gt; wie sehen zentrale aus?</li>
<li>[margin note, right]
<ul>
<li>Notiz?Prod. top = nur endlich viele</li>
<li><strong>entweder</strong> 0 oder 1</li>
<li>sonst Umgebung \(= {0,1}\)</li>
<li>-&gt; &quot;Wie \(2^{\mathbb{N}}\)&quot; Stetigkeit.</li>
</ul>
</li>
</ul>
<h3>partial translation</h3>
<ul>
<li><strong>Koppelberg</strong> 20. Aug. 2006
<ul>
<li>Repetition. \begin{split} C \subseteq S \text{ central} &amp; :\Longleftrightarrow &amp; \exists p \in E(\beta S) \cap K(\beta S): C \in p \\\\ &amp; \phantom{:}\Longleftrightarrow &amp; C \text{ IP-set &amp; piecewise syndetic}\end{split}</li>
</ul>
</li>
<li><strong>1. Dynamical System</strong> (DS)
<ul>
<li>Goal: central = dynamically central</li>
<li>Def.: DS \((X,\varphi)\) with \(X\) compact, \(T_ 2\), \(\varphi\) Op. from S to X (cts, in compact \((S,X)\)), we write \(s\cdot x\) (short for \(\varphi(s,x)\)).</li>
<li>Ex:
<ol>
<li>\(W\) ($ \to t^n$), \(S \to \beta S\)</li>
<li>\(S\leq Q\), \(X=2^Q\) (with Prod.topology),</li>
</ol>
<ul>
<li>\(s\cdot x = x (q\cdot s) \forall s \in S, q\in Q, x\in X\)</li>
<li><strong>?</strong> cts &amp; associative (obvious)</li>
<li>[e.g. \(S=Q=W\), \(shift\) -&gt; Ch. 8 lecture notes]</li>
</ul>
</li>
<li>Def.
<ul>
<li>dyn. subsystem, min. subsystem, \(\exists\) min. subsystem.</li>
<li>\(\beta S\) operates on \(X\) (as usual)</li>
<li>but <strong>not</strong> DS [continuity!)<br>
a. \(p\mapsto p \cdot x\) cts, but not \(x \mapsto p \cdot x\)!<br>
b. \((p \cdot q) \cdot x = p \cdot (q \cdot z)\) gilt. (i.A.)</li>
</ul>
</li>
<li>Example: \(Y\subseteq \beta S\) (as DS). \(Y \beta S\text{-invariant} \Leftrightarrow Y \text{ left ideal (LID) of } \beta S\)</li>
<li>\(Y \text{ min. subsystem} \Leftrightarrow Y \text{mininmal LID}\)</li>
</ul>
</li>
<li>[margin note, top]
<ul>
<li>Notes: \(S_ 0={e_ 0}, e_ 0 \cdot e_ 0 = e_ 0\)</li>
<li>\(S_ {i+1} = S_ i \cup {e_ {i+1}}\) mit \(e_ {i+1}\) Identitaet dazu</li>
<li>kepe adjoining identities =&gt; \(\bigcup S_ i \equiv (\mathbb{N}, \vee)\) (sup)</li>
<li>Hawaiian earring as DS =&gt; what do central sets look like?</li>
</ul>
</li>
</ul>
<h3>Notes</h3>
<p>My first workbook starts likemost would -- with lecture notes.</p>
<p>IIRC, these notes come from series of talks Sabine Koppelberg (my PhD advisor at FU Berlin) gave over the summer 2006 to a small audience (possibly just me? I don't remember). These talks followed her lecture notes for the course &quot;Ultrafilter, Topologie und Kombinatorik&quot; <a href="https://www.mi.fu-berlin.de/kvv/lecturer.htm?id=318">she gave in the previous semester</a> on all things \(\beta S\). The content is mainly based on <a href="http://www.degruyter.com/view/product/47147">Hindman, Strauss, Algebra in the Stone–Čech Compactification</a>, greatly improved by Sabine's own style.</p>
<p>The next two pages will continue this talk and ~20 pages will follow on the subject (interrupted by exercises and other notes). The topic are dynamical systems and recurrence, the famous Bergelman-Hindman result (as indicated: central = dynamically central), some notes on thick, pieceswise syndetic and the combinatorial description of central as well as the Central Sets Theorem.</p>
<p>It's funny to see how very inexperienced I was, e.g., the note on the product topology -- I really didn't know that? Wow. Then again, I never took a topology course while getting my Diplom (I could have used a better advisory infrastructure).</p>
<p>It's also funny (and somewhat alarming) to see how many subjects came up this early. But we'll get to that...</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red workbook, p1]]></title>
        <id>https://www.peterkrautzberger.org/0147/</id>
        <link href="https://www.peterkrautzberger.org/0147/">
        </link>
        <updated>2014-02-24T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Source</h3>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-cover.jpg">
    <img alt="red workbook, cover" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-cover.jpg">
  </a>
  <figcaption>
    Red Workbook, cover
  </figcaption>
</figure>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/red_workbook-p1.jpg">
    <img alt="red workbook, p1" src="https://www.peterkrautzberger.org/assets/2014/red_workbook-p1.jpg">
  </a>
  <figcaption>
    Red Workbook, p.1
  </figcaption>
</figure>
<h3>Transcript</h3>
<p>Arbeitsheft, 13. August 2006 bis 28. März 2007</p>
<h3>Translation</h3>
<p>Workbook, 13. August 2006 to 28. März 2007</p>
<h3>Notes</h3>
<p>This is the opening page of my first workbook, just after I had started to work on my PhD seriously (having finished my Diplom in Munich a few months earlier).</p>
<p>I'm using <code>p1</code> in the title to be intentionally vague -- while this happens to be page 1, I don't intend to publish every page, so the <code>p</code> might be read as <code>page</code>, <code>part</code>, or <code>piece</code>.</p>
<p>This workbook starts with a journal entry regarding traveling to TOPOSYM 2006 and continues with notes on the talks at TOPOSYM. It is curious to read those personal notes. For example, my first meeting with Wistar Comfort with whom I happened to share a close personal friend is notable mostly for the embarrassment I felt while being introduced to lots of researchers (whom WW Comfort all knew) whose name I barely caught (and never remembered) and with whom I wasn't able to have a conversation.</p>
<p>I won't reproduce the notes on conference talks -- they are neither interesting nor complete (and they deteriorate over the course of the week). I don't remember any of the talks now, but I remember the &quot;performance&quot; of some of the speakers (mostly the distinguished ones, like WW Comfort sharing stories from TOPOSYM during the Cold War). I do fondly remember spending that week with my fellow PhD students, Gido Scharfenberger and Steffi Frick, and getting the first taste of being among researchers -- exhilarating.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Asaf Karagila</strong>, 2014/02/24<br>
You know, that is really awesome.<br>
All I have to show for (this far, and in the future) is a huge pile of drafts which disprove Zermelo’s well-ordering theorem sitting between my desk and the closet.<br>
(My policy is to empty the pile each time I move an apartment, this one has at least a year and a half before its inevitable doom, it seems.)<br>
In fact, when I bought my tablet, I figured “Hey, I’ll just use it instead of pen and paper”, but it doesn’t work like that. I quickly returned to the pen and fragments of paper (I have math scribbled on bus tickets! that I wrote while sitting on my computer, next to a huge pile of actual pieces of paper!!).</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to publish all my research notes?]]></title>
        <id>https://www.peterkrautzberger.org/0146/</id>
        <link href="https://www.peterkrautzberger.org/0146/">
        </link>
        <updated>2014-02-23T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Last August, I finally finished my report for the DFG regarding my wonderful two years at Michigan. Part of this was to revisit all my old notes and publications. This has reminded me of something I've been wanting to do for a long time -- publish every last bit of research I produced during my PhD and postdoc.</p>
<p>A big part of this would be an effort to digitalize my handwritten notebooks. But what is a good platform? I could blog them, page after page, transcribing them and annotating the images. But perhaps a MediaWiki is a more suitable alternative? After all, searching navigating blog posts isn't exactly easy. Or perhaps both (should just be copy&amp;paste).</p>
<p>Perhaps I should use image annotations to directly markup the images? Perhaps I should wait for <a href="http://hypothes.is/">Hypothes.is</a> to support this? Also, pushing things to figshare would allow people to reference every note with DOI etc -- that's great, no? But are there other tools? Better tools? I have no clue. Help would be appreciated.</p>
<hr>
<p>Well, as you might have guessed, this draft has been sitting here for the last 6 months. So instead of waiting for the perfect solution, I'll start with the straight forward and reliable one. One blog post per page, transcribing the page, possibly adding translations, notes, comments. Since my notebooks sometimes contain personal notes, I will not necessarily publish every page of every notebook. For the same reason, I might blur parts of a page etc. Hopefully, this won't be too much of a mess (and interesting to someone, at least give them a laugh or something). We'll see how it goes.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Dana Ernst</strong>, 2014/02/24<br>
I’m looking forward to seeing how this turns out.</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Home sweet home]]></title>
        <id>https://www.peterkrautzberger.org/0145/</id>
        <link href="https://www.peterkrautzberger.org/0145/">
        </link>
        <updated>2014-01-26T00:00:00Z</updated>
        <summary type="html"><![CDATA[<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/Rhine_drachenfels.jpg">
    <img alt="the river Rhine and the Drachenfels" src="https://www.peterkrautzberger.org/assets/2014/Rhine_drachenfels.jpg">
  </a>
  <figcaption>
   The river Rhine and the Drachenfels
  </figcaption>
</figure>
<p>For the next few months I'll be in Bonn. As you can see, it's not for the weather.</p>
<p>Is there anything making this move worth while?</p>
<p>Yes, definitely.</p>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2014/Brot.jpg">
    <img alt="Loafs of bread" src="https://www.peterkrautzberger.org/assets/2014/Brot.jpg">
  </a>
  <figcaption>
  Loafs of bread in a German bakery.
  </figcaption>
</figure>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[This was goodbye]]></title>
        <id>https://www.peterkrautzberger.org/0144/</id>
        <link href="https://www.peterkrautzberger.org/0144/">
        </link>
        <updated>2013-12-31T00:00:00Z</updated>
        <summary type="html"><![CDATA[<figure>
  <a href="https://www.peterkrautzberger.org/assets/2013/downtown-los-angeles.jpg">
    <img alt="picture of downtown Los Angeles" src="https://www.peterkrautzberger.org/assets/2013/downtown-los-angeles.jpg">
  </a>
  <figcaption>
  Downtown Los Angeles.
  </figcaption>
</figure>
<p>It's been a fun 1½ years in LA. Time to move.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>saf</strong>, 2013/12/31<br>
Good Luck, Peter! Where are will you be going next?
<ul>
<li><strong>Peter</strong>, 2013/01/10<br>
Thanks, Saf! I’ll be in Germany for a while. Other than moving, not much changes for me, so it’s just a different timezone 😉</li>
</ul>
</li>
<li><strong>Samuel Coskey</strong>, 2014/01/05<br>
Say goodbye to the surveillance state known as USA! Oops I’m on the list now!
<ul>
<li><strong>Peter</strong>, 2014/01/06<br>
…</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A quick test post -- Jetpack connect edition]]></title>
        <id>https://www.peterkrautzberger.org/0142/</id>
        <link href="https://www.peterkrautzberger.org/0142/">
        </link>
        <updated>2013-12-19T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>You know how every blogger once in a while will have a test post that you find in your feed and then you click on it to learn more and it's already deleted?</p>
<p>I find that frustrating. So let's not do this. This is a test post to check out Jetpack connect and find a way to multishare to different social networks.</p>
<h3>Update.</h3>
<p>Alright, not too bad. Here's what this was about. Jetpack offers autoposting to a bunch of social networks, including my two current active ones - twitter and Google+. In particular the Google+ connection is painfully difficult with free tools. But still, a large amount of people I want to share things with are there. However, I strongly believe in my website being my primary digital outlet. I don't want to post content that will just be on Twitter or just on Google+. It is mine and should be shared from my website.</p>
<p>In addition, I have been thinking about how to write more frequently. One good piece of advise is to write less but more often. But I also find myself wanting to post different, more social content, e.g. a simple photo, share a link. One obvious tool is my phone and tablet. It has apps for all my networks as well my reading applications. A simple idea would be a multi-share app that would allow me to push shared content to all the apps I care about. Luckily, I couldn't find a well working one long enough to remember Jetpack Connect. Luckily it works with the WordPress app, so I can author once wherever I am and share where I want to share.</p>
<p>Unfortunately, for all my three readers, this means I might start posting little pieces of crappy content. Bear with me and yell at me from time to time. Here's to moar bloggings in 2014.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Another test post -- image sharing]]></title>
        <id>https://www.peterkrautzberger.org/0143/</id>
        <link href="https://www.peterkrautzberger.org/0143/">
        </link>
        <updated>2013-12-19T00:00:00Z</updated>
        <summary type="html"><![CDATA[<figure>
  <a href="https://www.peterkrautzberger.org/assets/2013/san-bernadino.jpg">
    <img alt="picture of San Bernadino" src="https://www.peterkrautzberger.org/assets/2013/san-bernadino.jpg">
  </a>
  <figcaption>
  San Bernadino, returning from Lake Arrowhead.
  </figcaption>
</figure>
<p>You might think Los Angeles and snow are separate, but surprisingly it's often not by far. Apart from the almost daily updates on NPR regarding snow packing strength during the winter (which is all about the water available the next summer), you have to drive barely two hours to find yourself in need for winter gear, being snowed in in front of a fireplace. At least I did.</p>
<h3>Update</h3>
<p>Unfortunately, not as good as I'd hoped. While Google+ will at least pull in the image into the mini-preview twitter won't do anything with it. That's too bad, but perhaps better than nothing.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Talk on Reverse Mathematics and the Modal Logic of Reverse Mathematics]]></title>
        <id>http://m6c.org/w/2013/11/talk-on-reverse-mathematics-and-the-modal-logic-of-reverse-mathematics/</id>
        <link href="http://m6c.org/w/2013/11/talk-on-reverse-mathematics-and-the-modal-logic-of-reverse-mathematics/">
        </link>
        <updated>2013-11-25T23:28:06Z</updated>
        <summary type="html"><![CDATA[This is a transcription of notes from a talk I gave on November 1, 2013 to the interdisciplinary logic seminar at the University of Connecticut. I gave a general introduction to Reverse Mathematics and then spoke about my work with &#8230; <a href="http://m6c.org/w/2013/11/talk-on-reverse-mathematics-and-the-modal-logic-of-reverse-mathematics/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Carl Mummert</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MathML Forges On -- notes, AAP leftovers, and a summary]]></title>
        <id>https://www.peterkrautzberger.org/0141/</id>
        <link href="https://www.peterkrautzberger.org/0141/">
        </link>
        <updated>2013-11-02T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://www.peterkrautzberger.org/0140/">&quot;The end (tm)&quot; of MathML in Chrome this week</a> happened to coincide with a piece I had been working on for a while now and which was published at O'Reilly's Programming blog (<a href="http://programming.oreilly.com/2013/11/mathml-forges-on.html">&quot;MathML Forges On&quot;</a>) yesterday. Originally, I had meant to write something for O'Reilly's TOC blog earlier this year, but then the TOC conference was retired (and so was the blog) so things got delayed.</p>
<p>Then in the summer, the ever fantastic <a href="https://twitter.com/tzviyasiegman">Tzviya Siegmann</a> pulled me into the <a href="https://web.archive.org/web/20150329081435/http://publishers.org/epub3implementationproject/">AAP's EPUB implementation project</a> and so I had a chance to be active in both the features and the accessibility groups. It was an extremely interesting experience all around so just two points. First, I am amazed at the work of the group leaders, handling the difficulties of running such a complex project, in a very short time, with a highly diverse group of participants. Second, it was an experience to, well, experience anti-trust concerns like that. While frustrating at times, I didn't find this tragic in the end; there was more to lose than to gain. But it felt strange to be on the other end of the stick, so to speak, wanting to drive publishers and reading systems to close collaboration so that we can finally get decent support for math &amp; science in ebooks. The <a href="https://web.archive.org/web/20150330160835/http://www.publishers.org/press/117/">AAP white paper came out</a> this week.</p>
<p>During that time I also wrote the first drafts for &quot;MathML Forges On&quot; (the title was a suggestion of Simon St. Laurent who has been a great editor). I want to thank Fred Wang, David Carlisle, Neil Soiffer and Dave Barton for many helpful comments and Sanders Kleinfeld for being a matchmaker, twice.</p>
<p>During the AAP project, I also summarized the technical details a little with suggestions for the short term. This wasn't useful to the AAP project but there's no reason to throw it away -- so here it is.</p>
<h2>A sort of summary</h2>
<blockquote>
<p><strong>Note.</strong> This was written with the following question in mind: how can we speed up MathML adoption in epub3? Well, one way would be to understand what level of support can be achieved in the short term. Since full MathML 3 support is simply not available, compromises have to be made. This means creating guidelines for publishers to ensure their content can be supported and for reading systems to understand how they can support that level. And for both sides to push each other -- publishers, pushing reading systems by pointing out an achievable level of support; reading systems pushing publishers to create reasonable MathML.</p>
</blockquote>
<p>Native MathML support in browser is limited to partial support in Firefox and Safari; JavaScript polyfills are available and have been used in reading systems.</p>
<p><strong>Recommendation</strong>: &quot;Firefox 24&quot;-level MathML support is a good baseline in the short term (6-12 months). This amount of MathML support covers most publishing needs and any ePub3 reading system can realistically provide this level of support via Gecko or polyfills within 6 months. The open source STIX and Asana fonts should be the default math fonts since technical limitations make them the only widely supported fonts in web environments.</p>
<h3>Browser support</h3>
<ul>
<li>Firefox: production ready. Good support for MathML, details at <a href="https://developer.mozilla.org/en-US/docs/Mozilla/MathML_Project/Status">https://developer.mozilla.org/en-US/docs/Mozilla/MathML_Project/Status</a>. Notably missing: linebreaking, elementary math, mtable labels and some mtable alignment attributes.</li>
<li>Safari/WebKit: not production ready. Partial MathML support, details <a href="https://trac.webkit.org/wiki/MathML%20Status">https://trac.webkit.org/wiki/MathML%20Status</a>. Notably limited/missing: horizontal stretch characters, multiscripts, RTL, linebreaking, elementary math, most mtable attributes.</li>
<li>IE: no support for MathML. For older IE versions (6-9), the MathPlayer plugin offers virtually complete MathML support.</li>
<li>Chrome: no support for MathML.</li>
</ul>
<h3>Polyfill support</h3>
<ul>
<li>MathJax: good MathML support, high rendering quality, details at <a href="http://docs.mathjax.org/en/latest/mathml.html">http://docs.mathjax.org/en/latest/mathml.html</a>. Notably missing are RTL, elementary math, and advanced mtable alignments.</li>
</ul>
<p>MathJax is modular, its primary output options are HTML and SVG, where it implements the TeX layout algorithm. MathJax can also augment native MathML output in Safari and Firefox (trading speed for layout quality). MathJax offers accessibility features (zoom, scale, copy&amp;paste) and works well with existing math accessibility solutions (MathPlayer, ChromeVox). MathJax has been integrated into epub3 reading systems such as Readium, Vitalsource Bookshelf, Azardi and IDEAL reader.</p>
<ul>
<li>Jqmath: MathML support is undocumented but will cover MathML 2; it exceeds WebKit/Safari and can render low-complexity content on par with Firefox, see <a href="http://mathscribe.com/author/jqmath.html">http://mathscribe.com/author/jqmath.html</a>.</li>
</ul>
<p>Jqmath tweaks browser layout instead of implementing a separate algorithm, trading speed for layout quality. Jqmath tries to be font agnostic and assumes browsers can access the necessary fonts and unicode points. Since its developer contributed to WebKit's MathML support, it works particularly well on Safari (augmenting the MathML output).</p>
<h3>Fonts</h3>
<p>Fonts are a particularly complex issue for mathematics and MathML. Here are a few problems:</p>
<ul>
<li>most fonts do not contain mathematical characters and cannot be used.</li>
<li>many mathematical and scientific characters lie outside the unicode BMP but only very recent browser versions support non-BMP codepoints.</li>
<li>MathML requires stretchy characters build out of multiple glyphs (such as parenthesis, braces, root signs etc); some of these do not have unicode points associated with them. To work around these issues:
<ul>
<li>Gecko/Firefox has hardcoded support for some fonts. Fully supported are only STIX and Asana Math, see <a href="https://developer.mozilla.org/en-US/docs/Mozilla/MathML_Project/Fonts">https://developer.mozilla.org/en-US/docs/Mozilla/MathML_Project/Fonts</a></li>
<li>Safari only supports some stretchy constructions with unicode glyphs.</li>
<li>MathJax provides fontdata for its own webfonts as well as STIX fonts. The upcoming MathJax v2.3 release will add custom webfonts for STIX, Asana Math, Neo Euler, and Gyre-Pagella.</li>
<li>MathPlayer supports a number of the legacy 8 bit fonts (symbol, Euclid, Mathematica fonts, ...) that it knows how to map and should support all modern &quot;unicode&quot; fonts (fonts whose characters are in their Unicode spots). It only deals with plane 0 characters at the moment. For stretchy characters, MathPlayer needs to know what extension characters go with what characters. Again, it support a number of legacy 8 bit fonts as well as the STIX fonts.</li>
</ul>
</li>
<li>Microsoft has developed (but not officially released) the OpenType MATH table extension which could eventually resolve these problems. However, no browser supports MATH tables; in addition, this kind of font data is not accessible to JavaScript. See also <a href="https://www.tug.org/TUGboat/tb30-1/tb94vieth.pdf">https://www.tug.org/TUGboat/tb30-1/tb94vieth.pdf</a></li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thoughts on "the end (tm)" of MathML in Chrome/Chromium]]></title>
        <id>https://www.peterkrautzberger.org/0140/</id>
        <link href="https://www.peterkrautzberger.org/0140/">
        </link>
        <updated>2013-10-29T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Today, <a href="https://code.google.com/p/chromium/issues/detail?id=152430#c43">a Chromium team member announced</a> that Chromium/Chrome does not plan to support MathML. (There's a bit of flaming going on on that thread so please don't fuel the flames.)</p>
<p>First off, this does not come as a surprise. Anyone who followed the topic closely must have come to the conclusion that Chrome does not plan to support MathML.</p>
<p>What is good about this post from the Chrome team is that it is now public and transparent. Instead of security issues or supposed architectural flaws in the WebKit code, the Chrome team makes it clear that they have made the conscious decision not to support MathML. That honesty is worth a lot.</p>
<p>It is important because others are less transparent. Microsoft keeps saying -- absolutely nothing. Apple has not invested in MathML development (save for VoiceOver) and relies on the work of unpaid volunteers -- yet almost brags about having support (not realizing that it is not actually usable in a professional context). While Mozilla technically hasn't paid developers for MathML rendering directly either, they have actively invested in maintaining the code base and helped its unpaid volunteers -- this is extremely important but something different form hiring a developer to work on the rendering.</p>
<p>Personally, I think today's announcement could be a good thing.</p>
<p>Not that Chrome doesn't plan MathML support of course -- MathJax's mission is to push MathML adoption to push browser support so that we can all push math on the web to and beyond MathML 3.0. But this might help to restart the conversation about how to achieve good math layout in HTML-CSS rendering engines (including how not to). That's a conversation worth having.</p>
<p>What is a slight problem is that the Chrome team has given no actual reasons. It doesn't help to guess the motives of Chrome's management or engineers. However, I can say with a reasonable degree of confidence that it should take no more than two full time developers to start with the WebKit code and push it past Firefox's rendering quality within a year. That's not a huge investment for Google so the problems must lie elsewhere. And perhaps they cannot be discussed publicly; that's ok.</p>
<p>But the flaming on that thread (including the MathJax bashing) reminded me of how little people understand the challenges facing browser (and MathJax) developers. MathJax is perhaps guilty of enabling these misconceptions as it makes mathematical layout look simple -- add one line of JavaScript; done -- hiding the many technical challenges that MathJax solves and that a browser developer would have to solve in more generality. (I will write more about these issues some time soon.)</p>
<p>In any case, I think this is an opportunity to have conversations rather than flaming and a chance to give more people an understanding of what it takes for math and science to succeed on the web.</p>
<hr>
<p>Update Nov 1, 2013: I've published a piece on the state of MathML on the web <a href="http://programming.oreilly.com/2013/11/mathml-forges-on.html">over at O'Reilly's Programming Blog</a>. It had been in the making for a while now and is unrelated to the above news.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>adam</strong>, 2013/10/30<br>
Very ironic that the Google engineering empire – full of all those geeky math and numbers nerdy types – won’t build Math support into their own products. I would love to know why. On a cultural level it really just doesn’t make any sense to me. Is it a company culture issue – seemingly going against their famed brainy mathy engineering image and ideology – and what does that signal? or is it a higher level strategic move to block competition (etc) …I don’t get it. So I would love love love to know what is behind this thinking. Very curious.<br>
But long live MathJax!
<ul>
<li><strong>Peter</strong>, 2013/10/30<br>
Thanks, Adam. As I said, I don’t want to speculate anymore (I have done so in the past and it usually makes matters worse). If they are interested in talking then that’s great. If not, well, then that’s that.</li>
</ul>
</li>
<li><strong>Alex Milowski</strong>, 2013/10/30<br>
I wish they would give more information as to why they don’t want to implement MathML. A conversation that is more than “we don’t like the existing code” would be really helpful.
<ul>
<li><strong>Peter</strong>. 2013/10/30<br>
Thanks for your comment. I agree, of course. While I understand that they can’t fully disclose their decision making process, I have heard from a number of Chrome developers that they are fundamentally in favor of MathML. We just need to move forward now. I think a third implementation after Gecko and WebKit could be very interesting (though it would seem a bit strange to me). But the basic challenge of reconciling mathematical layout with HTML-CSS remains.</li>
</ul>
</li>
<li><strong>Stephen Shankland</strong>. 2013/11/05<br>
FWIW, if you look at the bug-tracker thread, you can see some further discussion that indicates at least some of Google’s reasoning: 1. persistent security problems and 2. low usage of MathML on real-world Web.
<ul>
<li><strong>Peter</strong>, 2013/11/05<br>
Hi Steven. I’m following the thread, but there’s nothing new there. The Chrome team members have repeated their security concerns from back in May; these have all been fixed as Fred Wang pointed out in detail on the thread. I think the Chrome team has given the real reason: Google is not willing to hire a developer to develop MathML. That’s all there is to it (and of course it is their business decision to make). Everything else is a smoke screen.<br>
As for low usage of MathML on the web, that is a red herring. Yes, there will never be as much MathML on the web as there will be cat pictures. But it is simply a chicken and egg problem. For example, Wikipedia could switch its math content from images to MathML within days if browser support was available. All publishers are waiting to put out MathML on the web, in apps and in ebooks — but they can’t. As for usage today, the MathJax CDN alone sees 75 million monthly visitors (and ironically, the dominant browser is Chrome). So unless someone puts a number as to how much MathML there has to be, this is just misleading. Besides, Browser vendors did not argue that way about RTL or vertical text even though, undoubtedly, there was virtually no bidirectional text before browser support existed.<br>
Your article on CNet is very nice but you’re off when it comes to the group that would benefit the most. It’s not researchers but education that needs MathML. The educational sector is quickly moving towards web-based and HTML-driven content and MathML is the native, accessible, and reusable way of putting mathematics on the web. It is crucial for not just mathematics but science and technology education. In short, the need for mathematics in human communication is universal and constant even if it will not show up on the majority of websites.</li>
<li><strong>Stephen Shankland</strong>, 2013/11/05<br>
Yes, it seemed like the &quot;it's not a priority for us&quot; vibe came through better in follow-up comments -- they're not willing to pay somebody to maintain the code -- but also that Google is focusing on performance rather than new features. Perhaps they're sensitive to criticisms about Chrome bloat, for example: <a href="http://massivegreatness.com/bloated">http://massivegreatness.com/bloated</a><br>
Justin Schuh also said they stopped filing new bugs in the security domain once they decided remove support, so I at least wasn't clear whether all MathML security concerns have been resolved.<br>
Incidentally, I quoted your thorough O'Reilly write-up of the situation in my MathML story today: <a href="http://news.cnet.com/8301-1023_3-57610854-93/google-subtracts-mathml-from-chrome-and-anger-multiplies/">http://news.cnet.com/8301-1023_3-57610854-93/google-subtracts-mathml-from-chrome-and-anger-multiplies/</a>
<ul>
<li><strong>Peter</strong>, 2013/11/05<br>
If there had been performance issues that were tracked down to the MathML code, then that would have been an interesting discussion to have. Thanks for referencing my piece at O’Reilly, but out of context and in your context it sounds like Safari is holding back MathML while it is actually pushing it forward. As I point out in my conclusion, WebKit is in a good place from a development perspective and could quickly catch up to Firefox — most of the hard work is done.</li>
<li><strong>Stephen Shankland</strong>, 2013/11/05<br>
Thanks. I updated the story to address that concern.</li>
<li><strong>Peter</strong>, 2013/11/05<br>
Thanks, Stephen.</li>
</ul>
</li>
</ul>
</li>
<li><strong>John Savar</strong>, 2014/01/14<br>
MathML is verbose, and somewhat difficult to prepare manually. But some means of specifying mathematics should have been part of HTML 1.0, or at the least HTML 1.1, given that the WWW was originally designed at CERN specifically for the purpose of allowing researchers to present their work online.<br>
MathJax and jsMath before it are cumbersome solutions; ultimately, equations should be as much a normal part of text markup on web pages as italics and boldface. So I do agree that Firefox and Safari are doing the right thing, and Chrome appears to have taken a step backwards.<br>
But performance and security are important characteristics of a browser. If there really is something about the design of MathML that makes it difficult to meet those goals and support MathML at the same time (which, I have to admit, I find hard to understand) maybe another standard, like using TeX or AsciiMath, or something more like HTML, like MathML, only simpler, would be the way to go.
<ul>
<li><strong>Peter</strong>, 2014/01/28<br>
I don’t find MathML more verbose than HTML tables or SVG. Sure it’s not as short as asciimath but that’s comparing apples and oranges (or wikitext and HTML). It’s not meant to be manually authored (just like most contemporary HTML) and it’s not supposed to replace any authoring tool.<br>
As for performance and security, there is no sign that MathML is particularly prone to negatively influence either. The problem is really quite simple: an absence of developers working on it. Looking at how much progress lone-wolf volunteers have made in the past, it’s hard to believe that as small team at Chrome couldn’t implement MathML very quickly. Suggesting something other that MathML for HTML is neither necessary or helpful at this point (even though it’s a lot of fun to speculate what would have happened if HTML 3.2 had kept a limited math tag and people had actually embraced it, developed new forms of communicating mathematics using a restricted means of layout).</li>
</ul>
</li>
<li><a href="http://aperiodical.com/2013/11/dark-days-for-mathml-support-in-browsers/">Pingback</a></li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Equivalent to the axiom of choice that I didn't know about]]></title>
        <id>http://karagila.org/2013/equivalent-to-the-axiom-of-choice-that-i-didnt-know-about/</id>
        <link href="http://karagila.org/2013/equivalent-to-the-axiom-of-choice-that-i-didnt-know-about/">
        </link>
        <updated>2013-10-13T10:46:34Z</updated>
        <summary type="html"><![CDATA[<p>First I must apologize. I wanted to write a second post about forcing and preserving choice principles (I gave a nice talk in the student seminar about a week after the previous post), and I had a lot of things to say. I just ended up not writing it, and for absolutely no good reason. And somehow things continued that way and I felt more and more awkward to post anything because of that, but the vicious cycle must break somewhere.</p>

<p>I recently tried to figure out the consequence of some forcing in \(\ZF\). This has led me to the following statement: <a href="http://karagila.org/2013/equivalent-to-the-axiom-of-choice-that-i-didnt-know-about/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interview at Fidus Writer]]></title>
        <id>https://www.peterkrautzberger.org/0139/</id>
        <link href="https://www.peterkrautzberger.org/0139/">
        </link>
        <updated>2013-08-06T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>In the everlasting &quot;what I've said elsewhere&quot; category, I haven't really written much about MathJax around here; MathJax as my job, that is. Perhaps I should do it more often.</p>
<p>Anyway, Fidus Writer is a very interesting open source project for academic, collaborative writing in the cloud, putting HTML first and providing LaTeX and epub3 output. They interviewed me (representing the MathJax team) and the result is now <a href="http://fiduswriter.com/2013/08/06/math-in-the-browser/">on their blog</a>.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Minor updates]]></title>
        <id>https://www.peterkrautzberger.org/0138/</id>
        <link href="https://www.peterkrautzberger.org/0138/">
        </link>
        <updated>2013-08-02T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>It's been a while since I've posted regularly but I have a secret blogging project planned to get back into the groove. In the mean time I switched themes to twenty twelve (just as WordPress releases twenty thirteen, oh well).</p>
<p>I've also retroactively changed my licensing -- unless otherwise noted or attributed, all of my own original content is now licensed even more liberally under CC-by. Yes, that means you can go and use it for commercial use. Why? Because it means less headaches for anyone who wants to use it.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Dana Ernst</strong>, 2013/08/04<br>
Secret blogging project?!
<ul>
<li><strong>Peter</strong>, 2013/08/04<br>
Oh nothing special, just a way for me to blog more here.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The cardinal trichotomy: finite, countable, and uncoutnable.]]></title>
        <id>http://karagila.org/2013/the-cardinal-trichotomy-finite-countable-and-uncoutnable/</id>
        <link href="http://karagila.org/2013/the-cardinal-trichotomy-finite-countable-and-uncoutnable/">
        </link>
        <updated>2013-07-18T02:00:25Z</updated>
        <summary type="html"><![CDATA[<p>There is a special trichotomy for cardinality of sets. Sets are either finite, or countably infinite, or uncountable. It's an interesting distinction, and it has a very deep root -- at least in my perspective -- in the role of first-order logic.</p>

<p>Finite objects can be characterized in full using first-order logic. The fact that you can write down how many elements a set have, is a huge thing. For example, every finite structure of a first-order logic language has a categorical axiomatization. If the language is finite, then the axiomatization is finite as well. <a href="http://karagila.org/2013/the-cardinal-trichotomy-finite-countable-and-uncoutnable/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Name 5 top journals you read...]]></title>
        <id>https://www.peterkrautzberger.org/0137/</id>
        <link href="https://www.peterkrautzberger.org/0137/">
        </link>
        <updated>2013-07-17T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>The AMS is currently running a survey (I think it's members only? But if you got an invite, make sure to take the time).</p>
<p>It has asked me the following question</p>
<blockquote>
<p>Please list the top 5 journals that you read.</p>
</blockquote>
<p>My answer was:</p>
<blockquote>
<p>the arXiv is my only regular entry point. Search (MathSciNet, arXiv, Google Scholar etc) make my reading journal-agnostic and people-focused; this is especially true for non-mainstream subject areas.</p>
</blockquote>
<p>I don't think it matters that I've left research. On the one hand, the arXiv has always been my primary source (and things like Neil Hindman's homepage) and MathSciNet was the perfect search tool (although it feels like Google Scholar could ruin them if they wanted). On the other hand, I'm part of a generation that won't have to quit following mathematical research just because we've left research. We have the arXiv, we have researchers blogging, we have social media and they inform me much faster about interesting developments on all levels than a journal ever could.</p>
<p>But perhaps I'm just doin' it wrong.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Asaf Karagila</strong>, 2013/07/18<br>
I don’t think Google Scholar, whic is a great service can easily win over MathSciNet. The latter has the advantage of many mathematicians summarizing and reviewing papers. That’s something that is hard to replicate.
<ul>
<li><strong>Peter</strong>, 2013/07/18<br>
I wished I could agree with you. But that deserves another post.
<ul>
<li><strong>Asaf Karagila</strong>, 2013/07/19<br>
I can relate. I know how hard it can be to agree with me. 😉</li>
</ul>
</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Strong chain conditions and preservation of choice principles]]></title>
        <id>http://karagila.org/2013/strong-chain-conditions-and-preservation-of-choice-principles/</id>
        <link href="http://karagila.org/2013/strong-chain-conditions-and-preservation-of-choice-principles/">
        </link>
        <updated>2013-06-28T03:04:28Z</updated>
        <summary type="html"><![CDATA[<p>I recently returned from a wonderful week in Italy, where I attended the Young Set Theorist 2013 conference. I met a lot of new people, some old acquaintances, baffled people with oversized pickles, and most importantly shared and learned some great ideas.</p>

<p>One of the nicer things I'd done was to work with Thomas Johnstone on some preservation theorem related to forcing and choice principles (see also <a href="http://boolesrings.org/victoriagitman/2013/06/25/on-ground-model-definability/">this announcement by Victoria Gitman</a>). In order to clean up a bit the proof, I'll introduce a new definition which is going to slightly extend the ideas originally discussed in Italy. So without further jibber jabber, let's talk mathematics. <a href="http://karagila.org/2013/strong-chain-conditions-and-preservation-of-choice-principles/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[HoTT Math Series]]></title>
        <id>http://www.dorais.org/news/2013-06-23-hott-math-series.html</id>
        <link href="http://www.dorais.org/news/2013-06-23-hott-math-series.html">
        </link>
        <updated>2013-06-23T18:00:13Z</updated>
        <summary type="html"><![CDATA[<p>I am planning to do a series of posts where I attempt to do math in Homotopy Type Theory (HoTT). The plan is to do some relatively simple proof-relevant mathematics at an informal level. The topics will all be undergraduate level so the mathematics won’t be hard to follow. I’m hoping to keep the series brief so each post will only be an appetizer and not a full course dinner. Enjoy!</p>

<p>This preamble will serve to accumulate a table of contents and various conventions and notations that come up along the way. The only prerequisites (or rather corequisites) are the first two chapters of the (free) <a href="http://homotopytypetheory.org/book/">Homotopy Type Theory book</a>. Further prerequisites and reverences to later topics in the book will always be indicated where they occur.</p>

<hr />

<ol>
  <li><a href="/archives/1438">Elementary group theory</a></li>
  <li><a href="/archives/1476">More on equational logic</a></li>
  <li><a href="/archives/1488">Unit group of a ring</a></li>
  <li><a href="/archives/1517">Local rings and fields</a></li>
</ol>]]></summary>
        <author>
            <name>François G. Dorais</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Selected Papers Network]]></title>
        <id>http://www.dorais.org/news/2013-06-17-selected-papers-network.html</id>
        <link href="http://www.dorais.org/news/2013-06-17-selected-papers-network.html">
        </link>
        <updated>2013-06-17T13:59:43Z</updated>
        <summary type="html"><![CDATA[<p>I just made my <a href="https://plus.google.com/110930549217362212976/posts/UfFUcHpHQEi">first contribution</a> to the <a href="https://selectedpapers.net/">Selected Papers Network</a>. It was fun and easy and I strongly recommend you use it too!</p>

<p>It’s too early for serious commentary on the experience but there are a few things I noted right away:</p>

<ul>
  <li>The front page <a href="https://selectedpapers.net/">selectedpapers.net</a> does not yet support <a href="">MathJax</a>. (Neither does Google+ but that’s another problem.) Hopefully that will be fixed soon. Meanwhile, you can use the <a href="http://checkmyworking.com/misc/mathjax-bookmarklet/">MathJax bookmarklet</a>.</li>
  <li>The <a href="http://docs.selectedpapers.net/hashtags.html">hashtag syntax</a> is fairly simple and intuitive but there is room for improvement. The main improvement would be to relax the ID rules to allow full urls which are easier to cut and paste. For example, <code class="highlighter-rouge">http://arxiv.org/abs/1234.6789</code> for <code class="highlighter-rouge">arXiv:1234.6789</code>, <code class="highlighter-rouge">http://dx.doi.org/10.1234/0987654321</code> for <code class="highlighter-rouge">doi:10.1234/0987654321</code>.</li>
  <li>Comments do not seem to generate <a href="http://arxiv.org/help/trackback/">arXiv trackbacks</a>. (Or they have not yet made it through the arXiv editorial process.)</li>
  <li>I wish <a href="http://docs.selectedpapers.net/hashtags.html">topic (hash)tags</a> were allowed to have natural syntax. I can’t think of a good reason why this has to follow the Twitter standard. Should it be <code class="highlighter-rouge">#cstarAlgebras</code> or <code class="highlighter-rouge">#CstarAlgebras</code> or <code class="highlighter-rouge">#CStarAlgebras</code>… why not <code class="highlighter-rouge">C*-algebras</code>? It’s better to allow natural syntax and implement a tag synonym system.
You can track these and other issues here.</li>
</ul>]]></summary>
        <author>
            <name>François G. Dorais</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provable Equality Of Exponentiation]]></title>
        <id>http://karagila.org/2013/provable-equality-of-exponentiation/</id>
        <link href="http://karagila.org/2013/provable-equality-of-exponentiation/">
        </link>
        <updated>2013-05-30T00:01:17Z</updated>
        <summary type="html"><![CDATA[<p>It's an almost trivial theorem of cardinal arithmetics in \(\ZF\) that given four cardinals, \(\frak p,q,r,s\) such that \(\frak p&lt;q,\ r&lt;s\) we have \(\frak p^r\leq q^s\).</p>

<p>In <a href="http://math.stackexchange.com/q/402960/622">a recent question on math.SE</a> some user has asked whether or not we always have a strict inequality. Everyone sufficiently familiar with the basics of independence results would know that it is consistent to have \(2^{\aleph_0}=2^{\aleph_1}=\aleph_2\), in which case taking \(\mathfrak{p=r}=\aleph_0,\ \mathfrak{q=s}=\aleph_1\) gives us equality. But it's also trivial to see that we can always pick cardinals whose difference is large enough to keep the inequality true. <a href="http://karagila.org/2013/provable-equality-of-exponentiation/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[I don't always use LaTeX, but when I do…]]></title>
        <id>https://www.peterkrautzberger.org/0136/</id>
        <link href="https://www.peterkrautzberger.org/0136/">
        </link>
        <updated>2013-05-29T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Since I haven't published anything in almost two months, let me jot down one thought that has come to mind frequently over the past few months.</p>
<h2>If you use LaTeX …</h2>
<p>Well, first of all, are you sure you <em>have to</em> use LaTeX? By which I mean, are you sure you can't use Markdown+MathJax or textile+MathJax or restructuredText+MathJax? Especially if you're teaching your students, are you absolutely sure you are completely and utterly unable to use something simpler? Something that is more modern than learning a hundred bits of print typesetting that your student will never, ever need? Ok, just checking. So…</p>
<h2>If you (have to) use LaTeX, then make HTML your primary output.</h2>
<p>By which I mean: don't just produce PDFs that nobody can read on small screens, PDFs that nobody can read accessibly, PDFs that nobody will want to read in 5 years.</p>
<p>Make HTML your first output. It's important. HTML is the future engine for mathematical and scientific content. If you can't produce HTML, then ur doin it rong. If you don't produce HTML, you won't ever help all the people working on pushing math on the web forward.</p>
<p>It won't be trivial but easier than you think. Install <a href="http://dlmf.nist.gov/LaTeXML/a">LaTeXML</a> and learn how to use it. (Alternatively you probably have a copy of tex4ht installed with your TeX.) How hard is it? This hard:</p>
<pre><code>  latexml --dest=mydoc.xml mydoc.tex
  latexmlpost --dest=mydoc.html --format=html5 mydoc.xml
</code></pre>
<p>And when you run into LaTeXML limitations, then get over it, <a href="http://dlmf.nist.gov/LaTeXML/contact.html">report them back</a>, help make it better. If you run into problems with MathJax, <a href="https://github.com/mathjax/mathjax/issues">report them</a>, help make it better. You need graphics? Check out <a href="https://github.com/sonoisa/XyJax">xyjax</a>. You need pstricks? Check out <a href="http://mathapedia.com/">mathapedia</a>. You need computations? Check out <a href="http://www.sagemath.org/eval.html">Sage cell server</a>. It's all there, but you have to get started. To it today.</p>
<p>But if you've ever wanted math to be native on the web, then you have to realize that it <strong>won't happen without your help</strong>.</p>
<p>If you're too lazy for converting (e.g., when you're teaching), then use something that compiles to both TeX and HTML (like markdown+MathJax etc). Pick a decent tool for it, like <a href="http://www.inkcode.net/qute">Qute</a>, <a href="http://sourceforge.net/projects/retext/">ReText</a>, write on the web with <a href="http://fiduswriter.com/">FidusWriter</a> or <a href="http://authorea.com/">Authorea.com</a>, write in your favorite Mac-editor with <a href="http://markedapp.com/">Marked</a>, or <a href="https://github.com/revolunet/sublimetext-markdown-preview">extend sublimetext</a>, on an iPad app use <a href="https://itunes.apple.com/us/app/writing-kit-research-write/id426208994">Writing Kit</a> -- and that's just off the top of my head; there are many more editing environments that offer good syntax and MathJax integration. Many can save to TeX documents, anything can be converted via <a href="http://johnmacfarlane.net/pandoc/">pandoc</a>. It's not perfect yet but it won't get better unless you give everybody some feedback.</p>
<p>So, if you can, don't author LaTeX, author <em>into</em> LaTeX. And whatever you do, compile it to HTML. It's important.</p>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2013/mostinterestingman_meme.jpg">
    <img alt="I don't always use LaTeX but when I do, I compile to HTML" src="https://www.peterkrautzberger.org/assets/2013/mostinterestingman_meme.jpg">
  </a>
  <figcaption>
  credit: <a href="http://www.quickmeme.com/meme/3umuyt/">quickmeme.com</a>
  </figcaption>
</figure>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>michalh21</strong>, 2013/05/30<br>
For LaTeX to html conversion, I would really recommend tex4ht, its problem is fragmentation of documentation, some information is completely missing, but on the other side it can convert any LaTeX document, it can be even configured to convert tikz pictures to svg, or to output math as <a href="http://www.albany.edu/~hammond/demos/Html5/arXiv/" rel="nofollow">mathml with mathjax rendering</a><br>
I think it is a good idea to output html for people who wants to read on tablets or smart phones, but personally, I still prefer to read PDFs, even on my laptop or PC. For me, PDF has advantage in better readability. HTML even with most recent trends like web fonts and responsive typography is still far behind PDF in this regard. Other advantage is pagination, it helps me with orientation in document. Maybe not so many readers pay attention to such things today, but I think majority of writers in LaTeX wouldn't like how bad their documents look in HTML.<br>
And last point :) I don't really think LaTeX is hard. For things that markdown etc. supports, like sections, tables, links or footnotes, it is only few commands to learn, every editor today supports snippets for fast inserting these commands, you can use templates for document preamble etc. And when you want to use things like referencing, bibliographies, indexing, glossaries etc, using LaTeX is much easier. Plus, for new functionality, you can write your own macros, which is easier than modifying markdown parser and inventing new syntax :)
<ul>
<li><strong>Peter</strong>, 2013/06/06<br>
Thanks for your comments. tex4ht is certainly a nice and powerful tool. But there’s a fundamental difference: it’s really a dvi-to-html converter, not a LaTeX-to-html one. That allows it to circumvent a lot of problems (by letting the TeX binary do all the hard work) but also comes with losses since LaTeX is semantically richer than TeX/DVI (something that’s visible in the quality of the MathML output last time I tried it).<br>
I understand that most people find PDFs better. IMO, HTML has much more potential than PDF to provide a better reading experience, with rich content and easy interaction with other web content (and of course PDFs are virtually inaccessible). My main point was merely that we won’t get there if we don’t get started. Authors, in any case, should care more about their readers than their own reading experience. They can, after all, produce whatever they like for themselves whereas a reader rarely has that option. (Personally, I prefer my handwritten notes but that won’t help anyone given my illegible hand writing)<br>
I’m definitely not trying to tell people what they should use. Certainly, an experienced user often finds LaTeX the most flexible and powerful tool (TeX is a programming language, after all). But this power brings an awful lot of problems with it and in almost all situation that power is not needed. So I do like to argue for the right tool for the job instead, especially in educational settings — and above all, I would like to argue for conversion. No tool or format is perfect. But any content that cannot be converted to something else is (for better or worse) at a dead end.</li>
</ul>
</li>
<li><strong>Norman Lewis Perlmutter</strong>, 2013/06/04<br>
Given that LaTeX already compiles into pdf, might it be better to use or develop a pdf to html converter? This would have the added benefit of being able to convert pdf files not generated by LaTeX into html.
<ul>
<li><strong>Peter</strong>, 2013/06/06<br>
The short answer is: no. PDF is a very “loss-ful” format. The only way to extract e.g. mathematical content is by using heuristics, i.e., guessing from the placement what kind of expression was actually used. While converters like pdf.js do a good job at reproducing the layout, they do not really convert to HTML, they merely render it (much like a printer) — the output is inaccessible, doesn’t reflow well etc. TeX to HTML is already very solid and used in big publishing houses. Automatic conversion is perhaps at 95% — but to get to 100% (which is needed), the open source projects out there need feedback.<br>
Since the conversion from for strictly mathematical TeX to MathML is very solid, it’s much easier to go directly anyway. The only remaining problem are the messy packages, in particular the graphical packages that could either be converted to static graphics (like LaTeXML or tex4ht do) or re-implemented in javascript (like xyjax or mathapedia).</li>
</ul>
</li>
<li><strong>jessemckeown</strong>. 2013/06/06<br>
Well, I’m doing my very little bit, then; since you mention it, though, is there any plan to eventually absorb xyjax into the main mathjax? AMScd does do the arrows nicer than putting <code>\to</code> and <code>\downarrow</code> in a <code>\begin{array}\end{array}</code>, but…
<ul>
<li><strong>jessemckeown</strong>, 2013/06/06<br>
Oh, I forgot to make sure of the right website…</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Another silly experiment; mobile apps for content delivery]]></title>
        <id>https://www.peterkrautzberger.org/0135/</id>
        <link href="https://www.peterkrautzberger.org/0135/">
        </link>
        <updated>2013-03-30T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Here's another post from the category &quot;yet another silly idea&quot; or &quot;don't try this at home&quot;. Keep in mind that I have absolutely no idea about app development. In short, I don't know what I'm doing or what I'm talking about. But here it goes.</p>
</blockquote>
<p>I've written in the past about the problems of mathematical content in ebooks (well, epub3 anyway). Ideally, we should all start producing epub3 files right now and use PDFs only for legacy. Of course, even if we had good workflows for this (which we don't), we'd still face the problems that our readers couldn't use our content as ubiquitously as PDFs. Which is a tragedy given how crappy PDFs perform on mobile devices -- which are slowly but surely becoming my favorite reading devices. (And even print media does <a href="http://carta.info/51526/die-unterschwellige-botschaft-der-printmedien-hort-auf-uns-zu-lesen/">nothing but advertise</a> it)</p>
<p>So I wrote about how you could <a href="https://www.peterkrautzberger.org/0129/">include MathJax in an epub3 file</a> and hope for the best. But this is stupid. We can reliably create mathematical content in a mobile browser thanks to MathJax, but we can't easily do so in an offline, deliverable, stand-alone format.</p>
<p>Well, of course you can. MathJax is used in lots of mobile applications and there are even open source sample apps for developers to understand how to do this. Yet, authors don't want to be app developers. (Though especially LaTeX-affine communities seriously need to make HTML the primary output format -- not print.)</p>
<p>Luckily for us, app developers these days have a similar problem and there is much innovation in mobile app frameworks that (aims to) make app development a &quot;design once, compile everywhere&quot; kind of thing.</p>
<p>Why don't we go for a two pronged approach? Especially one that has been used successfully already: let's develop our content for standards like epub3, offer it as such -- DRM free, leaving it to the competent (possibly trained) user to use that file -- but also provide a comfortable version by wrapping an app around our (standard-driven) content? (And really, why not offer both for the same price.) In other words, why not do what <a href="https://web.archive.org/web/20130310082142/http://www.aldiko.com/blog/28-oreilly-books-now-available-as-android-apps-using-aldiko-technology">O'Reilly has done for years [Wayback Machine]</a>.</p>
<p>Instead of waiting for yet another awesome but proprietary framework (like iBooks Author or Inkling), let's use an open source, standards oriented framework.</p>
<p>How hard would that be? Well, I decided to give it a try (warning: silliness levels rising).</p>
<p>I chose <a href="https://en.wikipedia.org/wiki/PhoneGap">Phonegap</a> -- using HTML+CSS+javascript to develop hybrid apps seems fitting. Even more after hearing a wonderful quote an Adobe expert (Adobe bought PhoneGap): &quot;the goal of Phonegap is to standardize itself out of existence&quot;. But really because of <a href="https://build.phonegap.com/">Adobe PhoneGap Build</a> (honestly, I would never have imagined I'd get excited over an Adobe product, ever.)</p>
<p>Because even though you're using PhoneGap you'll (naturally) still need a complete development environment -- for each platform. That's a pain to set up. Thinking (not only) as an author, you just don't want to have to do that, you want to author and just wrap an app around it. Which is where PhoneGap Build comes in: a cloud compilation service. With a free account, you get one private project and infinitely many open source projects (and the peace of mind that you can always take your code home and compile it where you want). In fact, you can also simply link to a github repository to build an app (and <a href="http://www.mattgifford.co.uk/phonegap-build-github-post-commit-hooks">build your own webhook</a>). Simple as that. (Of course, if you want to get an iOS version, you have to pay Apple for a developer license etc but let's ignore that.)</p>
<p>So how hard is it?</p>
<p>Well, if we want to start with a really, really simple example, we start with a <a href="https://github.com/phonegap/phonegap-start">real example</a> and simplify it. Then you end up with something this &quot;hard&quot;:</p>
<ul>
<li>Create a file <code>config.xml</code>.</li>
</ul>
<pre><code class="language-xml">    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
    &lt;widget xmlns     = &quot;http://www.w3.org/ns/widgets&quot;
            xmlns:gap = &quot;http://phonegap.com/ns/1.0&quot;
            id        = &quot;com.phonegap.peter-hello&quot;
            version   = &quot;2.2.0&quot;&gt;
        &lt;name&gt;Peter's Hello&lt;/name&gt;

        &lt;description&gt;
            Peter says hello.
        &lt;/description&gt;

        &lt;author href=&quot;http://boolesrings.org/krautzberger&quot; email=&quot;admin@test.com&quot;&gt;
            Peter
        &lt;/author&gt;

        &lt;feature name=&quot;http://api.phonegap.com/1.0/device&quot; /&gt;

        &lt;preference name=&quot;phonegap-version&quot; value=&quot;2.2.0&quot; /&gt;
        &lt;preference name=&quot;orientation&quot;      value=&quot;default&quot; /&gt;
        &lt;preference name=&quot;target-device&quot;    value=&quot;universal&quot; /&gt;
        &lt;preference name=&quot;fullscreen&quot;       value=&quot;false&quot; /&gt;

    &lt;/widget&gt;
</code></pre>
<p>I hope it's clear what you might want to modify.</p>
<ul>
<li>Create a file <code>index.html</code></li>
</ul>
<pre><code class="language-html">    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
        &lt;head&gt;
            &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;
            &lt;meta name=&quot;format-detection&quot; content=&quot;telephone=no&quot; /&gt;
            &lt;meta name=&quot;viewport&quot; content=&quot;user-scalable=no, initial-scale=1, maximum-scale=1, minimum-scale=1, width=device-width, height=device-height, target-densitydpi=device-dpi&quot; /&gt;
            &lt;title&gt;Peter's Hello&lt;/title&gt;
        &lt;/head&gt;
        &lt;body&gt;
          &lt;h1&gt; Hello!&lt;h1&gt;
        &lt;/body&gt;
    &lt;/html&gt;
</code></pre>
<p>Again, I think it's pretty clear, no?</p>
<ul>
<li>Zip those two files up and upload the archive to PhoneGap Build.</li>
<li>Wait a bit.</li>
<li>Download and install your compiled app.</li>
<li>Done.</li>
</ul>
<p>Well, actually, now you have to author your content. Some people call that the hard part ;) But when you're done authoring, you zip it up, upload it (or push to your github repo) and you got yourself an app.</p>
<p>Of course, you can now do all the crazy stuff you'd be stupid enough to do on the web itself. Knock yourself out! Here's an <a href="https://build.phonegap.com/apps/323285/builds">example wrapping an old post of mine</a>, adding some <a href="https://github.com/hakimel/reveal.js">reveal.js</a> sparkle. Shiny, mostly useless -- but something you can't reliably produce in an epub3 right now (and nobody stops you from shipping an epub3 file of your content for download out of the app).</p>
<p>Of course, there's a lot (A LOT) that's wrong with this approach. I have no idea if this approach is feasible beyond very basic content. I have no idea how quickly you'll run into performance, memory or other hazardous problems. Nevertheless, this is not nothing. It shows what could be done and <em>should</em> be done, by professionals.</p>
<p>In short, it shows why we don't have to take no for an answer when we ask for better mathematical content on mobile devices today.</p>
<hr>
<p>Small edit: linked to the phonegap, corrected the Win8 comment.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Dana Ernst</strong>, 2013/03/30<br>
Thanks for spending the time playing around. What is supposed to be done with the example .apk file that you link? That is, what am I supposed to use to open it?
<ul>
<li><strong>Peter</strong>, 2013/03/30<br>
Oh yeah, I’ll edit it. That’s an Android app file. Just download it with an Android device and it will (after disabling some security setting) allow you to install it.
<ul>
<li><strong>Dana Ernst</strong>, 2013/03/30<br>
Oh, I’ve only got iOS devices.
<ul>
<li><strong>Peter</strong>, 2013/03/30<br>
Ah, sorry — iOS compilation needs an iOS developer license which costs money I don’t want to spend. You can try Windows and Symbian 😉 Or androvm with virtualbox (which everybody should have).</li>
<li><strong>Peter</strong>. 2013/03/30<br>
You could unzip the file and look at the content in a browser.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>Asaf Karagila</strong>, 2013/03/31<br>
I should point out that sometimes (and recently more often than not) when loading <a href="http://math.se/">math.SE</a> or MO pages full with MathJax the browser on my iPhone 4 hangs, crashes, and sometimes loads the page on the next load. Less common, but not unfamiliar are Atom Z2670 (x86) hangs (which completely paralyze my poor tablet, despite being top of the line), and also familiar are the x64 hangs on my linux, but these are much much more rare (nowadays anyway).<br>
Whether or not it’s the SE software or not, I can’t say that I trust MathJax fully for a 20, 50, or 150 pages long paper. PDF may be somewhat slow, but it works just fine most of the time. Despite not being a big fan of change, I am willing to try the new formats on my Win 8 tablet, but I am also concerned about the stability of such experiment (not the whole system, just local to the application) if many large files are opened simultaneously.
<ul>
<li><strong>Peter</strong>, 2013/03/31<br>
Sorry to hear that. We’ve heard stories like yours but nothing re-producible. Be sure to let me know if you find something we could track! It might be bugs in mobile Safari 6 and IE10 that we’re not yet aware of.<br>
Performance is not really a problem after MathJax has run. So for example, in a mobile app a good programmer/author would store the rendering in localstorage, so that MathJax really only ran once — after that it would all be “looking at HTML”. Similarly, if you want to store large documents, you’d chop them up and only load parts etc. So while all my attempts are naive, I have seen enough smart people (especially among the MathJax sponsors) do a lot of awesome stuff.<br>
One key problem with PDF is that it’s not accessible. Since accessibility actually benefits everyone (because you have do do better design to be accessible), that alone should be a reason to leave it behind. But more importantly: we need to experiment! I don’t think anyone believes the web will suddenly be re-written in TeX. HTML is where it’s at. Yet we don’t even know what “mathematics native on the web” could be. Currently, all mathematics is like ebooks: a faithful copy of what was done in the print past — it just happens to be a digital copy (PDF being the prime example but most other forms of online mathematics are that way, including MathOverflow and <a href="http://math.se/">math.SE</a>). It’s not surprising. The printing press output was essentially “scroll reproductions” for the first hundred years. We need to really start experimenting what math in the times of the web will become. Bret Victor has some interesting examples (the small networks paper, not the kill math stuff), mathbox is another cool one. But also mathematical storytelling, creation and collaboration has ways to go.</li>
<li><strong>Asaf Karagila</strong>, 2013/04/01<br>
I only did one thing with IE10 when I got the tablet. I opened the Mozilla site and downloaded Firefox… :-)<br>
As for mathematics on the web, I agree. Now that I have a Wacom digitizer pen I stopped scribbling math (at least serious math) on paper. I have been looking for a chance to collaborate with someone digitally, but that didn’t happen yet.<br>
I think that the problem is that currently PDF is pretty much the only format I can write into the document in a relatively smooth and working way (at least without paying a lot of money for a software which may or may not work). This is huge. It means that I really don’t have to print something, I can just write remarks into a paper I am reading. When I’m grading papers I do it like that, and it’s great.<br>
The future holds many secrets, but I have a hunch that digital pens will become ever more popular, and that collaboration on the web should be prepared for that. Not just HTML/JS/MathJax sort of collaborations, that for itself is nice, but won’t be enough in the long run.<br>
Lastly, for the hanging math pages, I think that the correct solution would be to develop some downloadable MathJax compilation server, that would “hijack” the calls to the web and do things on the computer. Yes, somewhat like downloading the JS scripts in advance, and redirecting the traffic from the web to your computer. While debugging on the iPhone is really impossible, I suspect that this may be – at least to some extent – the culprit in the case of my tablet.</li>
</ul>
</li>
<li><strong>John P. Wheeler</strong>, 2013/10/28<br>
Thanks for this article! I really like the disclaimer you included in the beginning. I’m thinking of playing around with it as well.
<ul>
<li><strong>Peter</strong>, 2013/10/30<br>
Thanks, John, glad to hear this is of use. Let me know how it goes!</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Choice Principles: What are they?]]></title>
        <id>http://karagila.org/2013/choice-principles-what-are-they/</id>
        <link href="http://karagila.org/2013/choice-principles-what-are-they/">
        </link>
        <updated>2013-03-05T02:37:32Z</updated>
        <summary type="html"><![CDATA[<p>What does the phrase &quot;\(\varphi\) is a choice principle&quot; mean? This is something that I have spent quite a lot of my time thinking about. Directly and indirectly. What are choice principles as we know them? And who gets to decide?</p>

<p>For a set theorist, at least a &quot;classical&quot; set theorist (working within the confines of \(\ZF\) and its extensions to \(\ZFC\) and so on), a choice principle can aptly be defined as &quot;Sentence \(\varphi\) in the language of set theory which is provable from \(\ZFC\) but independent from \(\ZF\)&quot;. Indeed that is how I think of choice principles, and how I referred to them in my masters thesis (albeit I prefaced that definition by pointing out its naivety). <a href="http://karagila.org/2013/choice-principles-what-are-they/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Publishers should invest in browser development (a comment at  the scholarly kitchen)]]></title>
        <id>https://www.peterkrautzberger.org/0134/</id>
        <link href="https://www.peterkrautzberger.org/0134/">
        </link>
        <updated>2013-02-28T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>In the tradition of posting stuff I write elsewhere, here's <a href="http://scholarlykitchen.sspnet.org/2013/02/28/ignorance-as-argument-a-chemist-alleges-publishers-exploit-typography-for-money/#comment-85434">a comment I just posted at <em>the scholarly kitchen</em></a>. It's not really about the article.</p>
</blockquote>
<p>On a slightly different note. Despite many investments in typesetting technologies in (and of) the past, publishers are investing very little in the primary typesetting technology of the future: HTML rendering engines.</p>
<p>A good example (though I'm biased) is MathML, the W3C standard for mathematical markup. Despite being used in XML publishing workflows for over a decade, and becoming part of HTML5, no browser vendor has ever spent any money on MathML development. Accordingly, browser typesetting &quot;quality&quot; is highly unreliable (unless you use MathJax -- which is where I get my bias from).</p>
<p>Trident (Internet Explorer) has no native support (but the excellent MathPlayer plugin), Gecko (Mozilla/Firefox) has good support thanks to volunteer work and WebKit (Chrome, Safari, and now Opera) has partial support -- again solely due to volunteer work. (Unfortunately, only Safari is actually using that code; Google recently yanked it out of Chrome after one release.)</p>
<p>This isn't surprising from a business perspective -- for the longest time, there was simply no MathML content on the web. But of course, this was a chicken-and-egg problem: no browser support =&gt; no content =&gt; no browser support =&gt; ... And it ignores the impact MathML support would have on the entire educational and scientific sector where it would enable interactivity, accessibility, re-usability, and searchability of mathematical and scientific content. (Including ebooks -- MathML is part of the epub3 standard.)</p>
<p>Now you might say MathML is just math, a niche at best. But very likely its success will determine if other scientific markup languages will become native to the web -- languages like CellML, ChemML, and data visualization languages. These will probably see even less interest from browser vendors but will have enormous relevance to the scientific community.</p>
<p>Right now, scientific publishers (in my experience) have neither expertise nor interest in browser engine development. Unfortunately, they also don't put pressure on browser vendors to improve typesetting (whether scientific or otherwise). That's very short sighted, I think. Given that Gecko and WebKit are open source, a joint effort of publishers could very well fix things -- and show the community that publishers have their eyes on the future rather than the past.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[kids, exponential growth and 42]]></title>
        <id>https://www.peterkrautzberger.org/0133/</id>
        <link href="https://www.peterkrautzberger.org/0133/">
        </link>
        <updated>2013-02-24T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Last week, I was lucky enough to attend the <a href="http://www.w3.org/2012/08/electronic-books/">W3C workshop on ebooks</a> in NYC. This allowed me to visit some old and very dear friends. In a conversation with one of their kids, I pulled out a classic that I like very much.</p>
<p>Today, I did some fact checking and -- lo and behold -- the answer was not 52 but <a href="https://en.wikipedia.org/wiki/42_(number)">42</a>! That is, of course, <a href="https://en.wikipedia.org/wiki/Answer_to_The_Ultimate_Question_of_Life,_the_Universe,_and_Everything#Answer_to_the_Ultimate_Question_of_Life.2C_the_Universe.2C_and_Everything_.2842.29">fantastic</a>.</p>
<p>Anyway, the question I asked was: how thick is an piece of regular office paper if you fold it <del>52</del> 42 times?</p>
<p>The answer is: it would reach all the way to the moon!</p>
<p>That usually surprises kids (and non-kids) and is a nice example for the surprises of <a href="https://en.wikipedia.org/wiki/Exponential_growth#Exponential_stories">exponential growth</a>. In fact, it also surprises me and I'm always somewhat nervous when a kid takes me up on the offer of checking that the number is actually correct.</p>
<p>For this you first have to decide what paper you're looking at. A piece of <a href="https://en.wikipedia.org/wiki/Paper_size#A_series">A4 paper</a> (I'm German after all) is on average 0.1 mm. That's actually hard to estimate but it's what I eventually found <a href="http://hypertextbook.com/facts/2001/JuliaSherlis.shtml">on the interwebs</a>; if you have the time, I invite you to delve into the art of <a href="https://en.wikipedia.org/wiki/Paper_density#Caliper">density and calipers</a>.</p>
<p>When you fold it 42 times, it's as if you stacked <span>test</span> \(2^{42}\) pieces of paper on top of each other. So the thickness is \(2^{42}\) x 0.1mm, which is ~439,804 km (and a kilometer is 1,000,000 milimeter).</p>
<p>The <a href="https://en.wikipedia.org/wiki/Moon">moon</a> is on average 384,400km from earth, and 405,410km at its farthest -- so we'll get there no matter what day. If, that is, we could fold a piece of paper 42 times.</p>
<p>For what it's worth, the world record for folding paper is 13 times -- achieved by <a href="http://www.boston.com/yourtown/news/cambridge/2011/12/toilet_paper_used_to_break_pap.html">high schoolers on MIT's campus</a> in 2011.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Dirk Lorenz</strong>, 2013/02/25<br>
You don’t need to google to estimate the thickness of one piece of paper: Just imagine a usual pack of 500 sheets. A rough estimate is that it is between 4cm and 8cm high which leads to a thickness of about 0.08mm and 0.16mm which is the right order of magnitude.
<ul>
<li><strong>Peter</strong>, 2013/02/25<br>
I don’t have such things as stacks of paper at home anymore :(
<ul>
<li><strong>Dirk Lorenz</strong>, 2013/02/26<br>
You could also make a very rough estimate of how high 500 sheets of paper are either from memory (as vague as it may be) or from the size of printers or their paper trays. To be off by factor of 10 would not be too bad. Anyway, nobody would think that 500 sheets are less than 0.5 cm high or more that 50 cm high. By the way: “How many piano tuners are there in Chicago?”</li>
<li><strong>Peter</strong>, 2013/02/26<br>
Nice, but I didn’t want to turn this into a Fermi problem.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Asaf Karagila</strong>, 2013/02/25<br>
That is awesome. MythBusters did a paper folding myth once. They prepared a sheet of paper the size of a hanger and used heavy machinery to help them fold it into halves. I think they got to 11 or something like that.</li>
<li><strong>Frédéric Wang</strong>, 2013/02/25<br>
I hope you didn’t forget to explain to the kids why the aspect ratio of A4 papers is much better than the one of U.S. paper sizes… And since I mention this, here is a related “MathML” problem: what is the minimal possible size for the bounding box of the element below, such that the ellipse drawn does not overlap the inner element?</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Infinite dimensions and the axiom of choice]]></title>
        <id>http://karagila.org/2013/infinite-dimensions-and-the-axiom-of-choice/</id>
        <link href="http://karagila.org/2013/infinite-dimensions-and-the-axiom-of-choice/">
        </link>
        <updated>2013-02-19T01:08:01Z</updated>
        <summary type="html"><![CDATA[<p>In <a href="http://math.stackexchange.com/q/300494/622" target="_blank">a recent math.SE question</a>, Thomas Andrews asked whether or not the existence of an infinite linearly independent set in a vector space which is not finitely generated requires the axiom of choice.</p>

<p>The answer is positive. It does require the axiom of choice. The counterexample is due to Läuchli who constructed a model in which there was a vector space which was not finitely generated, but every proper subspace is finitely generated. Given such vector space it is obvious that no infinite set can be linearly independent. <a href="http://karagila.org/2013/infinite-dimensions-and-the-axiom-of-choice/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vector Spaces and Antichains of Cardinals in Models of Set Theory]]></title>
        <id>http://karagila.org/2013/vector-spaces-and-antichains-of-cardinals-in-models-of-set-theory/</id>
        <link href="http://karagila.org/2013/vector-spaces-and-antichains-of-cardinals-in-models-of-set-theory/">
        </link>
        <updated>2013-02-11T03:28:34Z</updated>
        <summary type="html"><![CDATA[<p>I finally uploaded my M.Sc. thesis titled “<a href="../../wp-content/uploads/2012/10/msc-thesis.pdf">Vector Spaces and Antichains of Cardinals in Models of Set Theory</a>”.</p>

<p>There are several changed from the printed and submitted version, but those are minor. The <a title="Papers" href="../../papers.html">Papers</a> page lists them. <a href="http://karagila.org/2013/vector-spaces-and-antichains-of-cardinals-in-models-of-set-theory/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why academic societies should start fully fledged social networks]]></title>
        <id>https://www.peterkrautzberger.org/0132/</id>
        <link href="https://www.peterkrautzberger.org/0132/">
        </link>
        <updated>2013-02-04T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>The Joint Math Meetings 2013 ended with the AMS's 125th Anniversary banquet. One of the things mentioned there was that the AMS is working on some form of online communities. That's great, but doesn't go far enough.</p>
</blockquote>
<h2>1. It's their nature</h2>
<p>Academic societies have always been social networks. Online, social networks look different from conferences, book ordering and membership areas.</p>
<p>A lot has been done already. Take the AMS. MathsJobs has solved the job search problem, MathSciNet has solved publication research.</p>
<p>But what is needed is true social connectivity. Or in other words: conferences, workshops and seminars. The net connects everyone, all the time. Why leave it to people not caring for the community? The big social networks are important, but they will never help smaller communities like the mathematical one, never provide the tools we need.</p>
<h2>2. The ultimate appeal</h2>
<p>Nobody should trust a social network paid through ads. You may trust it a bit more when you pay for it (e.g., <a href="http://app.net/">app.net</a>).</p>
<p>But a network run by a society (or a joint venture of societies) would have the ultimate appeal: <strong>trust and oversight</strong>.</p>
<p>Because societies are democratic, they could establish transparent, democratic oversight over a key technology for the community.</p>
<h2>3. It's their mission</h2>
<p>But let's take it at least one step further. <a href="https://en.wikipedia.org/wiki/Diaspora_(social_network)">Diaspora</a> and other decentralized social networks are a beautiful idea. Societies could move such tools forward, thereby empowering distributed social networks.</p>
<p>On the one hand, members could easily connect across different societies, on the other hand, members could choose to fully control their data on their own servers.</p>
<p>A society that serves its members and community would not be opposed in principle. Which other social network could say the same?</p>
<p>In addition, the underlying software would naturally be open source -- both for transparency and scientific reasons.</p>
<p>This would enable everybody to take this important step -- a bit of internet enlightenment if you will.</p>
<h2>4. It's forward thinking</h2>
<p>Social networks are the new publishers. It's interesting to read this <a href="https://www.peterkrautzberger.org/0132/">post at the Scholarly Kitchen</a> which looks at societies from the reverse angle, the fact that PeerJ is moving publishing more towards a membership model is important.</p>
<p>Publishers should fear societies since they will always be able to offer something fundamentally different -- a self-governing community.</p>
<h2>5. It has consequences</h2>
<p>Right now, the majority of users are on at most one social network, usually Facebook (though mathematicians have sometimes skipped that and followed all the cool kids playing on google+).</p>
<p>I expect the majority of users to soon get comfortable to have multiple networks. This is why I also expect to eventually have better connectors between networks. Granted, this has to do with a lot of major internet issues (net neutrality, walled gardens etc), but I prefer to be optimistic about the future.</p>
<p>But the real consequence is: this will cost money. And members should be ready to pay for it. Just as we should for publishing.</p>
<hr>
<p><em>Note (2015)</em>: The link to the Scholarly Kitchen was not present in any WordPress revision of this post. Browsing <a href="http://scholarlykitchen.sspnet.org/2013/01/">The Scholarly Kitchen's archive</a>, I still don't know which one I may have meant.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Asaf</strong>, 2013/02/05<br>
Do I get extra-cool points for not having neither a Facebook account nor a G+ account? :-)
<ul>
<li><strong>Peter</strong>, 2013/02/05<br>
yes, but you massively loose for being a moderator on <a href="http://math.se/">math.SE</a> 😉
<ul>
<li><strong>Asaf</strong>, 2013/02/05<br>
But I’m not a moderator there… I just have a lot of points, and I waste a lot of time on meta issues. To my defense, a lot of the ideas I had in the past two years were “incepted” from <a href="http://math.se/">math.SE</a> questions, including the work I did in my thesis.</li>
<li><strong>Peter</strong>, 2013/02/05<br>
ah. OK I thought you were. But your research benefiting from social platforms – that’s a direct disqualification 😉</li>
</ul>
</li>
</ul>
</li>
<li><strong>Dirk Lorenz</strong>, 2013/02/06<br>
Is the community of the <a href="http://regularize.wordpress.com/2012/05/24/socializing-the-german-math-community/">German DMV</a> a good example or a cautionary tale?
<ul>
<li><strong>Peter</strong>, 2013/02/06<br>
Yes, thanks! I forgot about your post. Do you have any idea what software they use?
<ul>
<li><strong>Dirk Lorenz</strong>, 2013/02/14<br>
It seems that the network uses <a href="http://www.jomsocial.com/">JomSocial</a>.
<ul>
<li><strong>Peter</strong>, 2013/02/14<br>
Nice. I didn’t know Joomla had such an extension. Sad to hear it doesn’t work. I think MO and <a href="http://math.se/">math.SE</a> showed that it’s possible to build a math community. Maybe it’s just another sign that Europe just won’t catch up unless it can become a single community?</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>chorasimilarity</strong>, 2013/05/17<br>
I just discovered your excellent post. After thinking about how to gamify peer-review, I arrived to an idea close to the one here, namely why not using social games and visualisation of data techniques, as a virtual world for researchers? Wrote about this here: <a href="http://chorasimilarity.wordpress.com/2013/05/09/mmorpgames-at-the-knowledge-frontier/">MMORPGames at the knowledge frontier</a>
<ul>
<li><strong>Peter</strong>. 2013/05/17<br>
Thank for your kind words, Marius. I’ve been following your blog for a while (via <a href="http://mathblogging.org/">mathblogging.org</a> I think). I haven’t read your post yet, but your comment reminds me of stories of people using Second Life for meetups. It sounded crazy back then (ok, I was a student, these were big wig mathematicians) but I understand what they were after. Of course, Booles’ Rings is all about making your professional website that place (but the social networking features aren’t quite there yet). Anyway, I’ll comment after I read your post.</li>
</ul>
</li>
<li><a href="http://regularize.wordpress.com/2013/02/14/a-mathematical-social-network/">Pingback</a>, 2013/02/06</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New shiny toy; mathblogging.org gets a long overdue update]]></title>
        <id>https://www.peterkrautzberger.org/0131/</id>
        <link href="https://www.peterkrautzberger.org/0131/">
        </link>
        <updated>2013-01-31T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>It's been a lot of work and it has been delayed again and again, but here it is: <a href="http://www.mathblogging.org/">mathblogging.org 2.0</a>, powered by SubjectSeeker, the software behind <a href="http://scienceseeker.org/">ScienceSeeker</a>.</p>
<p>Read <a href="http://mathblogging.wordpress.com/2013/01/31/welcome-to-the-new-mathblogging-org/">the announcement</a>.</p>
<p>I would like to thank Dave Munger and the team at ScienceSeeker -- especially Gabriel and his infinite patience and support.</p>
<p>I would like to thank Sam for his support, expertise and everything.</p>
<p>Run, you fools! Go and break the server!</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Dave Munger</strong>, 2013/02/01<br>
Congratulations! The site looks fantastic!
<ul>
<li><strong>Peter</strong>, 2013/02/01<br>
Thanks, Dave!</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Philosophy of Cardinality: Pathologies or not?]]></title>
        <id>http://karagila.org/2013/the-philosophy-of-cardinality-pathologies-or-not/</id>
        <link href="http://karagila.org/2013/the-philosophy-of-cardinality-pathologies-or-not/">
        </link>
        <updated>2013-01-20T01:18:10Z</updated>
        <summary type="html"><![CDATA[<p>What are numbers? For the layman numbers are those things we use for counting and measuring. The complex numbers are on the edge of being numbers, but that's only because they are taught in high-schools and many people still consider them imaginary (despite them having some reasonably applicative uses).</p>

<p>But a mathematician knows that a number is basically a notion which represents a quantity. We have so many numbers that I don't even know where to begin if I wanted to list them. Luckily most of the readers (I suppose) are mathematicians and so I don't have to. <a href="http://karagila.org/2013/the-philosophy-of-cardinality-pathologies-or-not/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[3 questions in June or; LoC workshops are the best]]></title>
        <id>https://www.peterkrautzberger.org/0130/</id>
        <link href="https://www.peterkrautzberger.org/0130/">
        </link>
        <updated>2013-01-20T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Here's another old (forgotten?) draft to make up for my lack of original writing; this should've gone out in June... Instead of posting it, I had grand plans to write about the workshop itself -- but never had the time (you know, moving across the continent, starting a new job etc., it gets in the way of things...). Why now? Well, Anthony Salvagno reminded me with <a href="http://research.iheartanthony.com/2013/01/19/amazing/">his post yesterday</a> that I still had this.</p>
</blockquote>
<p>In late June, I had the enormous pleasure to be invited to the <em>Preserving Online Science</em> meeting at the Library of Congress. You can read about the workshop over at <a href="http://blogs.loc.gov/digitalpreservation/2012/07/preserving-online-science-reflections/">Trevor's blog</a>, and after that you can <a href="http://blogs.loc.gov/digitalpreservation/2012/12/call-to-action-to-preserve-science-discourse-on-the-open-web/">read the report</a> that was released in November, too.</p>
<p>I'm afraid I wasn't much use during the workshop and have the lingering feeling that I owe an apology to its instigators, <a href="http://blogs.loc.gov/digitalpreservation/author/trow/">Trevor</a> and <a href="http://blogs.loc.gov/digitalpreservation/author/abpo/">Abbey</a> (who also gave a few of us an amazing tour of the lair that is the LoC). Besides a serious case of impostor syndrome, there was just too much to take in and too much on my mind at the time (being literally on the move from Boston to Los Angeles).</p>
<h3>3 questions, 3 answers</h3>
<p>Before the workshop started, participants were asked to answer three questions. For what it's worth, here are my answers.</p>
<p><strong>1. Value of Content</strong>: 50 years from now, what kinds of online science content will invaluable for understanding science in our age? Please give an example of a particular piece of content and explain why it would be significant. Feel free to provide several examples if you wish.</p>
<p>In a fully connected, digital world, we can understand much better how individual researchers work and communities interact. I believe one of the most important &quot;new&quot; content is to be found in the combined virtual presence of individual researchers -- the future of personal archives. This ranges from our email inboxes, professional homepages and online teaching tools, to preprint servers, code and data storage, to activity on online platforms, blogs and social media.</p>
<p>This digital version of our academic self is greatly fractured right now but it can offer a much more complete insight into all aspects of research because it offers insight into being a researcher.</p>
<p><strong>2. Future Use of Content</strong>: What kinds of uses do you imagine this science content could serve? Please briefly describe the value that you think online science content provides for the future. Ideally, focus on specific kinds of content and explain what value that content provides to different types of users (ex, future scientists, historians, policy makers, etc)</p>
<p>Preserving researchers' actual activity will allow us to trace networks and interaction among and across research communities, in short. we may be able to globally capture the emergence of scientific thought and the communities around them. First and foremost, it will keep research results in context and thus more accessible to future researchers. Secondly, it will offer a much more complete background for historians to study. Third, as analytics improve, policy makers will not have to exclusively rely on static reports anymore, but base their decisions on the emerging and evolving trends within research communities, highlighting both endangered areas and growing hotspots.</p>
<p><strong>3. Identifying Curatorial Homes</strong>: Libraries, Archives and Museums have typically collected published works (like journals and books) unpublished works (like the papers of scientists) and a range of other special collections (everything from collections of specimens, to laboratory equipment, to a range of other artifacts). Where are the natural curatorial homes for various kinds of online science content?</p>
<p>Currently, the virtual presence of a researcher is highly fractured, their online activities spread across numerous institutions and platforms, some open and some proprietary. The first step to create curatorial homes for such diverse repositories is for researchers (and citizens in general) to gain access to their own data and to build tools that allow researchers to backup their activities in a reliable, self-governed fashion. Only then could we develop hubs to serve as archival systems which could be hosted practically anywhere. Given the increase in precarious employment for academic researchers, these hubs will more likely be close to researchers as people then researchers as members of institutions. Hence an archival effort needs to address both institutions and individuals to ensure that data is not lost. In particular, the work of early career researchers who might eventually leave academia is at risk even though they are an integral part of the way the research community makes progress today.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to include MathJax in an epub3 file to work with iBooks (and possibly others)]]></title>
        <id>https://www.peterkrautzberger.org/0129/</id>
        <link href="https://www.peterkrautzberger.org/0129/">
        </link>
        <updated>2013-01-13T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>At the Joint Mathematics Meetings <a href="http://jointmathematicsmeetings.org/meetings/national/jmm2013/2141_program_ss62.html">Present and Future of Mathematics on the Web</a> session, Lila Roberts presented an excellent demo of the good stuff you can do with iBooks author. The demo included MathJax and jsxgraph, and combined both with iBooks Author's easy, pretty layout tools. Of course, the drawback is that iBooks Author is</p>
<ul>
<li>a proprietary format</li>
<li>restricted to iPads (not just iOS)</li>
<li>you're not allowed to sell an iBooks Author file except through iTunes.</li>
<li>iBooks Author is not transparent about how its formula editor produces SVGs out of TeX but pastes MathML directly into a page, leading to inconsistent renderings of equivalent mathematics</li>
<li>MathML support of iBooks on iOS5 devices is severly broken (and will likely never be fixed) thanks to a mobile Safari bug that screws up the use of STIX fonts.</li>
</ul>
<p>Anyway, I mentioned in the session that you can actually include MathJax in epub3 files directly to get much of the same. Well, you have to do the pretty layouts yourself and you'll depend on a javascript-enabled epub3 reading software (like iBooks) but at least you're using an open standard and retain your rights.</p>
<h2>Let's get started!</h2>
<p>If you're lazy, grab the file at the end of the post and hack from there. But I'll walk you through it.</p>
<ul>
<li>If you want to learn something, grab a copy of <a href="http://github.com/mathjax/mathjax">MathJax</a></li>
<li>slim it down as described <a href="https://github.com/mathjax/MathJax/wiki/Shrinking-MathJax-for-%22local%22-installation">here</a></li>
<li>I went all the way and restricted output to SVG -- to minimize things and to make it work. HTML output should work on iOS5, but last I checked Apple changed something on iOS6 that I couldn't track down for lack of devices.</li>
</ul>
<p>Alright, that's the basics. You now have a copy of MathJax that works on any reasonably recent webkit browser, including most Android and iOS versions.</p>
<p>You have all inputs (LaTeX, asciimath, MathML) available but only SVG output (well, and native MathML but if that worked we wouldn't be here...).</p>
<h2>What's next?</h2>
<p>Create your document. That's actually hard if you don't have a workflow already and don't want to afford InDesign, Blue Griffon etc.</p>
<p>Personally, I will always try pandoc first. It's the most versatile tool there is and John McFarlane is just fantastic. Its TeX implementation is enough if you are writing TeX with HTML/epub output in mind, I'm sure you won't run into trouble.</p>
<p>If you can, consider to go through the Haskell-cabal-pain of installing the current development version -- see the instructions <a href="https://github.com/jgm/pandoc/wiki/Installing-the-development-version-of-pandoc-1.10">at the pandoc github wiki</a>. That will get you the new epub3 writer and things should be easy.</p>
<p>Of course, you can hack the example file below and just use a current version of pandoc or whatever you like to generate some xHTML5 (yes, xhtml, not html if you want your file to validate). You'll have to modify the manifest etc by hand.</p>
<p>Anyway, let's daringly assume you have an epub3 with your xhtml+mathml content.</p>
<h2>Adding MathJax.</h2>
<ul>
<li>add the slim down version of MathJax to your epub file using your favoriate tool for adding content to a zip file. (Don't unzip/rezip unless you know what epub needs when zipping...)</li>
<li>Assuming you're using the copy as in the attachement, add the following to your manifest (modify paths and id's if needed)<pre><code>&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Regular/BasicLatin.js&quot; id=&quot;id0&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/MiscMathSymbolsB.js&quot; id=&quot;id1&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/d.js&quot; id=&quot;id2&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/jax.js&quot; id=&quot;id3&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/cancel.js&quot; id=&quot;id4&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/a.js&quot; id=&quot;id5&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/AsciiMath/jax.js&quot; id=&quot;id6&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/autoload/ms.js&quot; id=&quot;id7&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/mathchoice.js&quot; id=&quot;id8&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Script/Regular/Main.js&quot; id=&quot;id9&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/extpfeil.js&quot; id=&quot;id10&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/AsciiMath/config.js&quot; id=&quot;id11&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/Arrows.js&quot; id=&quot;id12&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/images/CloseX-31.png&quot; id=&quot;id13&quot; media-type=&quot;image/png&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Italic/LatinExtendedA.js&quot; id=&quot;id14&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/SansSerif/Italic/Other.js&quot; id=&quot;id15&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Size3/Regular/Main.js&quot; id=&quot;id16&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Size2/Regular/Main.js&quot; id=&quot;id17&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/images/MenuArrow-15.png&quot; id=&quot;id18&quot; media-type=&quot;image/png&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/TeX/jax.js&quot; id=&quot;id19&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Size1/Regular/Main.js&quot; id=&quot;id20&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/h.js&quot; id=&quot;id21&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/l.js&quot; id=&quot;id22&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Fraktur/Bold/PUA.js&quot; id=&quot;id23&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/AMSsymbols.js&quot; id=&quot;id24&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Regular/CombDiacritMarks.js&quot; id=&quot;id25&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Fraktur/Regular/PUA.js&quot; id=&quot;id26&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/GreekAndCoptic.js&quot; id=&quot;id27&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Italic/LatinExtendedB.js&quot; id=&quot;id28&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/LatinExtendedA.js&quot; id=&quot;id29&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/MiscSymbols.js&quot; id=&quot;id30&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/scr.js&quot; id=&quot;id31&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Regular/MiscSymbols.js&quot; id=&quot;id32&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/MiscTechnical.js&quot; id=&quot;id33&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/newcommand.js&quot; id=&quot;id34&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/autoload/mmultiscripts.js&quot; id=&quot;id35&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/p.js&quot; id=&quot;id36&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Typewriter/Regular/Main.js&quot; id=&quot;id37&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/o.js&quot; id=&quot;id38&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/autoload/annotation-xml.js&quot; id=&quot;id39&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/u.js&quot; id=&quot;id40&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Fraktur/Bold/BasicLatin.js&quot; id=&quot;id41&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Fraktur/Regular/BasicLatin.js&quot; id=&quot;id42&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Size4/Regular/Main.js&quot; id=&quot;id43&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/noUndefined.js&quot; id=&quot;id44&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/k.js&quot; id=&quot;id45&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/LetterlikeSymbols.js&quot; id=&quot;id46&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/HTML.js&quot; id=&quot;id47&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Fraktur/Regular/Main.js&quot; id=&quot;id49&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/MiscSymbolsAndArrows.js&quot; id=&quot;id50&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/SansSerif/Bold/BasicLatin.js&quot; id=&quot;id51&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/GeometricShapes.js&quot; id=&quot;id52&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/GeometricShapes.js&quot; id=&quot;id53&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/config.js&quot; id=&quot;id54&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/enclose.js&quot; id=&quot;id55&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/EnclosedAlphanum.js&quot; id=&quot;id56&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/mhchem.js&quot; id=&quot;id57&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/verb.js&quot; id=&quot;id58&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/GeneralPunctuation.js&quot; id=&quot;id59&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/MathMenu.js&quot; id=&quot;id60&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/GeometricShapes.js&quot; id=&quot;id61&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/PUA.js&quot; id=&quot;id62&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Italic/LetterlikeSymbols.js&quot; id=&quot;id63&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/z.js&quot; id=&quot;id64&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Fraktur/Bold/Main.js&quot; id=&quot;id65&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/SpacingModLetters.js&quot; id=&quot;id66&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Fraktur/Bold/Other.js&quot; id=&quot;id67&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/autoload-all.js&quot; id=&quot;id68&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/SansSerif/Bold/CombDiacritMarks.js&quot; id=&quot;id69&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/noErrors.js&quot; id=&quot;id70&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/g.js&quot; id=&quot;id71&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/SansSerif/Regular/BasicLatin.js&quot; id=&quot;id72&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Regular/SpacingModLetters.js&quot; id=&quot;id73&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/MiscSymbols.js&quot; id=&quot;id74&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Regular/GreekAndCoptic.js&quot; id=&quot;id75&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Italic/Main.js&quot; id=&quot;id76&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/mml2jax.js&quot; id=&quot;id77&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Regular/GeometricShapes.js&quot; id=&quot;id78&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/i.js&quot; id=&quot;id79&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/q.js&quot; id=&quot;id80&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/toMathML.js&quot; id=&quot;id81&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/NativeMML/config.js&quot; id=&quot;id82&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/BasicLatin.js&quot; id=&quot;id83&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/boldsymbol.js&quot; id=&quot;id84&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Typewriter/Regular/Other.js&quot; id=&quot;id85&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/BoxDrawing.js&quot; id=&quot;id86&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/begingroup.js&quot; id=&quot;id87&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/v.js&quot; id=&quot;id88&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/MiscMathSymbolsA.js&quot; id=&quot;id89&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Math/BoldItalic/Main.js&quot; id=&quot;id90&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/SansSerif/Bold/Other.js&quot; id=&quot;id91&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/autoload/menclose.js&quot; id=&quot;id92&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/LetterlikeSymbols.js&quot; id=&quot;id93&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Typewriter/Regular/CombDiacritMarks.js&quot; id=&quot;id94&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Italic/GeneralPunctuation.js&quot; id=&quot;id95&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/MiscMathSymbolsB.js&quot; id=&quot;id96&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/x.js&quot; id=&quot;id97&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/SansSerif/Regular/Other.js&quot; id=&quot;id98&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/j.js&quot; id=&quot;id99&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/MathZoom.js&quot; id=&quot;id100&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/MiscMathSymbolsA.js&quot; id=&quot;id101&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/unicode.js&quot; id=&quot;id102&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/c.js&quot; id=&quot;id103&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/NativeMML/jax.js&quot; id=&quot;id104&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/SupplementalArrowsB.js&quot; id=&quot;id105&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/autobold.js&quot; id=&quot;id106&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/SuppMathOperators.js&quot; id=&quot;id107&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/SansSerif/Regular/Main.js&quot; id=&quot;id108&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/action.js&quot; id=&quot;id109&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/fr.js&quot; id=&quot;id110&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/Dingbats.js&quot; id=&quot;id111&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/Dingbats.js&quot; id=&quot;id112&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/SansSerif/Italic/CombDiacritMarks.js&quot; id=&quot;id113&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/Arrows.js&quot; id=&quot;id114&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/MathEvents.js&quot; id=&quot;id115&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Italic/MathOperators.js&quot; id=&quot;id116&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Caligraphic/Bold/Main.js&quot; id=&quot;id117&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Regular/MathOperators.js&quot; id=&quot;id118&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/Latin1Supplement.js&quot; id=&quot;id119&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/CombDiacritMarks.js&quot; id=&quot;id120&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/f.js&quot; id=&quot;id121&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/Main.js&quot; id=&quot;id122&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/bbox.js&quot; id=&quot;id123&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/config.js&quot; id=&quot;id124&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/CombDiactForSymbols.js&quot; id=&quot;id125&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/SansSerif/Regular/CombDiacritMarks.js&quot; id=&quot;id126&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/Arrows.js&quot; id=&quot;id127&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/SupplementalArrowsA.js&quot; id=&quot;id128&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/r.js&quot; id=&quot;id129&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/GeneralPunctuation.js&quot; id=&quot;id130&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/SansSerif/Italic/BasicLatin.js&quot; id=&quot;id131&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/SuppMathOperators.js&quot; id=&quot;id132&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/opf.js&quot; id=&quot;id133&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/fontdata.js&quot; id=&quot;id134&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/SpacingModLetters.js&quot; id=&quot;id135&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/autoload/mglyph.js&quot; id=&quot;id136&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/MathOperators.js&quot; id=&quot;id137&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Italic/GreekAndCoptic.js&quot; id=&quot;id138&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/CombDiactForSymbols.js&quot; id=&quot;id139&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/SansSerif/Bold/Main.js&quot; id=&quot;id140&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/w.js&quot; id=&quot;id141&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/MiscTechnical.js&quot; id=&quot;id142&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/Latin1Supplement.js&quot; id=&quot;id143&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/MathOperators.js&quot; id=&quot;id144&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Regular/LetterlikeSymbols.js&quot; id=&quot;id146&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/m.js&quot; id=&quot;id147&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/GeneralPunctuation.js&quot; id=&quot;id148&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/autoload/multiline.js&quot; id=&quot;id149&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/LatinExtendedA.js&quot; id=&quot;id150&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/autoload/mtable.js&quot; id=&quot;id151&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Regular/LatinExtendedA.js&quot; id=&quot;id152&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/SansSerif/Italic/Main.js&quot; id=&quot;id153&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/asciimath2jax.js&quot; id=&quot;id154&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/jax.js&quot; id=&quot;id155&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/AMSmath.js&quot; id=&quot;id156&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/b.js&quot; id=&quot;id157&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/fontdata-extra.js&quot; id=&quot;id158&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/SuppMathOperators.js&quot; id=&quot;id159&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/MathOperators.js&quot; id=&quot;id160&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/s.js&quot; id=&quot;id161&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Script/Regular/BasicLatin.js&quot; id=&quot;id162&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Caligraphic/Regular/Main.js&quot; id=&quot;id163&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/SpacingModLetters.js&quot; id=&quot;id164&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/GreekAndCoptic.js&quot; id=&quot;id165&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Italic/BasicLatin.js&quot; id=&quot;id166&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/SupplementalArrowsA.js&quot; id=&quot;id167&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/MathJax.js&quot; id=&quot;id168&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/TeX/config.js&quot; id=&quot;id169&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/BasicLatin.js&quot; id=&quot;id170&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/CombDiacritMarks.js&quot; id=&quot;id171&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/TeX/color.js&quot; id=&quot;id172&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/Main.js&quot; id=&quot;id173&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Regular/LatinExtendedB.js&quot; id=&quot;id174&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Italic/CombDiacritMarks.js&quot; id=&quot;id175&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Fraktur/Regular/Other.js&quot; id=&quot;id176&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/extensions/tex2jax.js&quot; id=&quot;id177&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/MiscTechnical.js&quot; id=&quot;id178&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/autoload/maction.js&quot; id=&quot;id179&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/GreekAndCoptic.js&quot; id=&quot;id180&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Bold/LatinExtendedB.js&quot; id=&quot;id181&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/n.js&quot; id=&quot;id182&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/t.js&quot; id=&quot;id183&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Typewriter/Regular/BasicLatin.js&quot; id=&quot;id184&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Regular/SuppMathOperators.js&quot; id=&quot;id185&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/y.js&quot; id=&quot;id186&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/jax.js&quot; id=&quot;id187&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/input/MathML/entities/e.js&quot; id=&quot;id188&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/LetterlikeSymbols.js&quot; id=&quot;id189&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/AMS/Regular/Latin1Supplement.js&quot; id=&quot;id190&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/element/mml/optable/CombDiacritMarks.js&quot; id=&quot;id191&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Math/Italic/Main.js&quot; id=&quot;id192&quot; media-type=&quot;application/x-javascript&quot;/&gt;
&lt;item href=&quot;mathjax/jax/output/SVG/fonts/TeX/Main/Regular/Main.js&quot; id=&quot;id193&quot; media-type=&quot;application/x-javascript&quot;/&gt;
</code></pre>
</li>
<li>To each xhtml file that contains MathML, add<br>
`<script type="text/x-mathjax-config"><br>
MathJax.Hub.Config({<br>
jax: [&quot;input/TeX&quot;,&quot;input/MathML&quot;,&quot;output/SVG&quot;],<br>
extensions: [&quot;tex2jax.js&quot;,&quot;mml2jax.js&quot;,&quot;MathEvents.js&quot;],<br>
TeX: {<br>
extensions: [&quot;noErrors.js&quot;,&quot;noUndefined.js&quot;,&quot;autoload-all.js&quot;]<br>
},<br>
MathMenu: {<br>
showRenderer: false<br>
},<br>
menuSettings: {<br>
zoom: &quot;Click&quot;<br>
},<br>
messageStyle: &quot;none&quot;<br>
});<br>
</script> <script type="text/javascript" src="https://www.peterkrautzberger.org/mathjax/MathJax.js"> </script>`
</li>
<li>I have not activated automatic linebreaking because there's currently <a href="http://github.com/mathjax/mathjax/issues/368">a bug</a> in MathJax on iOS6. If MathJax detects the need to break the line, you'll get Math Processing errors instead.</li>
<li>For each xhtml file with the above we'll have to modify the <code>properties</code>-part in the manifest to have both <code>mathml scripted</code>, e.g., in the sample file you'll see
<ul>
<li><code>&lt;item id=&quot;c3&quot; media-type=&quot;application/xhtml+xml&quot; href=&quot;xhtml/ch1.html&quot; properties=&quot;mathml scripted&quot;/&gt;</code></li>
</ul>
</li>
<li>And then you can include wonderful MathML and even webkit deficiencies or the horrible iOS5 Safari+STIX bug will be meaningless to your epub file and you can actually publish a mathematical epub file to be read on iBooks.<br>
<math><mrow><mover><mi>x</mi><mo>^</mo> </mover><mo>+</mo> <mover><mrow><mi>x</mi> <mo>⁢</mo> <mi>y</mi> </mrow><mo>^</mo> </mover><mo>+</mo> <mover><mrow><mi>x</mi> <mo>⁢</mo> <mi>y</mi> <mo>⁢</mo> <mi>z</mi> </mrow><mo>^</mo> </mover><mo>.</mo></mrow></math></li>
</ul>
<hr>
<p>This text is <a href="https://www.peterkrautzberger.org/assets/2013/How%20to%20include%20MathJax%20in%20an%20epub3%20file%20to%20work%20with%20iBooks%20%28and%20possibly%20others%29.epub">available as an epub3 file</a> which includes MathJax and should run on iOS devices.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Lila Roberts</strong>, 2013/01/15<br>
I’d like to try to create an epub file–I must admit the opf file is quite intimidating. pandoc looks nice; but I do have inDesign and BlueGriffon. I’ll keep you posted. Thanks, Peter!
<ul>
<li><strong>Peter</strong>, 2013/01/15<br>
yes, creating opf files is a pain. For experiments, you can just hack the sample file from the post. iBooks doesn’t complain if the opf is incomplete, so you can just add jsxgraph etc to the file, too.</li>
</ul>
</li>
<li><strong>AndrewMcDermott</strong>, 2013/01/25<br>
Hi Peter<br>
Great post, I’ll give this a go in the next week or so hopefully, if things calm down a little on our project. Will let you know how I get on!
<ul>
<li><strong>Peter</strong>, 2013/01/25<br>
great! let me know how it goes.</li>
</ul>
</li>
<li><strong>Peter</strong>, 2013/02/14<br>
Hi Andrew. I think this was caught in moderation — sorry. Great to hear it works for you. I hope we can get HTML output running again since that behaves better wrt to CSS.<br>
You can of course include both images and MathML and have MathJax replace the images with its rendering. That way you can support all systems using the same file.</li>
<li><strong>Johannes Wilm</strong>, 2013/05/04<br>
nice one! We have included this in our javascript based epub generator at <a href="http://www.fiduswriter.com/">http://www.fiduswriter.com</a>. I must admit though that I haven't found any ereaders that can make use of this. Is there a list somewhere of what readers support javascript? I noticed thatyou guys are really against prerendering things, but I wonder if maybe thatis needed anyway. So at first I tried looking at the style declarations that are being included in the -section by mathjax. The most important thing missing there seems to be the font-face declarations. I haven'tlooked too much into whether they can be recreated some way.<br>
The other way one could go would be to try to convert the rendered SVG to a canvas element and from there to an img, which could be saved within the epub. I haven't tried it, but was thinking of something like <a href="https://github.com/gabelerner/canvg">https://code.google.com/p/canvg/</a>.<br>
Are there any other recommentations you have?
<ul>
<li><strong>Peter</strong>, 2013/05/05<br>
Hi Johannes, sorry that this was stuck in the moderation queue. Somehow I didn’t get the notification… This warrants a longer reply, as your comment is hitting on many problems and misconceptions at once 😀 (not you personal, just the way the comment can be misunderstood).</li>
<li><strong>Peter</strong>, 2013/05/05<br>
Ok, here’s a longer attempt.<br>
The solution was only tested on iBooks. There are hardly any other javascript-enabled readers out there since epub3 does not require javascript support (although it at least premits it as opposed to epub2). I try to keep <a href="http://docs.mathjax.org/en/latest/misc/epub.html">docs.mathjax.org/en/latest/misc/epub.html</a> up to date but I know a number of Android apps are missing (one of which actually supports javscript).<br>
Why MathJax people often appear to be “against” pre-rendering is simple: that’s what MathJax set out to eliminate! Especially in professional publishing there’s a long history of rendering MathML as images (for over a decade now). We need to get beyond that. Another reason is that the MathJax team tries to get another point across: there’s no need anymore! Every epub3 reader out there uses a modern browser engine underneath that MathJax supports. So they can all integrate MathJax internally to get MathML support. Also, by now, there’s a MathML capable epub3 reader for every platform. Of course that’s not enough for professional publishing, but they are far too conservative anyway.<br>
Also, MathML is the only way to get accessible mathematics right now. Alt-text is simply wrong (except when it’s MathML I guess) — it is not adequate in today’s a11y world where several groups need drastically different rendering, mixed modes and verbosity levels (blind, low vision, learning disabilities etc).<br>
Now image renderings (well, SVG anyway) would be ok if anybody supported epub3’s switch element — then at least, publishing could develop forward.<br>
Sp you’re right: if fiduswriter wants to do epub3 production that works everywhere today, then image renderings are the only stable choice — as much as it pains me to say. At the same time, make sure you’re not stuck at that (too many math solutions are). A generally bad but here fitting example is the proprietary horror that is the iBooks Author format. If you use TeX input in iBA2, then you’ll end up with SVG and MathML in the file, likely so that Apple can switch to MathML once Safari supports MathML properly (which may never be the case since they have never paid anyone to actually develop it…). For a wonderful example of inconsistency: iBA2 also accepts MathML input, which gets copied as is — so won’t display properly when the MathML is beyond Safari’s limited MathML support… Way to push MathML, Apple…<br>
Finally, MathJax output cannot be very well pre-rendered, even as SVG. The HTML-CSS output depends strongly on the viewport configuration at the time of rendering. Which means reflow (which is basically the point of ebooks) easily screws it up, especially when fancy new CSS tricks comes into play at that point. Even the SVG output cannot be pre-produced on the level of real MathJax rendering, linebreaking and other tricks break (besides it blows when it comes to simple things like night mode and more generally at accessibility).<br>
PS: a canvas output is in our backlog.</li>
</ul>
</li>
<li><strong>Johannes Wilm</strong>, 2013/05/05<br>
I see. The epub with mathjax in it worked fine in IBooks, while in Adobe Digital Editings (installed via Wine) and my Nook Glow Light, it just doesn't run the Javascript. It seems to crash the ebook reading app that comes with Calibre.<br>
Epubs themselves may have a limited lifespan, as ebook readers will get fullblown browsers with time, and once there is MathML support everywhere, we may just need a smaller script of some kind to translate Tex-based maths to MathML... The point is that the landscape is changing rapidly and that one needs to adjust one's solutions quite a lot over the next few years.<br>
So, I was thinking: To get smething that is working with today's devices, instead of this:<br>
<code>$X=Y^2$</code><br>
which is rendered fine on only some devices, have something like this:<br>
 <br>
Then the ebook readers that cannot run jaascript will show the image and those that can (IBooks) can calculate the mathjax formula. Of course, mathjax has to be run manually with some javascript, as it cannot find the equation it should render as easily, but I'm sure this can be done.<br>
As for SVG vs. IMG -- I didn't look enough at the svg-canvas library, but assuming that it permits me to copy an already rendered SVG to a canvas, that should mean that I should be able to create a canvas which easily can be converted to an IMG and then saved inside the epub.<br>
But you would maybe argue that it is preferable to just include the SVG directly? For that I assume I would copy the SVG code from the DOM, copy the extra style information that has been added to the header, and find the fonts that have been added through some other trick (cannot find them in hte header) and add those to the mix as well. Right?</li>
<li><strong>Johannes Wilm</strong>, 2013/05/05<br>
Ah, this system ate most of my code examples. let me try again:<br>
So, I was thinking: To get something that is working with today’s devices, instead of this:<br>
<code>&lt;span class=&quot;equation&quot;&gt;&lt;MATH&gt;X=Y^2&lt;/MATH&gt;&lt;/span&gt;</code><br>
which is rendered fine on only some devices, have something like this:<br>
<code>&lt;span class=&quot;equation&quot; data-equation=&quot;X=Y^2&quot;&gt;&lt;IMG src=&quot;...&quot; alt=&quot;an equation showing X=Y^2&quot;/&gt;&lt;/span&gt;</code>
<ul>
<li><strong>Peter</strong>, 2013/05/05<br>
As I wrote, ideally, you would produce some kind of image fallback and use the epub-switch element. Unfortunately, very few epub3  reading systems support it. Even worse, they often react the wrong way to it: using MahtML instead of the image :(<br>
Unfortunately, your &quot;once there's MathML support everywhere&quot; makes me cry a little as I just replied to <a href="https://groups.google.com/forum/?fromgroups=#!topic/mozilla.dev.platform/96dZw1jXTvM">https://groups.google.com/forum/?fromgroups=#!topic/mozilla.dev.platform/96dZw1jXTvM</a>. There's currently zero development going into browsers. I hope we can change that, but this will be a while.<br>
Anyway, yes, MathJax can easily replace images by rendering embedded code. Case in point: bookmarklets for doing that on <a href="http://wordpress.com/">Wordpress.com</a> and Wikipedia <a href="https://gist.github.com/pkra">https://gist.github.com/pkra</a><br>
You can use SVG -- both canvas and SVG are part of epub3. Grabbing MathJax output is certainly possible, but with constraints. Making MathJax work also outside the DOM (with those constraints) is in our backlog, but has been for a while. You might find <a href="https://github.com/agrbin/svgtex">https://github.com/agrbin/svgtex</a> interesting.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[JMM 2013]]></title>
        <id>https://www.peterkrautzberger.org/0128/</id>
        <link href="https://www.peterkrautzberger.org/0128/">
        </link>
        <updated>2013-01-09T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Early this morning, I drove down to San Diego to be at the <a href="http://jointmathematicsmeetings.org/jmm">Joint Math Meetings 2013</a> for the very first time. (Well, last year, I mostly sneaked in to meet friends and didn't even register -- or got to talks, so I guess that's fair).</p>
<p>It seems ironic and yet fitting that my first JMM is also the first meeting since I left mathematical research (in the traditional and definitely the (for me) previous sense). Representing MathJax is challenging, exciting, and simply a lot of fun.</p>
<p>Of course, meeting up with old friends is an added bonus that's simply priceless.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Ben Webster</strong>, 2013/01/10<br>
I think meeting up with old friends is the main purpose of the JMM for all of us…
<ul>
<li><strong>Peter</strong>, 2013/01/10<br>
Indeed!</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What's the best TeX-to-HTML or TeX-to-ePUB converter?]]></title>
        <id>https://www.peterkrautzberger.org/0127/</id>
        <link href="https://www.peterkrautzberger.org/0127/">
        </link>
        <updated>2013-01-05T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>What do I do when I don't find the time to properly write here? I needlessly double post stuff I've written elsewhere.</p>
</blockquote>
<p><a href="http://www.linkedin.com/groups/Whats-best-TeXtoHTML-TeXtoePUB-converter-3772588.S.200461734">Somebody asked the title question on LinkedIn</a>. My reply was as follows (well, I'll do the links properly here).</p>
<h2>What's the best TeX-to-HTML or TeX-to-ePUB converter?</h2>
<p>I don't have that much experience with this, but it might be better than nothing.</p>
<p>I think the two main contenders for TeX-to-html are TeX4ht (which most LaTeX distributions ship) and <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML</a>.</p>
<p>TeX4ht is really a dvi-to-html converter so it behaves accordingly. In my limited experience, it is easier to get results.</p>
<p>LaTeXML seems more powerful, but I could never get it to produce results from &quot;arbitrary&quot; TeX (again, not a lot of time spent on this). On the other hand, LaTeXML is used systematically to convert the arXiv with reasonable success rates.</p>
<p>With respect to epub3 (ignoring html-to-epub3), I'm only aware of <a href="http://www.johnmacfarlane.net/pandoc/">pandoc</a> (disclaimer: my personal favorite).</p>
<p>The current development branch has an epub3 writer with MathML support. This works reliably in a handful of tests. Pandoc does not have complete TeX support but John McFarlane is just a fantastic guy who built a strong community around pandoc -- something the two others seem to lack.</p>
<p>Addendum: <a href="http://tex.stackexchange.com/">TeX.SE</a> has lots of expertise on tex4ht and latexml, of course. See <a href="http://tex.stackexchange.com/questions/43847/why-havent-any-tex-html-converters-been-updated-to-use-current-web-standards-s">this example</a></p>
<hr>
<p>Since the blog has to have something extra</p>
<h3>Bonus links from <a href="http://tex.se/">TeX.SE</a>:</h3>
<ul>
<li><a href="http://tex.stackexchange.com/questions/19928/how-can-i-use-latex-to-build-my-website/">http://tex.stackexchange.com/questions/19928/how-can-i-use-latex-to-build-my-website/</a></li>
<li><a href="http://tex.stackexchange.com/questions/68916/convert-latex-to-mathjax-html/">http://tex.stackexchange.com/questions/68916/convert-latex-to-mathjax-html/</a></li>
<li><a href="http://tex.stackexchange.com/questions/49208/why-is-latex-used-as-the-defacto-standard-for-math-equations/49228#49228">http://tex.stackexchange.com/questions/49208/why-is-latex-used-as-the-defacto-standard-for-math-equations/49228#49228</a> (I'll have to come back to that one)</li>
</ul>
<h3>Super Bonus links</h3>
<ul>
<li><a href="https://github.com/coolwanglu/pdf2htmlEX">https://github.com/coolwanglu/pdf2htmlEX</a> (via <a href="http://tex.se/">TeX.SE</a>) which simultaneously amazes &amp; freaks me out. (Look into the source of the example with formulas... brrr...)</li>
<li><a href="http://www.albany.edu/~hammond/demos/Html5/arXiv/">http://www.albany.edu/~hammond/demos/Html5/arXiv/</a> how I started with tex4ht.</li>
</ul>
<h3>Bonus observation</h3>
<p>the two posts that regularly drive traffic this way are about Markdown and epub. Just saying.</p>
<h3>Bonus bonus</h3>
<p>That last sentence about John McFarlane got shortened too much and doesn't quite make sense anymore. So I finally have a reason to embed the most important comic strip on the internet.</p>
<figure>
  <a href="http://xkcd.com/386/">
    <img alt="Are you coming to bed? -- I can't. This is important. -- What?  -- Someone is _wrong_ on the internet." src="https://www.peterkrautzberger.org/assets/2013/duty_calls.png">
  </a>
  <figcaption>
  <a href="http://xkcd.com/386/">Duty Calls</a> (&copy;  xkcd, cc-by-nc).
  </figcaption>
</figure>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Joerg Sixt</strong>, 2013/01/23<br>
Many thanks for this…although this answer made me lock myself in the basement for a week to get tex4ht to work(lol). It is probably powerful but a very badly documented piece of software. It is even unclear if MikTeX 2.9 contains a correct installation. It would love to get high-quality images for equations (PNG and SVG) out of tex4ht just to see how far you can go without MathML and MathJax but I failed so far.<br>
Probably will try PanDoc next…
<ul>
<li><strong>Peter</strong>, 2013/01/26<br>
I would suggest latexml first. pandoc is not on the level you expect.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Leinster's "Rethinking set theory"]]></title>
        <id>http://karagila.org/2013/on-leinsters-rethinking-set-theory/</id>
        <link href="http://karagila.org/2013/on-leinsters-rethinking-set-theory/">
        </link>
        <updated>2013-01-04T23:19:30Z</updated>
        <summary type="html"><![CDATA[<p>There has been a lot of recent discussions regarding Tom Leinster's paper &quot;<strong>Rethinking set theory</strong>&quot; (<a href="http://arxiv.org/abs/1212.6543">arXiv</a>). Being an opinionated person, I only found it natural that I had an opinion on the paper. Now that I have a blog, I have a place to write this opinion as well.</p>

<p>The paper challenges the hegemony of \(\ZFC\) as the choice set theory. It offers an alternative in the form of \(\newcommand{\ETCS}{\axiom{ETCS}}\newcommand{\ETCSR}{\axiom{ETCS+R}}\ETCS\), a categories based set theory. The problem with \(\ETCS\) is that it is slightly weaker than \(\ZFC\). But we also know how much weaker: it lacks the expressibility of the full replacement schema. In this case we can just add a replacement schema-like list of axioms to have \(\ETCSR\). <a href="http://karagila.org/2013/on-leinsters-rethinking-set-theory/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Internal combinatorics and uniform reducibility]]></title>
        <id>http://m6c.org/w/2012/12/internal-combinatorics-and-uniform-reducibility/</id>
        <link href="http://m6c.org/w/2012/12/internal-combinatorics-and-uniform-reducibility/">
        </link>
        <updated>2012-12-05T17:43:43Z</updated>
        <summary type="html"><![CDATA[This post is a set of notes from a talk I gave on December 5th for the discrete mathematics seminar at Marshall University. I want to argue that logical analysis can reveal the &#8220;internal combinatorics&#8221; of theorems, using some recent &#8230; <a href="http://m6c.org/w/2012/12/internal-combinatorics-and-uniform-reducibility/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Carl Mummert</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Forum of Mathematics, blessing or curse?]]></title>
        <id>https://www.peterkrautzberger.org/0126/</id>
        <link href="https://www.peterkrautzberger.org/0126/">
        </link>
        <updated>2012-11-11T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>When the Forum of Mathematics was announced <a href="https://gowers.wordpress.com/2012/07/02/a-new-open-access-venture-from-cambridge-university-press/">on Tim Gowers's blog</a> I mentioned this on twitter and I got a couple of replies asking what my thoughts on it were. Well, this post has been stuck in my draft folder for too long, long enough for these journals to   be open for submissions, blimey.<br>
2012-11-19 quick correction. People have pointed out in the comments, that <strong>Sigma</strong> is already going to be a regular old journal (see Gower's post, comparing it to Combinatorica). I'm not yet sure if that makes it better or worse.</p>
</blockquote>
<h3>Open thingamajig</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Forum_of_Mathematics">Forum of Mathematics</a> is a new journal. Well, no, it's actually two journals, <strong>Pi</strong> and <strong>Sigma</strong> (yes, <em>not</em> π and Σ). (This is surprisingly nerdy for the honorable Cambridge University Press -- just imagine all the inside jokes you can do with it (but we'll get back to that).)</p>
<p>These are two journals in mathematics. So far, so boring. They are <a href="https://en.wikipedia.org/wiki/Open_access_journal">open access</a> journals, more precisely <em>Gold</em> Open Access, i.e., you pay a fee once, when your publication is accepted, and then your publication is published and available under a permissive license (creative commons in this case).</p>
<p>My two regular readers may know that I'm a big fan of Gold OA as a mid-term solution to our primary publishing problem -- which is non-free publishing. A lot of people criticize the level of fees that Gold OA publishing comes with. For example, the biggest OA journal and the first &quot;mega journal&quot;, <a href="https://en.wikipedia.org/wiki/Plos_one">PLOS One</a>, charges a whopping <span>\(&lt;/span>1300 (there are institutional rebates and you can ask for a waiver) -- and that's cheap compared to Springer and Elsevier. But &lt;span>\)</span>1300 is something that most mathematicians do not get their hands on in their grant proposals right now. There are numerous explanations why this isn't the figure that you should be concerned, e.g., how your library saves money so that your department can fund your fee -- and then you usually get the return argument &quot;not everybody works in a department&quot;; and that's all good and fair and not the topic for this post.</p>
<p>It doesn't matter.</p>
<p>Gold OA is currently the only viable form of OA on a larger scale.</p>
<blockquote>
<p>Yes, we have examples of what some call &quot;diamond OA&quot; in mathematics (Open Access without any fees whatsoever). In fact, my first paper was specifically published in the NYJM because it was diamond OA. Here's what I based my decision: It was clear that that (any?) paper would not end up in anything fancy, you know, high-profile, glamour mag etc. So I looked for a long time to find one that a) had a publication in my field (the <a href="http://nyjm.albany.edu/j/2009/15-21.html">NYJM did</a>) and b) had other publications by respectable people (the <a href="http://nyjm.albany.edu/j/2009/15-14.html">NYJM had</a>). So I chose the NYJM and it was a fun experience although there's actually a very critical post that I have to write about it [[not so much critical of the NYJM, but my own work]].</p>
</blockquote>
<p>Back to the Forum of Mathematics. It tries to do the right thing. First off, it's open access; that's a good thing. Then it's Gold OA; that's the decent thing, and it's the only way we can be on that level while we lack the infrastructure for diamond OA on that level. (And I'll get to that, what I mean by &quot;this level&quot;.)</p>
<p>Then they try to be competitive; which is a good thing. Finally, they try to be affordable; which is a good thing. The journals will be free of charge for the first three years. They hope to find donors to keep it free but otherwise will start charging £500/€750 -- which is good, that's still not very low, but at least it's not what Elsevier and Springer will ask you to pay.</p>
<h3>Now you see me, now you don't</h3>
<p>So that's the open access part of the story. Now to the special mathematical twist. The Forum of Mathematics comes in two journals, both have the same price tag. What's the difference? The difference is that <strong>Pi</strong> stands for (let's follow Tim Gowers's suggestion) &quot;primo&quot; and <strong>Sigma</strong> stands for &quot;secondo&quot;. What does that mean? It means Sigma is what you'd call &quot;PLoS One for mathematics&quot;, it is designed to be a mega journal in the same vein where the refereeing process will only check correctness of your paper (yes, and plagiarism, nonsense etc).</p>
<p><strong>Pi</strong>, on the other hand, is aimed (as Gowers's describes), to become one of the top three journals in mathematics -- that's the goal. For this purpose, it also adds a few fancy innovations. For example, you actually have to write a two page statement for your submission to argue that your work is important enough -- which makes it's goal as transparent as it makes it ridiculous. (But let's not go there right now.)</p>
<h3>Pleasure and pain</h3>
<p>So what are my thoughts on it? My first thought was &quot;thank god, finally somebody is doing something serious about that&quot;. We're lacking a PloS ONE for mathematics and that's absolutely clear. In fact, it's bizarre that we've been so far ahead in the game (with the arXiv for 20+ years) and yet we're so far behind in everything else that's happened in publishing in the last 10 years. So thankfully somebody said &quot;let's do PLOS One for mathematics&quot; -- that's a great move.</p>
<p>But my immediate second reaction was: &quot;WTF?!?!&quot;. For me at least, the idea of PLoS ONE is ruined once you add something like <strong>Pi</strong>.</p>
<p>The whole idea of PLoS ONE is to leave the bickering of editorial boards behind. PLoS is investing quite a bit of money (now that they actually make a profit off PLoS ONE) in the fundamental idea that is PLoS ONE: editorial boards are not very good at identifying what's important research; they are simply bad at it. (I've ranted about editorial boards as the core problem of academic publishing before, <a href="https://www.peterkrautzberger.org/0118/">no</a>?)</p>
<p>So PLoS ONE goes the other way and says &quot;We don't care about importance, you check that it's science and let the community decide what's important&quot;. How do they do that? Well, for the longest time they didn't do much, they experimented, tried what they could with their means. But what you see now is a serious investment in <a href="http://altmetrics.org/">alternative metrics</a>, i.e., in means to aggregate the impact that an individual paper has in the community. Not the impact that some editorial board members think the paper <em>should</em> have in their community, no the actual, real impact. The impact of &quot;&quot;How many people get their hands on it?&quot;, How many people read it?&quot;, &quot;How many people leave a comment, talk about it on social networks, on blogs, on whatever else you can think of?&quot;. This is the true democratization of acadmic publishing: to realize that editorial boards are very good at organizing fact-checking but they are unnecessary for identifying what is important to the community. At first sight, this might be more prevalent in the sciences, but in reality it is extremely prevalent in mathematics as well. Mainstream mathematics dictates what's important (Field's medal anyone?) and non-mainstream fields can take it as an excuse for their own lack of impact.</p>
<p>Alright, that was maybe too much of a rant. I know that most editors are highly decent people; they are benevolent dictators but they are dictators none the less, and glamour mags editors have just as much power over the community as they do in the sciences.</p>
<h3>The Game of Thrones</h3>
<p>So what does <strong>Pi</strong> turn the idea of a PLoS ONE journal into? It turns it -- and this is my second point -- into a power grab.</p>
<p>If I was to imagine that <strong>Sigma</strong> becomes the PLoS ONE of mathematics and imagine that <strong>Pi</strong> will pick the &quot;great&quot; papers out of <strong>Sigma</strong>. Then what do you get? You get a mega journal that will collect a considerable amount of mathematical publishing (all of it?), and another that picks the raisins out of it. What's wrong with that picture?</p>
<p>That picture I'm left with is a massive collection of power within a single editorial board, across the entire publication range in mathematics. If <strong>Sigma</strong> can capture a large part of mathematical publications (and how could it not? it's respectable and free!)then the <strong>Pi</strong> editorial board will have all the power to dictate what is important and what isn't. Just think about it this way: why would I submit to the NYJM, if I can submit a weak paper to <strong>Sigma</strong> with the additional, faint hope of making it into <strong>Pi</strong>?</p>
<p>This is a huge issue!</p>
<p>Now I'm not saying this must happen. Just like with PLoS ONE, there can be competitors sooner or later, probably as soon as it becomes a successful business model. But the damage it can do in the mean time could be considerable.</p>
<p>PLoS ONE started out as an experiment, it was the first of its kind, it had no idea that it would take off to become the biggest journal in history. With <strong>Sigma</strong>, on the other hand, we <em>know this</em>, and we can see that <strong>Pi</strong> is designed to profit directly from this potential, picking raisins from the first mega journal in mathematics.</p>
<p>What would that mean to small, enthusiastic, diamond OA journals that exist right now? (Besides, is there enough room for a real competitor?)</p>
<p>Coda.</p>
<p><strong>Sigma</strong> is a copycat of PLoS ONE which was founded 10 years ago -- we remain that far behind. The only innovation is <strong>Pi</strong>, which is actually a step backwards (and the lack of alternative metrics, another step backwards).</p>
<p>Where are the really new experiments? Our research is made for the web, to be communicated through the web in text, speech and demonstration. Yet we do not take the experimental playground seriously enough. We simply stay behind everybody else, ready to complain about all the big bad things coming out of the scientific side of publishing.</p>
<p>Could we jump ahead? Based on the experience of MathOverflow and <a href="http://math.se/">math.SE</a>, no doubt. The mathematical community is open to exploring new ways to do and communicate research.</p>
<p>And I wonder: if Forum of Mathematics is considered a &quot;big experiment&quot; then I fear that we'll stay behind by 10 years and soon enough we will be behind 20 years.</p>
<hr>
<p>tl;dr<br>
Great to have a PLoS ONE for mathematics but I worry that the <strong>Pi</strong> editorial board could end up the absolute, most powerful editorial board in history.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Marshall Hampton</strong>, 2012/11/12<br>
Its not really different from PLOS ONE and PLOS Biology.</li>
<li><strong>Peter</strong>, 2012/11/12<br>
Yes there is a similarity but I think there are major differences.<br>
First of all, PLoS Biology was first chronologically (in fact, PLOS’s very first journal). They went from a traditional editorial model to creating the (really quite incredibly innovative) model of PLoS ONE.<br>
Then there’s the “picking raisins” aspect of Pi; as far as I know this doesn’t happen at PLoS Biology // PLoS ONE.<br>
Finally, PLoS ONE has much broader subject areas than Sigma which means it can’t really “hope” (if that’s the word) to dominate one field as much as Sigma might do for Mathematics. Hence, my worry.</li>
<li><strong>Christian Perfect</strong>, 2012/11/12<br>
Is there anything to stop other people compiling lists of good papers from Sigma?
<ul>
<li><strong>Peter</strong>, 2012/11/12<br>
That’s a great idea! We could get “Sigma overlay journals” just as people are trying to do “arXiv overlay journals” — but with free refereeing.</li>
</ul>
</li>
<li><strong>Siddhartha Gadgil</strong>, 2012/11/12<br>
I don’t think Sigma intends to be a PLOS One – just a collection of journals at the level of 'top journal in the field’ (while Pi is at the level of 'top journal in mathematics’)
<ul>
<li><strong>Peter</strong>, 2012/11/12<br>
I don’t know how else to describe PLoS ONE. There is of course a different way of assessing proper mathematics as compared to proper science. Some have argued that PLoS ONE allows bogus papers to pass, but I don’t think there’s much real evidence for that. certainly not more than a decent journal in mathematics.</li>
</ul>
</li>
<li><strong>Scott Morrison</strong>, 2012/11/19<br>
Sigma is certainly planning on rejecting correct but insufficiently important papers! I think you’re barking up the wrong tree wishing it were like PLoS One for mathematics.
<ul>
<li><strong>Peter</strong>, 2012/11/19<br>
Thanks Scott. I’ll double check and will add a correction. As I describe, I’m not really wishing for Sigma to be a PLoS One for mathematics — I’m rather worried about that. Assuming Sigma will really start at a “top” level, my worries about its influence would worsen…</li>
<li><strong>Peter</strong>, 2012/11/19<br>
Sorry for not double checking right away — you are right. (I should listen to comments more often :( )</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Axiom of Choice and Self-Dual Vector Spaces]]></title>
        <id>http://karagila.org/2012/the-axiom-of-choice-and-self-dual-vector-spaces/</id>
        <link href="http://karagila.org/2012/the-axiom-of-choice-and-self-dual-vector-spaces/">
        </link>
        <updated>2012-10-28T01:28:33Z</updated>
        <summary type="html"><![CDATA[<p>I have uploaded a note titled <a href='../../wp-content/uploads/2012/10/dual.pdf'>The Axiom of Choice and Self-Duality of Vector Spaces</a>. Here is a short summary and background.</p>

<p>It is a well known fact (in \(\ZFC\) at least) that if \(V\) is a vector space, and \(V^\ast\) is the algebraic dual of \(V\) then \(V\cong V^{\ast\ast}\) if and only if \(\dim V<\infty\). <a href="http://karagila.org/2012/the-axiom-of-choice-and-self-dual-vector-spaces/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[First Post]]></title>
        <id>http://karagila.org/2012/first-post/</id>
        <link href="http://karagila.org/2012/first-post/">
        </link>
        <updated>2012-10-19T04:46:50Z</updated>
        <summary type="html"><![CDATA[<p>Well... This is my first post on this blog, and I have absolutely no idea how to start it.</p>

<p>Should I make it about myself? about my life? about my academic status? How I about I tell cool stories from my life, perhaps inebriated adventures? army experiences? Maybe I should write about mathematics. Perhaps some nice proof or some nice theorem? <a href="http://karagila.org/2012/first-post/">Continue reading...</a></p>]]></summary>
        <author>
            <name>Asaf Karagila</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Happy 2nd Birthday, Mathblogging.org or My 136 favorite mathematical blogs]]></title>
        <id>https://www.peterkrautzberger.org/0125/</id>
        <link href="https://www.peterkrautzberger.org/0125/">
        </link>
        <updated>2012-10-14T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><a href="http://mathblogging.org/">Mathblogging.org</a> is nearing its 2nd birthday. We've passed the second anniversary of the domain registration and <a href="https://www.peterkrautzberger.org/0045/">my own blog post</a> is having it's second anniversary soon. Plenty of reason to write a post about this.</p>
<p>We (Fred, Felix and I) recently decided to put the <a href="http://mathblogging.wordpress.com/category/weekly-picks/">Mathblogging.org Weekly Picks</a> on hold. It was a bit of a sad moment for us, but for something we never planned on doing, it's been quite a ride these <a href="http://mathblogging.wordpress.com/2011/02/21/weekly-picks/">past 18 months</a> and I'd like to think we've helped people a little to get a peek into this living, breathing chaos that is the mathematical blogoshpere.</p>
<p>The thing is: we are not able to do a good job anymore. With 691 feeds aggregated it is very hard to fulfil our promise of &quot;reading all blog posts that go through <a href="http://mathblogging.org/">mathblogging.org</a>&quot;. Additionally, in the last few months a couple of changes caused the Weekly Picks to be done mostly by yours truly alone -- making this promise even less realistic and even more biased. For a while we could compensate by saying &quot;only a few categories each week&quot;, but even that is outside of what we can manage now.</p>
<p>So we turn a page.</p>
<p>If all goes well, we will re-launch in a few weeks, which will allow us to invite people to become editors, allowing us to aggregate interesting posts right on the front page. We're still looking for potential editors (read: people who read too many math blogs and are opinionated). But in fact, quite a number of mathematical bloggers are doing an amazing job already, though either separate or in small collectives.</p>
<p>A while back I tweeted that the best thing this year in mathematical blogging has been the launch of <a href="http://aperiodical.com/">The Aperiodical</a>. Well, they do have competition to this title. For example, <a href="http://mathbabe.org/">mathbabe.org's Cathy O'Neill</a> has established herself as one of the premier &quot;cross-culture&quot; math bloggers after blogging for little over a year. Also, right from the bat (a year ago next week), <a href="https://mathmunch.wordpress.com/">Math Munch</a> has been an awesome resource of weekly posts, so Anna Weltman, Paul Salomon and Justin Lanier are race for that immaterial title race of mine, too.</p>
<p>Add to that work of <a href="https://gottwurfelt.wordpress.com/">God Plays Dice</a>'s Michael Lugo with his weekly links and the grand old lady of math podcasts <a href="http://www.pulse-project.org/pulsemathsmaths">Math/Maths</a> with its weekly math news -- and you'll see that nobody really needs our Weekly Picks anymore. Finally, a couple of weeks ago, you could follow an amazing series of posts thanks to the initiative by <a href="http://samjshah.com/2012/08/06/new-blogger-initiation-pledge-by-tuesday-august-14th/">Sam Shah and Kate Nowak</a> to create a <a href="http://mathtwitterblogosphere.weebly.com/">math teacher blogger initiation</a> which us 200 new math bloggers (!) -- and giving <a href="http://mathblogging.org/">mathblogging.org</a> a slew of new blogs to include. Their work is, quite frankly, amazing.</p>
<p>The funny thing is, when we launched <a href="http://mathblogging.org/">mathblogging.org</a> we only reluctantly added a teacher/education category. Sure, we loved <a href="http://blog.mrmeyer.com/">Dan Meyer's blog dy/dan</a> but we were all researchers, so teacher bloggers were not our natural focus. It didn't take me long to completely change my mind. There are still some things that strike me as odd (say, some homeschooling blogs) but then again there is much more that strikes me as odd about research bloggers these days.</p>
<p>I'm amazed by the grassroots movement that is mathematical teacher bloggers. The way these people have built (and keep building) a strong online community, exchanging ideas, materials and technology, supporting each other and boosting outreach on a scale that research mathematicians could only dream of. Are research mathematician bloggers even aware of this effort? Unfortunately, the answer seems to be no.</p>
<p>Research bloggers in mathematics face one major issue: a blessing that is also a curse. Namely, we have -- unmatched by other sciences -- a high number of highest-level researchers blogging (relative to the size of our research community and blogoshpere anyway). <a href="https://terrytao.wordpress.com/">Terry Tao</a> and <a href="https://gowers.wordpress.com/">Tim Gowers</a> are probably the most well known, but I would count about 5-10 belonging to that &quot;inner circle&quot;. This is a blessing as especially Tao and Gowers prove time and again that the very greatest researchers are extraordinary communicator and teachers.<br>
Unfortunately, it turns out that having this truly elite group of bloggers does not help researchers at all to embrace blogging as a medium for their academic and popular outreach. On the one hand, young researchers (who are more likely to pick up this type of mathematical writing) are often intimidated. Yes, there are a few grad student blogs and yes, the group behind the <a href="https://sbseminar.wordpress.com/">Secret Blogging Seminar</a> has turned from grad students to tenure-track and tenured folk. But far more young researchers react with something along the lines of &quot;I can't blog on the level of Terry Tao!&quot;. (When I'm in a sour mood, I'll reply: Is this why you went into research? Because you asked yourself if you could do it on the level of Terry Tao and answered &quot;sure, no biggie&quot;?) But it's hard to underestimate how intimidating the situation is.</p>
<p>The other negative effect I noticed is curious: mathematical researcher bloggers can't even fight the good fight against old fashioned researchers and institutions (say, in tenure evaluations). Where science bloggers are building a strong community to support each other throughout the academic career path, fighting the <a href="http://scientopia.org/blogs/whizbang/2010/10/05/more-thoughts-on-st-kern/">St. Kerns</a> of their disciplines every step of the way, in mathematics you'll encounter a more wicked opposition, a soft wall: blogging is great! Terry Tao does it. Are you Terry Tao? Aha. (followed by snicker or evil laugh)</p>
<p>This would not be a problem if there were at least some influential researcher bloggers like <a href="http://blogs.scientificamerican.com/a-blog-around-the-clock/">Bora</a> (nobody is like <a href="http://twitter.com/search?q=%23ihuggedbora&amp;src=typd">Bora</a>!), actively promoting blogging as a most serious researcher activity. Instead, the influential math researcher bloggers do not give the impression as if they were interested in getting anyone to embrace blogging (yes, John Baez wrote a column once, I know). In fact, I have the impression that they hardly read other blogs outside their small, elite collective. To be honest, I find this highly disappointing (these are our scientific leaders, after all) but, sadly, not surprised.</p>
<p>Back to the second part of the title of this post. Since the Weekly Picks are soon to be retired, I've had to re-arrange my reading habits. You see, I used to read the <a href="http://mathblogging.org/">mathblogging.org</a> feeds -- simple as that. Now that the Weekly Picks have taken a leave of absence, I don't have to read all the blogs anymore and I found myself not reading any math blogs anymore!</p>
<p>So I grabbed the opml file that we kindly <a href="https://web.archive.org/web/*/http://www.mathblogging.org/database-opml.xml">provide at mathblogging.org</a> and imported it into Google reader, filtering it down to 136 blogs that I either really like or feel like I should keep an eye on (say, Terry Tao's posts; I don't enjoy them as a I used to yet I need to at least glance over it). You can find the correpsonding opml below, if you care.</p>
<p>These ~136 blogs will give you some overview over what the mathematical blogosphere has to offer. But not that much -- it's fully and totally biased (if you want to force me to check your blog, go add it to <a href="http://scienceseeker.org/">ScienceSeeker</a> where I'm an editor for mathematics). You can, for example, see my clear affinity for Italian math bloggers. Or you can see that I don't care that much for tumlbr-rebloggers (it's no that they are bad, but it's too much noise).</p>
<p>It's worthwhile to point out that the international mathematical blogoshpere is not as well-represented on <a href="http://mathblogging.org/">mathblogging.org</a> as we'd like. This has many reasons (e.g., a lot of people blog on English no matter their first language), but certainly one is the lack of ability on our side, the <a href="http://mathblogging.org/">mathblogging.org</a> editors. Spanish, French and Italian are roughly doable (with or without google translate), but, e.g., languages out of Asia or Africa are hard to deal with for us -- and we don't find them as easily (and honestly, we don't seek out blogs that much anymore).</p>
<p>It's strange however, how few blogger we have from France and Germany. Maybe France suffers from <a href="http://images.math.cnrs.fr/">Images des Mathématiques</a> being such an extraordinary online magazine. If you read nothing else, Images is likely enough. But it doesn't explain the absence. Just looking at the UK gives you a different example. While you have big, semi-traditional projects like <a href="http://plus.maths.org/content/">+maths</a> and other projects out of the <a href="http://mmp.maths.org/contact">Millenium Mathematics Project</a>, the UK has by far strongest local math blogger community I've seen anywhere -- and in addition a strong local math culture with Maths Jams. (And, as mentioned, the fantastic The Aperiodical and the HistSci Hulk himself, the <a href="https://thonyc.wordpress.com/">Renaissance Mathematicus</a>.)</p>
<p>German mathematical blogging, I'm afraid, is pitiful to behold (and of course I'm utterly biased). While <a href="http://scienceblogs.de/mathlog">Thilo Kuessner</a> still holds down the fort at the <a href="http://scienceblogs.de/">Scienceblogs.de</a>, that's about it. There aren't even that many German bloggers writing in English. (Well, Guenther Ziegler blogs -- cross-posting something once a year. Not that I blame him -- he's busy doing a lot of other awesome stuff. But he's not a blogger.) And how many German mathematicians are on twitter? Less than there are bloggers...</p>
<p>We do list a few Spanish-speaking math bloggers and you'll find some really good ones in my list. I'm sure there are more and I hope we can get more once we upgrade <a href="http://mathblogging.org/">mathblogging.org</a>. It's much better than French and German blogging (and it's not just Spain), then again given the number of native Spanish speakers in the world, it's still very very small -- but at least there it's worth reading. Oh, and Italy is surprisingly strong in terms of the mathematical blogosphere, ranging from online versions of print columns to weird creative bloggers.</p>
<p>So there you have it, kind of a &quot;state of the math blogosphere&quot;. It only took me two years to write it (even though <a href="http://blogs.plos.org/mfenner/">Martin Fenner</a> kindly offered us a guest post at PLoS blogs many moons ago).</p>
<hr>
<p>And now, the annotated list of the blogs I do read, most of which I simply love to read.</p>
<p>Mind you there are a number of blogs missing from that list. For example, all of Booles' Rings since those posts have a different status for me personally. But if you ever needed an infusion of blogs, here you go.</p>
<p><a href="https://www.peterkrautzberger.org/assets/2012/krautzberger_mathblogs_2012_10.xml">The OPML file</a>  <s>(on Dropbox)<s></s></s></p>
<ul>
<li><a href="http://plus.maths.org/content/Blog">+Plus magazine</a>, the more traditional media within the UK maths blogosphere, but accept submissions. I admit, I got quite tired of the repitive Olympics post this summer, but no reason not to keep checking it.</li>
<li><a href="http://11011110.livejournal.com/">0xDE</a>, one of the few anonymous, researcher bloggers and a marvelous Wikipedia editor.</li>
<li><a href="http://davidwees.com/">21st Century Educator</a>, David Wees, teacher blogger.</li>
<li><a href="http://teachingintrotocs.blogspot.com/">A CS Professor's Blog</a>, Claire Mathieu's blog, one of the few female math (well, CS) researchers who blog.</li>
<li>Andres Caicedo's <a href="http://andrescaicedo.wordpress.com/">A kind of library</a>, another researcher blogger, using his blog also extensively for teaching, which makes him unfortunately unique among researcher bloggers.</li>
<li>Samuel Hansen's <a href="http://acmescience.com/">ACME Science</a>, mathpodcaster extraordinnaire.</li>
<li><a href="http://alexbellos.com/">Alex Bellos</a>, British popular math writer, sadly blogs only very rarely, but to be found on twitter more actively</li>
<li><a href="http://agtb.wordpress.com/">Turing's Invisible Hand</a>, started by Noam Nisan, now a group blog, more CS/economy, but always interesting.</li>
<li><a href="http://amazings.es/categorias/matematicas/">amazings.es/math</a>, Spanish science blog magazine.</li>
<li>The <a href="http://mathgradblog.williams.edu/">AMS Graduate Student Blog</a>, currently searching for new student authors, so head over and get your writing out there if you're a math grad student.</li>
<li><a href="http://www.ams.org/">AMS News &amp; Events</a>, to keep up with what old-fashioned institutions consider worthwhile.</li>
<li><a href="http://anglesofreflection.blogspot.com/">Angles of Reflection</a>, great math teacher blogger.</li>
<li><a href="http://www.angrymath.com/">AngryMath</a>, another great math teacher blogger.</li>
<li><a href="http://qchu.wordpress.com/">Annoying Precision</a>, one of the few grad student bloggers, unfortunately blogging less after becoming <a href="http://math.se/">math.SE</a> moderator.</li>
<li><a href="http://conan777.wordpress.com/">Area 777</a>, not to give you the wrong idea, but another grad student, though posting less frequently recently.</li>
<li><a href="http://www.askamathematician.com/">Ask a Mathematician / Ask a Physicist</a> used to be without competition, but xkcd's what-if is not really a threat.</li>
<li>John Baez's <a href="http://johncarlosbaez.wordpress.com/">Azimuth</a>, great researcher blogger switching from the purest of pure math to saving the world.</li>
<li><a href="http://bit-player.org/">bit-player</a>, math journalistic writer.</li>
<li><a href="http://blanchetblog.net/">blanchetBlog</a>, one of the first teacher bloggers we added who also helped us improve our twitter lists tremendously through her own math teacher list.</li>
<li><a href="http://www.brokenairplane.com/">Brokenairplane</a>, ex-teacher blogger, now google-math-ed blogger so to speak.</li>
<li><a href="http://williewong.wordpress.com/">Bubbles Bad; Ripples Good</a>, researcher blogger.</li>
<li><a href="http://busynessgirl.com/">Busynessgirl</a>, former college lecturer, tech-afficionado and LMS specialist.</li>
<li><a href="http://calculus7.org/">Calculus VII</a>, researcher blogger</li>
<li><a href="http://chronicle.com/blognetwork/castingoutnines">Casting Out Nines</a>, the only math researcher blogger on a major network, always interested in math ed technologies.</li>
<li>Gil Kalai's <a href="http://gilkalai.wordpress.com/">Combinatorics and more</a>, researcher blogger, part of the Gowers-Tao-group.</li>
<li><a href="http://momath.org/">MoMath</a>, to check what the upcoming Museum of Mathematics in Manhattan is up to.</li>
<li><a href="http://blog.computationalcomplexity.org/">Computational Complexity</a>, Lance Fortnow and Bill Gasarch blog about all sorts of topics, mostly TCS-related.</li>
<li>Sam Shahs' <a href="http://samjshah.com/">Continuous Everywhere but Differentiable Nowhere</a>, currently working hard to bring in a new wave of teacher bloggers.</li>
<li>Christian Perfect's <a href="http://checkmyworking.com/">cp's mathem-o-blog</a> -- hard to describe, always worth a read.</li>
<li><a href="http://www.mathteacherctk.com/blog/">CTK Insights</a>, from the make of Cut The Knot.</li>
<li><a href="http://www.dataisnature.com/">Dataisnature</a>, one of the top mathematical art blogs, posting sparingly but can't be missed.</li>
<li><a href="http://devlinsangle.blogspot.com/">Devlin's Angle</a> and all his other blogs (<a href="http://huffingtonpost.com/author/index.php?author=dr-keith-devlin">HuffPo</a>,)-- you can't miss Keith Devlin (seriously, he'll hunt you down and force you to listen or read or worse: do math)</li>
<li><a href="http://matheuscmss.wordpress.com/">Disquisitiones Mathematicae</a> another gem among researcher bloggers.</li>
<li><a href="http://divisbyzero.com/">Division by Zero</a></li>
<li><a href="http://dropseaofulaula.blogspot.com/">DropSea</a> Italian blogger.</li>
<li>[dy/dan](<a href="http://blog.mrmeyer.com/">http://blog.mrmeyer.com</a>] Dan Meyer's blog (teacher blog, now grad student blog).</li>
<li><a href="http://exzuberant.blogspot.com/">exzuberant</a> another teacher blog</li>
<li><a href="http://fawnnguyen.com/">Finding Ways to Nguyen Students Over</a> teacher blogger.</li>
<li><a href="http://flowingdata.com/">FlowingData</a> statistics and data visualization</li>
<li><a href="http://function-of-time.blogspot.com/">f(t), function of time</a> teacher</li>
<li><a href="http://gaussianos.com/">Gaussianos</a></li>
<li><a href="http://lamington.wordpress.com/">Geometry and the imagination</a></li>
<li><a href="http://girlsangle.wordpress.com/">Girls' Angle</a> an MIT, student run math-circle-type thing. For those who know the play, certainly more than good news.</li>
<li><a href="http://proooof.blogspot.com/">Gli studenti di oggi</a></li>
<li><a href="http://gottwurfelt.wordpress.com/">God plays dice</a></li>
<li><a href="http://scientopia.org/blogs/goodmath/">Good Math, Bad Math</a></li>
<li><a href="http://gowers.wordpress.com/">Gowers's Weblog</a></li>
<li><a href="http://www.abstractmath.org/Word%20Press/">Gyre &amp;Gimble</a></li>
<li><a href="http://rjlipton.wordpress.com/">Gödel's Lost Letter and P=NP</a></li>
<li><a href="http://ichoosemath.wordpress.com/">I Choose Math</a> Just Lanier, one of the Math Munch people.</li>
<li><a href="http://untilnextstop.blogspot.com/">I hope this old train breaks down...</a> a personal favorite since she is now teaching in Berlin :)</li>
<li><a href="http://images.math.cnrs.fr/">Images des mathématiques</a>, CNRS online magazine.</li>
<li><a href="http://poetrywithmathematics.blogspot.com/">Intersections -- Poetry with Mathematics</a>, a blog dedicated to poetry and mathematics.</li>
<li>[James Colliander's Blog](<a href="http://blog.math.toronto.edu/colliand/">http://blog.math.toronto.edu/colliand/</a>], another one of the Canadian top researcher bloggers.</li>
<li><a href="http://scholarship.claremont.edu/jhm/">Journal of Humanistic Mathematics</a>.</li>
<li><a href="http://haggisthesheep.wordpress.com/">Knot your average sheep...</a> one of the few pseudonymous (female) math bloggers.</li>
<li><a href="http://launchings.blogspot.com/">Launchings by David Bressoud</a> another top researhcer.</li>
<li><a href="http://lostinrecursion.wordpress.com/">Lost In Recursion</a> fantastic teacher blogger, one of the Math Munch people.</li>
<li><a href="http://www.lanostra-matematica.org/">Matem@ticaMente</a>, Italian teacher bloger.</li>
<li><a href="http://mathforlove.com/">math for love</a>, teacher.</li>
<li><a href="http://mathhombre.blogspot.com/">Math Hombre</a>, a teacher education blogger.</li>
<li><a href="http://mathjokes4mathyfolks.wordpress.com/">Math Jokes 4 Mathy Folks</a>, one of my first math blogs ever.</li>
<li><a href="http://mathmunch.wordpress.com/">Math Munch</a>, nuff said.</li>
<li><a href="http://www.mathalicious.com/">Mathalicious</a> young education startup.</li>
<li><a href="http://mathbabe.org/">mathbabe</a>, nuff said.</li>
<li><a href="http://mathematical-objects.tumblr.com/">Mathematical Objects</a>, mathematical art.</li>
<li><a href="http://micromath.wordpress.com/">Mathematics under the Microscope</a> researcher.</li>
<li><a href="http://mathe2008.wordpress.com/">mathematik, bücher &amp; meer</a>, one of the two German math blogs.</li>
<li><a href="http://www.scienceblogs.de/mathlog/">Mathlog</a>, and the other.</li>
<li><a href="http://mathymcmatherson.wordpress.com/">Mathy McMatherson</a> teacher blogger.</li>
<li><a href="http://blogs.20minutos.es/mati-una-profesora-muy-particular">Mati, una profesora muy particular</a>, teacher and researcher, Spanish.</li>
<li><a href="http://blog.matthen.com/">matthen</a>, fantastic visuals, almost always with code.</li>
<li><a href="http://www.ilpost.it/mauriziocodogno">Maurizio Codogno</a>, Italian journalist.</li>
<li><a href="http://maxwelldemon.com/">Maxwell's Demon</a></li>
<li><a href="http://mat.tepper.cmu.edu/blog">Michael Trick's Operations Research Blog</a>, researcher.</li>
<li><a href="http://misscalculate.blogspot.com/">misscalcul8</a>, great teacher blogger.</li>
<li><a href="http://mrhonner.com/">Mr Honner</a>, teacher blogger, art, bicycles and all around great guy.</li>
<li><a href="http://www.neverendingbooks.org/">neverendingbooks</a>, one of the first math bloggers I interacted with.</li>
<li><a href="http://nuit-blanche.blogspot.com/">Nuit Blanche</a>, amazing research blogger, allowing you to keep up with all of compressive sensing in one blog -- fantastic.</li>
<li><a href="http://orbythebeach.wordpress.com/">O.R. by the Beach</a>, research blogger</li>
<li><a href="http://page2rss.com/rss/69bacf7e3cfac715759da8b0db2f3188">Opinions of Doron Zeilberger</a>, thanks to page2rss as a feed :)</li>
<li><a href="http://orinanobworld.blogspot.com/">OR in an OB World</a>, another OR blogger.</li>
<li><a href="http://outofthenormmaths.wordpress.com/">Out of the Norm</a>, great research &amp; mathsjam blogger.</li>
<li><a href="http://cameroncounts.wordpress.com/">Peter Cameron's Blog</a> research blogger.</li>
<li><a href="http://blogs.ams.org/phdplus">PhD + epsilon</a>, one of the few tenure-track female bloggers, sadly hidden deep down in the rabbit hole that is the AMS website.</li>
<li><a href="http://nghoussoub.com/">Piece of Mind</a>, another great Canadian mathematician, more about the politics, but no less interesting or important.</li>
<li><a href="http://larkolicio.us/blog">Point of Inflection</a> great teacher.</li>
<li><a href="http://keespopinga.blogspot.com/">Popinga</a>, great Italian blogger, sometimes historic, sometimes artistic, always worth checking</li>
<li><a href="http://profkeithdevlin.org/">profkeithdevlin</a> Keith Devlin's personal blog.</li>
<li><a href="http://pulse-project.org/pulsemathsmathsx">Math/Maths</a>, THE mathematical podcast.</li>
<li><a href="http://punkrockor.wordpress.com/">Punk Rock Operations Research</a> cool OR blogging and podcasting.</li>
<li><a href="http://qedinsight.wordpress.com/">QED Insight</a> education blogger.</li>
<li><a href="http://quomodocumque.wordpress.com/">Quomodocumque</a>, one of the big research bloggers.</li>
<li><a href="http://regularize.wordpress.com/">regularize</a>, another German researcher, but writing in English.</li>
<li><a href="http://reperiendi.wordpress.com/">reperiendi</a>, a crazily mixed blog.</li>
<li><a href="http://www.republicofmath.com/">Republic of Mathematics</a>, teacher blogger.</li>
<li><a href="http://shuisman.com/">Sander Huisman</a>, great visuals.</li>
<li><a href="http://sarcasymptote.wordpress.com/">Sarcasymptote</a>, teacher blogger.</li>
<li><a href="http://minds.acmescience.com/">Second-Rate Minds</a>, a collaborative experiment in mathematical writing by Samuel Hansen and Peter Rowlett.</li>
<li><a href="http://sbseminar.wordpress.com/">Secret Blogging Seminar</a> the Berkeley grad students that are now faculty (and also gave you MathOverflow indirectly).</li>
<li><a href="http://www.scottaaronson.com/blog">Shtetl-Optimized</a>, Scott Aaronson's Blog.</li>
<li><a href="http://richardelwes.co.uk/">Simple City</a>, more journalistic in writing style.</li>
<li><a href="http://sketchesoftopology.wordpress.com/">Sketches of Topology</a>, great visual blog.</li>
<li><a href="http://spikedmath.com/">Spiked Math</a>, webcomics about mathematics.</li>
<li><a href="http://statisfaction.wordpress.com/">Statisfaction</a>.</li>
<li><a href="http://andrewgelman.com/">Statistical Modeling, Causal Inference, and Social Science</a>, statistician Andrew Gelman's blog.</li>
<li><a href="http://blog.tanyakhovanova.com/">Tanya Khovanova's Math Blog</a> researcher blogger doesn't cover it.</li>
<li><a href="http://ilaba.wordpress.com/">The Accidental Mathematician</a>, ditto -- not even close.</li>
<li><a href="http://aperiodical.com/">The Aperiodical</a>, nuff said before.</li>
<li><a href="http://education.lms.ac.uk/">The De Morgan Journal</a>, a fantastic experiment in what a journal can be.</li>
<li><a href="http://www.johndcook.com/blog">The Endeavour</a>, John Cook's blog, probably the mathematically inclined blogger with the most klout.</li>
<li><a href="http://geomblog.blogspot.com/">The Geomblog</a>, TCS blogger.</li>
<li><a href="http://laughmaths.blogspot.com/">The Laughing Mathematician</a>, researcher blogger but outreach focused.</li>
<li><a href="http://mathtourist.blogspot.com/">The Mathematical Tourist</a>, MAA's Ivars Peterson blog.</li>
<li><a href="http://themathematiciansshirts.wordpress.com/">The Mathematician's Shirts</a>, a project blog.</li>
<li><a href="http://numberwarrior.wordpress.com/">The Number Warrior</a>, teacher blogger.</li>
<li><a href="http://thonyc.wordpress.com/">The Renaissance Mathematicus</a>, history of science blogger par excellence and home of the HistSciHulk.</li>
<li><a href="http://shawncornally.com/wordpress">ThinkThankThunk</a></li>
<li><a href="http://huffingtonpost.com/author/index.php?author=tim-chartier">Tim Chartier</a>, one of three HuffPo math blogs (always makes me shudder to write that)</li>
<li><a href="http://eliatron.blogspot.com/">Tito Eliatron Dixit</a>, diverse Spanish blog.</li>
<li><a href="http://understandinguncertainty.org/">Understanding Uncertainty</a>, statistics blogger.</li>
<li><a href="http://www.walkingrandomly.com/">Walking Randomly</a>, great research blog, former perpetual host of the Carnival of Mathematics.</li>
<li><a href="http://terrytao.wordpress.com/">What's new (with Terry Tao)</a>, need no introduction.</li>
<li><a href="http://whatsonmyblackboard.wordpress.com/">What's on my blackboard?</a>, another HaggisTheSheep blog :)</li>
<li><a href="http://wildaboutmath.com/">Wild About Math!</a>, a high-level math entusiast and podcaster.</li>
<li><a href="http://www.withoutgeometry.com/">Without Geometry, Life is Pointless</a>, research blogger.</li>
<li><a href="http://womeninmathematics.wordpress.com/">Women in mathematics</a>, a blog run by female grad students at the Berlin Mathematical School.</li>
<li><a href="https://xianblog.wordpress.com/">Xi'an's Og</a>, Christian Robert's research, travel and climbing blog.</li>
<li><a href="https://yabm.wordpress.com/">Yet another blogging mathematician...</a>, researcher blog.</li>
<li><a href="http://www.yofx.org/">yofx</a>, comic blog.</li>
<li><a href="http://artymaths.tumblr.com/">You got your art in my maths!</a>, mathematical art.</li>
<li><a href="http://musingmathematically.blogspot.com/">{Musing Mathematically</a>,</li>
<li><a href="http://math-frolic.blogspot.com/">Math-Frolic</a>, a math enthusiast.</li>
</ul>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>maurizio codogno</strong>, 2012/11/08<br>
hallo Peter, and thanks for all the great work you has made in collecting math-related feeds! (yes, I am quite late in answering, but sometimes it is difficult to look for everything…<br>
As far as Italian blogosphere is concerned, I think that our added value is that we are few but well connected among us… and maybe we managed to overcome one of the greatest faults of Italian school: it favours a lot humanistic themes rather than scientific ones. So the few of us which are interested in math have a literary background too :-)
<ul>
<li><strong>Peter</strong>, 2012/11/11<br>
Mille grazie. That makes a lot of sense! It’s a great benefit to have literary skills — but in smaller language communities it’s probably critical (not that I’m defending the lack of scientific training in the Italian school system…).</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[n things a set theorist should have done at least once]]></title>
        <id>https://www.peterkrautzberger.org/0124/</id>
        <link href="https://www.peterkrautzberger.org/0124/">
        </link>
        <updated>2012-09-30T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>So there's a meme going around in the CS blogging community: &quot;Things that a ___ researcher should have done at least once&quot;. It started at <a href="http://geomblog.blogspot.com/2012/09/things-tcser-should-have-done-at-least.html">The Geomblog</a> by Suresh Venkatasubramanian, was picked up for complexity theory by Lance Fortnow at <a href="http://blog.computationalcomplexity.org/2012/09/things-complexity-theorist-should-do-at.html">Computational Complexity</a> and for game theory &amp; economics by Noam Nisam at <a href="https://agtb.wordpress.com/2012/09/28/things-a-agteer-should-do-at-least-once/">Turing's Invisible Hand</a>.</p>
<p>Now, I'm not really qualified to count up to \(n\), but I thought I'd give it a try anyway.</p>
<ol>
<li>Prove something to be independent of ZFC. (Bonus points if it is independent of CH as well.)</li>
<li>Find a &quot;natural&quot; statement and prove it's equivalent to CH.</li>
<li>Find a new forcing axiom (that is actually useful).</li>
<li>Find a new type of ultrafilter.</li>
<li>Find a new large cardinal.</li>
<li>Use a non-standard model of PA.</li>
<li>Use PCF theory.</li>
<li>Find a new cardinal characteristic of the continuum.</li>
<li>Collapse some cardinal characteristics of the continuum.</li>
<li>Separate some cardinal characteristics of the continuum. (Bonus points if the balance is kept.)</li>
<li>Improve a consistency result to a ZFC result.</li>
<li>Have an application outside of set theory.</li>
<li>Write a paper with Saharon Shelah.</li>
</ol>
<p>What else?</p>
<hr>
<p>Update Oct 1, 2012: there's now also a graph theory one by Derrick Stolee at <a href="http://computationalcombinatorics.wordpress.com/2012/09/28/things-a-graph-theorist-should-do-at-least-once/">Computational Combinatorics</a>.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Thony C</strong>, 2012/09/30<br>
Define an undefinable set.
<ul>
<li><strong>Peter</strong>, 2012/09/30<br>
Nice!</li>
</ul>
</li>
<li><strong>saf</strong>, 2012/09/30<br>
a variation of 11: prove a ZFC result via forcing
<ul>
<li><strong>Peter</strong>, 2012/09/30<br>
Nice. I thought about adding that but then I decided that 3 should cover that. but you’re probably right – it deserves independence (pardon the pun).</li>
</ul>
</li>
<li><strong>Asaf</strong>, 2012/10/01<br>
Find a new choice principle.
<ul>
<li><strong>Asaf</strong>, 2012/10/01<br>
Bonus points: find its location within the common principles’ hierarchy. E.g., it implies countable choice but not dependent choice.
<ul>
<li><strong>Peter</strong>, 2012/10/01<br>
Very nice — I didn’t think about choice principles (comes from working with ultrafilters 😉 )</li>
</ul>
</li>
</ul>
</li>
<li><strong>saf</strong>, 2012/10/01<br>
Have the following statements included somewhere in your proof:<br>
(a) “take a countable elementary submodel of \(\langle \mathcal H(\lambda)\,\in\,&lt;_ \lambda\,\ldots\) for a large enough regular cardinal \(lambda\), containing everything relevant to this proof&quot;<br>
(b) “note that by absoluteness, it suffices to prove that &quot;1+1=2&quot; holds in L&quot;
<ul>
<li><strong>Peter</strong>, 2012/10/01<br>
Thanks! Good stuff :)</li>
</ul>
</li>
<li><strong>David Roberts</strong>, 2012/12/09<br>
What about proving something independent of ZF? (over ZF!)
<ul>
<li><strong>Peter</strong>, 2012/12/09<br>
Not my cup of tea, but nice!</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A virtual Kaffehaus on g+]]></title>
        <id>https://www.peterkrautzberger.org/0123/</id>
        <link href="https://www.peterkrautzberger.org/0123/">
        </link>
        <updated>2012-08-12T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>So that went well.</p>
</blockquote>
<p>Two weeks ago I tried to do something that I always wanted to do and that <a href="http://boolesrings.org/scoskey/tag/hangouts/">Sam had done</a> a couple of times with a more specific focus. That is, use google+ hangouts to simply meet people.</p>
<p>If you don't know them by now (go read Sam's posts!), google+ hangouts are really the only reason to be on google+ for me. I know, I know, there's tons of mathematicians on google+ and really for a research mathematician it's probalby the best social network. But that's besides the point.</p>
<p>For me, the key feature are the hangouts. The hangouts are the first, free video conferencing system that <em>works</em>, in fact amazingly well, with a wealth of features (screensharing, collaborative writing and, of course, pirate hats), with the <em>on air</em> feature, it even allows you to record your hangout and have it on youtube afterwards. In short, it is a pretty good deal (you pay in privacy, of course) and you see a lot of fantastic people using it for all kinds of stuff, e.g. very prominently Barack Obama but also scientists such as <a href="http://www.youtube.com/user/TheBadAstronomer">Bad Astronomer Phil Plait</a> doing Q&amp;As or <a href="http://www.youtube.com/watch?v=0s1PZ-70bzk&amp;feature=plcp">virtual star parties</a>, hooking up a telescope to look at your favorite planets. It's fantastic stuff.</p>
<p>So what would I be doing with the hangouts? I just moved to LA, which means I left a good deal of friends and contacts behind (yet again) and I have the need to literally hang out with friends. Then there are also other people I always wanted to get in touch with. That is all these fantastic bloggers that I got to know on twitter, on their blogs and in other places, that are doing interesting stuff all the time -- I would love a chance to talk to them.</p>
<p>Finally, two weeks ago, I tried to have a hangout. I didn't announce it until it started -- and (surprise!) it didn't work at all. The simple reason was: nobody was around! Desperate that I was, I even made the hangout &quot;public&quot; (which means anybody can join in) which quickly got really weird. Thankfully, my connection immediately crashed when random people showed up and tried talking to me. (I should've known better, actually since there are websites that list public hangouts -- be careful what you wish for...)</p>
<p>How could I create a hangout as I had wanted? A hangout where you actually want to be open for people to join but not demanding it from them. You don't want to be open to everybody, but you want to be open to a lot of people, people you may have never met in person but know by some form of communication or another.</p>
<p>Last week, I tried to do it a little bit better and I specifically invited people to an &quot;event&quot;, another google+ feature (as on other social networks) which annoys people with invites to random events that they don't care about.</p>
<p>To be less offensive, I did this last minute, i.e., the evening before the hangout, and explained the point of this in the &quot;invitation&quot;. Mostly, I wanted to give people ample opportunity to ignore the &quot;invitation&quot; because I wanted to keep the hangout light, informal, no strings attached.</p>
<p>And it actually worked. I got a chance to hook up with one American and two English mathematicians and bloggers that I actually quite admire -- <a href="http://checkmyworking.com/">Christian Perfect</a>, <a href="http://drvinceknight.blogspot.com/">Vincent Knight</a> and <a href="http://mrhonner.com/">Patrick Honner</a>. All four of us where there for only half an hour but it was wonderful: I had my morning coffee, talked to interesting people in person for the first time and just generally enjoyed being able to connect.</p>
<p>And that's what I would like to have. The equivalent of a <a href="https://en.wikipedia.org/wiki/Viennese_caf%C3%A9">Wiener Kaffehaus</a>, a place where interesting people gather and you're essentially sure that you'll run into someone, even though you might not know who exactly or for how long. But when you do, you can sit down, sip your coffee and have a decent conversation.</p>
<p>But any good experiment requires reproduction, so yesterday I followed the same pattern and chanced upon Patrick Honner, Vincent Knight, <a href="http://danaernst.com/">Dana Ernst</a>, our own Sam Coskey and even <a href="http://kurt.scitec.kobe-u.ac.jp/~andrewbt/">Andrew Brooke-Taylor</a> (on <a href="https://plus.google.com/117349872509920766423">g+</a>) stopped by for a few minutes before going to bed (in Japan). Arguably, I talked too much (nobody who's met me will be surprise), but it was a lot of fun.</p>
<p>Well, that's three data points. But it has again strengthened my conviction that hangouts/videconferencing will have a huge impact. Don't get me wrong. We're not there yet. For example, when Andrew jumped in, I would have loved to &quot;get up from the table&quot; and sit down with him privately to catch up. But nevertheless, hangouts go in the right direction. As a video chat room they are not yet as flexible as a Kaffeehaus, but it feels like we're almost there and that it's not the technology per se that's holding us back anymore (10 video-streams are almost certainly enough for my purposes).</p>
<p>Soon enough, we might get a real Kaffeehaus, where you can sit at a single table following a single conversation, step away for a nice quiet chat (yet overhearing the ongoing conversation) or wander over and meet some new people at some new table.</p>
<p>For mathematics (and research in general) this is a great opportunity, to be able to connect with other researchers (or even the great unknown &quot;public&quot;) in yet another crucial way. If MathOverflow becomes the common room, then video-conferencing could become the coffee shop.</p>
<p>I look forward to trying this again next week. If you want to drop by, just let me know.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[self-publishing, the academic community and LaTeX fanboyism -- a comment at Devlin's Angle]]></title>
        <id>https://www.peterkrautzberger.org/0122/</id>
        <link href="https://www.peterkrautzberger.org/0122/">
        </link>
        <updated>2012-08-11T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Yet another one of those &quot;Peter babbled too long on somebody else blog&quot;-posts. This time at Keith Devlin's MAA column/blog <a href="http://devlinsangle.blogspot.com/2012/08/the-future-of-textbook-publishing-is-us.html">Devlin's Angle</a></p>
</blockquote>
<p>A few comments.</p>
<p>About your reply to Corey's comment. &quot;That will surely change very quickly&quot; is something I've been hearing all my (academic) life but nothing is happening -- academia proves highly conservative. The main problem is that the young researchers willing to seriously experiment will often not gain enough &quot;traditional&quot; merit compared to those who just play the game -- and those who successfully play the game will rarely see the need to experiment later.</p>
<p>This is a serious problem that would deserve much more effort from the few established researchers that are both influential, established, and open to new ideas: help young researcher get the credit they deserve with their experiments such as self-publishing (can't help but add: and publish open-access or even open-source). Or in other words: it's great to hear that self-publishing worked for you, this time, but can somebody else reproduce it?</p>
<p>Finally, LaTeX (as a binary) is nice for producing print output -- but practically incapable of doing anything else (and actually, professional typesetters will easily complain about the quality of TeX's output).</p>
<p>As Peter Rowlett and yourself pointed out, even the best reflow-PDF viewers (Kindle, Nook) are quite limited. However, that is actually the author's fault. It's like trying to build an iPad with manufacturing equipment from 1978 (or for that matter, teaching a MOOC in 1978).</p>
<p>So instead of using LaTeX to do what it can't do -- produce content for an html environment -- authors need to take the next step and switch to authoring systems that can produce both good print and good html. That's hard right now, but worth an experimental effort (good keywords: pandoc, asciidoc, restructured-text, sphinx-doc -- and I'd volunteer right away to help actually.)</p>
<p>After all, with the adoption of MathML3 in two critical standards (html5 and epub3) and with technologies like MathJax, mathematical content in html finally makes sense.</p>
<p>(Disclaimer: I'm involved in the MathJax development)</p>
<hr>
<blockquote>
<p>Thanks to <a href="https://plus.google.com/u/0/102694188490946876191/posts/R7Kv6ZXdQsZ">this discussion on g+</a>, here's I just had to add another comment</p>
</blockquote>
<p>One small addendum. Here's such an experiment going all the way to XML: <a href="http://linear.ups.edu/index.html">Rob Beezer's Linear Algebra book</a> which (due to it's flexibility) is part of IDPF's official <a href="https://code.google.com/p/epub-samples/">epub3 sample repository</a></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Has it really been a year?]]></title>
        <id>https://www.peterkrautzberger.org/0121/</id>
        <link href="https://www.peterkrautzberger.org/0121/">
        </link>
        <updated>2012-08-07T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>This is a joined post with Sam -- go <a href="http://boolesrings.org/scoskey/has-it-really-been-a-year/">comment at his place</a>!</p>
</blockquote>
<p>Almost exactly a year ago, the two of us (<a href="http://boolesrings.org/scoskey/">Sam</a> and <a href="http://boolesrings.org/krautzberger/">Peter</a>) sat down to talk about what we could do together to help mathematicians using the internet.</p>
<p>A few months earlier, we had started a small project we called SetTheoryTalks, <a href="http://settheorytalks.wordpress.com/">a simple wordpress.com blog</a> that announces and aggregates set-theoretic talks from around the world. Even though it has grown to <a href="http://settheory.mathtalks.org/">its own website</a>, STT is, at heart, a very simple service, and we wanted to take another step.</p>
<p>Essentially, we just wanted to do a better job with our professional home pages. Sam for example was quite simply sick of ssh'ing in to the server -- it's not the way professional web pages are updated anymore, and it certainly isn't conducive to displaying the most up-to-date information. (Peter on the other hand just wanted some cool and shiny stuff that hid his incompetence at web design).</p>
<p>But while we were at it we thought: why can't we do something that helps everybody? There are all of those weird and sometimes laughable &quot;home pages&quot; that we constantly come across when we search for mathematicians and articles. Can't we do something about that?</p>
<p>We basically saw two major problems with math home pages. The first is what we called &quot;the Geschke problem&quot;. (We hope <a href="http://www.hcm.uni-bonn.de/homepages/prof-dr-stefan-geschke/">Stefan</a> won't take offence -- in fact, his problem has since been fixed.) Until recently, if you searched for Stefan Geschke on the internet, you would find his FU Berlin profile page, which provided some basic but outdated information about him. At the bottom of the page there was an inconspicuous link which said &quot;This page now lives at Boise State&quot; and took you to another wonderful homepage of Stefan Geschke at BSU. Again, scroll to the bottom of the page and lo and behold you found a link saying &quot;This page now lives at the Hausdorff Center&quot; and took you to his true (current as of 2012) home page. It's nothing new, but like all researchers, mathematicians move around a lot, and their web sites shouldn't have to hide behind their institution.</p>
<p>The second issue we wanted to tackle we called &quot;the Zeilberger problem&quot;. The root of this problem is that mathematicians have been using the internet for a very long time. Since the early nineties we have actively used the web for preprints, for notes, for lecture notes, for research material and so on. But meanwhile, the internet has been changing and we have not changed with it. A Mathematician such as <a href="http://www.math.rutgers.edu/~zeilberg/">Doron Zeilberger</a> can get away with that because of his stature. But other researchers really have no excuse when their web site looks as if it was written in 1992---and moreover makes it extremely hard to interact with the researcher, i.e., uses none of what modern web technology has to offer in terms of interactivity, exchange and generally presentation of content. The web is much more than just hand-written HTML with GIF-tiled backgrounds.</p>
<p>And so we registered a domain and set up shop embracing the wonderful <a href="http://www.wordpress.org/">wordpress</a>. It <a href="https://www.peterkrautzberger.org/0074/">took a while</a> to come up with a name but we chose Booles' Rings and <a href="http://boolesrings.org/">boolesrings.org</a>.</p>
<p>It's been quite a ride in the last year. We started out with a group of really just three, including the two of us and Katie Thompson. We slowly expanded to arrive at roughly 10 users, which is not too shabby considering that set theorists aren't exactly known to be the most outgoing of people. And while we could not have predicted how it would look today, the outcome exhibits exactly what we had hoped: the members of Booles' Rings are using their sites in quite a diverse fashion.</p>
<p>First of all, a good deal of academic progress has been disseminated on Booles' Rings. For instance, Joel Hamkins has an incredible academic output and he continually posts his talks and papers. Others like Vika Gitman have followed his lead, posting long summaries of her latest research.</p>
<p>Then you have people like Saf who write detailed notes on research-level mathematics, piling through Todorčević's lecture notes, and making a serious contribution to the amount of of information that is available on the web. And yet another style can be found at François's site where short posts with just a quote, a comic, or a problem meet serious academic research and an overflow of ideas from his work at MathOverflow.</p>
<p>Of course, we also had a few positive discussions about blogs, publishing, and interactive home pages in general. While Sam covered everything from refereeing to experimental math-hangouts on G+, Peter went all the way from the ongoing publishing debate to experimenting with a format he calls the &quot;micro-contribution&quot; (a nugget of research that shouldn't be kept secret but which is too small for a formal journal).</p>
<p>Overall we are very happy with this small ecosystem of articles. But there are still many more things we wish to accomplish. First and foremost, we want to introduce the concept of a dynamic web page to a much wider audience. To do this, we plan to build a repository of documents and tools to help others reproduce our experiment. We also plan to create a version of the site that is open to the public---a version which is more stable and which learns from the Booles' Rings experiment.</p>
<p>Finally, we want to make Booles' Rings even more useful to academics by adding more features. While we have developed a few plugins and scripts to help with dissemination and collaboration on boolesrings, a lot more can be done. For instance, we plan to develop a plugin to use your home page as courseware for teaching.</p>
<p>We hope we can count on you to help us get us to the next stage and we look forward to the second year in the life of the Booles and their Rings!</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Where was I?]]></title>
        <id>https://www.peterkrautzberger.org/0120/</id>
        <link href="https://www.peterkrautzberger.org/0120/">
        </link>
        <updated>2012-07-24T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Oh yes, I live here now. Some call it paradise, others moloch. I think both are right but what do I know after a two weeks?</p>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2012/Angelino-Heights.jpg">
    <img alt="Angelino Heights, est. 1886, 1st historic preservation overlay zone est 1983" src="https://www.peterkrautzberger.org/assets/2012/Angelino-Heights.jpg">
  </a>
  <figcaption>
  Angelino Heights, Los Angeles, CA.
  </figcaption>
</figure>
<p>Hopefully, I'll get back to blogging a bit more regularly and tell you more.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>François G. Dorais</strong>, 2012/07/24<br>
Most people who “move to LA” actually move to Santa Monica, Pasadena, Long Beach, or whatnot… I see you moved right in the center of LA! Very nice!</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SMBC on madness…]]></title>
        <id>http://www.dorais.org/news/2012-07-17-smbc-on-madness.html</id>
        <link href="http://www.dorais.org/news/2012-07-17-smbc-on-madness.html">
        </link>
        <updated>2012-07-17T21:59:38Z</updated>
        <summary type="html"><![CDATA[<p>It’s very easy to imagine a mad scientist: combine a bad hair day with a lab coat, surround with vats, oscillators, and other instruments, throw the mix into a cave and voilà!</p>

<p>It’s much harder to imagine a mad mathematician: bad hair and … what? Fortunately, <a href="http://www.smbc-comics.com">SMBC</a> has figured it out!</p>

<p><img src="http://www.smbc-comics.com/comics/20120717.gif" alt="Mad Mathematician!" /></p>]]></summary>
        <author>
            <name>François G. Dorais</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11 dreams for the publishing debate, the complete version]]></title>
        <id>https://www.peterkrautzberger.org/0119/</id>
        <link href="https://www.peterkrautzberger.org/0119/">
        </link>
        <updated>2012-07-11T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>This is a double-post of sorts. The reasons is that it took me a very long time to write this (in fact, the first draft is marked April 18). In the process, quite a number of versions were stored by Wordpress. As you can see, I ended up splitting the original post into 11 individual ones. (Actually, I ended up extending each of the individual posts, adding another ~1000 words to it, a whopping 4000+ words.) Anyway, the point is, I wouldn't want to delete this original draft for its history should be quite interesting if I can ever get myself to make all revisions public (there's some rude ranting in there). So please excuse this double post.<br>
As always, check out the <a href="https://www.peterkrautzberger.org/0108/">first post</a> for more context.</p>
</blockquote>
<p>These are dreams. Some are realistic---perhaps just around the corner; others are way out there---basically crazy. Some will apply to everyone, others only to some. But all have diversity in mind, diversity in our expectations of who researchers are and what they do.</p>
<h3>1. write fewer original-research papers</h3>
<p>I know what you're going to say. But hear me out. This is at the core: to enable researchers to publish fewer &quot;new result&quot;-papers.</p>
<p>I believe all major problems brought up in the debate are, at the heart, caused by the immense increase in publications -- but not the global increase, the personal one. You have to publish far too much/big these days to get a half-decent position/grant. Increasing publication numbers did not increase the quality of research or, for that matter, the &quot;quality of life&quot; in our communities.</p>
<p>Instead, the <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2909426/">massive inflation</a> is <a href="http://carlzimmer.com/articles/index.php?subaction=showfull&amp;id=1336594400&amp;archive=&amp;start_from=&amp;ucat=15&amp;">killing us</a>, devaluating everything we do as researchers. More papers mean that our papers are worth less. Having to publish more papers means we produce more research of questionable quality (unintentionally and otherwise). Especially young researchers have to publish for metrics instead of quality. Worst of all, evaluating researchers only by this steam-punkesque output means that the jobs go to people with this one singular skill -- writing the right kind of papers to please the editorial boards of the right kind of journals -- leading to an intellectual monoculture instead of diverse, stable, rich communities. In particular, the pressure works against women and minorities as they often start with and continue to face disadvantages in their careers that make it harder to produce the desired &quot;output&quot; in the desired time frame.</p>
<p>(If you're wondering why I'm not bashing &quot;evil publishers&quot;. I don't think they are the problem -- we are. If you are happy with the inflation of papers-in-journals, then big publishers are what you need.)</p>
<h3>2. get real credit for surveys, reviews and exposition</h3>
<p>Surveys, reviews and expositions are research -- nothing more, nothing less. We live in a time where it is actually <em>more</em> important to write expository work. Why? Because we've optimized our production pipeline so well that there is no shortage of new (looking) results. Yes, you can argue about &quot;relevance&quot; (I won't, but I can't stop you). But if you're serious about all that &quot;research for research's-sake&quot;-talk, then you might notice that we've figured out how to educate people in the tens of thousands every year that do nothing else but churn out result after result.</p>
<p>As <a href="http://blog.felixbreuer.net/2012/02/27/beyondtheorems.html">Felix aptly wrote</a>: we need to move beyond &quot;new&quot; results. And this means to step back from them and, well, review. Surveys are the glue that holds our fields together, holds our communities together. We do it all the time -- if you read a paper thoroughly, you'll most likely write a review anyway. As we aggregate, work on larger projects or grant proposals these aggregate and easily become surveys and expositions. We need to make all of these public so that the community and the original author(!) can benefit from this enormous creative output that otherwise might only show up in a reading seminar or a journal club.</p>
<p>Mathematicians usually do even more. If we read a paper, we create our own version of the results. Mathematics need these just like music needs different interpretations. We need to give people who are &quot;just&quot; re-writing proofs the credit they deserve, the credit for keeping results alive, accessible and understandable to a wider audience than the original author and referee.</p>
<p>And with credit, I don't mean vouchers for some bookstore. Surveys must be first-class citizens! Surveying and reviewing other peoples work belongs on your CV, it is no less original than your &quot;original research&quot; and every department should have people that are exceptional at it, that are better at surveys, reviews or exposition than &quot;new&quot; research and add to the diversity of a department.</p>
<h3>3. get real credit for refereeing</h3>
<p>Refereeing is research, just like surveys and &quot;new results&quot;. It might seem redundant after dream #2 (and in many ways I would say that's the goal), but given the importance of refereeing right now and the way we do it, it's separate.</p>
<p>Currently, good refereeing seems nearly impossible. With the increase of publications we can't even catch up with what's happening in our own narrowly focused interests -- how, then, can we expect to referee properly? Sam tells his own funny but sad <a href="http://boolesrings.org/scoskey/peer-review-failure/">story of refereeing honestly</a> but the problem runs deep. Good referees are hard to find and when you find them, they could be writing a paper instead of refereeing -- and why should they not?</p>
<p>There are many ways we could improve refereeing. We can (and should) split up the different stages of refereeing (reference checking, correctness checking on different levels, opinion gathering etc), we should open pre- and post-publication peer review (and in-between peer review), we should use alternative methods to collect these reviews (instead of review journals that have at most one opinion per paper).</p>
<p>One key of refereeing is forming an opinion -- and voicing it. That's very hard, in particular for young and disadvantaged researchers who fear significant repercussions. But we don't need less people sharing their opinions on other researchers' output, we need more (whether they agree or not); it's a responsibility both to our own research communities and to a larger society.</p>
<p>But all of these are very unlikely to work, if we don't find a way to give referees the credit (and criticism) they deserve. Before we can <a href="https://xianblog.wordpress.com/2012/05/24/in-praise-of-the-referee-2/">praise referees</a> we need tools to evaluate refereeing, both in current and future form. Above all, we need to be able to put refereeing on the CV, it's part of the research qualities every strong department should strive for.</p>
<h3>4. get real credit for communicating</h3>
<p>Communicating other people's work through surveys, exposition and reviews is important. Then there's communicating to students aka teaching. This is an especially sore point for mathematics where undergraduate teaching has become a blunt tool to weed out graduates for other disciplines -- our self-respect seems greatly lacking. And then, of course, there's spreading the word to the wider public.</p>
<p>Have you ever noticed that many of the great researchers are excellent communicators (and teachers and surveyors and referees)? I would go as far as to say that a <em>truly</em> great researcher will be great in at least one of these ways to communicate. Without this, you're only a great something-else. We should cherish not just one ability of our truly great minds, but all of them. Right now we promote researchers according to how their &quot;new result&quot;-output compares to the &quot;new result&quot;-output of the truly great ones. Why are we so one dimensional?</p>
<p>Also, communication goes both ways, so we must listen. Can you imagine a graduate-student-run, &quot;Law Review&quot;-like journal for mathematics? Graduate students are perfect for forcing you to reflect on your research -- we should encourage them to make their thoughts public (including anonymously and pseudonomously). But we mathematicians need to go further. When <a href="http://en.wikipedia.org/wiki/Robert_Parris_Moses">Bob Moses</a> was speaking at Michigan earlier this year he argued that history will judge us as math literacy becomes a <a href="http://news.harvard.edu/gazette/2001/05.17/e04-moses.html">civil rights issue</a> in the 21st century. Are we listening?</p>
<p>Without communication, we risk the longevity of our own research areas because we won't be <em>understood</em> by the next generation, by other areas and by society as a whole. But this means <a href="http://scientopia.org/blogs/scicurious/2012/06/06/on-outreach-somethings-got-to-give/">something's gotta give</a> and we need to accept that by giving real credit.</p>
<h3>5. sharing all our work every way we can</h3>
<p>One battle that most scientists are still fighting -- full self-archival rights -- mathematics has long won. We need to make this happen for everyone. We must use the arXiv, our homepages or (if you must) walled gardens such as <a href="http://www.academia.edu/">academia.edu</a> and <a href="http://www.researchgate.net/">researchgate</a>. But we should also embrace more recent alternatives like <a href="http://figshare.com/">figshare</a> and <a href="http://github.com/">github</a> to post <em>all</em> our research publicly -- preprints, notes, lecture notes, expository notes, simply everything. <a href="https://en.wikipedia.org/wiki/Open_Notebook_Science">Open notebook science</a> is the key, but it's in its infancy. We need to find ways (many different ones) that work for a larger part of our communities so it becomes easier for people to experiment with it and to make it something even better. It might not be for everyone, but it's something everybody will benefit from.</p>
<p>However, the truth is that even among mathematicians a large group doesn't use the arXiv, let alone keep professional homepages deserving the name. I know that especially older researchers often hesitate because technical issues &quot;are more trouble than it's worth&quot;. This is a challenge and we must argue against this and more importantly help to sort out problems, within departments, within small research communities etc to overcome these obstacles. Approach people, ask them why their papers aren't availabe and help them put them properly online. In all other cases: <a href="https://sbseminar.wordpress.com/2010/02/09/grothendiecks-letter/">Don't be a Grothendieck</a>.</p>
<h3>6. publishing in smaller increments</h3>
<p>Have you ever read a paper that seemed to hide its true goal because the author wasn't finished but had to publish something out of the pressure of not having a job otherwise? Have you ever read a paper that made a small but reasonable result look much more than it really was just so that it will make the least publishable unit? Have you ever read a paper that was so badly written that you couldn't make sense of it?</p>
<p>Paradoxically, one way to publish fewer &quot;new results&quot; papers might be to publish more but differently. For scientists this might seem easier, publishing as the data comes in. But even for mathematics we have all those little results -- the small gems, the one-line-proof, the clever counterexample, the good reformulation, the useful shortcut -- all those could be published quickly and openly instead of waiting to find enough to &quot;make it a paper&quot;. Just like data, these could be reviewed publicly much more easily and we should get proper credit for doing so (both author and reviewer).</p>
<p>Longer results could (depending on their nature) be published incrementally, with multiple, public revisions. Take the preprint idea one step further and make your writing process public. Use a revision system like github to expose the process. Allow for outside input in your writing process, in your working process. The internet makes us an intricately connected community and we can work together in one big virtual seminar. There are already excellent examples in that area. In mathematics in particular, we have the <a href="http://polymathprojects.org/">Polymath project</a> or Ryan O'Donnell's <a href="http://www.analysisofbooleanfunctions.org/">Analysis of Boolean Functions</a>, a text book he's working out as a blog.</p>
<p>But as I've argued <a href="https://www.peterkrautzberger.org/0107/">Polymath doesn't work for very many people</a> so, again, we need many, many more projects like these so that more people have the opportunity to find a way that works for them.</p>
<p>There's of course a risk -- this could create a lot of noise as incrementally published results implode when data turns out to be flawed, proofs disintegrate and general anarchy rears its head! But I think it's worth the risk. Search technology is constantly improving and good scientific standards should ensure that failed research is marked accordingly. And we have so much to gain! We might be able to finally give credit for failing productively -- the main thing researchers do anyway, we fail and fail and fail until we understand what's going on. Sometimes we have to give up, but why shouldn't somebody else continue for us?</p>
<p>Even if your research implodes, you should get credit and, much, much more importantly, you will help others not to repeat your mistake. <a href="http://boolesrings.org/vonheymann/">Fred</a> once worked on a nice old problem which, after a few months, clearly didn't get anywhere. But he realized that all his attacks had probably been attempted before and so he wrote a pre-print on all the ways to fail, published <a href="http://boolesrings.org/vonheymann/publications/code/">his code along with it</a> so that people in the future might benefit from his failure. Or as <a href="http://www.math.rutgers.edu/~zeilberg/Opinion39.html">Doron Zeilberger wrote</a>: if only John von Neumann's maid had saved all the notes he'd thrown away each day!</p>
<p>Or to put it differently: the most exciting result in 2011 was having <a href="http://m-phi.blogspot.com/2011/10/inconsistency-of-pa-and-consensus-in.html">no result about Con(PA)</a>.</p>
<h3>7. an affordable open access model</h3>
<p>Research publications should be free, for both authors and readers. When it comes to traditional journals, there are already some in mathematics (e.g. <a href="http://nyjm.albany.edu/">NYJM</a>) that offer open access without any fees. I believe we can move to a journal system that is entirely open access and without publishing fees but we're not there yet. Mathematical journals are said to have profit margins of 90% so we should be the first to get there. Gold open access is already realistic and, more importantly, can be made affordable right now. With <a href="http://peerj.com/">peerj</a>, this is already around the corner on a much larger scale.</p>
<p>On the other hand, it seems natural to me to return academic publications to universities and academic societies. For journals, this could simply be done PLoS-ONE style (checking correctness, not &quot;importance&quot;) and our institutions could certainly make such journals open access, non-profit and actually free (just have each department produce one journal). But new ways of doing and sharing research will hardly fit into the journal model. These methods will be much more user centric, will be about people, not publishers. And the natural place to store information about people is their professional homepage as a repository of their work. It seems natural that universities or academic societies could play a much better role in this then proprietary social networks.</p>
<p>However, one problem we'd be facing is that journal publishing is the cash cow of many societies and this money is often used to cross-finance important services. This is not helpful in a time where <a href="https://web.archive.org/web/20140723061813/http://blog.findings.com/post/20527246081/how-we-will-read-clay-shirky">publishing is a button [Wayback machine]</a>. We'll have to find another way to finance things that need financing and we'll have to talk about that, too. Additionally, if we move scientific &quot;publishing&quot; to the next level, there will be new costs: costs for research into doing it, costs for experiments, costs for failures. We need to talk about those, too.</p>
<h3>8. a cultural change of doing research (and metrics for it)</h3>
<p>If we publish less &quot;new results&quot;, some structural problems might just disappear. Fewer papers means fewer journals means fewer subscriptions means fewer refereeing. Smaller workload and smaller costs. But this can only work if we have tools to nevertheless show what happens in between writing-down-a-decent-result-which-takes-years-dammit. Thanks to the internet, we can actually hope to do this. But the internet will also change everything (again and again) and it will change our communities (again and again). We need to invest resources right now to be able to benefit from this change, find a way to evolve into a work mode that is more appropriate for what is yet to come than what was in the past. We need to get into a constant-change mentality and we need to make this worth everybody's while.</p>
<p>Our funding bodies, academic societies, universities and other institutions must fund more experiments for doing research differently and the metrics needed for this. At the very least, we need more incubators like Macmillan's <a href="http://www.digital-science.com/">Digital-Science</a>, but also in a non-profit fashion along the lines of <a href="http://www.mathjax.org/">MathJax</a>'s business model. Reversely, our communities must value anybody's effort of joining new experimental platforms such as MO/math.SE, blogs, citizen science projects, polymath-esque projects, wikipedia and all those platforms that are still only dreams. The <a href="http://altmetrics.org/manifesto/">altmetrics</a> people are already setting many good examples and platforms such as Stackexchange and Wikipedia are working hard to develop reputation technology that will allow us to measure people's activity in these new scientific environments.</p>
<p>This, of course, means breaking out of the mono-culture of &quot;papers in journals&quot; -- a rough cultural change. Nobody talks about this drastic change which, I believe, makes it is the biggest problem in this entire debate. If we change the way we do (and evaluate) research, then we ask incredibly much of the people who are working well in the current model, who are good at (only?) writing the right kind of papers for the right kind of journals. It would be a revolution if people were hired because their non-traditional research activities outweigh the traditional paper count of other applicants -- in other words, if hiring would happen strategically, with that kind of diversity in mind. Case in point: even Michael Nielsen overlooks this problem completely in <a href="http://michaelnielsen.org/blog/reinventing-discovery/">his wonderful book</a>.</p>
<p>This change is even more important for smaller research areas (and must be made to work for them) who can't play the impact factor game. Failing to adapt, might even mean extinction in this case. But the potential is equally great as more diverse ways of doing research can also mean a better chance to work across fields and improve collaboration and visibility of small fields.</p>
<h3>9. propagating the Shelah Model -- encouraging bad writers to seek out good writers</h3>
<p>This may seem a very math-specific dream, possibly extending to the humanities, but it does apply to the sciences in more than one way.</p>
<p>Not only do we have too many &quot;new result&quot; papers, we also have too many horribly written papers. Although there's certainly a talent to being a great writer of research publications, we're facing the problem that our communities just down care enough to enforce even mediocre standards of writing. This is particularly hard with leading researchers who will find their manuscripts barely scrutinized.</p>
<p>Much worse, however, young researchers have an incentive <em>not</em> to care for the quality of their writing and the work necessary for it. Instead the motto is: &quot;Just get it by the referee and be done with it! You could produce a new result while you waste your time revising this one!&quot;. Referees and editors in turn have little incentive to spend their unpaid time improving a paper, so it's easier to simply dismiss a paper or ignore the communicative shortcomings (after all, the referee understood the damn thing...).</p>
<p>As <a href="http://logic.dorais.org/archives/630">Dor-Bar Natan said</a></p>
<blockquote>
<p>Papers are written so that their author(s) can forget their content and move on to other things.</p>
</blockquote>
<p>The lack of quality control in academic writing endangers long term accessibility of our research as much as data supplements in proprietary formats. In the long run, it makes papers less trustworthy and compromises the greatest strength of research, to build on earlier work. Simply put, archival is rather pointless if nobody can comprehend the content.</p>
<p>Of course, some people are more skilled, some are less skilled as writers. So why not join them up? <a href="https://en.wikipedia.org/wiki/Saharon_Shelah">Saharon Shelah</a> has published over 1,000 papers with 220 co-authors. Not only does the number of co-authors allow Shelah to produce more papers, it also allows the community to understand them better. Yet some of his co-authors are mocked as &quot;Shelah's secretaries&quot;, supposedly not publishing enough &quot;alone&quot;. Besides being pathetic ad-hominem attacks, this completely overlooks the fact that in many cases only these co-authors make Shelah's incredible output accessible to the research community.</p>
<p>Let's have editors and referees tell bad writers to find a capable co-author instead. It should be a win-win situation -- good writers will get to be on more papers and researchers lacking in writing skills get their thoughts polished so that other people can actually build on their work. As a bonus, the papers get some pre-publication peer-review and editors and referees shoulder a smaller workload. All we have to do is give up the notion that only &quot;new results&quot; are acceptable research currency. It seems a small price to pay.</p>
<p>And don't call them secretaries, when they really are smiths. They might not mine the ore, but without them it's all a pretty useless lump of rock.</p>
<h3>10. getting from the come-to-me mentality to the go-out-and-find-them mentality.</h3>
<p>Sometimes in my dreams, <a href="https://gowers.wordpress.com/2011/10/31/how-might-we-get-to-a-new-model-of-mathematical-publishing/#comment-12847">somebody screams</a> &quot;I need journal rankings and impact factors because that's the only way to weed out 600 applicants&quot; and I awake sweating, panicking, thinking: you're doing it wrong!</p>
<p>It's quite simple really. If you have a job which attracts 600 serious applicants you should be headhunting to find the best fit -- not passively wait for applications to pile on a search committee's desk. Of course, the current system does not allow such a behavior. But without a doubt this is a better strategy for hiring a candidate, a strategy with an actual chance of finding a good fit for your department, for all aspects of research.</p>
<p>This simple idea is far fetched given the established system. There would be many challenges to change our culture in this direction, not the least of which is keeping nepotism in check. I don't think it will really happen, actually, even if I dream it would.</p>
<p>But to use impact factors instead is simply lazy. The fact that we rely on this is actually damaging to our community as it is a metric that can be badly gamed and is heavily biased towards mainstream research. Needless to say, hiring committees are yet another research activity which deserves much more recognition. Only if this work gets proper acknowledgement is there any chance to spend more resources on a productive strategy for one of the highest impact activities of any researcher -- hiring fellow faculty members.</p>
<h3>11. a democratization of the communities</h3>
<p>Here's my biggest dream: a democratically organized scientific community. With this I'm not talking about the challenges of representing interests of scientific communities within a democratic society. Also, I'm not talking about the democratic aspects of <a href="https://en.wikipedia.org/wiki/Citizen_science">citizen science</a>. (Both of these are extremely important, of course.)</p>
<p>Instead, I'm baffled by the aristocratic and often oligarchic structures of scientific communities. Can you imagine editorial boards or grant committees being appointed through a democratic process, say through a parliament of researchers? And can you then imagine this parliament to be elected by <em>all</em> researchers of a specific field -- the faculty of small colleges, the researchers in the industry, the grad students, the postdocs, they'd all get the same vote as prize winning researchers in this?</p>
<p><a href="http://agtb.wordpress.com/2011/11/03/the-good-things-about-journals/">Noam Nisan once wrote</a> a quote that (brutally out of context) reminds me of 18th century aristocracy:</p>
<blockquote>
<p>[...] one shudders at the thought of papers being evaluated by popular vote rather than by trusted experts.</p>
</blockquote>
<p>It seems true enough until you ask: who decides which experts are considered trusted?</p>
<p>One of the biggest problems of academia today is that positions of power and responsibility are assigned by what is currently considered academic merit -- basically, the &quot;new results&quot; count, impact factors, blah blah. This often leads to problems, since researchers who are exceptional at producing new results are often poor at managing our communities. But there's something more fundamental at play: meritocracy only seems fine until you notice <a href="http://mathbabe.org/2012/05/05/the-meritocracy-myth/">there's no such thing</a>. Academia is not about merit, it is about reputation -- and reputation is currently exclusively determined by the journals you publish in and hence the editorial boards that think your research is &quot;interesting&quot;. However, appointments to these editorial boards are essentially oligarchic. Could it be different? After all, it's not like there's nothing that we organize by popular vote in our society -- we organize <strong>everything</strong> so that trust is connected to popular vote.</p>
<p>Democracy is the best of the worst -- in academia as elsewhere. But in academia, democracy hasn't really been possible until the advent of the internet. It used to be that we were all so disconnected that each prof <em>had</em> to be the lone ruler over a small academic duchy. But the net brings us so close together that we can constantly work in much larger groups, our collaborations span continents, our communication is instantaneous and world wide. We are so connected that democratic decisions are not only possible, they are inevitable.</p>
<p>This may sound like a revolution but it isn't. It really isn't. If we had an election today for Grand Nagus of Mathematics -- how would Tim Gowers <strong>not</strong> win? That is to say, if we had elections, we'd most likely vote for the same people who are in charge now.</p>
<p>But at least we could <a href="http://scientopia.org/blogs/drugmonkey/2010/10/13/what-the-nsf-allows-unfunded-people-to-review-their-grants/">hold them accountable</a>. You see, what still comes back to haunt me is <a href="https://gowers.wordpress.com/2012/02/02/abstract-thoughts-about-online-review-systems/">this quote from Tim Gowers</a>:</p>
<blockquote>
<p>I have often had to referee papers that seem completely uninteresting. But these papers will often have a string of references and will state that they are answering questions from those references. In short, there are little communities of mathematicians out there who are carrying out research that has no impact at all on what one might call the big story of mathematics. Nevertheless, it is good that these researchers exist. To draw an analogy with sport, if you want your country to produce grand slam winners at tennis, you want to have a big infrastructure that includes people competing at lower levels, people who play for fun, and so on.</p>
</blockquote>
<p>As true as the comment appears, it comes across as terribly elitist. The huddled masses are tolerated by the elite only because their uninteresting efforts (is there a greater insult?) are needed for justification. This is, of course, completely upside down. It is the large body of hard working &quot;average&quot; researchers that ensures the future of our community and allows a few talented minds to go to extremes. The average researchers are the ones giving them the enormous privilege of pursuing pure research idly.</p>
<p>Maybe we could use a new constitution for our scientific communities. And then let's have elections. And then let's have transparency and accountability.</p>
<p>Oh well, it's only a dream.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>fbreuer</strong>, 2012/07/17<br>
Thanks for this great list! I agree with you completely in spirit (and mostly as far as the details are concerned). The wider social, cultural and political issues you raise are exactly what we need to talk about in the current publishing debate.<br>
I have a meta question, however. I realize that all of these are dreams, i.e., they are not formulated with an eye towards practicality. Nonetheless I would like to ask you how these dreams could be turned into reality. Precisely because most of these dreams involve fundamental social and cultural change, their implementation is a huge political issue. And I can see no way whatsoever to convince math departments, university administrators and funding agencies everywhere (or, indeed, anywhere) to implement such radical policy changes.<br>
So my question is this: Do you see a grass-roots way to make some of these changes happen? What can a small, decentralized, non-tenured group of mathematicians do to make any of these dreams come true?
<ul>
<li><strong>Peter</strong>, 2012/08/04<br>
The biggest grassroots movements is probably the ScienceOnline community <a href="http://scienceonlinenow.com/">http://scienceonlinenow.com/</a>. Unfortunately, not a lot of mathematicians are interested.<br>
In mathematics, the state of the web is a bit of a sad story.  We’ve been so far ahead earlier (arXiv, mathoverflow) that these structures are full of “old” people, unwilling to embrace the next steps — and so we’re way behind in current communication methods (blogging networks are a perfect example). Don’t get me wrong, there are fantastic people out there, but there is zero initiative/leadership that actually is grassroots. Gowers is the perfect example: great stuff, great initiatives but then most of it ends up in old-dudes networks creating boring things like the Forum of Mathematics So, honestly, I doubt mathematics will see a movement — just look at the miserable level of discussions at <a href="http://publishing.mathforge.org/">publishing.mathforge.org</a> and non-transparent activities by the big players (have you heard of the international library of mathematics?). Instead, I fear, pure mathematics might simply be run over in the end.What math research is particularly missing out on is another great advantage over the sciences: math teachers. In the US there’s a great network of math teacher bloggers and they really are a grassroots movement (out of sheer necessity). Do researchers interact with them? Nope. It’s a shame.<br>
Of course, <a href="http://mathblogging.org/">mathblogging.org</a> brings a lot of that together. But we don’t have the time to take it to the next level right now.</li>
<li><strong>fbreuer</strong>, 2012/08/07<br>
Thanks for the pointers!<br>
Apart from looking at what groups are (or are not) out there, my question was also about what such a movement might actually aim to achieve. Suppose we are in a dream world, where there is a well-organized group of determined non-tenured mathematicians who want to change the current system. What would they do? (In addition to having a discussion.)</li>
</ul>
</li>
<li><strong>saf</strong>, 2012/10/14<br>
Brian Osserman (UC Davis) has <a href="http://www.ams.org/notices/201210/rtx121001383p.pdf">a simple proposal</a> that I wish would be adopted in the very near future.
<ul>
<li><strong>Peter</strong>, 2012/10/14<br>
You forgot the http 😉<br>
<a href="http://www.ams.org/notices/201210/rtx121001383p.pdf">http://www.ams.org/notices/201210/rtx121001383p.pdf</a><br>
That’s an interesting approach, especially since it’s the reverse of what everybody else is suggesting. Instead of going the PLoS ONE route of <em>only</em> checking correctness, this suggestion wants to delay correctness until it’s “important” enough.<br>
It’s an interesting thought. Personally, I’m opposed to the notion that editorial board can be relied upon for identifying “important” results, so this isn’t my cup of tea. But I could imagine that it could make the current system more efficient. Maybe that would actually make it easier for people to see the ridiculousness of the current system.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Back to the origin…]]></title>
        <id>http://www.dorais.org/news/2012-06-30-back-to-the-origin.html</id>
        <link href="http://www.dorais.org/news/2012-06-30-back-to-the-origin.html">
        </link>
        <updated>2012-06-30T16:38:17Z</updated>
        <summary type="html"><![CDATA[<p>I am now settling into my new place in Hanover, New Hampshire. I am starting my new position as a <a href="http://www.ams.org/journals/bull/1932-38-09/S0002-9904-1932-05469-6/home.html">John Wesley Young</a> Research Instructor at <a href="http://www.math.dartmouth.edu/">Dartmouth College</a> on July 1. It’s great to be back where it all started!</p>]]></summary>
        <author>
            <name>François G. Dorais</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11 dreams for the publishing debate — #11 a democratization of the communities]]></title>
        <id>https://www.peterkrautzberger.org/0118/</id>
        <link href="https://www.peterkrautzberger.org/0118/">
        </link>
        <updated>2012-06-27T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>And now the conclusion.<br>
Each new post will start from the top, so scroll down a little if you've read the previous one -- but also check out the <a href="https://www.peterkrautzberger.org/0108/">first post</a> for some motivation.</p>
</blockquote>
<p>These are dreams. Some are realistic---perhaps just around the corner; others are way out there---basically crazy. Some will apply to everyone, others only to some. But all have diversity in mind, diversity in our expectations of who researchers are and what they do.</p>
<h3>1. write fewer original-research papers</h3>
<p>I know what you're going to say. But hear me out. This is at the core: to enable researchers to publish fewer &quot;new result&quot;-papers.</p>
<p>I believe all major problems brought up in the debate are, at the heart, caused by the immense increase in publications -- but not the global increase, the personal one. You have to publish far too much/big these days to get a half-decent position/grant. Increasing publication numbers did not increase the quality of research or, for that matter, the &quot;quality of life&quot; in our communities.</p>
<p>Instead, the <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2909426/">massive inflation</a> is <a href="http://carlzimmer.com/articles/index.php?subaction=showfull&amp;id=1336594400&amp;archive=&amp;start_from=&amp;ucat=15&amp;">killing us</a>, devaluating everything we do as researchers. More papers mean that our papers are worth less. Having to publish more papers means we produce more research of questionable quality (unintentionally and otherwise). Especially young researchers have to publish for metrics instead of quality. Worst of all, evaluating researchers only by this steam-punkesque output means that the jobs go to people with this one singular skill -- writing the right kind of papers to please the editorial boards of the right kind of journals -- leading to an intellectual monoculture instead of diverse, stable, rich communities. In particular, the pressure works against women and minorities as they often start with and continue to face disadvantages in their careers that make it harder to produce the desired &quot;output&quot; in the desired time frame.</p>
<p>(If you're wondering why I'm not bashing &quot;evil publishers&quot;. I don't think they are the problem -- we are. If you are happy with the inflation of papers-in-journals, then big publishers are what you need.)</p>
<h3>2. get real credit for surveys, reviews and exposition</h3>
<p>Surveys, reviews and expositions are research -- nothing more, nothing less. We live in a time where it is actually <em>more</em> important to write expository work. Why? Because we've optimized our production pipeline so well that there is no shortage of new (looking) results. Yes, you can argue about &quot;relevance&quot; (I won't, but I can't stop you). But if you're serious about all that &quot;research for research's-sake&quot;-talk, then you might notice that we've figured out how to educate people in the tens of thousands every year that do nothing else but churn out result after result.</p>
<p>As <a href="http://blog.felixbreuer.net/2012/02/27/beyondtheorems.html">Felix aptly wrote</a>: we need to move beyond &quot;new&quot; results. And this means to step back from them and, well, review. Surveys are the glue that holds our fields together, holds our communities together. We do it all the time -- if you read a paper thoroughly, you'll most likely write a review anyway. As we aggregate, work on larger projects or grant proposals these aggregate and easily become surveys and expositions. We need to make all of these public so that the community and the original author(!) can benefit from this enormous creative output that otherwise might only show up in a reading seminar or a journal club.</p>
<p>Mathematicians usually do even more. If we read a paper, we create our own version of the results. Mathematics need these just like music needs different interpretations. We need to give people who are &quot;just&quot; re-writing proofs the credit they deserve, the credit for keeping results alive, accessible and understandable to a wider audience than the original author and referee.</p>
<p>And with credit, I don't mean vouchers for some bookstore. Surveys must be first-class citizens! Surveying and reviewing other peoples work belongs on your CV, it is no less original than your &quot;original research&quot; and every department should have people that are exceptional at it, that are better at surveys, reviews or exposition than &quot;new&quot; research and add to the diversity of a department.</p>
<h3>3. get real credit for refereeing</h3>
<p>Refereeing is research, just like surveys and &quot;new results&quot;. It might seem redundant after dream #2 (and in many ways I would say that's the goal), but given the importance of refereeing right now and the way we do it, it's separate.</p>
<p>Currently, good refereeing seems nearly impossible. With the increase of publications we can't even catch up with what's happening in our own narrowly focused interests -- how, then, can we expect to referee properly? Sam tells his own funny but sad <a href="http://boolesrings.org/scoskey/peer-review-failure/">story of refereeing honestly</a> but the problem runs deep. Good referees are hard to find and when you find them, they could be writing a paper instead of refereeing -- and why should they not?</p>
<p>There are many ways we could improve refereeing. We can (and should) split up the different stages of refereeing (reference checking, correctness checking on different levels, opinion gathering etc), we should open pre- and post-publication peer review (and in-between peer review), we should use alternative methods to collect these reviews (instead of review journals that have at most one opinion per paper).</p>
<p>One key of refereeing is forming an opinion -- and voicing it. That's very hard, in particular for young and disadvantaged researchers who fear significant repercussions. But we don't need less people sharing their opinions on other researchers' output, we need more (whether they agree or not); it's a responsibility both to our own research communities and to a larger society.</p>
<p>But all of these are very unlikely to work, if we don't find a way to give referees the credit (and criticism) they deserve. Before we can <a href="https://xianblog.wordpress.com/2012/05/24/in-praise-of-the-referee-2/">praise referees</a> we need tools to evaluate refereeing, both in current and future form. Above all, we need to be able to put refereeing on the CV, it's part of the research qualities every strong department should strive for.</p>
<h3>4. get real credit for communicating</h3>
<p>Communicating other people's work through surveys, exposition and reviews is important. Then there's communicating to students aka teaching. This is an especially sore point for mathematics where undergraduate teaching has become a blunt tool to weed out graduates for other disciplines -- our self-respect seems greatly lacking. And then, of course, there's spreading the word to the wider public.</p>
<p>Have you ever noticed that many of the great researchers are excellent communicators (and teachers and surveyors and referees)? I would go as far as to say that a <em>truly</em> great researcher will be great in at least one of these ways to communicate. Without this, you're only a great something-else. We should cherish not just one ability of our truly great minds, but all of them. Right now we promote researchers according to how their &quot;new result&quot;-output compares to the &quot;new result&quot;-output of the truly great ones. Why are we so one dimensional?</p>
<p>Also, communication goes both ways, so we must listen. Can you imagine a graduate-student-run, &quot;Law Review&quot;-like journal for mathematics? Graduate students are perfect for forcing you to reflect on your research -- we should encourage them to make their thoughts public (including anonymously and pseudonomously). But we mathematicians need to go further. When <a href="http://en.wikipedia.org/wiki/Robert_Parris_Moses">Bob Moses</a> was speaking at Michigan earlier this year he argued that history will judge us as math literacy becomes a <a href="http://news.harvard.edu/gazette/2001/05.17/e04-moses.html">civil rights issue</a> in the 21st century. Are we listening?</p>
<p>Without communication, we risk the longevity of our own research areas because we won't be <em>understood</em> by the next generation, by other areas and by society as a whole. But this means <a href="http://scientopia.org/blogs/scicurious/2012/06/06/on-outreach-somethings-got-to-give/">something's gotta give</a> and we need to accept that by giving real credit.</p>
<h3>5. sharing all our work every way we can</h3>
<p>One battle that most scientists are still fighting -- full self-archival rights -- mathematics has long won. We need to make this happen for everyone. We must use the arXiv, our homepages or (if you must) walled gardens such as <a href="http://www.academia.edu/">academia.edu</a> and <a href="http://www.researchgate.net/">researchgate</a>. But we should also embrace more recent alternatives like <a href="http://figshare.com/">figshare</a> and <a href="http://github.com/">github</a> to post <em>all</em> our research publicly -- preprints, notes, lecture notes, expository notes, simply everything. <a href="https://en.wikipedia.org/wiki/Open_Notebook_Science">Open notebook science</a> is the key, but it's in its infancy. We need to find ways (many different ones) that work for a larger part of our communities so it becomes easier for people to experiment with it and to make it something even better. It might not be for everyone, but it's something everybody will benefit from.</p>
<p>However, the truth is that even among mathematicians a large group doesn't use the arXiv, let alone keep professional homepages deserving the name. I know that especially older researchers often hesitate because technical issues &quot;are more trouble than it's worth&quot;. This is a challenge and we must argue against this and more importantly help to sort out problems, within departments, within small research communities etc to overcome these obstacles. Approach people, ask them why their papers aren't availabe and help them put them properly online. In all other cases: <a href="https://sbseminar.wordpress.com/2010/02/09/grothendiecks-letter/">Don't be a Grothendieck</a>.</p>
<h3>6. publishing in smaller increments</h3>
<p>Have you ever read a paper that seemed to hide its true goal because the author wasn't finished but had to publish something out of the pressure of not having a job otherwise? Have you ever read a paper that made a small but reasonable result look much more than it really was just so that it will make the least publishable unit? Have you ever read a paper that was so badly written that you couldn't make sense of it?</p>
<p>Paradoxically, one way to publish fewer &quot;new results&quot; papers might be to publish more but differently. For scientists this might seem easier, publishing as the data comes in. But even for mathematics we have all those little results -- the small gems, the one-line-proof, the clever counterexample, the good reformulation, the useful shortcut -- all those could be published quickly and openly instead of waiting to find enough to &quot;make it a paper&quot;. Just like data, these could be reviewed publicly much more easily and we should get proper credit for doing so (both author and reviewer).</p>
<p>Longer results could (depending on their nature) be published incrementally, with multiple, public revisions. Take the preprint idea one step further and make your writing process public. Use a revision system like github to expose the process. Allow for outside input in your writing process, in your working process. The internet makes us an intricately connected community and we can work together in one big virtual seminar. There are already excellent examples in that area. In mathematics in particular, we have the <a href="http://polymathprojects.org/">Polymath project</a> or Ryan O'Donnell's <a href="http://www.analysisofbooleanfunctions.org/">Analysis of Boolean Functions</a>, a text book he's working out as a blog.</p>
<p>But as I've argued <a href="https://www.peterkrautzberger.org/0107/">Polymath doesn't work for very many people</a> so, again, we need many, many more projects like these so that more people have the opportunity to find a way that works for them.</p>
<p>There's of course a risk -- this could create a lot of noise as incrementally published results implode when data turns out to be flawed, proofs disintegrate and general anarchy rears its head! But I think it's worth the risk. Search technology is constantly improving and good scientific standards should ensure that failed research is marked accordingly. And we have so much to gain! We might be able to finally give credit for failing productively -- the main thing researchers do anyway, we fail and fail and fail until we understand what's going on. Sometimes we have to give up, but why shouldn't somebody else continue for us?</p>
<p>Even if your research implodes, you should get credit and, much, much more importantly, you will help others not to repeat your mistake. <a href="http://boolesrings.org/vonheymann/">Fred</a> once worked on a nice old problem which, after a few months, clearly didn't get anywhere. But he realized that all his attacks had probably been attempted before and so he wrote a pre-print on all the ways to fail, published <a href="http://boolesrings.org/vonheymann/publications/code/">his code along with it</a> so that people in the future might benefit from his failure. Or as <a href="http://www.math.rutgers.edu/~zeilberg/Opinion39.html">Doron Zeilberger wrote</a>: if only John von Neumann's maid had saved all the notes he'd thrown away each day!</p>
<p>Or to put it differently: the most exciting result in 2011 was having <a href="http://m-phi.blogspot.com/2011/10/inconsistency-of-pa-and-consensus-in.html">no result about Con(PA)</a>.</p>
<h3>7. an affordable open access model</h3>
<p>Research publications should be free, for both authors and readers. When it comes to traditional journals, there are already some in mathematics (e.g. <a href="http://nyjm.albany.edu/">NYJM</a>) that offer open access without any fees. I believe we can move to a journal system that is entirely open access and without publishing fees but we're not there yet. Mathematical journals are said to have profit margins of 90% so we should be the first to get there. Gold open access is already realistic and, more importantly, can be made affordable right now. With <a href="http://peerj.com/">peerj</a>, this is already around the corner on a much larger scale.</p>
<p>On the other hand, it seems natural to me to return academic publications to universities and academic societies. For journals, this could simply be done PLoS-ONE style (checking correctness, not &quot;importance&quot;) and our institutions could certainly make such journals open access, non-profit and actually free (just have each department produce one journal). But new ways of doing and sharing research will hardly fit into the journal model. These methods will be much more user centric, will be about people, not publishers. And the natural place to store information about people is their professional homepage as a repository of their work. It seems natural that universities or academic societies could play a much better role in this then proprietary social networks.</p>
<p>However, one problem we'd be facing is that journal publishing is the cash cow of many societies and this money is often used to cross-finance important services. This is not helpful in a time where <a href="https://web.archive.org/web/20140723061813/http://blog.findings.com/post/20527246081/how-we-will-read-clay-shirky">publishing is a button [Wayback machine]</a>. We'll have to find another way to finance things that need financing and we'll have to talk about that, too. Additionally, if we move scientific &quot;publishing&quot; to the next level, there will be new costs: costs for research into doing it, costs for experiments, costs for failures. We need to talk about those, too.</p>
<h3>8. a cultural change of doing research (and metrics for it)</h3>
<p>If we publish less &quot;new results&quot;, some structural problems might just disappear. Fewer papers means fewer journals means fewer subscriptions means fewer refereeing. Smaller workload and smaller costs. But this can only work if we have tools to nevertheless show what happens in between writing-down-a-decent-result-which-takes-years-dammit. Thanks to the internet, we can actually hope to do this. But the internet will also change everything (again and again) and it will change our communities (again and again). We need to invest resources right now to be able to benefit from this change, find a way to evolve into a work mode that is more appropriate for what is yet to come than what was in the past. We need to get into a constant-change mentality and we need to make this worth everybody's while.</p>
<p>Our funding bodies, academic societies, universities and other institutions must fund more experiments for doing research differently and the metrics needed for this. At the very least, we need more incubators like Macmillan's <a href="http://www.digital-science.com/">Digital-Science</a>, but also in a non-profit fashion along the lines of <a href="http://www.mathjax.org/">MathJax</a>'s business model. Reversely, our communities must value anybody's effort of joining new experimental platforms such as MO/math.SE, blogs, citizen science projects, polymath-esque projects, wikipedia and all those platforms that are still only dreams. The <a href="http://altmetrics.org/manifesto/">altmetrics</a> people are already setting many good examples and platforms such as Stackexchange and Wikipedia are working hard to develop reputation technology that will allow us to measure people's activity in these new scientific environments.</p>
<p>This, of course, means breaking out of the mono-culture of &quot;papers in journals&quot; -- a rough cultural change. Nobody talks about this drastic change which, I believe, makes it is the biggest problem in this entire debate. If we change the way we do (and evaluate) research, then we ask incredibly much of the people who are working well in the current model, who are good at (only?) writing the right kind of papers for the right kind of journals. It would be a revolution if people were hired because their non-traditional research activities outweigh the traditional paper count of other applicants -- in other words, if hiring would happen strategically, with that kind of diversity in mind. Case in point: even Michael Nielsen overlooks this problem completely in <a href="http://michaelnielsen.org/blog/reinventing-discovery/">his wonderful book</a>.</p>
<p>This change is even more important for smaller research areas (and must be made to work for them) who can't play the impact factor game. Failing to adapt, might even mean extinction in this case. But the potential is equally great as more diverse ways of doing research can also mean a better chance to work across fields and improve collaboration and visibility of small fields.</p>
<h3>9. propagating the Shelah Model -- encouraging bad writers to seek out good writers</h3>
<p>This may seem a very math-specific dream, possibly extending to the humanities, but it does apply to the sciences in more than one way.</p>
<p>Not only do we have too many &quot;new result&quot; papers, we also have too many horribly written papers. Although there's certainly a talent to being a great writer of research publications, we're facing the problem that our communities just down care enough to enforce even mediocre standards of writing. This is particularly hard with leading researchers who will find their manuscripts barely scrutinized.</p>
<p>Much worse, however, young researchers have an incentive <em>not</em> to care for the quality of their writing and the work necessary for it. Instead the motto is: &quot;Just get it by the referee and be done with it! You could produce a new result while you waste your time revising this one!&quot;. Referees and editors in turn have little incentive to spend their unpaid time improving a paper, so it's easier to simply dismiss a paper or ignore the communicative shortcomings (after all, the referee understood the damn thing...).</p>
<p>As <a href="http://logic.dorais.org/archives/630">Dor-Bar Natan said</a></p>
<blockquote>
<p>Papers are written so that their author(s) can forget their content and move on to other things.</p>
</blockquote>
<p>The lack of quality control in academic writing endangers long term accessibility of our research as much as data supplements in proprietary formats. In the long run, it makes papers less trustworthy and compromises the greatest strength of research, to build on earlier work. Simply put, archival is rather pointless if nobody can comprehend the content.</p>
<p>Of course, some people are more skilled, some are less skilled as writers. So why not join them up? <a href="https://en.wikipedia.org/wiki/Saharon_Shelah">Saharon Shelah</a> has published over 1,000 papers with 220 co-authors. Not only does the number of co-authors allow Shelah to produce more papers, it also allows the community to understand them better. Yet some of his co-authors are mocked as &quot;Shelah's secretaries&quot;, supposedly not publishing enough &quot;alone&quot;. Besides being pathetic ad-hominem attacks, this completely overlooks the fact that in many cases only these co-authors make Shelah's incredible output accessible to the research community.</p>
<p>Let's have editors and referees tell bad writers to find a capable co-author instead. It should be a win-win situation -- good writers will get to be on more papers and researchers lacking in writing skills get their thoughts polished so that other people can actually build on their work. As a bonus, the papers get some pre-publication peer-review and editors and referees shoulder a smaller workload. All we have to do is give up the notion that only &quot;new results&quot; are acceptable research currency. It seems a small price to pay.</p>
<p>And don't call them secretaries, when they really are smiths. They might not mine the ore, but without them it's all a pretty useless lump of rock.</p>
<h3>10. getting from the come-to-me mentality to the go-out-and-find-them mentality.</h3>
<p>Sometimes in my dreams, <a href="https://gowers.wordpress.com/2011/10/31/how-might-we-get-to-a-new-model-of-mathematical-publishing/#comment-12847">somebody screams</a> &quot;I need journal rankings and impact factors because that's the only way to weed out 600 applicants&quot; and I awake sweating, panicking, thinking: you're doing it wrong!</p>
<p>It's quite simple really. If you have a job which attracts 600 serious applicants you should be headhunting to find the best fit -- not passively wait for applications to pile on a search committee's desk. Of course, the current system does not allow such a behavior. But without a doubt this is a better strategy for hiring a candidate, a strategy with an actual chance of finding a good fit for your department, for all aspects of research.</p>
<p>This simple idea is far fetched given the established system. There would be many challenges to change our culture in this direction, not the least of which is keeping nepotism in check. I don't think it will really happen, actually, even if I dream it would.</p>
<p>But to use impact factors instead is simply lazy. The fact that we rely on this is actually damaging to our community as it is a metric that can be badly gamed and is heavily biased towards mainstream research. Needless to say, hiring committees are yet another research activity which deserves much more recognition. Only if this work gets proper acknowledgement is there any chance to spend more resources on a productive strategy for one of the highest impact activities of any researcher -- hiring fellow faculty members.</p>
<h3>11. a democratization of the communities</h3>
<p>Here's my biggest dream: a democratically organized scientific community. With this I'm not talking about the challenges of representing interests of scientific communities within a democratic society. Also, I'm not talking about the democratic aspects of <a href="https://en.wikipedia.org/wiki/Citizen_science">citizen science</a>. (Both of these are extremely important, of course.)</p>
<p>Instead, I'm baffled by the aristocratic and often oligarchic structures of scientific communities. Can you imagine editorial boards or grant committees being appointed through a democratic process, say through a parliament of researchers? And can you then imagine this parliament to be elected by <em>all</em> researchers of a specific field -- the faculty of small colleges, the researchers in the industry, the grad students, the postdocs, they'd all get the same vote as prize winning researchers in this?</p>
<p><a href="http://agtb.wordpress.com/2011/11/03/the-good-things-about-journals/">Noam Nisan once wrote</a> a quote that (brutally out of context) reminds me of 18th century aristocracy:</p>
<blockquote>
<p>[...] one shudders at the thought of papers being evaluated by popular vote rather than by trusted experts.</p>
</blockquote>
<p>It seems true enough until you ask: who decides which experts are considered trusted?</p>
<p>One of the biggest problems of academia today is that positions of power and responsibility are assigned by what is currently considered academic merit -- basically, the &quot;new results&quot; count, impact factors, blah blah. This often leads to problems, since researchers who are exceptional at producing new results are often poor at managing our communities. But there's something more fundamental at play: meritocracy only seems fine until you notice <a href="http://mathbabe.org/2012/05/05/the-meritocracy-myth/">there's no such thing</a>. Academia is not about merit, it is about reputation -- and reputation is currently exclusively determined by the journals you publish in and hence the editorial boards that think your research is &quot;interesting&quot;. However, appointments to these editorial boards are essentially oligarchic. Could it be different? After all, it's not like there's nothing that we organize by popular vote in our society -- we organize <strong>everything</strong> so that trust is connected to popular vote.</p>
<p>Democracy is the best of the worst -- in academia as elsewhere. But in academia, democracy hasn't really been possible until the advent of the internet. It used to be that we were all so disconnected that each prof <em>had</em> to be the lone ruler over a small academic duchy. But the net brings us so close together that we can constantly work in much larger groups, our collaborations span continents, our communication is instantaneous and world wide. We are so connected that democratic decisions are not only possible, they are inevitable.</p>
<p>This may sound like a revolution but it isn't. It really isn't. If we had an election today for Grand Nagus of Mathematics -- how would Tim Gowers <strong>not</strong> win? That is to say, if we had elections, we'd most likely vote for the same people who are in charge now.</p>
<p>But at least we could <a href="http://scientopia.org/blogs/drugmonkey/2010/10/13/what-the-nsf-allows-unfunded-people-to-review-their-grants/">hold them accountable</a>. You see, what still comes back to haunt me is <a href="https://gowers.wordpress.com/2012/02/02/abstract-thoughts-about-online-review-systems/">this quote from Tim Gowers</a>:</p>
<blockquote>
<p>I have often had to referee papers that seem completely uninteresting. But these papers will often have a string of references and will state that they are answering questions from those references. In short, there are little communities of mathematicians out there who are carrying out research that has no impact at all on what one might call the big story of mathematics. Nevertheless, it is good that these researchers exist. To draw an analogy with sport, if you want your country to produce grand slam winners at tennis, you want to have a big infrastructure that includes people competing at lower levels, people who play for fun, and so on.</p>
</blockquote>
<p>As true as the comment appears, it comes across as terribly elitist. The huddled masses are tolerated by the elite only because their uninteresting efforts (is there a greater insult?) are needed for justification. This is, of course, completely upside down. It is the large body of hard working &quot;average&quot; researchers that ensures the future of our community and allows a few talented minds to go to extremes. The average researchers are the ones giving them the enormous privilege of pursuing pure research idly.</p>
<p>Maybe we could use a new constitution for our scientific communities. And then let's have elections. And then let's have transparency and accountability.</p>
<p>Oh well, it's only a dream.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>fbreuer</strong>, 2012/07/17<br>
I want to chip in on one particular point: I agree completely that academia is not about merit but about reputation. But I disagree with your assessment that reputation is determined entirely via publications.<br>
I have never been on a committee appointing a position, so my experience is limited. But my impression is that the single most important factor for getting a position is simply who you know. Or more precisely: who knows you. In this way, careers in academia are precisely the kind of social game that Cathy O’Neil criticises in the business world.<br>
Of course the assessment that academia is not a meritocracy still holds, but for a different reason. Consequently, fixing the publishing system or making mathematics more democratic is not going to change anything about the myth of meritocracy. In fact, such measures might give the myth of meritocracy even more of a justified appearance.<br>
PS: The Grand Nagus of Mathematics is an absolutely brilliant title. :)</li>
<li><a href="http://checkmyworking.com/2012/07/carnival-of-mathematics-88/">pingback</a></li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11 dreams for the publishing debate — #10 from come-to-me to the go-out-and-find-them]]></title>
        <id>https://www.peterkrautzberger.org/0117/</id>
        <link href="https://www.peterkrautzberger.org/0117/">
        </link>
        <updated>2012-06-20T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>I got two more, just two more...<br>
Each new post will start from the top, so scroll down a little if you've read the previous one -- but also check out the <a href="http://wp.me/p1Jsxx-Bs">first post</a> for some motivation.</p>
</blockquote>
<p>These are dreams. Some are realistic---perhaps just around the corner; others are way out there---basically crazy. Some will apply to everyone, others only to some. But all have diversity in mind, diversity in our expectations of who researchers are and what they do.</p>
<h3>1. write fewer original-research papers</h3>
<p>I know what you're going to say. But hear me out. This is at the core: to enable researchers to publish fewer &quot;new result&quot;-papers.</p>
<p>I believe all major problems brought up in the debate are, at the heart, caused by the immense increase in publications -- but not the global increase, the personal one. You have to publish far too much/big these days to get a half-decent position/grant. Increasing publication numbers did not increase the quality of research or, for that matter, the &quot;quality of life&quot; in our communities.</p>
<p>Instead, the <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2909426/">massive inflation</a> is <a href="http://carlzimmer.com/articles/index.php?subaction=showfull&amp;id=1336594400&amp;archive=&amp;start_from=&amp;ucat=15&amp;">killing us</a>, devaluating everything we do as researchers. More papers mean that our papers are worth less. Having to publish more papers means we produce more research of questionable quality (unintentionally and otherwise). Especially young researchers have to publish for metrics instead of quality. Worst of all, evaluating researchers only by this steam-punkesque output means that the jobs go to people with this one singular skill -- writing the right kind of papers to please the editorial boards of the right kind of journals -- leading to an intellectual monoculture instead of diverse, stable, rich communities. In particular, the pressure works against women and minorities as they often start with and continue to face disadvantages in their careers that make it harder to produce the desired &quot;output&quot; in the desired time frame.</p>
<p>(If you're wondering why I'm not bashing &quot;evil publishers&quot;. I don't think they are the problem -- we are. If you are happy with the inflation of papers-in-journals, then big publishers are what you need.)</p>
<h3>2. get real credit for surveys, reviews and exposition</h3>
<p>Surveys, reviews and expositions are research -- nothing more, nothing less. We live in a time where it is actually <em>more</em> important to write expository work. Why? Because we've optimized our production pipeline so well that there is no shortage of new (looking) results. Yes, you can argue about &quot;relevance&quot; (I won't, but I can't stop you). But if you're serious about all that &quot;research for research's-sake&quot;-talk, then you might notice that we've figured out how to educate people in the tens of thousands every year that do nothing else but churn out result after result.</p>
<p>As <a href="http://blog.felixbreuer.net/2012/02/27/beyondtheorems.html">Felix aptly wrote</a>: we need to move beyond &quot;new&quot; results. And this means to step back from them and, well, review. Surveys are the glue that holds our fields together, holds our communities together. We do it all the time -- if you read a paper thoroughly, you'll most likely write a review anyway. As we aggregate, work on larger projects or grant proposals these aggregate and easily become surveys and expositions. We need to make all of these public so that the community and the original author(!) can benefit from this enormous creative output that otherwise might only show up in a reading seminar or a journal club.</p>
<p>Mathematicians usually do even more. If we read a paper, we create our own version of the results. Mathematics need these just like music needs different interpretations. We need to give people who are &quot;just&quot; re-writing proofs the credit they deserve, the credit for keeping results alive, accessible and understandable to a wider audience than the original author and referee.</p>
<p>And with credit, I don't mean vouchers for some bookstore. Surveys must be first-class citizens! Surveying and reviewing other peoples work belongs on your CV, it is no less original than your &quot;original research&quot; and every department should have people that are exceptional at it, that are better at surveys, reviews or exposition than &quot;new&quot; research and add to the diversity of a department.</p>
<h3>3. get real credit for refereeing</h3>
<p>Refereeing is research, just like surveys and &quot;new results&quot;. It might seem redundant after dream #2 (and in many ways I would say that's the goal), but given the importance of refereeing right now and the way we do it, it's separate.</p>
<p>Currently, good refereeing seems nearly impossible. With the increase of publications we can't even catch up with what's happening in our own narrowly focused interests -- how, then, can we expect to referee properly? Sam tells his own funny but sad <a href="http://boolesrings.org/scoskey/peer-review-failure/">story of refereeing honestly</a> but the problem runs deep. Good referees are hard to find and when you find them, they could be writing a paper instead of refereeing -- and why should they not?</p>
<p>There are many ways we could improve refereeing. We can (and should) split up the different stages of refereeing (reference checking, correctness checking on different levels, opinion gathering etc), we should open pre- and post-publication peer review (and in-between peer review), we should use alternative methods to collect these reviews (instead of review journals that have at most one opinion per paper).</p>
<p>One key of refereeing is forming an opinion -- and voicing it. That's very hard, in particular for young and disadvantaged researchers who fear significant repercussions. But we don't need less people sharing their opinions on other researchers' output, we need more (whether they agree or not); it's a responsibility both to our own research communities and to a larger society.</p>
<p>But all of these are very unlikely to work, if we don't find a way to give referees the credit (and criticism) they deserve. Before we can <a href="https://xianblog.wordpress.com/2012/05/24/in-praise-of-the-referee-2/">praise referees</a> we need tools to evaluate refereeing, both in current and future form. Above all, we need to be able to put refereeing on the CV, it's part of the research qualities every strong department should strive for.</p>
<h3>4. get real credit for communicating</h3>
<p>Communicating other people's work through surveys, exposition and reviews is important. Then there's communicating to students aka teaching. This is an especially sore point for mathematics where undergraduate teaching has become a blunt tool to weed out graduates for other disciplines -- our self-respect seems greatly lacking. And then, of course, there's spreading the word to the wider public.</p>
<p>Have you ever noticed that many of the great researchers are excellent communicators (and teachers and surveyors and referees)? I would go as far as to say that a <em>truly</em> great researcher will be great in at least one of these ways to communicate. Without this, you're only a great something-else. We should cherish not just one ability of our truly great minds, but all of them. Right now we promote researchers according to how their &quot;new result&quot;-output compares to the &quot;new result&quot;-output of the truly great ones. Why are we so one dimensional?</p>
<p>Also, communication goes both ways, so we must listen. Can you imagine a graduate-student-run, &quot;Law Review&quot;-like journal for mathematics? Graduate students are perfect for forcing you to reflect on your research -- we should encourage them to make their thoughts public (including anonymously and pseudonomously). But we mathematicians need to go further. When <a href="http://en.wikipedia.org/wiki/Robert_Parris_Moses">Bob Moses</a> was speaking at Michigan earlier this year he argued that history will judge us as math literacy becomes a <a href="http://news.harvard.edu/gazette/2001/05.17/e04-moses.html">civil rights issue</a> in the 21st century. Are we listening?</p>
<p>Without communication, we risk the longevity of our own research areas because we won't be <em>understood</em> by the next generation, by other areas and by society as a whole. But this means <a href="http://scientopia.org/blogs/scicurious/2012/06/06/on-outreach-somethings-got-to-give/">something's gotta give</a> and we need to accept that by giving real credit.</p>
<h3>5. sharing all our work every way we can</h3>
<p>One battle that most scientists are still fighting -- full self-archival rights -- mathematics has long won. We need to make this happen for everyone. We must use the arXiv, our homepages or (if you must) walled gardens such as <a href="http://www.academia.edu/">academia.edu</a> and <a href="http://www.researchgate.net/">researchgate</a>. But we should also embrace more recent alternatives like <a href="http://figshare.com/">figshare</a> and <a href="http://github.com/">github</a> to post <em>all</em> our research publicly -- preprints, notes, lecture notes, expository notes, simply everything. <a href="https://en.wikipedia.org/wiki/Open_Notebook_Science">Open notebook science</a> is the key, but it's in its infancy. We need to find ways (many different ones) that work for a larger part of our communities so it becomes easier for people to experiment with it and to make it something even better. It might not be for everyone, but it's something everybody will benefit from.</p>
<p>However, the truth is that even among mathematicians a large group doesn't use the arXiv, let alone keep professional homepages deserving the name. I know that especially older researchers often hesitate because technical issues &quot;are more trouble than it's worth&quot;. This is a challenge and we must argue against this and more importantly help to sort out problems, within departments, within small research communities etc to overcome these obstacles. Approach people, ask them why their papers aren't availabe and help them put them properly online. In all other cases: <a href="https://sbseminar.wordpress.com/2010/02/09/grothendiecks-letter/">Don't be a Grothendieck</a>.</p>
<h3>6. publishing in smaller increments</h3>
<p>Have you ever read a paper that seemed to hide its true goal because the author wasn't finished but had to publish something out of the pressure of not having a job otherwise? Have you ever read a paper that made a small but reasonable result look much more than it really was just so that it will make the least publishable unit? Have you ever read a paper that was so badly written that you couldn't make sense of it?</p>
<p>Paradoxically, one way to publish fewer &quot;new results&quot; papers might be to publish more but differently. For scientists this might seem easier, publishing as the data comes in. But even for mathematics we have all those little results -- the small gems, the one-line-proof, the clever counterexample, the good reformulation, the useful shortcut -- all those could be published quickly and openly instead of waiting to find enough to &quot;make it a paper&quot;. Just like data, these could be reviewed publicly much more easily and we should get proper credit for doing so (both author and reviewer).</p>
<p>Longer results could (depending on their nature) be published incrementally, with multiple, public revisions. Take the preprint idea one step further and make your writing process public. Use a revision system like github to expose the process. Allow for outside input in your writing process, in your working process. The internet makes us an intricately connected community and we can work together in one big virtual seminar. There are already excellent examples in that area. In mathematics in particular, we have the <a href="http://polymathprojects.org/">Polymath project</a> or Ryan O'Donnell's <a href="http://www.analysisofbooleanfunctions.org/">Analysis of Boolean Functions</a>, a text book he's working out as a blog.</p>
<p>But as I've argued <a href="https://www.peterkrautzberger.org/0107/">Polymath doesn't work for very many people</a> so, again, we need many, many more projects like these so that more people have the opportunity to find a way that works for them.</p>
<p>There's of course a risk -- this could create a lot of noise as incrementally published results implode when data turns out to be flawed, proofs disintegrate and general anarchy rears its head! But I think it's worth the risk. Search technology is constantly improving and good scientific standards should ensure that failed research is marked accordingly. And we have so much to gain! We might be able to finally give credit for failing productively -- the main thing researchers do anyway, we fail and fail and fail until we understand what's going on. Sometimes we have to give up, but why shouldn't somebody else continue for us?</p>
<p>Even if your research implodes, you should get credit and, much, much more importantly, you will help others not to repeat your mistake. <a href="http://boolesrings.org/vonheymann/">Fred</a> once worked on a nice old problem which, after a few months, clearly didn't get anywhere. But he realized that all his attacks had probably been attempted before and so he wrote a pre-print on all the ways to fail, published <a href="http://boolesrings.org/vonheymann/publications/code/">his code along with it</a> so that people in the future might benefit from his failure. Or as <a href="http://www.math.rutgers.edu/~zeilberg/Opinion39.html">Doron Zeilberger wrote</a>: if only John von Neumann's maid had saved all the notes he'd thrown away each day!</p>
<p>Or to put it differently: the most exciting result in 2011 was having <a href="http://m-phi.blogspot.com/2011/10/inconsistency-of-pa-and-consensus-in.html">no result about Con(PA)</a>.</p>
<h3>7. an affordable open access model</h3>
<p>Research publications should be free, for both authors and readers. When it comes to traditional journals, there are already some in mathematics (e.g. <a href="http://nyjm.albany.edu/">NYJM</a>) that offer open access without any fees. I believe we can move to a journal system that is entirely open access and without publishing fees but we're not there yet. Mathematical journals are said to have profit margins of 90% so we should be the first to get there. Gold open access is already realistic and, more importantly, can be made affordable right now. With <a href="http://peerj.com/">peerj</a>, this is already around the corner on a much larger scale.</p>
<p>On the other hand, it seems natural to me to return academic publications to universities and academic societies. For journals, this could simply be done PLoS-ONE style (checking correctness, not &quot;importance&quot;) and our institutions could certainly make such journals open access, non-profit and actually free (just have each department produce one journal). But new ways of doing and sharing research will hardly fit into the journal model. These methods will be much more user centric, will be about people, not publishers. And the natural place to store information about people is their professional homepage as a repository of their work. It seems natural that universities or academic societies could play a much better role in this then proprietary social networks.</p>
<p>However, one problem we'd be facing is that journal publishing is the cash cow of many societies and this money is often used to cross-finance important services. This is not helpful in a time where <a href="https://web.archive.org/web/20140723061813/http://blog.findings.com/post/20527246081/how-we-will-read-clay-shirky">publishing is a button [Wayback machine]</a>. We'll have to find another way to finance things that need financing and we'll have to talk about that, too. Additionally, if we move scientific &quot;publishing&quot; to the next level, there will be new costs: costs for research into doing it, costs for experiments, costs for failures. We need to talk about those, too.</p>
<h3>8. a cultural change of doing research (and metrics for it)</h3>
<p>If we publish less &quot;new results&quot;, some structural problems might just disappear. Fewer papers means fewer journals means fewer subscriptions means fewer refereeing. Smaller workload and smaller costs. But this can only work if we have tools to nevertheless show what happens in between writing-down-a-decent-result-which-takes-years-dammit. Thanks to the internet, we can actually hope to do this. But the internet will also change everything (again and again) and it will change our communities (again and again). We need to invest resources right now to be able to benefit from this change, find a way to evolve into a work mode that is more appropriate for what is yet to come than what was in the past. We need to get into a constant-change mentality and we need to make this worth everybody's while.</p>
<p>Our funding bodies, academic societies, universities and other institutions must fund more experiments for doing research differently and the metrics needed for this. At the very least, we need more incubators like Macmillan's <a href="http://www.digital-science.com/">Digital-Science</a>, but also in a non-profit fashion along the lines of <a href="http://www.mathjax.org/">MathJax</a>'s business model. Reversely, our communities must value anybody's effort of joining new experimental platforms such as MO/math.SE, blogs, citizen science projects, polymath-esque projects, wikipedia and all those platforms that are still only dreams. The <a href="http://altmetrics.org/manifesto/">altmetrics</a> people are already setting many good examples and platforms such as Stackexchange and Wikipedia are working hard to develop reputation technology that will allow us to measure people's activity in these new scientific environments.</p>
<p>This, of course, means breaking out of the mono-culture of &quot;papers in journals&quot; -- a rough cultural change. Nobody talks about this drastic change which, I believe, makes it is the biggest problem in this entire debate. If we change the way we do (and evaluate) research, then we ask incredibly much of the people who are working well in the current model, who are good at (only?) writing the right kind of papers for the right kind of journals. It would be a revolution if people were hired because their non-traditional research activities outweigh the traditional paper count of other applicants -- in other words, if hiring would happen strategically, with that kind of diversity in mind. Case in point: even Michael Nielsen overlooks this problem completely in <a href="http://michaelnielsen.org/blog/reinventing-discovery/">his wonderful book</a>.</p>
<p>This change is even more important for smaller research areas (and must be made to work for them) who can't play the impact factor game. Failing to adapt, might even mean extinction in this case. But the potential is equally great as more diverse ways of doing research can also mean a better chance to work across fields and improve collaboration and visibility of small fields.</p>
<h3>9. propagating the Shelah Model -- encouraging bad writers to seek out good writers</h3>
<p>This may seem a very math-specific dream, possibly extending to the humanities, but it does apply to the sciences in more than one way.</p>
<p>Not only do we have too many &quot;new result&quot; papers, we also have too many horribly written papers. Although there's certainly a talent to being a great writer of research publications, we're facing the problem that our communities just down care enough to enforce even mediocre standards of writing. This is particularly hard with leading researchers who will find their manuscripts barely scrutinized.</p>
<p>Much worse, however, young researchers have an incentive <em>not</em> to care for the quality of their writing and the work necessary for it. Instead the motto is: &quot;Just get it by the referee and be done with it! You could produce a new result while you waste your time revising this one!&quot;. Referees and editors in turn have little incentive to spend their unpaid time improving a paper, so it's easier to simply dismiss a paper or ignore the communicative shortcomings (after all, the referee understood the damn thing...).</p>
<p>As <a href="http://logic.dorais.org/archives/630">Dor-Bar Natan said</a></p>
<blockquote>
<p>Papers are written so that their author(s) can forget their content and move on to other things.</p>
</blockquote>
<p>The lack of quality control in academic writing endangers long term accessibility of our research as much as data supplements in proprietary formats. In the long run, it makes papers less trustworthy and compromises the greatest strength of research, to build on earlier work. Simply put, archival is rather pointless if nobody can comprehend the content.</p>
<p>Of course, some people are more skilled, some are less skilled as writers. So why not join them up? <a href="https://en.wikipedia.org/wiki/Saharon_Shelah">Saharon Shelah</a> has published over 1,000 papers with 220 co-authors. Not only does the number of co-authors allow Shelah to produce more papers, it also allows the community to understand them better. Yet some of his co-authors are mocked as &quot;Shelah's secretaries&quot;, supposedly not publishing enough &quot;alone&quot;. Besides being pathetic ad-hominem attacks, this completely overlooks the fact that in many cases only these co-authors make Shelah's incredible output accessible to the research community.</p>
<p>Let's have editors and referees tell bad writers to find a capable co-author instead. It should be a win-win situation -- good writers will get to be on more papers and researchers lacking in writing skills get their thoughts polished so that other people can actually build on their work. As a bonus, the papers get some pre-publication peer-review and editors and referees shoulder a smaller workload. All we have to do is give up the notion that only &quot;new results&quot; are acceptable research currency. It seems a small price to pay.</p>
<p>And don't call them secretaries, when they really are smiths. They might not mine the ore, but without them it's all a pretty useless lump of rock.</p>
<h3>10. getting from the come-to-me mentality to the go-out-and-find-them mentality.</h3>
<p>Sometimes in my dreams, <a href="https://gowers.wordpress.com/2011/10/31/how-might-we-get-to-a-new-model-of-mathematical-publishing/#comment-12847">somebody screams</a> &quot;I need journal rankings and impact factors because that's the only way to weed out 600 applicants&quot; and I awake sweating, panicking, thinking: you're doing it wrong!</p>
<p>It's quite simple really. If you have a job which attracts 600 serious applicants you should be headhunting to find the best fit -- not passively wait for applications to pile on a search committee's desk. Of course, the current system does not allow such a behavior. But without a doubt this is a better strategy for hiring a candidate, a strategy with an actual chance of finding a good fit for your department, for all aspects of research.</p>
<p>This simple idea is far fetched given the established system. There would be many challenges to change our culture in this direction, not the least of which is keeping nepotism in check. I don't think it will really happen, actually, even if I dream it would.</p>
<p>But to use impact factors instead is simply lazy. The fact that we rely on this is actually damaging to our community as it is a metric that can be badly gamed and is heavily biased towards mainstream research. Needless to say, hiring committees are yet another research activity which deserves much more recognition. Only if this work gets proper acknowledgement is there any chance to spend more resources on a productive strategy for one of the highest impact activities of any researcher -- hiring fellow faculty members.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11 dreams for the publishing debate — #9 propagating the Shelah Model]]></title>
        <id>https://www.peterkrautzberger.org/0116/</id>
        <link href="https://www.peterkrautzberger.org/0116/">
        </link>
        <updated>2012-06-18T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>3, 2, 1...<br>
Each new post will start from the top, so scroll down a little if you've read the previous one -- but also check out the <a href="https://www.peterkrautzberger.org/0108/">first post</a> for some motivation.</p>
</blockquote>
<p>These are dreams. Some are realistic---perhaps just around the corner; others are way out there---basically crazy. Some will apply to everyone, others only to some. But all have diversity in mind, diversity in our expectations of who researchers are and what they do.</p>
<h3>1. write fewer original-research papers</h3>
<p>I know what you're going to say. But hear me out. This is at the core: to enable researchers to publish fewer &quot;new result&quot;-papers.</p>
<p>I believe all major problems brought up in the debate are, at the heart, caused by the immense increase in publications -- but not the global increase, the personal one. You have to publish far too much/big these days to get a half-decent position/grant. Increasing publication numbers did not increase the quality of research or, for that matter, the &quot;quality of life&quot; in our communities.</p>
<p>Instead, the <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2909426/">massive inflation</a> is <a href="http://carlzimmer.com/articles/index.php?subaction=showfull&amp;id=1336594400&amp;archive=&amp;start_from=&amp;ucat=15&amp;">killing us</a>, devaluating everything we do as researchers. More papers mean that our papers are worth less. Having to publish more papers means we produce more research of questionable quality (unintentionally and otherwise). Especially young researchers have to publish for metrics instead of quality. Worst of all, evaluating researchers only by this steam-punkesque output means that the jobs go to people with this one singular skill -- writing the right kind of papers to please the editorial boards of the right kind of journals -- leading to an intellectual monoculture instead of diverse, stable, rich communities. In particular, the pressure works against women and minorities as they often start with and continue to face disadvantages in their careers that make it harder to produce the desired &quot;output&quot; in the desired time frame.</p>
<p>(If you're wondering why I'm not bashing &quot;evil publishers&quot;. I don't think they are the problem -- we are. If you are happy with the inflation of papers-in-journals, then big publishers are what you need.)</p>
<h3>2. get real credit for surveys, reviews and exposition</h3>
<p>Surveys, reviews and expositions are research -- nothing more, nothing less. We live in a time where it is actually <em>more</em> important to write expository work. Why? Because we've optimized our production pipeline so well that there is no shortage of new (looking) results. Yes, you can argue about &quot;relevance&quot; (I won't, but I can't stop you). But if you're serious about all that &quot;research for research's-sake&quot;-talk, then you might notice that we've figured out how to educate people in the tens of thousands every year that do nothing else but churn out result after result.</p>
<p>As <a href="http://blog.felixbreuer.net/2012/02/27/beyondtheorems.html">Felix aptly wrote</a>: we need to move beyond &quot;new&quot; results. And this means to step back from them and, well, review. Surveys are the glue that holds our fields together, holds our communities together. We do it all the time -- if you read a paper thoroughly, you'll most likely write a review anyway. As we aggregate, work on larger projects or grant proposals these aggregate and easily become surveys and expositions. We need to make all of these public so that the community and the original author(!) can benefit from this enormous creative output that otherwise might only show up in a reading seminar or a journal club.</p>
<p>Mathematicians usually do even more. If we read a paper, we create our own version of the results. Mathematics need these just like music needs different interpretations. We need to give people who are &quot;just&quot; re-writing proofs the credit they deserve, the credit for keeping results alive, accessible and understandable to a wider audience than the original author and referee.</p>
<p>And with credit, I don't mean vouchers for some bookstore. Surveys must be first-class citizens! Surveying and reviewing other peoples work belongs on your CV, it is no less original than your &quot;original research&quot; and every department should have people that are exceptional at it, that are better at surveys, reviews or exposition than &quot;new&quot; research and add to the diversity of a department.</p>
<h3>3. get real credit for refereeing</h3>
<p>Refereeing is research, just like surveys and &quot;new results&quot;. It might seem redundant after dream #2 (and in many ways I would say that's the goal), but given the importance of refereeing right now and the way we do it, it's separate.</p>
<p>Currently, good refereeing seems nearly impossible. With the increase of publications we can't even catch up with what's happening in our own narrowly focused interests -- how, then, can we expect to referee properly? Sam tells his own funny but sad <a href="http://boolesrings.org/scoskey/peer-review-failure/">story of refereeing honestly</a> but the problem runs deep. Good referees are hard to find and when you find them, they could be writing a paper instead of refereeing -- and why should they not?</p>
<p>There are many ways we could improve refereeing. We can (and should) split up the different stages of refereeing (reference checking, correctness checking on different levels, opinion gathering etc), we should open pre- and post-publication peer review (and in-between peer review), we should use alternative methods to collect these reviews (instead of review journals that have at most one opinion per paper).</p>
<p>One key of refereeing is forming an opinion -- and voicing it. That's very hard, in particular for young and disadvantaged researchers who fear significant repercussions. But we don't need less people sharing their opinions on other researchers' output, we need more (whether they agree or not); it's a responsibility both to our own research communities and to a larger society.</p>
<p>But all of these are very unlikely to work, if we don't find a way to give referees the credit (and criticism) they deserve. Before we can <a href="https://xianblog.wordpress.com/2012/05/24/in-praise-of-the-referee-2/">praise referees</a> we need tools to evaluate refereeing, both in current and future form. Above all, we need to be able to put refereeing on the CV, it's part of the research qualities every strong department should strive for.</p>
<h3>4. get real credit for communicating</h3>
<p>Communicating other people's work through surveys, exposition and reviews is important. Then there's communicating to students aka teaching. This is an especially sore point for mathematics where undergraduate teaching has become a blunt tool to weed out graduates for other disciplines -- our self-respect seems greatly lacking. And then, of course, there's spreading the word to the wider public.</p>
<p>Have you ever noticed that many of the great researchers are excellent communicators (and teachers and surveyors and referees)? I would go as far as to say that a <em>truly</em> great researcher will be great in at least one of these ways to communicate. Without this, you're only a great something-else. We should cherish not just one ability of our truly great minds, but all of them. Right now we promote researchers according to how their &quot;new result&quot;-output compares to the &quot;new result&quot;-output of the truly great ones. Why are we so one dimensional?</p>
<p>Also, communication goes both ways, so we must listen. Can you imagine a graduate-student-run, &quot;Law Review&quot;-like journal for mathematics? Graduate students are perfect for forcing you to reflect on your research -- we should encourage them to make their thoughts public (including anonymously and pseudonomously). But we mathematicians need to go further. When <a href="http://en.wikipedia.org/wiki/Robert_Parris_Moses">Bob Moses</a> was speaking at Michigan earlier this year he argued that history will judge us as math literacy becomes a <a href="http://news.harvard.edu/gazette/2001/05.17/e04-moses.html">civil rights issue</a> in the 21st century. Are we listening?</p>
<p>Without communication, we risk the longevity of our own research areas because we won't be <em>understood</em> by the next generation, by other areas and by society as a whole. But this means <a href="http://scientopia.org/blogs/scicurious/2012/06/06/on-outreach-somethings-got-to-give/">something's gotta give</a> and we need to accept that by giving real credit.</p>
<h3>5. sharing all our work every way we can</h3>
<p>One battle that most scientists are still fighting -- full self-archival rights -- mathematics has long won. We need to make this happen for everyone. We must use the arXiv, our homepages or (if you must) walled gardens such as <a href="http://www.academia.edu/">academia.edu</a> and <a href="http://www.researchgate.net/">researchgate</a>. But we should also embrace more recent alternatives like <a href="http://figshare.com/">figshare</a> and <a href="http://github.com/">github</a> to post <em>all</em> our research publicly -- preprints, notes, lecture notes, expository notes, simply everything. <a href="https://en.wikipedia.org/wiki/Open_Notebook_Science">Open notebook science</a> is the key, but it's in its infancy. We need to find ways (many different ones) that work for a larger part of our communities so it becomes easier for people to experiment with it and to make it something even better. It might not be for everyone, but it's something everybody will benefit from.</p>
<p>However, the truth is that even among mathematicians a large group doesn't use the arXiv, let alone keep professional homepages deserving the name. I know that especially older researchers often hesitate because technical issues &quot;are more trouble than it's worth&quot;. This is a challenge and we must argue against this and more importantly help to sort out problems, within departments, within small research communities etc to overcome these obstacles. Approach people, ask them why their papers aren't availabe and help them put them properly online. In all other cases: <a href="https://sbseminar.wordpress.com/2010/02/09/grothendiecks-letter/">Don't be a Grothendieck</a>.</p>
<h3>6. publishing in smaller increments</h3>
<p>Have you ever read a paper that seemed to hide its true goal because the author wasn't finished but had to publish something out of the pressure of not having a job otherwise? Have you ever read a paper that made a small but reasonable result look much more than it really was just so that it will make the least publishable unit? Have you ever read a paper that was so badly written that you couldn't make sense of it?</p>
<p>Paradoxically, one way to publish fewer &quot;new results&quot; papers might be to publish more but differently. For scientists this might seem easier, publishing as the data comes in. But even for mathematics we have all those little results -- the small gems, the one-line-proof, the clever counterexample, the good reformulation, the useful shortcut -- all those could be published quickly and openly instead of waiting to find enough to &quot;make it a paper&quot;. Just like data, these could be reviewed publicly much more easily and we should get proper credit for doing so (both author and reviewer).</p>
<p>Longer results could (depending on their nature) be published incrementally, with multiple, public revisions. Take the preprint idea one step further and make your writing process public. Use a revision system like github to expose the process. Allow for outside input in your writing process, in your working process. The internet makes us an intricately connected community and we can work together in one big virtual seminar. There are already excellent examples in that area. In mathematics in particular, we have the <a href="http://polymathprojects.org/">Polymath project</a> or Ryan O'Donnell's <a href="http://www.analysisofbooleanfunctions.org/">Analysis of Boolean Functions</a>, a text book he's working out as a blog.</p>
<p>But as I've argued <a href="https://www.peterkrautzberger.org/0107/">Polymath doesn't work for very many people</a> so, again, we need many, many more projects like these so that more people have the opportunity to find a way that works for them.</p>
<p>There's of course a risk -- this could create a lot of noise as incrementally published results implode when data turns out to be flawed, proofs disintegrate and general anarchy rears its head! But I think it's worth the risk. Search technology is constantly improving and good scientific standards should ensure that failed research is marked accordingly. And we have so much to gain! We might be able to finally give credit for failing productively -- the main thing researchers do anyway, we fail and fail and fail until we understand what's going on. Sometimes we have to give up, but why shouldn't somebody else continue for us?</p>
<p>Even if your research implodes, you should get credit and, much, much more importantly, you will help others not to repeat your mistake. <a href="http://boolesrings.org/vonheymann/">Fred</a> once worked on a nice old problem which, after a few months, clearly didn't get anywhere. But he realized that all his attacks had probably been attempted before and so he wrote a pre-print on all the ways to fail, published <a href="http://boolesrings.org/vonheymann/publications/code/">his code along with it</a> so that people in the future might benefit from his failure. Or as <a href="http://www.math.rutgers.edu/~zeilberg/Opinion39.html">Doron Zeilberger wrote</a>: if only John von Neumann's maid had saved all the notes he'd thrown away each day!</p>
<p>Or to put it differently: the most exciting result in 2011 was having <a href="http://m-phi.blogspot.com/2011/10/inconsistency-of-pa-and-consensus-in.html">no result about Con(PA)</a>.</p>
<h3>7. an affordable open access model</h3>
<p>Research publications should be free, for both authors and readers. When it comes to traditional journals, there are already some in mathematics (e.g. <a href="http://nyjm.albany.edu/">NYJM</a>) that offer open access without any fees. I believe we can move to a journal system that is entirely open access and without publishing fees but we're not there yet. Mathematical journals are said to have profit margins of 90% so we should be the first to get there. Gold open access is already realistic and, more importantly, can be made affordable right now. With <a href="http://peerj.com/">peerj</a>, this is already around the corner on a much larger scale.</p>
<p>On the other hand, it seems natural to me to return academic publications to universities and academic societies. For journals, this could simply be done PLoS-ONE style (checking correctness, not &quot;importance&quot;) and our institutions could certainly make such journals open access, non-profit and actually free (just have each department produce one journal). But new ways of doing and sharing research will hardly fit into the journal model. These methods will be much more user centric, will be about people, not publishers. And the natural place to store information about people is their professional homepage as a repository of their work. It seems natural that universities or academic societies could play a much better role in this then proprietary social networks.</p>
<p>However, one problem we'd be facing is that journal publishing is the cash cow of many societies and this money is often used to cross-finance important services. This is not helpful in a time where <a href="https://web.archive.org/web/20140723061813/http://blog.findings.com/post/20527246081/how-we-will-read-clay-shirky">publishing is a button [Wayback machine]</a>. We'll have to find another way to finance things that need financing and we'll have to talk about that, too. Additionally, if we move scientific &quot;publishing&quot; to the next level, there will be new costs: costs for research into doing it, costs for experiments, costs for failures. We need to talk about those, too.</p>
<h3>8. a cultural change of doing research (and metrics for it)</h3>
<p>If we publish less &quot;new results&quot;, some structural problems might just disappear. Fewer papers means fewer journals means fewer subscriptions means fewer refereeing. Smaller workload and smaller costs. But this can only work if we have tools to nevertheless show what happens in between writing-down-a-decent-result-which-takes-years-dammit. Thanks to the internet, we can actually hope to do this. But the internet will also change everything (again and again) and it will change our communities (again and again). We need to invest resources right now to be able to benefit from this change, find a way to evolve into a work mode that is more appropriate for what is yet to come than what was in the past. We need to get into a constant-change mentality and we need to make this worth everybody's while.</p>
<p>Our funding bodies, academic societies, universities and other institutions must fund more experiments for doing research differently and the metrics needed for this. At the very least, we need more incubators like Macmillan's <a href="http://www.digital-science.com/">Digital-Science</a>, but also in a non-profit fashion along the lines of <a href="http://www.mathjax.org/">MathJax</a>'s business model. Reversely, our communities must value anybody's effort of joining new experimental platforms such as MO/math.SE, blogs, citizen science projects, polymath-esque projects, wikipedia and all those platforms that are still only dreams. The <a href="http://altmetrics.org/manifesto/">altmetrics</a> people are already setting many good examples and platforms such as Stackexchange and Wikipedia are working hard to develop reputation technology that will allow us to measure people's activity in these new scientific environments.</p>
<p>This, of course, means breaking out of the mono-culture of &quot;papers in journals&quot; -- a rough cultural change. Nobody talks about this drastic change which, I believe, makes it is the biggest problem in this entire debate. If we change the way we do (and evaluate) research, then we ask incredibly much of the people who are working well in the current model, who are good at (only?) writing the right kind of papers for the right kind of journals. It would be a revolution if people were hired because their non-traditional research activities outweigh the traditional paper count of other applicants -- in other words, if hiring would happen strategically, with that kind of diversity in mind. Case in point: even Michael Nielsen overlooks this problem completely in <a href="http://michaelnielsen.org/blog/reinventing-discovery/">his wonderful book</a>.</p>
<p>This change is even more important for smaller research areas (and must be made to work for them) who can't play the impact factor game. Failing to adapt, might even mean extinction in this case. But the potential is equally great as more diverse ways of doing research can also mean a better chance to work across fields and improve collaboration and visibility of small fields.</p>
<h3>9. propagating the Shelah Model -- encouraging bad writers to seek out good writers</h3>
<p>This may seem a very math-specific dream, possibly extending to the humanities, but it does apply to the sciences in more than one way.</p>
<p>Not only do we have too many &quot;new result&quot; papers, we also have too many horribly written papers. Although there's certainly a talent to being a great writer of research publications, we're facing the problem that our communities just down care enough to enforce even mediocre standards of writing. This is particularly hard with leading researchers who will find their manuscripts barely scrutinized.</p>
<p>Much worse, however, young researchers have an incentive <em>not</em> to care for the quality of their writing and the work necessary for it. Instead the motto is: &quot;Just get it by the referee and be done with it! You could produce a new result while you waste your time revising this one!&quot;. Referees and editors in turn have little incentive to spend their unpaid time improving a paper, so it's easier to simply dismiss a paper or ignore the communicative shortcomings (after all, the referee understood the damn thing...).</p>
<p>As <a href="http://logic.dorais.org/archives/630">Dor-Bar Natan said</a></p>
<blockquote>
<p>Papers are written so that their author(s) can forget their content and move on to other things.</p>
</blockquote>
<p>The lack of quality control in academic writing endangers long term accessibility of our research as much as data supplements in proprietary formats. In the long run, it makes papers less trustworthy and compromises the greatest strength of research, to build on earlier work. Simply put, archival is rather pointless if nobody can comprehend the content.</p>
<p>Of course, some people are more skilled, some are less skilled as writers. So why not join them up? <a href="https://en.wikipedia.org/wiki/Saharon_Shelah">Saharon Shelah</a> has published over 1,000 papers with 220 co-authors. Not only does the number of co-authors allow Shelah to produce more papers, it also allows the community to understand them better. Yet some of his co-authors are mocked as &quot;Shelah's secretaries&quot;, supposedly not publishing enough &quot;alone&quot;. Besides being pathetic ad-hominem attacks, this completely overlooks the fact that in many cases only these co-authors make Shelah's incredible output accessible to the research community.</p>
<p>Let's have editors and referees tell bad writers to find a capable co-author instead. It should be a win-win situation -- good writers will get to be on more papers and researchers lacking in writing skills get their thoughts polished so that other people can actually build on their work. As a bonus, the papers get some pre-publication peer-review and editors and referees shoulder a smaller workload. All we have to do is give up the notion that only &quot;new results&quot; are acceptable research currency. It seems a small price to pay.</p>
<p>And don't call them secretaries, when they really are smiths. They might not mine the ore, but without them it's all a pretty useless lump of rock.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Andreas Blass</strong>, 2012/06/19<br>
As one of Shelah’s co-authors/secretaries/smiths, let me point out a limitation of your suggestion.  I find it a very good use of my time to work through a draft by Shelah, ask him about whatever difficulties I encounter, fill in missing material, perhaps modify some parts when I see a clearer approach, and write up the result for public consumption.  But this depends on the fact that I gain by learning Shelah’s ideas.  Substitute a randomly chosen bad writer for Shelah, and you’ll probably find me very unwilling to be a co-author.  So, if an editor were to follow your suggestion, telling authors of badly written papers to find a capable co-author, and even if the authors were to honestly try to do this, the usual result will be that no suitable co-author is found and the badly written paper simply goes to another journal.  In other words, the Shelah “system” depends strongly on Shelah’s reputation for outstanding research, and there are very few people with such reputations.  (By the way, the Shelah “system” also depends on Shelah’s willingness to patiently explain things to people like me, who sometimes need two pages of notes to support Shelah’s “clearly”.)
<ul>
<li><strong>Peter</strong>, 2012/06/19<br>
Thank you for all your comments, Andreas!<br>
I agree that Saharon Shelah is a unique case given, but he is a wonderful role model, so I chose him for explaining this idea.<br>
You're right, of course, and I don't actually expect it to be as easy as editors making a suggestion and then it just works (not in the current situation or on a large scale anyway). I do think something could be done, at least in part (also, this idea falls under &quot;works for some&quot;, not &quot;must work for everyone).<br>
For example, I could imagine a system where a bad writer advertises an interesting result on a specialized platform to find a match with a good writer (or at least better or maybe just willing to work on that aspect). Granted, it's less appealing than the admiration I would feel towards working with Shelah; maybe it's more something for young researchers, eager to learn about new topics, get some experience, hone their skills.   If I was trying to be funny, I'd call it a dating site (who knows, the algorithms might just work 😉 ).<br>
In general, I wanted to make the point that the mockery &quot;Shelah's secretaries&quot; is silly and damaging to our communities. These collaborations are a wonderful example for how some research activities do not fall into established categories, yet are very important to our fields. Instead of ridiculing it, we should value the service and research level good writers provide. If we gave proper credit, the number of volunteers might also increase. (Of course, there's no linear scale here anyway and it's really a question of matching co-authors that complete each other).<br>
To highlight how silly the insult is, one might argue in the other extreme: it's much better for the mathematical community to grab as many Shelah results as possible instead of allowing &quot;mediocre&quot; researchers to &quot;waste&quot; their time doing their own research.<br>
PS: this dream was also influenced by <a href="http://boolesrings.org/krautzberger/2012/01/29/a-comment-on-tim-gowerss-blog/#comment-727">Izabella Laba's comment</a> (even though that one is aimed at expository skills). Perhaps, there are more good researchers out there that could successfully follow Shelah's model.</li>
</ul>
</li>
<li><strong>Thilo</strong>, 2012/06/25<br>
I totally agree with your critique of attacks against people spending much of their time coauthoring papers with Shelah. It seems to be seen as easy and unimportant while it very probably is neither.<br>
Personally I doubt whether every researcher would like to change the way she or he works to the extent you are suggesting. But humans are different and a research community is likely to profit from encouraging diversity in topics of and approach towards research, I think.<br>
Another point: It seems to me that the quality of a paper is likely to increase even if a bad writer joins up with just another bad writer. People can get carried away by their idiosyncrasies(I know what I am speaking of.), so unless the colleague tends to write bad in exactly the same way the paper might just get better by consulting a colleague.
<ul>
<li><strong>Peter</strong>, 2012/08/04<br>
Thanks for your comment Thilo. I also agree with you that teaming up is always a good idea, no matter how bad our own writing is. In particular, seeing how departments are shrinking almost everywhere, it will be much harder to find people locally, no matter what. But the net can help, I think. You just need to put yourself out there a little.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11 dreams for the publishing debate — #8 a cultural change of doing research (and metrics for it)]]></title>
        <id>https://www.peterkrautzberger.org/0115/</id>
        <link href="https://www.peterkrautzberger.org/0115/">
        </link>
        <updated>2012-06-17T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>On and on and on...<br>
Each new post will start from the top, so scroll down a little if you've read the previous one -- but also check out the <a href="https://www.peterkrautzberger.org/0108/">first post</a> for some motivation.</p>
</blockquote>
<p>These are dreams. Some are realistic---perhaps just around the corner; others are way out there---basically crazy. Some will apply to everyone, others only to some. But all have diversity in mind, diversity in our expectations of who researchers are and what they do.</p>
<h3>1. write fewer original-research papers</h3>
<p>I know what you're going to say. But hear me out. This is at the core: to enable researchers to publish fewer &quot;new result&quot;-papers.</p>
<p>I believe all major problems brought up in the debate are, at the heart, caused by the immense increase in publications -- but not the global increase, the personal one. You have to publish far too much/big these days to get a half-decent position/grant. Increasing publication numbers did not increase the quality of research or, for that matter, the &quot;quality of life&quot; in our communities.</p>
<p>Instead, the <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2909426/">massive inflation</a> is <a href="http://carlzimmer.com/articles/index.php?subaction=showfull&amp;id=1336594400&amp;archive=&amp;start_from=&amp;ucat=15&amp;">killing us</a>, devaluating everything we do as researchers. More papers mean that our papers are worth less. Having to publish more papers means we produce more research of questionable quality (unintentionally and otherwise). Especially young researchers have to publish for metrics instead of quality. Worst of all, evaluating researchers only by this steam-punkesque output means that the jobs go to people with this one singular skill -- writing the right kind of papers to please the editorial boards of the right kind of journals -- leading to an intellectual monoculture instead of diverse, stable, rich communities. In particular, the pressure works against women and minorities as they often start with and continue to face disadvantages in their careers that make it harder to produce the desired &quot;output&quot; in the desired time frame.</p>
<p>(If you're wondering why I'm not bashing &quot;evil publishers&quot;. I don't think they are the problem -- we are. If you are happy with the inflation of papers-in-journals, then big publishers are what you need.)</p>
<h3>2. get real credit for surveys, reviews and exposition</h3>
<p>Surveys, reviews and expositions are research -- nothing more, nothing less. We live in a time where it is actually <em>more</em> important to write expository work. Why? Because we've optimized our production pipeline so well that there is no shortage of new (looking) results. Yes, you can argue about &quot;relevance&quot; (I won't, but I can't stop you). But if you're serious about all that &quot;research for research's-sake&quot;-talk, then you might notice that we've figured out how to educate people in the tens of thousands every year that do nothing else but churn out result after result.</p>
<p>As <a href="http://blog.felixbreuer.net/2012/02/27/beyondtheorems.html">Felix aptly wrote</a>: we need to move beyond &quot;new&quot; results. And this means to step back from them and, well, review. Surveys are the glue that holds our fields together, holds our communities together. We do it all the time -- if you read a paper thoroughly, you'll most likely write a review anyway. As we aggregate, work on larger projects or grant proposals these aggregate and easily become surveys and expositions. We need to make all of these public so that the community and the original author(!) can benefit from this enormous creative output that otherwise might only show up in a reading seminar or a journal club.</p>
<p>Mathematicians usually do even more. If we read a paper, we create our own version of the results. Mathematics need these just like music needs different interpretations. We need to give people who are &quot;just&quot; re-writing proofs the credit they deserve, the credit for keeping results alive, accessible and understandable to a wider audience than the original author and referee.</p>
<p>And with credit, I don't mean vouchers for some bookstore. Surveys must be first-class citizens! Surveying and reviewing other peoples work belongs on your CV, it is no less original than your &quot;original research&quot; and every department should have people that are exceptional at it, that are better at surveys, reviews or exposition than &quot;new&quot; research and add to the diversity of a department.</p>
<h3>3. get real credit for refereeing</h3>
<p>Refereeing is research, just like surveys and &quot;new results&quot;. It might seem redundant after dream #2 (and in many ways I would say that's the goal), but given the importance of refereeing right now and the way we do it, it's separate.</p>
<p>Currently, good refereeing seems nearly impossible. With the increase of publications we can't even catch up with what's happening in our own narrowly focused interests -- how, then, can we expect to referee properly? Sam tells his own funny but sad <a href="http://boolesrings.org/scoskey/peer-review-failure/">story of refereeing honestly</a> but the problem runs deep. Good referees are hard to find and when you find them, they could be writing a paper instead of refereeing -- and why should they not?</p>
<p>There are many ways we could improve refereeing. We can (and should) split up the different stages of refereeing (reference checking, correctness checking on different levels, opinion gathering etc), we should open pre- and post-publication peer review (and in-between peer review), we should use alternative methods to collect these reviews (instead of review journals that have at most one opinion per paper).</p>
<p>One key of refereeing is forming an opinion -- and voicing it. That's very hard, in particular for young and disadvantaged researchers who fear significant repercussions. But we don't need less people sharing their opinions on other researchers' output, we need more (whether they agree or not); it's a responsibility both to our own research communities and to a larger society.</p>
<p>But all of these are very unlikely to work, if we don't find a way to give referees the credit (and criticism) they deserve. Before we can <a href="https://xianblog.wordpress.com/2012/05/24/in-praise-of-the-referee-2/">praise referees</a> we need tools to evaluate refereeing, both in current and future form. Above all, we need to be able to put refereeing on the CV, it's part of the research qualities every strong department should strive for.</p>
<h3>4. get real credit for communicating</h3>
<p>Communicating other people's work through surveys, exposition and reviews is important. Then there's communicating to students aka teaching. This is an especially sore point for mathematics where undergraduate teaching has become a blunt tool to weed out graduates for other disciplines -- our self-respect seems greatly lacking. And then, of course, there's spreading the word to the wider public.</p>
<p>Have you ever noticed that many of the great researchers are excellent communicators (and teachers and surveyors and referees)? I would go as far as to say that a <em>truly</em> great researcher will be great in at least one of these ways to communicate. Without this, you're only a great something-else. We should cherish not just one ability of our truly great minds, but all of them. Right now we promote researchers according to how their &quot;new result&quot;-output compares to the &quot;new result&quot;-output of the truly great ones. Why are we so one dimensional?</p>
<p>Also, communication goes both ways, so we must listen. Can you imagine a graduate-student-run, &quot;Law Review&quot;-like journal for mathematics? Graduate students are perfect for forcing you to reflect on your research -- we should encourage them to make their thoughts public (including anonymously and pseudonomously). But we mathematicians need to go further. When <a href="http://en.wikipedia.org/wiki/Robert_Parris_Moses">Bob Moses</a> was speaking at Michigan earlier this year he argued that history will judge us as math literacy becomes a <a href="http://news.harvard.edu/gazette/2001/05.17/e04-moses.html">civil rights issue</a> in the 21st century. Are we listening?</p>
<p>Without communication, we risk the longevity of our own research areas because we won't be <em>understood</em> by the next generation, by other areas and by society as a whole. But this means <a href="http://scientopia.org/blogs/scicurious/2012/06/06/on-outreach-somethings-got-to-give/">something's gotta give</a> and we need to accept that by giving real credit.</p>
<h3>5. sharing all our work every way we can</h3>
<p>One battle that most scientists are still fighting -- full self-archival rights -- mathematics has long won. We need to make this happen for everyone. We must use the arXiv, our homepages or (if you must) walled gardens such as <a href="http://www.academia.edu/">academia.edu</a> and <a href="http://www.researchgate.net/">researchgate</a>. But we should also embrace more recent alternatives like <a href="http://figshare.com/">figshare</a> and <a href="http://github.com/">github</a> to post <em>all</em> our research publicly -- preprints, notes, lecture notes, expository notes, simply everything. <a href="https://en.wikipedia.org/wiki/Open_Notebook_Science">Open notebook science</a> is the key, but it's in its infancy. We need to find ways (many different ones) that work for a larger part of our communities so it becomes easier for people to experiment with it and to make it something even better. It might not be for everyone, but it's something everybody will benefit from.</p>
<p>However, the truth is that even among mathematicians a large group doesn't use the arXiv, let alone keep professional homepages deserving the name. I know that especially older researchers often hesitate because technical issues &quot;are more trouble than it's worth&quot;. This is a challenge and we must argue against this and more importantly help to sort out problems, within departments, within small research communities etc to overcome these obstacles. Approach people, ask them why their papers aren't availabe and help them put them properly online. In all other cases: <a href="https://sbseminar.wordpress.com/2010/02/09/grothendiecks-letter/">Don't be a Grothendieck</a>.</p>
<h3>6. publishing in smaller increments</h3>
<p>Have you ever read a paper that seemed to hide its true goal because the author wasn't finished but had to publish something out of the pressure of not having a job otherwise? Have you ever read a paper that made a small but reasonable result look much more than it really was just so that it will make the least publishable unit? Have you ever read a paper that was so badly written that you couldn't make sense of it?</p>
<p>Paradoxically, one way to publish fewer &quot;new results&quot; papers might be to publish more but differently. For scientists this might seem easier, publishing as the data comes in. But even for mathematics we have all those little results -- the small gems, the one-line-proof, the clever counterexample, the good reformulation, the useful shortcut -- all those could be published quickly and openly instead of waiting to find enough to &quot;make it a paper&quot;. Just like data, these could be reviewed publicly much more easily and we should get proper credit for doing so (both author and reviewer).</p>
<p>Longer results could (depending on their nature) be published incrementally, with multiple, public revisions. Take the preprint idea one step further and make your writing process public. Use a revision system like github to expose the process. Allow for outside input in your writing process, in your working process. The internet makes us an intricately connected community and we can work together in one big virtual seminar. There are already excellent examples in that area. In mathematics in particular, we have the <a href="http://polymathprojects.org/">Polymath project</a> or Ryan O'Donnell's <a href="http://www.analysisofbooleanfunctions.org/">Analysis of Boolean Functions</a>, a text book he's working out as a blog.</p>
<p>But as I've argued <a href="https://www.peterkrautzberger.org/0107/">Polymath doesn't work for very many people</a> so, again, we need many, many more projects like these so that more people have the opportunity to find a way that works for them.</p>
<p>There's of course a risk -- this could create a lot of noise as incrementally published results implode when data turns out to be flawed, proofs disintegrate and general anarchy rears its head! But I think it's worth the risk. Search technology is constantly improving and good scientific standards should ensure that failed research is marked accordingly. And we have so much to gain! We might be able to finally give credit for failing productively -- the main thing researchers do anyway, we fail and fail and fail until we understand what's going on. Sometimes we have to give up, but why shouldn't somebody else continue for us?</p>
<p>Even if your research implodes, you should get credit and, much, much more importantly, you will help others not to repeat your mistake. <a href="http://boolesrings.org/vonheymann/">Fred</a> once worked on a nice old problem which, after a few months, clearly didn't get anywhere. But he realized that all his attacks had probably been attempted before and so he wrote a pre-print on all the ways to fail, published <a href="http://boolesrings.org/vonheymann/publications/code/">his code along with it</a> so that people in the future might benefit from his failure. Or as <a href="http://www.math.rutgers.edu/~zeilberg/Opinion39.html">Doron Zeilberger wrote</a>: if only John von Neumann's maid had saved all the notes he'd thrown away each day!</p>
<p>Or to put it differently: the most exciting result in 2011 was having <a href="http://m-phi.blogspot.com/2011/10/inconsistency-of-pa-and-consensus-in.html">no result about Con(PA)</a>.</p>
<h3>7. an affordable open access model</h3>
<p>Research publications should be free, for both authors and readers. When it comes to traditional journals, there are already some in mathematics (e.g. <a href="http://nyjm.albany.edu/">NYJM</a>) that offer open access without any fees. I believe we can move to a journal system that is entirely open access and without publishing fees but we're not there yet. Mathematical journals are said to have profit margins of 90% so we should be the first to get there. Gold open access is already realistic and, more importantly, can be made affordable right now. With <a href="http://peerj.com/">peerj</a>, this is already around the corner on a much larger scale.</p>
<p>On the other hand, it seems natural to me to return academic publications to universities and academic societies. For journals, this could simply be done PLoS-ONE style (checking correctness, not &quot;importance&quot;) and our institutions could certainly make such journals open access, non-profit and actually free (just have each department produce one journal). But new ways of doing and sharing research will hardly fit into the journal model. These methods will be much more user centric, will be about people, not publishers. And the natural place to store information about people is their professional homepage as a repository of their work. It seems natural that universities or academic societies could play a much better role in this then proprietary social networks.</p>
<p>However, one problem we'd be facing is that journal publishing is the cash cow of many societies and this money is often used to cross-finance important services. This is not helpful in a time where <a href="https://web.archive.org/web/20140723061813/http://blog.findings.com/post/20527246081/how-we-will-read-clay-shirky">publishing is a button [Wayback machine]</a>. We'll have to find another way to finance things that need financing and we'll have to talk about that, too. Additionally, if we move scientific &quot;publishing&quot; to the next level, there will be new costs: costs for research into doing it, costs for experiments, costs for failures. We need to talk about those, too.</p>
<h3>8. a cultural change of doing research (and metrics for it)</h3>
<p>If we publish less &quot;new results&quot;, some structural problems might just disappear. Fewer papers means fewer journals means fewer subscriptions means fewer refereeing. Smaller workload and smaller costs. But this can only work if we have tools to nevertheless show what happens in between writing-down-a-decent-result-which-takes-years-dammit. Thanks to the internet, we can actually hope to do this. But the internet will also change everything (again and again) and it will change our communities (again and again). We need to invest resources right now to be able to benefit from this change, find a way to evolve into a work mode that is more appropriate for what is yet to come than what was in the past. We need to get into a constant-change mentality and we need to make this worth everybody's while.</p>
<p>Our funding bodies, academic societies, universities and other institutions must fund more experiments for doing research differently and the metrics needed for this. At the very least, we need more incubators like Macmillan's <a href="http://www.digital-science.com/">Digital-Science</a>, but also in a non-profit fashion along the lines of <a href="http://www.mathjax.org/">MathJax</a>'s business model. Reversely, our communities must value anybody's effort of joining new experimental platforms such as MO/math.SE, blogs, citizen science projects, polymath-esque projects, wikipedia and all those platforms that are still only dreams. The <a href="http://altmetrics.org/manifesto/">altmetrics</a> people are already setting many good examples and platforms such as Stackexchange and Wikipedia are working hard to develop reputation technology that will allow us to measure people's activity in these new scientific environments.</p>
<p>This, of course, means breaking out of the mono-culture of &quot;papers in journals&quot; -- a rough cultural change. Nobody talks about this drastic change which, I believe, makes it is the biggest problem in this entire debate. If we change the way we do (and evaluate) research, then we ask incredibly much of the people who are working well in the current model, who are good at (only?) writing the right kind of papers for the right kind of journals. It would be a revolution if people were hired because their non-traditional research activities outweigh the traditional paper count of other applicants -- in other words, if hiring would happen strategically, with that kind of diversity in mind. Case in point: even Michael Nielsen overlooks this problem completely in <a href="http://michaelnielsen.org/blog/reinventing-discovery/">his wonderful book</a>.</p>
<p>This change is even more important for smaller research areas (and must be made to work for them) who can't play the impact factor game. Failing to adapt, might even mean extinction in this case. But the potential is equally great as more diverse ways of doing research can also mean a better chance to work across fields and improve collaboration and visibility of small fields.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11 dreams for the publishing debate — #7 an affordable open access model]]></title>
        <id>https://www.peterkrautzberger.org/0114/</id>
        <link href="https://www.peterkrautzberger.org/0114/">
        </link>
        <updated>2012-06-16T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Here we go again...<br>
Each new post will start from the top, so scroll down a little if you've read the previous one -- but also check out the <a href="https://www.peterkrautzberger.org/0108/">first post</a> for some motivation.</p>
</blockquote>
<p>These are dreams. Some are realistic---perhaps just around the corner; others are way out there---basically crazy. Some will apply to everyone, others only to some. But all have diversity in mind, diversity in our expectations of who researchers are and what they do.</p>
<h3>1. write fewer original-research papers</h3>
<p>I know what you're going to say. But hear me out. This is at the core: to enable researchers to publish fewer &quot;new result&quot;-papers.</p>
<p>I believe all major problems brought up in the debate are, at the heart, caused by the immense increase in publications -- but not the global increase, the personal one. You have to publish far too much/big these days to get a half-decent position/grant. Increasing publication numbers did not increase the quality of research or, for that matter, the &quot;quality of life&quot; in our communities.</p>
<p>Instead, the <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2909426/">massive inflation</a> is <a href="http://carlzimmer.com/articles/index.php?subaction=showfull&amp;id=1336594400&amp;archive=&amp;start_from=&amp;ucat=15&amp;">killing us</a>, devaluating everything we do as researchers. More papers mean that our papers are worth less. Having to publish more papers means we produce more research of questionable quality (unintentionally and otherwise). Especially young researchers have to publish for metrics instead of quality. Worst of all, evaluating researchers only by this steam-punkesque output means that the jobs go to people with this one singular skill -- writing the right kind of papers to please the editorial boards of the right kind of journals -- leading to an intellectual monoculture instead of diverse, stable, rich communities. In particular, the pressure works against women and minorities as they often start with and continue to face disadvantages in their careers that make it harder to produce the desired &quot;output&quot; in the desired time frame.</p>
<p>(If you're wondering why I'm not bashing &quot;evil publishers&quot;. I don't think they are the problem -- we are. If you are happy with the inflation of papers-in-journals, then big publishers are what you need.)</p>
<h3>2. get real credit for surveys, reviews and exposition</h3>
<p>Surveys, reviews and expositions are research -- nothing more, nothing less. We live in a time where it is actually <em>more</em> important to write expository work. Why? Because we've optimized our production pipeline so well that there is no shortage of new (looking) results. Yes, you can argue about &quot;relevance&quot; (I won't, but I can't stop you). But if you're serious about all that &quot;research for research's-sake&quot;-talk, then you might notice that we've figured out how to educate people in the tens of thousands every year that do nothing else but churn out result after result.</p>
<p>As <a href="http://blog.felixbreuer.net/2012/02/27/beyondtheorems.html">Felix aptly wrote</a>: we need to move beyond &quot;new&quot; results. And this means to step back from them and, well, review. Surveys are the glue that holds our fields together, holds our communities together. We do it all the time -- if you read a paper thoroughly, you'll most likely write a review anyway. As we aggregate, work on larger projects or grant proposals these aggregate and easily become surveys and expositions. We need to make all of these public so that the community and the original author(!) can benefit from this enormous creative output that otherwise might only show up in a reading seminar or a journal club.</p>
<p>Mathematicians usually do even more. If we read a paper, we create our own version of the results. Mathematics need these just like music needs different interpretations. We need to give people who are &quot;just&quot; re-writing proofs the credit they deserve, the credit for keeping results alive, accessible and understandable to a wider audience than the original author and referee.</p>
<p>And with credit, I don't mean vouchers for some bookstore. Surveys must be first-class citizens! Surveying and reviewing other peoples work belongs on your CV, it is no less original than your &quot;original research&quot; and every department should have people that are exceptional at it, that are better at surveys, reviews or exposition than &quot;new&quot; research and add to the diversity of a department.</p>
<h3>3. get real credit for refereeing</h3>
<p>Refereeing is research, just like surveys and &quot;new results&quot;. It might seem redundant after dream #2 (and in many ways I would say that's the goal), but given the importance of refereeing right now and the way we do it, it's separate.</p>
<p>Currently, good refereeing seems nearly impossible. With the increase of publications we can't even catch up with what's happening in our own narrowly focused interests -- how, then, can we expect to referee properly? Sam tells his own funny but sad <a href="http://boolesrings.org/scoskey/peer-review-failure/">story of refereeing honestly</a> but the problem runs deep. Good referees are hard to find and when you find them, they could be writing a paper instead of refereeing -- and why should they not?</p>
<p>There are many ways we could improve refereeing. We can (and should) split up the different stages of refereeing (reference checking, correctness checking on different levels, opinion gathering etc), we should open pre- and post-publication peer review (and in-between peer review), we should use alternative methods to collect these reviews (instead of review journals that have at most one opinion per paper).</p>
<p>One key of refereeing is forming an opinion -- and voicing it. That's very hard, in particular for young and disadvantaged researchers who fear significant repercussions. But we don't need less people sharing their opinions on other researchers' output, we need more (whether they agree or not); it's a responsibility both to our own research communities and to a larger society.</p>
<p>But all of these are very unlikely to work, if we don't find a way to give referees the credit (and criticism) they deserve. Before we can <a href="https://xianblog.wordpress.com/2012/05/24/in-praise-of-the-referee-2/">praise referees</a> we need tools to evaluate refereeing, both in current and future form. Above all, we need to be able to put refereeing on the CV, it's part of the research qualities every strong department should strive for.</p>
<h3>4. get real credit for communicating</h3>
<p>Communicating other people's work through surveys, exposition and reviews is important. Then there's communicating to students aka teaching. This is an especially sore point for mathematics where undergraduate teaching has become a blunt tool to weed out graduates for other disciplines -- our self-respect seems greatly lacking. And then, of course, there's spreading the word to the wider public.</p>
<p>Have you ever noticed that many of the great researchers are excellent communicators (and teachers and surveyors and referees)? I would go as far as to say that a <em>truly</em> great researcher will be great in at least one of these ways to communicate. Without this, you're only a great something-else. We should cherish not just one ability of our truly great minds, but all of them. Right now we promote researchers according to how their &quot;new result&quot;-output compares to the &quot;new result&quot;-output of the truly great ones. Why are we so one dimensional?</p>
<p>Also, communication goes both ways, so we must listen. Can you imagine a graduate-student-run, &quot;Law Review&quot;-like journal for mathematics? Graduate students are perfect for forcing you to reflect on your research -- we should encourage them to make their thoughts public (including anonymously and pseudonomously). But we mathematicians need to go further. When <a href="http://en.wikipedia.org/wiki/Robert_Parris_Moses">Bob Moses</a> was speaking at Michigan earlier this year he argued that history will judge us as math literacy becomes a <a href="http://news.harvard.edu/gazette/2001/05.17/e04-moses.html">civil rights issue</a> in the 21st century. Are we listening?</p>
<p>Without communication, we risk the longevity of our own research areas because we won't be <em>understood</em> by the next generation, by other areas and by society as a whole. But this means <a href="http://scientopia.org/blogs/scicurious/2012/06/06/on-outreach-somethings-got-to-give/">something's gotta give</a> and we need to accept that by giving real credit.</p>
<h3>5. sharing all our work every way we can</h3>
<p>One battle that most scientists are still fighting -- full self-archival rights -- mathematics has long won. We need to make this happen for everyone. We must use the arXiv, our homepages or (if you must) walled gardens such as <a href="http://www.academia.edu/">academia.edu</a> and <a href="http://www.researchgate.net/">researchgate</a>. But we should also embrace more recent alternatives like <a href="http://figshare.com/">figshare</a> and <a href="http://github.com/">github</a> to post <em>all</em> our research publicly -- preprints, notes, lecture notes, expository notes, simply everything. <a href="https://en.wikipedia.org/wiki/Open_Notebook_Science">Open notebook science</a> is the key, but it's in its infancy. We need to find ways (many different ones) that work for a larger part of our communities so it becomes easier for people to experiment with it and to make it something even better. It might not be for everyone, but it's something everybody will benefit from.</p>
<p>However, the truth is that even among mathematicians a large group doesn't use the arXiv, let alone keep professional homepages deserving the name. I know that especially older researchers often hesitate because technical issues &quot;are more trouble than it's worth&quot;. This is a challenge and we must argue against this and more importantly help to sort out problems, within departments, within small research communities etc to overcome these obstacles. Approach people, ask them why their papers aren't availabe and help them put them properly online. In all other cases: <a href="https://sbseminar.wordpress.com/2010/02/09/grothendiecks-letter/">Don't be a Grothendieck</a>.</p>
<h3>6. publishing in smaller increments</h3>
<p>Have you ever read a paper that seemed to hide its true goal because the author wasn't finished but had to publish something out of the pressure of not having a job otherwise? Have you ever read a paper that made a small but reasonable result look much more than it really was just so that it will make the least publishable unit? Have you ever read a paper that was so badly written that you couldn't make sense of it?</p>
<p>Paradoxically, one way to publish fewer &quot;new results&quot; papers might be to publish more but differently. For scientists this might seem easier, publishing as the data comes in. But even for mathematics we have all those little results -- the small gems, the one-line-proof, the clever counterexample, the good reformulation, the useful shortcut -- all those could be published quickly and openly instead of waiting to find enough to &quot;make it a paper&quot;. Just like data, these could be reviewed publicly much more easily and we should get proper credit for doing so (both author and reviewer).</p>
<p>Longer results could (depending on their nature) be published incrementally, with multiple, public revisions. Take the preprint idea one step further and make your writing process public. Use a revision system like github to expose the process. Allow for outside input in your writing process, in your working process. The internet makes us an intricately connected community and we can work together in one big virtual seminar. There are already excellent examples in that area. In mathematics in particular, we have the <a href="http://polymathprojects.org/">Polymath project</a> or Ryan O'Donnell's <a href="http://www.analysisofbooleanfunctions.org/">Analysis of Boolean Functions</a>, a text book he's working out as a blog.</p>
<p>But as I've argued <a href="https://www.peterkrautzberger.org/0107/">Polymath doesn't work for very many people</a> so, again, we need many, many more projects like these so that more people have the opportunity to find a way that works for them.</p>
<p>There's of course a risk -- this could create a lot of noise as incrementally published results implode when data turns out to be flawed, proofs disintegrate and general anarchy rears its head! But I think it's worth the risk. Search technology is constantly improving and good scientific standards should ensure that failed research is marked accordingly. And we have so much to gain! We might be able to finally give credit for failing productively -- the main thing researchers do anyway, we fail and fail and fail until we understand what's going on. Sometimes we have to give up, but why shouldn't somebody else continue for us?</p>
<p>Even if your research implodes, you should get credit and, much, much more importantly, you will help others not to repeat your mistake. <a href="http://boolesrings.org/vonheymann/">Fred</a> once worked on a nice old problem which, after a few months, clearly didn't get anywhere. But he realized that all his attacks had probably been attempted before and so he wrote a pre-print on all the ways to fail, published <a href="http://boolesrings.org/vonheymann/publications/code/">his code along with it</a> so that people in the future might benefit from his failure. Or as <a href="http://www.math.rutgers.edu/~zeilberg/Opinion39.html">Doron Zeilberger wrote</a>: if only John von Neumann's maid had saved all the notes he'd thrown away each day!</p>
<p>Or to put it differently: the most exciting result in 2011 was having <a href="http://m-phi.blogspot.com/2011/10/inconsistency-of-pa-and-consensus-in.html">no result about Con(PA)</a>.</p>
<h3>7. an affordable open access model</h3>
<p>Research publications should be free, for both authors and readers. When it comes to traditional journals, there are already some in mathematics (e.g. <a href="http://nyjm.albany.edu/">NYJM</a>) that offer open access without any fees. I believe we can move to a journal system that is entirely open access and without publishing fees but we're not there yet. Mathematical journals are said to have profit margins of 90% so we should be the first to get there. Gold open access is already realistic and, more importantly, can be made affordable right now. With <a href="http://peerj.com/">peerj</a>, this is already around the corner on a much larger scale.</p>
<p>On the other hand, it seems natural to me to return academic publications to universities and academic societies. For journals, this could simply be done PLoS-ONE style (checking correctness, not &quot;importance&quot;) and our institutions could certainly make such journals open access, non-profit and actually free (just have each department produce one journal). But new ways of doing and sharing research will hardly fit into the journal model. These methods will be much more user centric, will be about people, not publishers. And the natural place to store information about people is their professional homepage as a repository of their work. It seems natural that universities or academic societies could play a much better role in this then proprietary social networks.</p>
<p>However, one problem we'd be facing is that journal publishing is the cash cow of many societies and this money is often used to cross-finance important services. This is not helpful in a time where <a href="https://web.archive.org/web/20140723061813/http://blog.findings.com/post/20527246081/how-we-will-read-clay-shirky">publishing is a button [Wayback machine]</a>. We'll have to find another way to finance things that need financing and we'll have to talk about that, too. Additionally, if we move scientific &quot;publishing&quot; to the next level, there will be new costs: costs for research into doing it, costs for experiments, costs for failures. We need to talk about those, too.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>fbreuer</strong>, 2012/07/17<br>
Have you spoken to editors of academic journals about your ideas for creating an affordable open access model? Even editors who would like their journal to move towards an open access publishing model often have various objections to plans such as those you outlined above. The two most interesting objections I have heard are these:
<ol>
<li>All you need to run a journal are a) a full-time administrative position to organize everything and b) teaching relief for the editor-in-chief. In the US, these cost easily $60,000. Where is that money supposed to come from?</li>
<li>Reviews are not about checking correctness but only about checking importance. Reviewers cannot possibly be asked to guarantee the correctness of an article – this is the responsibility of the author. Instead reviewers are supposed to ensure quality by assessing whether an article makes interesting, understandable and well-rounded mathematical reading.<br>
How would you respond to these objections?</li>
</ol>
<ul>
<li><strong>Peter</strong>, 2012/08/04<br>
No, I haven’t had the opportunity.  But there are such journals (there are quite a few discussions about costs at <a href="http://publishing.mathforge.org/">http://publishing.mathforge.org/</a>). I published in the NYJM for that exact reason — fully free OA.<br>
PLoS ONE is, in a way, such a journal as it waives fees frequently. Then there’s the new cool kid on the blog, PeerJ.Finally (and this will be another post), there’s the new Forum Of Mathematics (Pi and Sigma, shudder) which also waives fees for the first two years and hope to waive them later, too (with sponsors).To the first “objection”: I think the societies and universities should be doing journals “for free”, since they are to gain the most (both financially and by reputation) and can most easily provide the infrastructure (editors, staff, archival etc). Sponsorship models are also not unreasonable to help initially.<br>
The second one: I’m a fan of altmetrics and I don’t believe that journals can do that job very well (e.g. NASA’s arsenic life paper) — and more importantly I think they shouldn’t. I believe in the PLoS ONE model where judging importance is left to the community; the editorial process ensures correctness and scientific method.</li>
<li><strong>fbreuer</strong>, 2012/08/07<br>
You are certainly right that universities stand to gain the most in the long run by running OA journals. However, given the tightening budget constraints that most universities face today, I think few are in the position to afford taking over even a single journal. Societies may be in a better position to do that, I do not know.<br>
But you are certainly right, there are great journals out there who do manage. Two such OA journals that I have had good experiences with are <a href="http://www.combinatorics.org/">the Electronic Journal of Combinatorics</a> and <a href="http://www.integers-ejcnt.org/">Integers</a>.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11 dreams for the publishing debate — #6 publishing in smaller increments]]></title>
        <id>https://www.peterkrautzberger.org/0113/</id>
        <link href="https://www.peterkrautzberger.org/0113/">
        </link>
        <updated>2012-06-15T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>One more, one more, one more...<br>
Each new post will start from the top, so scroll down a little if you've read the previous one -- but also check out the <a href="https://www.peterkrautzberger.org/0108/">first post</a> for some motivation.</p>
</blockquote>
<p>These are dreams. Some are realistic---perhaps just around the corner; others are way out there---basically crazy. Some will apply to everyone, others only to some. But all have diversity in mind, diversity in our expectations of who researchers are and what they do.</p>
<h3>1. write fewer original-research papers</h3>
<p>I know what you're going to say. But hear me out. This is at the core: to enable researchers to publish fewer &quot;new result&quot;-papers.</p>
<p>I believe all major problems brought up in the debate are, at the heart, caused by the immense increase in publications -- but not the global increase, the personal one. You have to publish far too much/big these days to get a half-decent position/grant. Increasing publication numbers did not increase the quality of research or, for that matter, the &quot;quality of life&quot; in our communities.</p>
<p>Instead, the <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2909426/">massive inflation</a> is <a href="http://carlzimmer.com/articles/index.php?subaction=showfull&amp;id=1336594400&amp;archive=&amp;start_from=&amp;ucat=15&amp;">killing us</a>, devaluating everything we do as researchers. More papers mean that our papers are worth less. Having to publish more papers means we produce more research of questionable quality (unintentionally and otherwise). Especially young researchers have to publish for metrics instead of quality. Worst of all, evaluating researchers only by this steam-punkesque output means that the jobs go to people with this one singular skill -- writing the right kind of papers to please the editorial boards of the right kind of journals -- leading to an intellectual monoculture instead of diverse, stable, rich communities. In particular, the pressure works against women and minorities as they often start with and continue to face disadvantages in their careers that make it harder to produce the desired &quot;output&quot; in the desired time frame.</p>
<p>(If you're wondering why I'm not bashing &quot;evil publishers&quot;. I don't think they are the problem -- we are. If you are happy with the inflation of papers-in-journals, then big publishers are what you need.)</p>
<h3>2. get real credit for surveys, reviews and exposition</h3>
<p>Surveys, reviews and expositions are research -- nothing more, nothing less. We live in a time where it is actually <em>more</em> important to write expository work. Why? Because we've optimized our production pipeline so well that there is no shortage of new (looking) results. Yes, you can argue about &quot;relevance&quot; (I won't, but I can't stop you). But if you're serious about all that &quot;research for research's-sake&quot;-talk, then you might notice that we've figured out how to educate people in the tens of thousands every year that do nothing else but churn out result after result.</p>
<p>As <a href="http://blog.felixbreuer.net/2012/02/27/beyondtheorems.html">Felix aptly wrote</a>: we need to move beyond &quot;new&quot; results. And this means to step back from them and, well, review. Surveys are the glue that holds our fields together, holds our communities together. We do it all the time -- if you read a paper thoroughly, you'll most likely write a review anyway. As we aggregate, work on larger projects or grant proposals these aggregate and easily become surveys and expositions. We need to make all of these public so that the community and the original author(!) can benefit from this enormous creative output that otherwise might only show up in a reading seminar or a journal club.</p>
<p>Mathematicians usually do even more. If we read a paper, we create our own version of the results. Mathematics need these just like music needs different interpretations. We need to give people who are &quot;just&quot; re-writing proofs the credit they deserve, the credit for keeping results alive, accessible and understandable to a wider audience than the original author and referee.</p>
<p>And with credit, I don't mean vouchers for some bookstore. Surveys must be first-class citizens! Surveying and reviewing other peoples work belongs on your CV, it is no less original than your &quot;original research&quot; and every department should have people that are exceptional at it, that are better at surveys, reviews or exposition than &quot;new&quot; research and add to the diversity of a department.</p>
<h3>3. get real credit for refereeing</h3>
<p>Refereeing is research, just like surveys and &quot;new results&quot;. It might seem redundant after dream #2 (and in many ways I would say that's the goal), but given the importance of refereeing right now and the way we do it, it's separate.</p>
<p>Currently, good refereeing seems nearly impossible. With the increase of publications we can't even catch up with what's happening in our own narrowly focused interests -- how, then, can we expect to referee properly? Sam tells his own funny but sad <a href="http://boolesrings.org/scoskey/peer-review-failure/">story of refereeing honestly</a> but the problem runs deep. Good referees are hard to find and when you find them, they could be writing a paper instead of refereeing -- and why should they not?</p>
<p>There are many ways we could improve refereeing. We can (and should) split up the different stages of refereeing (reference checking, correctness checking on different levels, opinion gathering etc), we should open pre- and post-publication peer review (and in-between peer review), we should use alternative methods to collect these reviews (instead of review journals that have at most one opinion per paper).</p>
<p>One key of refereeing is forming an opinion -- and voicing it. That's very hard, in particular for young and disadvantaged researchers who fear significant repercussions. But we don't need less people sharing their opinions on other researchers' output, we need more (whether they agree or not); it's a responsibility both to our own research communities and to a larger society.</p>
<p>But all of these are very unlikely to work, if we don't find a way to give referees the credit (and criticism) they deserve. Before we can <a href="https://xianblog.wordpress.com/2012/05/24/in-praise-of-the-referee-2/">praise referees</a> we need tools to evaluate refereeing, both in current and future form. Above all, we need to be able to put refereeing on the CV, it's part of the research qualities every strong department should strive for.</p>
<h3>4. get real credit for communicating</h3>
<p>Communicating other people's work through surveys, exposition and reviews is important. Then there's communicating to students aka teaching. This is an especially sore point for mathematics where undergraduate teaching has become a blunt tool to weed out graduates for other disciplines -- our self-respect seems greatly lacking. And then, of course, there's spreading the word to the wider public.</p>
<p>Have you ever noticed that many of the great researchers are excellent communicators (and teachers and surveyors and referees)? I would go as far as to say that a <em>truly</em> great researcher will be great in at least one of these ways to communicate. Without this, you're only a great something-else. We should cherish not just one ability of our truly great minds, but all of them. Right now we promote researchers according to how their &quot;new result&quot;-output compares to the &quot;new result&quot;-output of the truly great ones. Why are we so one dimensional?</p>
<p>Also, communication goes both ways, so we must listen. Can you imagine a graduate-student-run, &quot;Law Review&quot;-like journal for mathematics? Graduate students are perfect for forcing you to reflect on your research -- we should encourage them to make their thoughts public (including anonymously and pseudonomously). But we mathematicians need to go further. When <a href="http://en.wikipedia.org/wiki/Robert_Parris_Moses">Bob Moses</a> was speaking at Michigan earlier this year he argued that history will judge us as math literacy becomes a <a href="http://news.harvard.edu/gazette/2001/05.17/e04-moses.html">civil rights issue</a> in the 21st century. Are we listening?</p>
<p>Without communication, we risk the longevity of our own research areas because we won't be <em>understood</em> by the next generation, by other areas and by society as a whole. But this means <a href="http://scientopia.org/blogs/scicurious/2012/06/06/on-outreach-somethings-got-to-give/">something's gotta give</a> and we need to accept that by giving real credit.</p>
<h3>5. sharing all our work every way we can</h3>
<p>One battle that most scientists are still fighting -- full self-archival rights -- mathematics has long won. We need to make this happen for everyone. We must use the arXiv, our homepages or (if you must) walled gardens such as <a href="http://www.academia.edu/">academia.edu</a> and <a href="http://www.researchgate.net/">researchgate</a>. But we should also embrace more recent alternatives like <a href="http://figshare.com/">figshare</a> and <a href="http://github.com/">github</a> to post <em>all</em> our research publicly -- preprints, notes, lecture notes, expository notes, simply everything. <a href="https://en.wikipedia.org/wiki/Open_Notebook_Science">Open notebook science</a> is the key, but it's in its infancy. We need to find ways (many different ones) that work for a larger part of our communities so it becomes easier for people to experiment with it and to make it something even better. It might not be for everyone, but it's something everybody will benefit from.</p>
<p>However, the truth is that even among mathematicians a large group doesn't use the arXiv, let alone keep professional homepages deserving the name. I know that especially older researchers often hesitate because technical issues &quot;are more trouble than it's worth&quot;. This is a challenge and we must argue against this and more importantly help to sort out problems, within departments, within small research communities etc to overcome these obstacles. Approach people, ask them why their papers aren't availabe and help them put them properly online. In all other cases: <a href="https://sbseminar.wordpress.com/2010/02/09/grothendiecks-letter/">Don't be a Grothendieck</a>.</p>
<h3>6. publishing in smaller increments</h3>
<p>Have you ever read a paper that seemed to hide its true goal because the author wasn't finished but had to publish something out of the pressure of not having a job otherwise? Have you ever read a paper that made a small but reasonable result look much more than it really was just so that it will make the least publishable unit? Have you ever read a paper that was so badly written that you couldn't make sense of it?</p>
<p>Paradoxically, one way to publish fewer &quot;new results&quot; papers might be to publish more but differently. For scientists this might seem easier, publishing as the data comes in. But even for mathematics we have all those little results -- the small gems, the one-line-proof, the clever counterexample, the good reformulation, the useful shortcut -- all those could be published quickly and openly instead of waiting to find enough to &quot;make it a paper&quot;. Just like data, these could be reviewed publicly much more easily and we should get proper credit for doing so (both author and reviewer).</p>
<p>Longer results could (depending on their nature) be published incrementally, with multiple, public revisions. Take the preprint idea one step further and make your writing process public. Use a revision system like github to expose the process. Allow for outside input in your writing process, in your working process. The internet makes us an intricately connected community and we can work together in one big virtual seminar. There are already excellent examples in that area. In mathematics in particular, we have the <a href="http://polymathprojects.org/">Polymath project</a> or Ryan O'Donnell's <a href="http://www.analysisofbooleanfunctions.org/">Analysis of Boolean Functions</a>, a text book he's working out as a blog.</p>
<p>But as I've argued <a href="https://www.peterkrautzberger.org/0107/">Polymath doesn't work for very many people</a> so, again, we need many, many more projects like these so that more people have the opportunity to find a way that works for them.</p>
<p>There's of course a risk -- this could create a lot of noise as incrementally published results implode when data turns out to be flawed, proofs disintegrate and general anarchy rears its head! But I think it's worth the risk. Search technology is constantly improving and good scientific standards should ensure that failed research is marked accordingly. And we have so much to gain! We might be able to finally give credit for failing productively -- the main thing researchers do anyway, we fail and fail and fail until we understand what's going on. Sometimes we have to give up, but why shouldn't somebody else continue for us?</p>
<p>Even if your research implodes, you should get credit and, much, much more importantly, you will help others not to repeat your mistake. <a href="http://boolesrings.org/vonheymann/">Fred</a> once worked on a nice old problem which, after a few months, clearly didn't get anywhere. But he realized that all his attacks had probably been attempted before and so he wrote a pre-print on all the ways to fail, published <a href="http://boolesrings.org/vonheymann/publications/code/">his code along with it</a> so that people in the future might benefit from his failure. Or as <a href="http://www.math.rutgers.edu/~zeilberg/Opinion39.html">Doron Zeilberger wrote</a>: if only John von Neumann's maid had saved all the notes he'd thrown away each day!</p>
<p>Or to put it differently: the most exciting result in 2011 was having <a href="http://m-phi.blogspot.com/2011/10/inconsistency-of-pa-and-consensus-in.html">no result about Con(PA)</a>.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Andreas Blass</strong>, 2012/06/16<br>
Perhaps even more useful than publishing one’s own failures is publishing a survey that also includes other people’s failures on the same problem.  The instance that I know about is a paper by Frank Drake, explaining why the approaches people had tried to solve the singular cardinal problem, by extending Easton’s proof for the regular case, couldn’t work.  (This was written just before Silver gave an even better explanation, namely that the result they were trying to prove was false.)
<ul>
<li><strong>Peter</strong>, 2012/06/16<br>
Thank you for the comment, Andreas. I fully agree, of course, that all errors are useful. It’s a great example. I wished we had a culture of mistakes, now that we have tools that would allow easy dissemination of these.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11 dreams for the publishing debate — #5 sharing all our work every way we can]]></title>
        <id>https://www.peterkrautzberger.org/0112/</id>
        <link href="https://www.peterkrautzberger.org/0112/">
        </link>
        <updated>2012-06-14T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Hop, skip and a jump -- missed a day there, sorry.<br>
Each new post will start from the top, so scroll down a little if you've read the previous one -- but also check out the <a href="https://www.peterkrautzberger.org/0108/">first post</a> for some motivation.</p>
</blockquote>
<p>These are dreams. Some are realistic---perhaps just around the corner; others are way out there---basically crazy. Some will apply to everyone, others only to some. But all have diversity in mind, diversity in our expectations of who researchers are and what they do.</p>
<h3>1. write fewer original-research papers</h3>
<p>I know what you're going to say. But hear me out. This is at the core: to enable researchers to publish fewer &quot;new result&quot;-papers.</p>
<p>I believe all major problems brought up in the debate are, at the heart, caused by the immense increase in publications -- but not the global increase, the personal one. You have to publish far too much/big these days to get a half-decent position/grant. Increasing publication numbers did not increase the quality of research or, for that matter, the &quot;quality of life&quot; in our communities.</p>
<p>Instead, the <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2909426/">massive inflation</a> is <a href="http://carlzimmer.com/articles/index.php?subaction=showfull&amp;id=1336594400&amp;archive=&amp;start_from=&amp;ucat=15&amp;">killing us</a>, devaluating everything we do as researchers. More papers mean that our papers are worth less. Having to publish more papers means we produce more research of questionable quality (unintentionally and otherwise). Especially young researchers have to publish for metrics instead of quality. Worst of all, evaluating researchers only by this steam-punkesque output means that the jobs go to people with this one singular skill -- writing the right kind of papers to please the editorial boards of the right kind of journals -- leading to an intellectual monoculture instead of diverse, stable, rich communities. In particular, the pressure works against women and minorities as they often start with and continue to face disadvantages in their careers that make it harder to produce the desired &quot;output&quot; in the desired time frame.</p>
<p>(If you're wondering why I'm not bashing &quot;evil publishers&quot;. I don't think they are the problem -- we are. If you are happy with the inflation of papers-in-journals, then big publishers are what you need.)</p>
<h3>2. get real credit for surveys, reviews and exposition</h3>
<p>Surveys, reviews and expositions are research -- nothing more, nothing less. We live in a time where it is actually <em>more</em> important to write expository work. Why? Because we've optimized our production pipeline so well that there is no shortage of new (looking) results. Yes, you can argue about &quot;relevance&quot; (I won't, but I can't stop you). But if you're serious about all that &quot;research for research's-sake&quot;-talk, then you might notice that we've figured out how to educate people in the tens of thousands every year that do nothing else but churn out result after result.</p>
<p>As <a href="http://blog.felixbreuer.net/2012/02/27/beyondtheorems.html">Felix aptly wrote</a>: we need to move beyond &quot;new&quot; results. And this means to step back from them and, well, review. Surveys are the glue that holds our fields together, holds our communities together. We do it all the time -- if you read a paper thoroughly, you'll most likely write a review anyway. As we aggregate, work on larger projects or grant proposals these aggregate and easily become surveys and expositions. We need to make all of these public so that the community and the original author(!) can benefit from this enormous creative output that otherwise might only show up in a reading seminar or a journal club.</p>
<p>Mathematicians usually do even more. If we read a paper, we create our own version of the results. Mathematics need these just like music needs different interpretations. We need to give people who are &quot;just&quot; re-writing proofs the credit they deserve, the credit for keeping results alive, accessible and understandable to a wider audience than the original author and referee.</p>
<p>And with credit, I don't mean vouchers for some bookstore. Surveys must be first-class citizens! Surveying and reviewing other peoples work belongs on your CV, it is no less original than your &quot;original research&quot; and every department should have people that are exceptional at it, that are better at surveys, reviews or exposition than &quot;new&quot; research and add to the diversity of a department.</p>
<h3>3. get real credit for refereeing</h3>
<p>Refereeing is research, just like surveys and &quot;new results&quot;. It might seem redundant after dream #2 (and in many ways I would say that's the goal), but given the importance of refereeing right now and the way we do it, it's separate.</p>
<p>Currently, good refereeing seems nearly impossible. With the increase of publications we can't even catch up with what's happening in our own narrowly focused interests -- how, then, can we expect to referee properly? Sam tells his own funny but sad <a href="http://boolesrings.org/scoskey/peer-review-failure/">story of refereeing honestly</a> but the problem runs deep. Good referees are hard to find and when you find them, they could be writing a paper instead of refereeing -- and why should they not?</p>
<p>There are many ways we could improve refereeing. We can (and should) split up the different stages of refereeing (reference checking, correctness checking on different levels, opinion gathering etc), we should open pre- and post-publication peer review (and in-between peer review), we should use alternative methods to collect these reviews (instead of review journals that have at most one opinion per paper).</p>
<p>One key of refereeing is forming an opinion -- and voicing it. That's very hard, in particular for young and disadvantaged researchers who fear significant repercussions. But we don't need less people sharing their opinions on other researchers' output, we need more (whether they agree or not); it's a responsibility both to our own research communities and to a larger society.</p>
<p>But all of these are very unlikely to work, if we don't find a way to give referees the credit (and criticism) they deserve. Before we can <a href="https://xianblog.wordpress.com/2012/05/24/in-praise-of-the-referee-2/">praise referees</a> we need tools to evaluate refereeing, both in current and future form. Above all, we need to be able to put refereeing on the CV, it's part of the research qualities every strong department should strive for.</p>
<h3>4. get real credit for communicating</h3>
<p>Communicating other people's work through surveys, exposition and reviews is important. Then there's communicating to students aka teaching. This is an especially sore point for mathematics where undergraduate teaching has become a blunt tool to weed out graduates for other disciplines -- our self-respect seems greatly lacking. And then, of course, there's spreading the word to the wider public.</p>
<p>Have you ever noticed that many of the great researchers are excellent communicators (and teachers and surveyors and referees)? I would go as far as to say that a <em>truly</em> great researcher will be great in at least one of these ways to communicate. Without this, you're only a great something-else. We should cherish not just one ability of our truly great minds, but all of them. Right now we promote researchers according to how their &quot;new result&quot;-output compares to the &quot;new result&quot;-output of the truly great ones. Why are we so one dimensional?</p>
<p>Also, communication goes both ways, so we must listen. Can you imagine a graduate-student-run, &quot;Law Review&quot;-like journal for mathematics? Graduate students are perfect for forcing you to reflect on your research -- we should encourage them to make their thoughts public (including anonymously and pseudonomously). But we mathematicians need to go further. When <a href="http://en.wikipedia.org/wiki/Robert_Parris_Moses">Bob Moses</a> was speaking at Michigan earlier this year he argued that history will judge us as math literacy becomes a <a href="http://news.harvard.edu/gazette/2001/05.17/e04-moses.html">civil rights issue</a> in the 21st century. Are we listening?</p>
<p>Without communication, we risk the longevity of our own research areas because we won't be <em>understood</em> by the next generation, by other areas and by society as a whole. But this means <a href="http://scientopia.org/blogs/scicurious/2012/06/06/on-outreach-somethings-got-to-give/">something's gotta give</a> and we need to accept that by giving real credit.</p>
<h3>5. sharing all our work every way we can</h3>
<p>One battle that most scientists are still fighting -- full self-archival rights -- mathematics has long won. We need to make this happen for everyone. We must use the arXiv, our homepages or (if you must) walled gardens such as <a href="http://www.academia.edu/">academia.edu</a> and <a href="http://www.researchgate.net/">researchgate</a>. But we should also embrace more recent alternatives like <a href="http://figshare.com/">figshare</a> and <a href="http://github.com/">github</a> to post <em>all</em> our research publicly -- preprints, notes, lecture notes, expository notes, simply everything. <a href="https://en.wikipedia.org/wiki/Open_Notebook_Science">Open notebook science</a> is the key, but it's in its infancy. We need to find ways (many different ones) that work for a larger part of our communities so it becomes easier for people to experiment with it and to make it something even better. It might not be for everyone, but it's something everybody will benefit from.</p>
<p>However, the truth is that even among mathematicians a large group doesn't use the arXiv, let alone keep professional homepages deserving the name. I know that especially older researchers often hesitate because technical issues &quot;are more trouble than it's worth&quot;. This is a challenge and we must argue against this and more importantly help to sort out problems, within departments, within small research communities etc to overcome these obstacles. Approach people, ask them why their papers aren't availabe and help them put them properly online. In all other cases: <a href="https://sbseminar.wordpress.com/2010/02/09/grothendiecks-letter/">Don't be a Grothendieck</a>.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11 dreams for the publishing debate — #4 get real credit for communicating]]></title>
        <id>https://www.peterkrautzberger.org/0111/</id>
        <link href="https://www.peterkrautzberger.org/0111/">
        </link>
        <updated>2012-06-12T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Meanwhile back on the ranch...<br>
Each new post will start from the top, so scroll down a little if you've read the previous one -- but also check out the <a href="https://www.peterkrautzberger.org/0108/">first post</a> for some motivation.</p>
</blockquote>
<p>These are dreams. Some are realistic---perhaps just around the corner; others are way out there---basically crazy. Some will apply to everyone, others only to some. But all have diversity in mind, diversity in our expectations of who researchers are and what they do.</p>
<h3>1. write fewer original-research papers</h3>
<p>I know what you're going to say. But hear me out. This is at the core: to enable researchers to publish fewer &quot;new result&quot;-papers.</p>
<p>I believe all major problems brought up in the debate are, at the heart, caused by the immense increase in publications -- but not the global increase, the personal one. You have to publish far too much/big these days to get a half-decent position/grant. Increasing publication numbers did not increase the quality of research or, for that matter, the &quot;quality of life&quot; in our communities.</p>
<p>Instead, the <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2909426/">massive inflation</a> is <a href="http://carlzimmer.com/articles/index.php?subaction=showfull&amp;id=1336594400&amp;archive=&amp;start_from=&amp;ucat=15&amp;">killing us</a>, devaluating everything we do as researchers. More papers mean that our papers are worth less. Having to publish more papers means we produce more research of questionable quality (unintentionally and otherwise). Especially young researchers have to publish for metrics instead of quality. Worst of all, evaluating researchers only by this steam-punkesque output means that the jobs go to people with this one singular skill -- writing the right kind of papers to please the editorial boards of the right kind of journals -- leading to an intellectual monoculture instead of diverse, stable, rich communities. In particular, the pressure works against women and minorities as they often start with and continue to face disadvantages in their careers that make it harder to produce the desired &quot;output&quot; in the desired time frame.</p>
<p>(If you're wondering why I'm not bashing &quot;evil publishers&quot;. I don't think they are the problem -- we are. If you are happy with the inflation of papers-in-journals, then big publishers are what you need.)</p>
<h3>2. get real credit for surveys, reviews and exposition</h3>
<p>Surveys, reviews and expositions are research -- nothing more, nothing less. We live in a time where it is actually <em>more</em> important to write expository work. Why? Because we've optimized our production pipeline so well that there is no shortage of new (looking) results. Yes, you can argue about &quot;relevance&quot; (I won't, but I can't stop you). But if you're serious about all that &quot;research for research's-sake&quot;-talk, then you might notice that we've figured out how to educate people in the tens of thousands every year that do nothing else but churn out result after result.</p>
<p>As <a href="http://blog.felixbreuer.net/2012/02/27/beyondtheorems.html">Felix aptly wrote</a>: we need to move beyond &quot;new&quot; results. And this means to step back from them and, well, review. Surveys are the glue that holds our fields together, holds our communities together. We do it all the time -- if you read a paper thoroughly, you'll most likely write a review anyway. As we aggregate, work on larger projects or grant proposals these aggregate and easily become surveys and expositions. We need to make all of these public so that the community and the original author(!) can benefit from this enormous creative output that otherwise might only show up in a reading seminar or a journal club.</p>
<p>Mathematicians usually do even more. If we read a paper, we create our own version of the results. Mathematics need these just like music needs different interpretations. We need to give people who are &quot;just&quot; re-writing proofs the credit they deserve, the credit for keeping results alive, accessible and understandable to a wider audience than the original author and referee.</p>
<p>And with credit, I don't mean vouchers for some bookstore. Surveys must be first-class citizens! Surveying and reviewing other peoples work belongs on your CV, it is no less original than your &quot;original research&quot; and every department should have people that are exceptional at it, that are better at surveys, reviews or exposition than &quot;new&quot; research and add to the diversity of a department.</p>
<h3>3. get real credit for refereeing</h3>
<p>Refereeing is research, just like surveys and &quot;new results&quot;. It might seem redundant after dream #2 (and in many ways I would say that's the goal), but given the importance of refereeing right now and the way we do it, it's separate.</p>
<p>Currently, good refereeing seems nearly impossible. With the increase of publications we can't even catch up with what's happening in our own narrowly focused interests -- how, then, can we expect to referee properly? Sam tells his own funny but sad <a href="http://boolesrings.org/scoskey/peer-review-failure/">story of refereeing honestly</a> but the problem runs deep. Good referees are hard to find and when you find them, they could be writing a paper instead of refereeing -- and why should they not?</p>
<p>There are many ways we could improve refereeing. We can (and should) split up the different stages of refereeing (reference checking, correctness checking on different levels, opinion gathering etc), we should open pre- and post-publication peer review (and in-between peer review), we should use alternative methods to collect these reviews (instead of review journals that have at most one opinion per paper).</p>
<p>One key of refereeing is forming an opinion -- and voicing it. That's very hard, in particular for young and disadvantaged researchers who fear significant repercussions. But we don't need less people sharing their opinions on other researchers' output, we need more (whether they agree or not); it's a responsibility both to our own research communities and to a larger society.</p>
<p>But all of these are very unlikely to work, if we don't find a way to give referees the credit (and criticism) they deserve. Before we can <a href="https://xianblog.wordpress.com/2012/05/24/in-praise-of-the-referee-2/">praise referees</a> we need tools to evaluate refereeing, both in current and future form. Above all, we need to be able to put refereeing on the CV, it's part of the research qualities every strong department should strive for.</p>
<h3>4. get real credit for communicating</h3>
<p>Communicating other people's work through surveys, exposition and reviews is important. Then there's communicating to students aka teaching. This is an especially sore point for mathematics where undergraduate teaching has become a blunt tool to weed out graduates for other disciplines -- our self-respect seems greatly lacking. And then, of course, there's spreading the word to the wider public.</p>
<p>Have you ever noticed that many of the great researchers are excellent communicators (and teachers and surveyors and referees)? I would go as far as to say that a <em>truly</em> great researcher will be great in at least one of these ways to communicate. Without this, you're only a great something-else. We should cherish not just one ability of our truly great minds, but all of them. Right now we promote researchers according to how their &quot;new result&quot;-output compares to the &quot;new result&quot;-output of the truly great ones. Why are we so one dimensional?</p>
<p>Also, communication goes both ways, so we must listen. Can you imagine a graduate-student-run, &quot;Law Review&quot;-like journal for mathematics? Graduate students are perfect for forcing you to reflect on your research -- we should encourage them to make their thoughts public (including anonymously and pseudonomously). But we mathematicians need to go further. When <a href="http://en.wikipedia.org/wiki/Robert_Parris_Moses">Bob Moses</a> was speaking at Michigan earlier this year he argued that history will judge us as math literacy becomes a <a href="http://news.harvard.edu/gazette/2001/05.17/e04-moses.html">civil rights issue</a> in the 21st century. Are we listening?</p>
<p>Without communication, we risk the longevity of our own research areas because we won't be <em>understood</em> by the next generation, by other areas and by society as a whole. But this means <a href="http://scientopia.org/blogs/scicurious/2012/06/06/on-outreach-somethings-got-to-give/">something's gotta give</a> and we need to accept that by giving real credit.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11 dreams for the publishing debate — #3 get real credit for refereeing]]></title>
        <id>https://www.peterkrautzberger.org/0110/</id>
        <link href="https://www.peterkrautzberger.org/0110/">
        </link>
        <updated>2012-06-11T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Meanwhile back on the ranch...<br>
Each new post will start from the top, so scroll down a little if you've read the previous one -- but also check out the <a href="https://www.peterkrautzberger.org/0108/">first post</a> for some motivation.</p>
</blockquote>
<p>These are dreams. Some are realistic---perhaps just around the corner; others are way out there---basically crazy. Some will apply to everyone, others only to some. But all have diversity in mind, diversity in our expectations of who researchers are and what they do.</p>
<h3>1. write fewer original-research papers</h3>
<p>I know what you're going to say. But hear me out. This is at the core: to enable researchers to publish fewer &quot;new result&quot;-papers.</p>
<p>I believe all major problems brought up in the debate are, at the heart, caused by the immense increase in publications -- but not the global increase, the personal one. You have to publish far too much/big these days to get a half-decent position/grant. Increasing publication numbers did not increase the quality of research or, for that matter, the &quot;quality of life&quot; in our communities.</p>
<p>Instead, the <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2909426/">massive inflation</a> is <a href="http://carlzimmer.com/articles/index.php?subaction=showfull&amp;id=1336594400&amp;archive=&amp;start_from=&amp;ucat=15&amp;">killing us</a>, devaluating everything we do as researchers. More papers mean that our papers are worth less. Having to publish more papers means we produce more research of questionable quality (unintentionally and otherwise). Especially young researchers have to publish for metrics instead of quality. Worst of all, evaluating researchers only by this steam-punkesque output means that the jobs go to people with this one singular skill -- writing the right kind of papers to please the editorial boards of the right kind of journals -- leading to an intellectual monoculture instead of diverse, stable, rich communities. In particular, the pressure works against women and minorities as they often start with and continue to face disadvantages in their careers that make it harder to produce the desired &quot;output&quot; in the desired time frame.</p>
<p>(If you're wondering why I'm not bashing &quot;evil publishers&quot;. I don't think they are the problem -- we are. If you are happy with the inflation of papers-in-journals, then big publishers are what you need.)</p>
<h3>2. get real credit for surveys, reviews and exposition</h3>
<p>Surveys, reviews and expositions are research -- nothing more, nothing less. We live in a time where it is actually <em>more</em> important to write expository work. Why? Because we've optimized our production pipeline so well that there is no shortage of new (looking) results. Yes, you can argue about &quot;relevance&quot; (I won't, but I can't stop you). But if you're serious about all that &quot;research for research's-sake&quot;-talk, then you might notice that we've figured out how to educate people in the tens of thousands every year that do nothing else but churn out result after result.</p>
<p>As <a href="http://blog.felixbreuer.net/2012/02/27/beyondtheorems.html">Felix aptly wrote</a>: we need to move beyond &quot;new&quot; results. And this means to step back from them and, well, review. Surveys are the glue that holds our fields together, holds our communities together. We do it all the time -- if you read a paper thoroughly, you'll most likely write a review anyway. As we aggregate, work on larger projects or grant proposals these aggregate and easily become surveys and expositions. We need to make all of these public so that the community and the original author(!) can benefit from this enormous creative output that otherwise might only show up in a reading seminar or a journal club.</p>
<p>Mathematicians usually do even more. If we read a paper, we create our own version of the results. Mathematics need these just like music needs different interpretations. We need to give people who are &quot;just&quot; re-writing proofs the credit they deserve, the credit for keeping results alive, accessible and understandable to a wider audience than the original author and referee.</p>
<p>And with credit, I don't mean vouchers for some bookstore. Surveys must be first-class citizens! Surveying and reviewing other peoples work belongs on your CV, it is no less original than your &quot;original research&quot; and every department should have people that are exceptional at it, that are better at surveys, reviews or exposition than &quot;new&quot; research and add to the diversity of a department.</p>
<h3>3. get real credit for refereeing</h3>
<p>Refereeing is research, just like surveys and &quot;new results&quot;. It might seem redundant after dream #2 (and in many ways I would say that's the goal), but given the importance of refereeing right now and the way we do it, it's separate.</p>
<p>Currently, good refereeing seems nearly impossible. With the increase of publications we can't even catch up with what's happening in our own narrowly focused interests -- how, then, can we expect to referee properly? Sam tells his own funny but sad <a href="http://boolesrings.org/scoskey/peer-review-failure/">story of refereeing honestly</a> but the problem runs deep. Good referees are hard to find and when you find them, they could be writing a paper instead of refereeing -- and why should they not?</p>
<p>There are many ways we could improve refereeing. We can (and should) split up the different stages of refereeing (reference checking, correctness checking on different levels, opinion gathering etc), we should open pre- and post-publication peer review (and in-between peer review), we should use alternative methods to collect these reviews (instead of review journals that have at most one opinion per paper).</p>
<p>One key of refereeing is forming an opinion -- and voicing it. That's very hard, in particular for young and disadvantaged researchers who fear significant repercussions. But we don't need less people sharing their opinions on other researchers' output, we need more (whether they agree or not); it's a responsibility both to our own research communities and to a larger society.</p>
<p>But all of these are very unlikely to work, if we don't find a way to give referees the credit (and criticism) they deserve. Before we can <a href="https://xianblog.wordpress.com/2012/05/24/in-praise-of-the-referee-2/">praise referees</a> we need tools to evaluate refereeing, both in current and future form. Above all, we need to be able to put refereeing on the CV, it's part of the research qualities every strong department should strive for.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11 dreams for the publishing debate -- #2 get real credit for surveys and exposition]]></title>
        <id>https://www.peterkrautzberger.org/0109/</id>
        <link href="https://www.peterkrautzberger.org/0109/">
        </link>
        <updated>2012-06-10T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>And now the continuation...<br>
Each new post will start from the top, so scroll down a little if you've read the previous one -- but also check out the <a href="https://www.peterkrautzberger.org/0108/">first post</a> for some motivation.</p>
</blockquote>
<p>These are dreams. Some are realistic---perhaps just around the corner; others are way out there---basically crazy. Some will apply to everyone, others only to some. But all have diversity in mind, diversity in our expectations of who researchers are and what they do.</p>
<h3>1. write fewer original-research papers</h3>
<p>I know what you're going to say. But hear me out. This is at the core: to enable researchers to publish fewer &quot;new result&quot;-papers.</p>
<p>I believe all major problems brought up in the debate are, at the heart, caused by the immense increase in publications -- but not the global increase, the personal one. You have to publish far too much/big these days to get a half-decent position/grant. Increasing publication numbers did not increase the quality of research or, for that matter, the &quot;quality of life&quot; in our communities.</p>
<p>Instead, the <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2909426/">massive inflation</a> is <a href="http://carlzimmer.com/articles/index.php?subaction=showfull&amp;id=1336594400&amp;archive=&amp;start_from=&amp;ucat=15&amp;">killing us</a>, devaluating everything we do as researchers. More papers mean that our papers are worth less. Having to publish more papers means we produce more research of questionable quality (unintentionally and otherwise). Especially young researchers have to publish for metrics instead of quality. Worst of all, evaluating researchers only by this steam-punkesque output means that the jobs go to people with this one singular skill -- writing the right kind of papers to please the editorial boards of the right kind of journals -- leading to an intellectual monoculture instead of diverse, stable, rich communities. In particular, the pressure works against women and minorities as they often start with and continue to face disadvantages in their careers that make it harder to produce the desired &quot;output&quot; in the desired time frame.</p>
<p>(If you're wondering why I'm not bashing &quot;evil publishers&quot;. I don't think they are the problem -- we are. If you are happy with the inflation of papers-in-journals, then big publishers are what you need.)</p>
<h3>2. get real credit for surveys, reviews and exposition</h3>
<p>Surveys, reviews and expositions are research -- nothing more, nothing less. We live in a time where it is actually <em>more</em> important to write expository work. Why? Because we've optimized our production pipeline so well that there is no shortage of new (looking) results. Yes, you can argue about &quot;relevance&quot; (I won't, but I can't stop you). But if you're serious about all that &quot;research for research's-sake&quot;-talk, then you might notice that we've figured out how to educate people in the tens of thousands every year that do nothing else but churn out result after result.</p>
<p>As <a href="http://blog.felixbreuer.net/2012/02/27/beyondtheorems.html">Felix aptly wrote</a>: we need to move beyond &quot;new&quot; results. And this means to step back from them and, well, review. Surveys are the glue that holds our fields together, holds our communities together. We do it all the time -- if you read a paper thoroughly, you'll most likely write a review anyway. As we aggregate, work on larger projects or grant proposals these aggregate and easily become surveys and expositions. We need to make all of these public so that the community and the original author(!) can benefit from this enormous creative output that otherwise might only show up in a reading seminar or a journal club.</p>
<p>Mathematicians usually do even more. If we read a paper, we create our own version of the results. Mathematics need these just like music needs different interpretations. We need to give people who are &quot;just&quot; re-writing proofs the credit they deserve, the credit for keeping results alive, accessible and understandable to a wider audience than the original author and referee.</p>
<p>And with credit, I don't mean vouchers for some bookstore. Surveys must be first-class citizens! Surveying and reviewing other peoples work belongs on your CV, it is no less original than your &quot;original research&quot; and every department should have people that are exceptional at it, that are better at surveys, reviews or exposition than &quot;new&quot; research and add to the diversity of a department.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11 dreams for the publishing debate -- #1 fewer papers]]></title>
        <id>https://www.peterkrautzberger.org/0108/</id>
        <link href="https://www.peterkrautzberger.org/0108/">
        </link>
        <updated>2012-06-09T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Many moons ago, <a href="https://gowers.wordpress.com/2011/10/31/how-might-we-get-to-a-new-model-of-mathematical-publishing/">Gowers' &quot;alternative&quot; model for publishing</a> started a new <a href="http://boolesrings.org/krautzberger/2011/11/26/the-recent-publishing-debate-a-timeline/">round in the publishing debate</a> and ever since, drafts have piled up around here, some bad, some worse, some long, some short. It's time for some summer cleaning (used to say &quot;spring cleaning&quot;, that's how long it took me) so I tried to cut out the bits that seemed not so bad. Also, I haven't posted anything in May -- how could that happen? My favorite month, mpf.<br>
Anyway, I hope you don't mind that I stretch this out a little and release this piece in pieces, over the next few days. If you do, just come back in a week or so.</p>
</blockquote>
<p>These are dreams. Some are realistic---perhaps just around the corner; others are way out there---basically crazy. Some will apply to everyone, others only to some. But all have diversity in mind, diversity in our expectations of who researchers are and what they do.</p>
<h3>1. write fewer original-research papers</h3>
<p>I know what you're going to say. But hear me out. This is at the core: to enable researchers to publish fewer &quot;new result&quot;-papers.</p>
<p>I believe all major problems brought up in the debate are, at the heart, caused by the immense increase in publications -- but not the global increase, the personal one. You have to publish far too much/big these days to get a half-decent position/grant. Increasing publication numbers did not increase the quality of research or, for that matter, the &quot;quality of life&quot; in our communities.</p>
<p>Instead, the <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2909426/">massive inflation</a> is <a href="http://carlzimmer.com/articles/index.php?subaction=showfull&amp;id=1336594400&amp;archive=&amp;start_from=&amp;ucat=15&amp;">killing us</a>, devaluating everything we do as researchers. More papers mean that our papers are worth less. Having to publish more papers means we produce more research of questionable quality (unintentionally and otherwise). Especially young researchers have to publish for metrics instead of quality. Worst of all, evaluating researchers only by this steam-punkesque output means that the jobs go to people with this one singular skill -- writing the right kind of papers to please the editorial boards of the right kind of journals -- leading to an intellectual monoculture instead of diverse, stable, rich communities. In particular, the pressure works against women and minorities as they often start with and continue to face disadvantages in their careers that make it harder to produce the desired &quot;output&quot; in the desired time frame.</p>
<p>(If you're wondering why I'm not bashing &quot;evil publishers&quot;. I don't think they are the problem -- we are. If you are happy with the inflation of papers-in-journals, then big publishers are what you need.)</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Waiting for the Polymath revolution -- thoughts from a bystander]]></title>
        <id>https://www.peterkrautzberger.org/0107/</id>
        <link href="https://www.peterkrautzberger.org/0107/">
        </link>
        <updated>2012-04-30T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://gowers.wordpress.com/2012/04/23/polymath-paper-published/">Tim Gowers</a> has hinted at a revival of the fifth Polymath project. Which brings something back from the bottom of my draft folder.</p>
<h3>Let's talk about Polymath</h3>
<p>If you haven't heard of the Polymath project, then, hm, well... anyway, here's the beginning of <a href="https://en.wikipedia.org/wiki/Polymath_Project">its Wikipedia entry</a>:</p>
<blockquote>
<p>The Polymath Project is a collaboration among mathematicians to solve important and difficult mathematical problems by coordinating many mathematicians to communicate with each other on finding the best route to the solution. The project began in January 2009 on Tim Gowers' blog when he posted a problem and asked his readers to post partial ideas and partial progress toward a solution. This experiment resulted in a new answer to a difficult problem, and since then the Polymath Project has grown to describe a particular process of using an online collaboration to solve any math problem.</p>
</blockquote>
<p>(If you've really never heard of the Polymath project, then you might want to go through the references on Wikipedia.)</p>
<p>I think nobody who stumbled upon Polymath in 2009 and 2010 could escape the deep fascination and exhilaration of its early successes and the positive spirit it created in the online math community. It was an exciting time. Personally, I was not actively involved in any Polymath project, have neither contributed nor seriously tried to follow the intricate but vast amount of information that Polymath projects have left in their wake -- it was simply too far from my own research interests. Like many mathematicians, however, I have followed it as an interested party.</p>
<p>I write, therefore, as a bystander, a simple mathematician who has an ongoing interested in the future of the field and its community. And as such, I've begun to worry about the impact of the Polymath project.</p>
<p>To return to the above quote, what continues to bug me is the last half-sentence.</p>
<blockquote>
<p>[...] since then the Polymath Project has grown to describe a particular process of using an online collaboration to solve any math problem.</p>
</blockquote>
<figure>
  <a href="http://www.flickr.com/photos/shianux/298719507/">
    <img alt="O RLY?" src="https://www.peterkrautzberger.org/assets/2012/orly.jpg">
  </a>
  <figcaption>
  O RLY? by shianux, on Flickr
  </figcaption>
</figure>
<h3>Isn't Polymath dead?</h3>
<p>Now that's just silly, of course it isn't. I just told you Tim Gowers will have another one, didn't I? In fact, I'm quite certain that a revival led by Tim Gowers will get another paper out of it (I mean, <a href="https://gowers.wordpress.com/2012/04/23/polymath-paper-published/">he got</a> the dHJ paper into Annals for crying out loud).</p>
<p>But that doesn't change my feeling that Polymath is dead -- or rather, that it is a mirage.</p>
<h3>What is Polymath, actually?</h3>
<p>Polymath is certainly not dead if you think of it as a research project of Tim Gowers, Terry Tao, Michael Nielsen and some of their friends. However, this is not how most people think about it. Instead, Polymath has left a much larger impression in- and outside the mathematical community thanks to <a href="http://michaelnielsen.org/polymath1/index.php?title=Main_Page#Discussions_about_polymath">numerous mentions on all kinds of news outlets</a>. And then there's the position Polymath takes in Michael Nielsen's writing, in particular in <em>Reinventing Discovery</em> which has lead to every science journalist hearing about this &quot;great revolution&quot; of how we do (mathematical) research.</p>
<p>If you think that that's what Polymath is -- a revolutionary new way of doing research -- then, unfortunately, Polymath is either dead or, more appropriately, has never existed in the first place, has only been an illusion.</p>
<h3>Would the real revolutionary please stand up?</h3>
<p><a href="https://en.wikipedia.org/wiki/Revolution">Wikipedia</a> tells us</p>
<blockquote>
<p>A revolution (from the Latin revolutio, &quot;a turn around&quot;) is a fundamental change in power or organizational structures that takes place in a relatively short period of time.</p>
</blockquote>
<p>Hm...</p>
<p>Maybe it's still too early. It's <a href="https://en.wikipedia.org/wiki/MathOverflow#Origin">only been three years</a>.</p>
<p>Maybe it isn't and instead it's time to think about what's keeping this revolution from happening.</p>
<ul>
<li>Polymath aims to proof theorems to publish as papers in journals.</li>
</ul>
<p>Compared to <a href="https://en.wikipedia.org/wiki/Open_notebook_science#Partial/Pseudo_Open_Notebooks">open notebook science</a>, <a href="https://en.wikipedia.org/wiki/Citizen_science">citizen science</a>, <a href="http://www.tricki.org/">tricki.org</a> or Wikipedia, Polymath fails to be revolutionary in its output. It does not add to the accepted notions of &quot;research activity&quot;. It produces more papers, in traditional journals. Perfectly fine mathematics, just not exactly revolutionary.</p>
<ul>
<li>Polymath cannot be reproduced by people other than Gowers and Tao.</li>
</ul>
<p>Six <a href="http://michaelnielsen.org/polymath1/index.php?title=Main_Page#Existing_polymath_projects">Polymath projects</a> have been formally started so far. Only two seem to have come to the desired conclusion. These two were headed by Gowers and Tao. Two Fields Medalists leading a research project, even a cool one like Polymath, well, it's not &quot;fundamental change in power or organizational structures&quot;.</p>
<ul>
<li>Polymath has not become a model of research activity, i.e., nobody else is doing it.</li>
</ul>
<p>Besides the fact that only Gowers and Tao seem to be able to bring a Polymath project to a conclusion, there's a much bigger issue: Nobody else is even trying. The projects can be traced back to a close circle of bloggers around Gowers, Nielsen and Tao -- Kalai, Lipton, Ellenberg etc. Here's an (unfair) comparison: the <a href="https://en.wikipedia.org/wiki/ArXiv">arXiv</a> did not revolutionize the dissemination of preprints because Paul Ginsparg put his own and his bff's papers up on the web. Instead, a continued effort reached more and more of the community and established the arXiv as the standard for pre-print releases and self-archival, making it a corner stone of many scientific communities today. (Fun fact: according to Michael Nielsen in <em>Reinventing Discovery</em>, a physicist once described Ginsparg as wasting his talents, collecting &quot;garbage&quot;. Would anybody say anything like this about Polymath? In other words, is a Polymath project in any sense risky?)</p>
<ul>
<li>Polymath does not seem to scale in terms of difficulty.</li>
</ul>
<p>The few Polymath projects that have been attempted have all had a reasonably high level of complexity. Additionally, the tendency seems to be towards more complicated research questions rather than simpler ones. Maybe this is MathOverflow's fault for taking care of so many &quot;easy&quot; questions, i.e., questions somebody else simply seems to have the answer to. Additionally, people on MO often spend a considerable amount of work on solving questions -- an effort that could just easily be considered a <a href="https://www.peterkrautzberger.org/0103/">micro-contribution</a> if we had a platform for these.</p>
<ul>
<li>The Polymath projects are not understood.</li>
</ul>
<p>There's a lot of talk about how <em>awesomesauce !eleventy!1!</em> Polymath projects are but there seems to be no effort towards understanding the successes and failures. Of course, this is not surprising since there aren't that many examples to consider. But there is nevertheless a lot of data. Analyzing the available data, the process, what works and what doesn't could help immensely. In particular, if the &quot;failed&quot; projects could be turned into productive contributions, we might actually get a new form of research activity that benefits the greater part of the community. Failed atttempts are the mathematical analogue of negative data in the sciences and there's similar lack of dissemination.</p>
<h3>Evolution or how could Polymath become something meaningful for the entire community?</h3>
<p>It may seem that I have some kind of beef with Polymath, but that's not the case at all. Polymath was quite simply amazing. I did wish, however, it (or something like it) would work for more people and would actually turn into a (much needed) revolution.</p>
<p>Mathematics has the greatest potential for &quot;doing research online&quot;. There's no physical entity needed and our primary standard of scientific communication is the written word. There's nothing in mathematical research that cannot be digitalized. We will never face the problem that somebody on the other side on the net would have to actually look at our specimen, our antibody staining, our test subjects. The web works perfectly for us.</p>
<p>Hence, mathematicians could be at the forefront of experimenting with new research activities that use the connectivity the web can offer in new and imaginative ways. Polymath was one experiment and it worked to a certain point. Even if Polymath5 can be revived in its current form, this most likely won't help the community as a whole (except in lazy bragging rights). Just like anywhere else on the web, the experiments continue -- 20 years into the invention of this mind boggling creation, we don't have a clue what the future has in store for us.</p>
<p>The goal could be to find a way to do Polymath-esque research on a large scale, involving large parts of the mathematical community (or at least, the online community). But maybe we need something completely different. It would simply be a shame if the Polymath projects ended up &quot;a fun project for a few top mathematicians&quot;. Maybe we need another Ginsparg, ready to endure the ridicule of &quot;wasting&quot; a research career. But I don't like heroic sacrifice.</p>
<p>I would rather hope for a group effort, maybe led by an innovative department or a group of college faculties coming together or some grant agency or academice society supporting a significant grant for the development of new ideas, looking to other successful projects like MathOverflow, wikipedia, the n-lab, blogs, activity on social networks etc. But more likely we simply need a crazy group of young researchers fighting to revolutionize the community regardless of the consequences for themselves, ready to kick the hornets' nest of <del datetime="2012-04-30T14:13:21+00:00">old white dudes</del> established researchers.</p>
<p>Just keep experimenting. Polymath doesn't work for most people, that's ok, let's try something else, change it, revamp it, do the complete opposite.</p>
<p>But, please, for a change, let's not ask Tim Gowers to do everything for us!</p>
<blockquote>
<p><a href="http://en.wikipedia.org/wiki/Answering_the_Question:_What_is_Enlightenment%3F">Aufklärung</a> ist der Ausgang des Menschen aus seiner selbstverschuldeten Unmündigkeit.</p>
</blockquote>
<hr>
<h3>Coda.</h3>
<p>Do you expect a project led by Fields Medalists to create a revolution? Overthrowing what exactly?</p>
<p>But there might be a more fundamental problem: do we have the right people in the first place? <a href="http://online.wsj.com/article/SB10001424052970204644504576653573191370088.html">Michael Nielsen wrote in WSJ</a>:</p>
<blockquote>
<p>The tools are a way of connecting the right people to the right problems at the right time, activating what would otherwise be latent expertise.</p>
</blockquote>
<p>Throughout <em>Reinventing Discovery</em>, there's something that Michael Nielsen does not discuss: the social impact. New ways of doing research will have a huge impact on the actual people involved and will require them to be willing and able incorporate these changes. The &quot;right people&quot; does not just mean &quot;the researchers who know the right thing&quot; but also &quot;the researchers who can work with these tools&quot;.</p>
<p>It could be that the groups of mathematicians that influence the conversations and developments within the mathematical community, e.g., tenured faculty at the top math departments, consist entirely of the &quot;wrong&quot; people, unable to be in the right place at the right time. Simply because it's not why they got the job -- they are where they are because they are excellent at doing research in the current model, the <a href="https://en.wikipedia.org/wiki/Steampunk">steampunk</a> approach of &quot;papers in journals&quot;.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Mike Pawliuk</strong>, 2012/04/15<br>
“It could be that the groups of mathematicians that influence the conversations and developments within the mathematical community, e.g., tenured faculty at the top math departments, consist entirely of the<br>
“wrong” people, unable to be in the right place at the right time. Simply because it’s not why they got the job — they are where they are because they are excellent at doing research in the current model, the steampunk approach of “papers in journals”.”<br>
+1. It is hard enough to get grants if you publish lots of papers in respectable set theory journals, why would you want to publish in outlets that the grant-giving agencies don’t recognize?<br>
I also get the feeling that this sort of project if lead by non-expert experts would just fail. Part of it seems like Gowers is trying to right a conventional paper by doing something harder than usual. I have difficulty enough writing papers when everything goes my way, let alone with one hand tied behind my back. It seems like someone like Gowers would be immensely useful for this type of project.</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[yay, I'm an editor at ScienceSeeker.org]]></title>
        <id>https://www.peterkrautzberger.org/0106/</id>
        <link href="https://www.peterkrautzberger.org/0106/">
        </link>
        <updated>2012-04-21T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Apparently, I totally forgot to announce this anywhere on my interwebz!</p>
<p>With its <a href="https://web.archive.org/web/20120509091827/http://scienceseeker.org/news/2012/04/03/introducing-new-features-and-new-editors/">major code update</a> three weeks ago, <a href="http://scienceseeker.org/">scienceseeker.org</a> introduced an editorial system where editors can mark particular posts and leave a small note -- and I was invited to become one of the fancy new editors (and given <a href="https://web.archive.org/web/20121029181018/http://scienceseeker.org/news/2012/04/03/introducing-our-new-slate-of-editors/">my fellow editors</a> methinks I'm the n00b).</p>
<p><a href="http://sciencseeker.org/">sciencseeker.org</a> came out of <a href="https://web.archive.org/web/20110415043257/http://scienceblogging.org/">scienceblogging.org</a> (originally dubbed its &quot;v2.0&quot;). (For those who remember, <a href="http://www.felixbreuer.net/">Felix</a>, <a href="http://boolesrings.org/vonheymann/">Fred</a> and I <a href="http://mathblogging.wordpress.com/about/">originally</a> modeled <a href="http://mathblogging.org/">mathblogging.org</a> after <a href="http://scienceblogging.org/">scienceblogging.org</a>.)</p>
<p>In fact, <a href="http://scienceseeker.org/">scienceseeker.org</a> is much more like <a href="http://mathblogging.org/">mathblogging.org</a> in that it accepts every blog with (some) scientific content. So it was only natural to meet up with <a href="http://twitter.com/#!/davemunger">Dave Munger</a> at <a href="https://web.archive.org/web/20110826202353/http://scienceonline2012.com/">Science Online 2012</a> (which was another one of those great <a href="http://twitter.com/#!/search/%23scio12">#Scio12</a> conversations that just keep returning like a million boomerangs).</p>
<p>Now if you visited <a href="http://scienceseeker.org/">sciencseeker.org</a> a few weeks ago, you may have found its database to be somewhat lacking in mathematical blogs. To remedy that, the kind people at <a href="http://scienceseeker.org/">scienceseeker.org</a> accepted a list of ~30 of my favorite blogs I simply exported out of <a href="http://mathblogging.org/">mathblogging.org</a> (did you know you can <a href="https://web.archive.org/web/20120307135703/http://www.mathblogging.org/feeds">download our database as csv and opml</a>?).</p>
<p>So I hope I'll be doing a decent job (and you probably won't be surprised if my picks for <a href="http://scienceseeker.org/">scienceseeker.org</a> might also appear on <a href="http://mathblogging.wordpress.com/category/weekly-picks/">our Mathblogging.org Weekly Picks</a>. You can follow the <a href="https://web.archive.org/web/*/http://scienceseeker.org/displayfeed/?type=post&amp;filter0=modifier&amp;value0=editorsPicks">Editors' Picks on scienceseeker.org</a> and on twitter <a href="http://twitter.com/#!/SciSeekEds">@sciseekeds</a>. I usually post a pick every other day and on Fridays.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>François G. Dorais</strong>, 2012/04/22<br>
Congratulations, Peter!</li>
<li><strong>Andreas Blass</strong>, 2012/04/22<br>
Congratulations!<br>
Looking at the list of editors and their areas, I get the impression that science consists of the biological sciences plus some peripheral stuff.  So please do a great job representing our periphery.</li>
<li><strong>Peter</strong>, 2012/04/23<br>
Thank you both, Andreas and François.<br>
Yes, the biological sciences dominate in blogging just like everywhere else in academia (last time I checked, extra-mural funding in the EU went to 40<span>%</span> to the life sciences with another 40<span>%</span> to engineering).<br>
But there’s a lot to learn from them, too. The way top bloggers help make the inner workings of their scientific community transparent is impressive — from being hired to being on hiring committees, from grant writing to grant panels from graduate student experiences to mentoring.<br>
Mathematical researcher bloggers are way behind when it comes to using blogs to help our community, especially the younger generations (math teachers on the other hand are quite impressive already).</li>
<li><strong>Dave Munger</strong>, 2012/04/24<br>
Andreas, we are looking to add some editors in the physical sciences. If you know anyone who you think would be good, send them our way — I’m @davemunger on twitter.</li>
<li><strong>Igorcarron</strong>, 2012/04/24<br>
Congrats (as the Chinese proverb says, be careful what you wish for :-)).<br>
One of the feature that was a little off putting when I initially looked at the earlier generation called v 2.0 was this need to connect posts to a peer review article.  I did not bother too much making that connection between their aggragtor and Nuit Blanche then.<br>
On Nuit Blanche, or any blogs relying on conferences/arxiv style prepublications, when it is peer reviewed, it is already too late and so I could not even mention any of my posts then because none of them would appear before “a certain time”. I also worried that my blog entries would not be taken seriously because there would never be a “peer reviewed article” stamp on these entries.  I wonder if the over-representation of life science articles  there is not directly related to this need of relying on peer-reviewed papers and I wonder how blogs that rely on arxiv/conferences/unreviewed presentation would fit into the more “explanational” nature of blog entries written on already published works.</li>
<li><strong>Patrick Siklossy</strong>, 2012/05/12<br>
OK, not scientific – but equally important: HAPPY BIRTHDAY! lieber Peter.<br>
Liebe Grüsse aus Bonn, ich wünsche Dir einen herrlichen Tag und viele zufriedene Tage im kommenden Jahr.<br>
Mach et jot. Patrick
<ul>
<li><strong>Peter</strong>, 2012/05/12<br>
Vielen Dank, Patrick. Grüße nach Bonn!</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[state of foundational research]]></title>
        <id>https://www.peterkrautzberger.org/0105/</id>
        <link href="https://www.peterkrautzberger.org/0105/">
        </link>
        <updated>2012-04-13T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I was catching up on some fun google-reader reading today but found with a depressing combination of content.</p>
<h3>To be</h3>
<p>The title of this post is taken from <a href="http://math.stackexchange.com/questions/131338/is-foundational-research-a-dead-field">this</a> <a href="http://math.se/">math.SE</a> question which boils down to:</p>
<blockquote>
<p>Is it true? Is it mostly a dead field filled with quacks and not much going on?</p>
</blockquote>
<p>The question was answered very kindly by <a href="http://m6c.org/w/blog/">Carl</a> but there was also a comment with a link to <a href="http://math.stackexchange.com/questions/24854/what-are-the-issues-in-modern-set-theory">another question</a> on <a href="http://math.se/">math.SE</a>:</p>
<blockquote>
<p>What are the issues in modern set theory?</p>
</blockquote>
<p>which received a vibrant answer by <a href="http://jdh.hamkins.org/">Joel</a>.</p>
<p>You should go and read it. It will make you feel all fuzzy in warm inside about studying set theory.</p>
<h3>Or not to be</h3>
<p>But then I continue reading.</p>
<p>And find <a href="http://mathbabe.org/2012/04/13/should-we-have-a-ratings-agency-for-scientific-theories/">mathbabe discussing</a> an idea put forth by Harvard physicist Abraham Loeb in <em>Nature</em> to have ratings agencies for scientific theories.</p>
<p>And I find <a href="http://gowers.wordpress.com/2012/04/13/a-brief-epsrc-update/">Tim Gowers discussing</a> that last year's scare is now reality -- EPSRC has essentially cancelled pure math postdoc fellowships. (This was and is an embarrassment and failure of the leaders of the UK math community, really. How could the major grant agency make such major policy changes without anyone noticing?)</p>
<p>And then I start to remember other posts.</p>
<p>And I remember <a href="http://nghoussoub.com/2012/04/05/turmoil-at-the-tri-council/">Nassif Ghoussoub foreseeing</a> the massive future cuts in foundational research in Canada.</p>
<p>And I remember <a href="http://blog.math.toronto.edu/colliand/2012/01/03/636/">James Colliander analyzing</a> the same drift.</p>
<p>And I remember <a href="http://sites.williams.edu/Morgan/2011/09/22/nsf-division-of-mathematical-and-statistical-sciences/">Frank Morgan's post</a> that might foreshadow a change at the NSF much akin to the change at EPRSC.</p>
<h3>That is the question</h3>
<p>How can we survive in such a climate?</p>
<h4>postscriptum</h4>
<p>On the one hand, Loeb's idea for rating agencies seems mostly designed to identify &quot;weak&quot; fields and to eliminate those. On the other hand, <a href="http://doi.org/10.1038/nj7393-279a">his article</a> opens with</p>
<blockquote>
<p>Too many young physicists embark on projects without knowing the risks.</p>
</blockquote>
<p>So while rating agencies would be stupid, I do like the idea to improve transparency for students. Is anybody thinking about that at all? Do we have transparent statistics about the number of research mathematicians, their fields, their activity etc? Do we have any idea about the number of future open positions in mathematics, their fields etc?</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>David Roberts</strong>, 2012/04/13<br>
“(This was and is an embarrassment and failure of the leaders of the UK<br>
math community, really. How could the major grant agency make such major<br>
policy changes without anyone noticing?)”<br>
It was more of a unilateral move on the behalf of the grant agency without consulting the field. The decision was presented as a fait accompli and then leaders in the UK math community, including people like Atiyah and his ilk, made a fuss to no avail.
<ul>
<li><strong>Peter</strong>, 2012/04/13<br>
I’m aware of that. But it still leaves me with the impression that there’s a lack of involvement in the necessary politics. To put it differently, this wouldn’t have happened to the AMS with its active campaigning and an office in DC.</li>
</ul>
</li>
<li><strong>Samuel Coskey</strong>, 2014/04/14<br>
So whose responsibility is it to make sure pure math receives funding?</li>
<li><strong>Carl Mummert</strong>, 2014/04/15<br>
I did give a short answer there, but there is a lot more that I don’t have a clear way to express.<br>
I think a particular difficulty with logic is that it is a young enough field that the seminal papers are all easily available and written in a way that they can (mostly) be read today. Only someone studying history would read Galois to learn about abstract algebra, but plenty of people try to read Goedel’s original paper to learn about the incompleteness theorems. The problem with that is that those old papers are beautiful but lack 75 years of improved perspective.<br>
What I don’t know of is a good book or paper that describes the current perspective on “foundations of mathematics”. There are email posts by Harvey Friedman, but they might be too polemical for an undergraduate who doesn’t have the perspective to appreciate exactly what argument is being made. On the other hand there are textbooks like Enderton’s book, which I like very much but which scrupulously avoids the topic of foundations. Does anyone else know of something that could be used to introduce an undergraduate to the modern idea(s) of foundations?</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rapid idempotent ultrafilters]]></title>
        <id>https://www.peterkrautzberger.org/0104/</id>
        <link href="https://www.peterkrautzberger.org/0104/">
        </link>
        <updated>2012-04-08T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Welcome back to the second (and final) part on why <a href="https://www.peterkrautzberger.org/0103/">strongly summable ultrafilters are rapid</a>.</p>
<p>Why the new title? Well, first, I needed another one (I've had too many posts with &quot;Part X&quot; in them, I think). Second, after I proved the results I mentioned last time, I quickly found an additional, somewhat more general observation regarding idempotents.</p>
<p>Here's the problem with this post though. I want to give the argument. But you know how it is in mathematics: standing on the shoulders of <del datetime="2012-04-06T14:42:13+00:00">the huddled masses</del> giants and all that. All work relies on established results. In the first post, I gave a lot of &quot;unnecessary&quot; proofs to motivate the story behind the result. In this post, I'll get to the actual proof and I'm torn, I'm not sure how much to quote and how much to prove. So bear with me and leave comments whenever I screw up.</p>
<h3>Strongly summables are rapid.</h3>
<p>Why could this be true? On the one hand, because we already established partial results <a href="https://www.peterkrautzberger.org/0103/">last time</a>. On the other hand there's an old result attributed to Pierre Matet which, for now, I can only state in a obfuscated fashion.</p>
<blockquote>
<p><strong>Theorem</strong> (<a href="http://dx.doi.org/10.2307/2274523">Matet 87</a>)<br>
If \(p\) is a <a href="https://www.peterkrautzberger.org/0026/">strongly summable ultrafilter</a>, then there exists a function &quot;\(\max\)&quot; such that \(\max(p)\) is rapid.</p>
</blockquote>
<p>So you see, strongly summable ultrafilters imply the existence of rapid ultrafilters -- via a very simple \(\max\)-function.</p>
<p>What's \(\max\), you're asking?</p>
<p>Ah yes, I should talk about \(\max\)...</p>
<h3>\(\max\) to the Max.</h3>
<p>For <a href="https://www.peterkrautzberger.org/0026/">FS-sets</a>, there is a natural notion of maximum. If you have a bunch of elements summed up, then it makes sense to call the largest summand the maximum. So intuitively, the maximum should simply map each element in the FS-set to the largest generator involved in producing it. This might not appear very well defined but bear with me.</p>
<p>Consider an <a href="https://www.peterkrautzberger.org/0026/">FS-set</a>, let's keep calling it \(FS(x_ n)\). If we're lucky, there is a <em>unique</em> way to write each \(y \in FS(x_ n)\) as a sum of \(x_ i\) (or should I write \(x_ n\)? indices are hard...). For example, the sequence $ (2^n)_  {n\in \omega} $ has this property while \((n)_ {n\in \mathbb{N}}\) fails to have this property (quite badly, I suppose).</p>
<p>It turns out that there's an easy property to ensure this: the sequence just has to grow quickly.</p>
<blockquote>
<p><strong>Proposition</strong> (folklore? can be found in <a href="http://dx.doi.org/10.1090/S0002-9947-1987-0906807-4#sthash.YLoWoL89.dpuf">Blass, Hindman 87</a>)<br>
If \(x_ n > \sum_ {i&lt;n} x_ i\) for all \(n\), then \[\sum_ {i\in s} x_ i = \sum_ {i \in t} x_ i \Rightarrow s=t. \]<br>
In other words, each element in \(FS(x_ n)\) has a <em>unique representation</em>.</p>
</blockquote>
<p>[Edit May 22, 2012: modified attribution]</p>
<p>The proof is an easy induction on $\left\vert s\right\vert, \left\vert t\right\vert $, using the growth factor to argue that the maximal element of \(s\) and \(t\) must be equal.</p>
<ul>
<li>If \(\left\vert s\right\vert  = \left\vert t\right\vert  = 1\), then \(s = t\) follows immediately from the growth assumption.</li>
<li>Now assume inductively that we've proved the claim for smaller sets.</li>
<li>Let \(n\) be the maximum of \(s\cup t\).</li>
<li>Wlog, \(n\in s\).</li>
<li>Then we must also have \(n\in t\) -- otherwise \[ \sum_ {i \in s} x_ i \geq x_ n > \sum_ {i &lt;n} x_ i \geq \sum_ {i \in t} x_ i, \] a contradiction to the assumed equality of both sums.</li>
<li>But if both \(s\) and \(t\) contain \(n\), we also have \(\sum_ {s \setminus \{n\}} x_ i = \sum_ {t \setminus \{n\}} x_ i\).</li>
<li>Using our induction hypothesis, we have $ s \setminus {n} = t \setminus {n} $, hence \(s=t\).</li>
</ul>
<p>So <em>if</em> we have unique representations of elements in \(FS(x_ n)\), we can define a function \[\max: FS(x_ n) \rightarrow \mathbb{N}, \max(y) := x_ {\max s} \text{ where } \sum_ {i \in s} x_ i = y. \]</p>
<h3>Growth, growth, growth and more growth</h3>
<p>Unfortunately, we need to tweak this a little bit more. Remember that FS-sets are all about sums. Very often \(y, z \in FS(x_ n)\) will have \(y+z \in FS(x_ n)\). So assuming growth, \(y,z , y+z\) each have a unique representation in terms of the \(x_ i\).</p>
<p>It's natural to assume that there's some kind of connection between the representations of \(y,z, y+z\). For one thing, we know that if \(s \cap t = \emptyset\), then \(\sum_ {i\in s} x_ i + \sum_ {i \in t} x_ i \in FS(x_ n)\). The growth as above does not guarantee the reverse, though (just consider \(FS(2^n)\)), and the reverse often simplifies things. Fortunately, all we have to do is improve the growth!</p>
<blockquote>
<p><strong>Proposition</strong> (<a href="http://dx.doi.org/10.1090/S0002-9947-1987-0906807-4#sthash.YLoWoL89.dpuf">Hindman, Blass 87</a>)<br>
If \(x_ n > 2\cdot \sum_ {i&lt;n} x_ i\), then \(\sum_ {i\in s} x_ i + \sum_ {i \in t} x_ i = \sum_ {i\in v} x_ i\) if and only if $s \cap t = \emptyset $ and \(v = s \cup t\).</p>
</blockquote>
<p>The proof is much like the earlier proof.</p>
<ul>
<li>Again, we're doing an induction on $\left\vert s\cup t \cup v\right\vert $.</li>
<li>If \(\left\vert s \cup t \cup v\right\vert  = 1\), then \(s\) or \(t\) must be empty and the growth condition does the rest.</li>
<li>For the inductive step, let \(n := \max(s,t,v)\).</li>
<li>Due to the growth condition, \(n\) must be in \(v\).</li>
<li>But it must also lie in \(s\cup t\).
<ul>
<li>Else \(\sum_ {i\in v} x_ i \geq x_ n > 2 \sum_ {i &lt;n} x_ i \geq \sum_ {i\in s} x_ i + \sum_ {i\in t} x_ i\).</li>
</ul>
</li>
<li>But it can't be in both \(s\) and \(t\).
<ul>
<li>Else \(\sum_ {i \in v} x_ i &lt; 2 x_ n &lt; \sum_ {i\in s} x_ i + \sum_ {i \in t} x_ i\).</li>
</ul>
</li>
<li>Wlog \(n\in s\)</li>
<li>Th \(\sum_ {i \in s\setminus{n}} x_ i + \sum_ {i\in t} x_ o = \sum_ {i \in v\setminus{n}} x_ i\).</li>
<li>Applying our induction hypothesis to $\left\vert (s \setminus {n}) \cup t \cup (v\setminus {n})\right\vert $, we get $ s\setminus {n} \cap t = \emptyset$ and \((s \setminus \{n\}) \cup t = v \setminus \{n\}\).</li>
<li>This in turn gives us \(s \cap t = \emptyset\) (as \(n \notin t\)) and \(s\cup t = v\) -- as desired.</li>
</ul>
<p>Why all this trouble? Well, there are many uses for this. For what's coming below, it simplifies an important calculation. In general, it is extremely important since it allows us to switch from the addition of numbers to the union of disjoint, finite sets. (I don't know about you, but I find the union operation on disjoint sets much easier to comprehend.)</p>
<blockquote>
<p><strong>Corollary</strong><br>
If \(FS(x_ n)\) has growth as above, then if we ever have \(y, z, y+z \in FS(x_ n)\) (and we will), then, assuming \(y&lt;z\), we have \(\max(y+z) = \max(z)\).<br>
In particular, if \(FS(y_ n) \subseteq FS(x_ n)\), then \(\max[FS(y_ n)] = \max[\{ y_ n: n\in \omega\}]\).</p>
</blockquote>
<h3>Strongly summable ultrafitlers are rapid -- the proof.</h3>
<p>Anyway, let's get back to where we started. First, we should make a connection to strongly summable ultrafilters.</p>
<blockquote>
<p><strong>Lemma</strong> (<a href="http://dx.doi.org/10.1090/S0002-9947-1987-0906807-4#sthash.YLoWoL89.dpuf">Blass, Hindman 87</a>)<br>
If \(p\) is strongly summable, then \(p\) has a base of FS-sets whose sequences satisfy the growth condition (the stronger one with factor \(2\), of course).</p>
</blockquote>
<p>This is a great lemma (though maybe not a <a href="http://www.math.rutgers.edu/~zeilberg/Opinion82.html">true lemma</a>) and the reason why I spend so much time above talking about growth conditions -- it comes in handy in many situations and really tells us something about strongly summable ultrafilters and the sets they contain. The proof, however, is weird so I'll skip it (unless you insist in the comments).</p>
<p>And now it makes sense to state the initial theorem.</p>
<blockquote>
<p><strong>Theorem</strong> (<a href="http://dx.doi.org/10.1017/S0022481200028450">Matet, 87</a> / <a href="http://dx.doi.org/10.1090/S0002-9947-1987-0906807-4#sthash.YLoWoL89.dpuf">Blass, Hindman 87</a>)<br>
Let \(p\) be a strongly summable ultrafilter and \(FS(x_ n) \in p\) with growth (or just unique representations); fix the \(\max\)-function for \(FS(x_ n)\) as above. Then \(\max(p)\) is a rapid P-point.</p>
</blockquote>
<p>[Edit on May 21, 2012: I rephrased the theorem to improve clarity -- thanks to the comment-by-email who suggested it!]</p>
<p>You can skip the proof if you like because it's not important to us (and I'm cheating a little on the important part, rapidity). But I find the argument appealing and since I've had to go through all the trouble to introduce the growth condition and so forth, I think I might as well include this, too. It's a typical proof for strongly summable ultrafilters -- just write down a good partition and let it do the work for you.</p>
<ul>
<li>Fix \(f:\mathbb{N} \rightarrow \mathbb{N}\).</li>
<li>We will prove that \(f\) is either constant on a set in \(\max(p)\) or it is finite-to-one.</li>
<li>Pick any \(FS(x_ n) \in p\) with \(x_ n > 2\sum_ {i&lt;n} x_ i\).</li>
<li>Let \(\min\) be the minimum function analogous to \(\max\).</li>
<li>Now partition \(FS(x_ n)\) into<br>
\[ \{ y\in FS(x_ n) : f(\max(y)) &lt; \min(y)\}\] and \[ \{ y\in FS(x_ n) : f(\max(y)) \geq \min(y)\} . \]</li>
<li>Our strongly sumable ultrafilter will give us \(FS(y_ n)\) (with the usual growth condition) included in one of these two parts.</li>
<li>If \(FS(y_ n)\) is included in the first part, then \(f\) is bounded on \(\max[FS(y_ n)] = \max[\{ y_ n: n\in \omega\}]\). (In particular, \(f\) is constant on a set in \(\max(p)\).)
<ul>
<li>Consider \(y_ 0\) and pick any other \(y_ n\).</li>
<li>Due to the growth condition, we have \(\max(y_ n) = \max(y_ 0 + y_ n)\) and reversely \(\min(y_ 0 + y_ n) = \min(y_ 0)\).</li>
<li>In particular, \(f(\max(y_ n) = f(\max(y_ 0 + y_ n)) &lt; \min(y_ 0+y_ n) = \min(y_ 0)\).</li>
<li>So \(f\) is bounded on \(\max[FS(y_ n)]\) and we find a</li>
</ul>
</li>
<li>If \(FS(y_ n)\) is included in the second part, then \(f\) is finite-to-one on \(\max[FS(y_ n)] = \max(\{ y_ n: n\in \omega \})\).
<ul>
<li>Consider some point in the image of \(f\), say \(k\).</li>
<li>If for some \(y_ n\) we have \(f(\max(y_ n)) = k\), then \(k = f(\max(y_ n)) \geq \min(y_ n)\) by our assumption.</li>
<li>But how many \(y_ n\) can there be with \(\min(y_ n) \leq k\)? At most \(k\)-many!
<ul>
<li>The \(y_ n\) will have pairwise distinct minima. Why?</li>
<li>Remember that for \(n\neq m\) we naturally have \(y_ m + y_ n \in FS(y_ n)\subseteq FS(x_ n)\).</li>
<li>By the growth condition of the \(x_ n\), we know that \(y_ n\) and \(y_ m\) are sums of disjoint sets of \(x_ n\)'s.</li>
<li>In particular, their minima will differ!</li>
</ul>
</li>
<li>Therefore, \(f\) is finite-to-one.</li>
</ul>
</li>
<li>And now the cheating: the last argument shows that \(f^{-1}(k)\) is at most size \(k\). To be able to make any finite-to-one function an \(k\)-to-one function is, in fact, equivalent to being a rapid ultrafilter. It's a nice exercise, but feel free to insist in the comments.</li>
</ul>
<p>This theorem is the reason I originally (back in 2010, in my conversations with Jana at BLAST) thought there's a chance that all strongly summable ultrafilters are rapid. First, \(\max\) is a finite-to-one function. It's an old, probably folklore result (cf. <a href="http://dx.doi.org/10.1090/S0002-9939-1980-0548093-2#sthash.ygG3UBVz.dpuf">Miller, 1980</a>) that the finite-to-one image of a rapid ultrafilter is again rapid. Now the reverse is not true <em>but</em> our function \(\max\) is so easy that it's possible to prove this.</p>
<p>[Edit May 22, 2012: modified attribution]</p>
<blockquote>
<p><strong>Theorem</strong> (Krautzberger (yep, this is it))<br>
If \(p\) is strongly summable, then \(p\) is rapid.</p>
</blockquote>
<p>Here's the gist: the trick is simple: speed up functions by $ 2^n$ and let that sped-up function be dominated in the rapid image. Then we pick an FS-set in our strongly summable ultrafilter that witnesses this domination, in particular, it's generating sequence will dominate that sped-up function. Finally, just as in our initial observations in the first post, the FS-set will still grow fast enough to dominate the original function.</p>
<ul>
<li>By Matet's theorem pick \(FS(x_ n) \in p\) such that \(\max(p)\) is rapid.</li>
<li>Now pick any \(f: \mathbb{N} \rightarrow \mathbb{N}\).</li>
<li>We may assume that \(f\) is strictly monotone (that's all the functions we need to dominate).</li>
<li>By Matet's theorem we can find a set \(A \in \max(p)\) that dominates $f \circ 2^{n+1} $.</li>
<li>Now fix $ FS(y_ n) \subseteq FS(x_ n), FS(y_ n) \in p $ such that \(\max[FS(y_ n)] \subseteq A\); for simplicity, we can assume that the \((y_ n)_ {n\in \omega}\) also satisfy the growth condition.</li>
<li>Then \(FS(y_ n)\) dominates \(f\).
<ul>
<li>Let \(i\in \mathbb{N}\). We'll show that \(\left\vert FS(y_ n) \cap f(i)\right\vert  &lt; i\).</li>
<li>Pick the maximal \(y_ k &lt; f(i)\).</li>
<li>So \(f(i) \cap FS(y_ n) \subseteq f(i) \cap FS(y_ 0,\ldots, y_ k)\), i.e., we only need to find out how large \(k\) is.</li>
<li>Of course, \(f(i) > y_ k \geq \max(y_ k)\).</li>
<li>Now \(\max[FS(y_ n)] = \max[\{ y_ n: n \in \omega\} ] \subseteq A\), so \(\max(y_ k)\) is greater or equal to the \(k\)-th element of \(A\).</li>
<li>Since the \(A\) dominates \(f\circ (2^{n+1})\), this gives us \(\max(y_ k) > f(2^{k+1})\).</li>
<li>By \(f\)'s monotonicity, $ i &gt; 2^{k+1}$,</li>
<li>But the set \(FS(y_ 0,\ldots, y_ k)\) contains exactly $ 2^{k+1}$-many elements, i.e., less than \(i\)-many elements -- precisely as desired.</li>
</ul>
</li>
</ul>
<p>Whew, ok. That's done.</p>
<h3>Jana asked one more question</h3>
<p>After I got around to writing my argument up properly after the conference, Jana asked me whether there are could be other rapid idempotent ultrafilters. In particular, could there be so-called <em>minimal idempotents</em> which are rapid? This, again, sounded rather drastic to me. Minimal idempotents have extremely rich algebraic properties, in particular, any set in them is central and thus all versions of the Central Sets Theorem hold for such sets (as opposed to FS-sets where no FS-set with the growth condition satisfies even the simplest <a href="https://www.peterkrautzberger.org/0079/">Central Sets Theorem</a>).</p>
<p>But, of course, by now I was skeptical of my own skepticism.</p>
<p>To understand this question, we have to go back to strongly summable ultafilters for a second. Due to Matet's result, we know that the existence of stongly summable ultrafilters imply the existence of rapid P-points. In particular, the existence of strongly summable ultrafilters cannot be proved using ZFC alone.</p>
<p>But speaking of P-points and rapidity, it is a famous open problems whether there is a model with neither P-points nor Q-points. We can achieve a model without P-points and a model without Q-points, but incidentally not both. (As a taste of the problem: the continuum must at least be \(\omega_ 3\) in such a model.)</p>
<p>On top of that, there exists a model without rapid ultrafilters (hence without Q-points), but disturbingly, afaik, nobody has a model without Q-points but with rapid ultrafilters! In other words, all known models without Q-points are without rapid ultrafilters (but with P-points).</p>
<p>Also, as a consequence of the big open question, any known model without P-points has Q-points, hence rapid ultrafilters.</p>
<p>What I'm trying to say is that Jana's question leads to a whole bunch of interesting and classical open problems. So it was very much worth thinking about.</p>
<p>If there are other rapid idempotents, how do we get them? It turns out we can get the possibly strongest positive answer to this question.</p>
<blockquote>
<p><strong>Theorem</strong> (Krautzberger (yippie, another micro-contribution))<br>
If there exists a rapid ultrafilter, then there exist rapid idempotent ultrafilters. In fact, then there exists a whole closed left ideal of rapid ultrafilters, in particular there are minimal idempotents which are rapid.</p>
</blockquote>
<p>As it turns out this follows easily from two well-known results on rapid ultrafilters which give us the following:</p>
<blockquote>
<p><strong>Proposition</strong><br>
If \(p\) is rapid, \(q\) any ultrafilter, then \(q+p\) is rapid.</p>
</blockquote>
<ul>
<li>Since \(p\) is rapid, the tensor product \(q\otimes p\) is rapid (this can be found in <a href="http://dx.doi.org/10.1090/S0002-9939-1980-0548093-2#sthash.ygG3UBVz.dpuf">Miller, 1980</a>).</li>
<li>Also, the finite-to-one image of a rapid ultrafilter is rapid (again, see <a href="http://dx.doi.org/10.1090/S0002-9939-1980-0548093-2#sthash.ygG3UBVz.dpuf">Miller, 1980</a>).</li>
<li>But \(q+p = +(q\otimes p)\) and addition is a finite-to-one map.</li>
<li>Hence \(q+p\) is rapid.</li>
</ul>
<p>Then the proof of the theorem is as follows:</p>
<ul>
<li>Let \(p\) be a rapid ultrafilter.</li>
<li>Then \(\beta \mathbb{N} + p\) is a closed left ideal containing only rapid ultrafilters.
<ul>
<li>This is a closed left ideal since \(\cdot +p\) is a continuous map.</li>
<li>If \(q\) is any ultrafilter, then \(q+p\) is rapid.</li>
</ul>
</li>
<li>Every closed left ideal contains (by compactness) a minimal left ideal which in turn contains a minimal idempotent (that's one way of defining them, actually).</li>
</ul>
<p>This theorem seems very strong to me. If I have one rapid, I have an entire closed left ideal of rapid ultrafilters -- that's one of the crucial structures in Algebra in the Stone–Čech compactification!</p>
<p>If you happen to have strongly summable ultrafilters, this gives an even nicer observation. You see, the definition of minimal idempotent can be given in terms of minimality in a certain partial order on the idempotents, namely</p>
<p>\[p \leq q \text{ iff } p+q = q+p = p. \]</p>
<p>There are two obvious related orders, $ p\leq_ R q$ iff \(q+p=p\), and \(\leq_ L\) (guess how it's defined). It's an easy exercise (really), that minimality in either partial order is minimality in all others.</p>
<p>An old result is that strongly summable ultrafilters are right maximal (in fact, strongly right maximal: \(x+p=p\) has only one solution, \(x=p\)).</p>
<p>This means that assuming we have strongly summable ultrafilters, then we have a &quot;full spectrum&quot; of rapid idempotents -- from right maximal all the way to (right) minimal.</p>
<hr>
<p>Well, and that's all folks. I hope you enjoyed my little experiment as much as I have. I'll certainly write a follow-up post when I've decided where to put a fixed copy of this.</p>
<p>Please let me know if you find any errors in the proof and, more importantly, if you think I should clarify certain parts.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Andreas Blass</strong>, 2012/04/15<br>
I think you’re giving me (and Neil Hindman) more credit than we deserve.  In the theorem that you attribute to us and to Pierre Matet, the part about rapidity of max is, if I remember correctly, due solely to Matet.  I believe the only occurrence of “rapid” in that joint paper by Neil and me is in the paragraph acknowledging Pierre’s work.<br>
Also, at the end of the proof of that theorem, you get that the function f can take any value k at most k times on the y’s.  But it’s the FS set generated by the y’s that is in the ultrafilter, and on that set it seems that f can take the value k about \(2^k\) times.  That does no real harm; this weaker conclusion still implies rapidity because you can compose f with an exponential function.
<ul>
<li><strong>Andreas Blass</strong>, 2012/04/15<br>
Ignore (or better delete) the second half of my previous comment.  I was thinking too much about your theorem and not about Matet’s.
<ul>
<li><strong>Peter</strong>, 2012/05/21<br>
I’m sorry for not responding to this. If you insist, I will delete it.</li>
</ul>
</li>
<li><strong>Peter</strong>, 2012/04/18<br>
Thank you for your comments, Andreas! Why I give you and Neil credit is because the proof is from your paper. It’s just that your paper doesn’t actually mention that the proof therein shows rapidity, instead refers to Matet.<br>
On the other hand, I couldn’t reconstruct Matet’s proof from his paper. I remember that I once understood it and that back then I thought both proofs are the same but looking at Matet’s paper again for this post I found it hard to get back into his notation of filters on partitions.</li>
</ul>
</li>
<li><strong>Neil Hindman</strong>, 2012/05/21<br>
I have not yet understood the proof that strongly summable ultrafilters are rapid.  But I have gone through the proof that if there are rapid ultrafilters, then there is a closed left ideal consisting of such things.  You are way too modest in calling it a micro contribution.  The proof is, indeed, very simple.  But you should be congratulated for coming up with it, and Jana should be congratulated for asking the question.  It is to me very shocking that such things can be found in the smallest ideal.  Had Jana asked me — and who knows, maybe she did — I would have said “of course not” without thinking.
<ul>
<li><strong>Peter</strong>, 2012/05/21<br>
Thank you for your kind words, Neil.<br>
I hope I can clarify any questions you may have about the other result.</li>
</ul>
</li>
<li><strong>David Fernandez</strong>, 2013/10/17<br>
Hi Peter! I just went through your proof that strongly summable ultrafilters are rapid (the one that you uploaded to the arXiv). There's a little detail that bothers me, and it's your way of phrasing Theorem 1, which is a result of Blass and Hindman. It seems to me that you do need to explicitly state that the sequence \(x_n\) given by this Theorem satisfies \(x_n&amp;gt;\sum_{k&amp;lt;n}x_k\) for every \(n\) (you do so here in the blog post, but not in the arXiv paper). Because afterwards, in the proof of Theorem 3 (which is the same proof that appears here), once you've got your sequence \(y_k\) (it's also worth noting that we assume \(y_k\) is increasing, by the way), you're implicitly using the fact that if \(k&amp;lt;l\) then \(x_n-\mathrm{max}(y_k)&amp;lt;x_n-\mathrm{max}(y_l)\) (i.e. that bigger members of the sequence \(y_k\) must have bigger \(x_n\)-maximum). This seems to me to be crucial for the step where you say that any \(x_n-\mathrm{max}(y_k)\) is greater than or equal to the \(k\)-th element of \(A\). At least I don't see how else to justify this step without the stronger assumption on \(x_n\), which in any case doesn't affect either the veracity of the theorem nor the main ideas of its proof.<br>
On another note, I have to say that I don't agree with a sentence that you wrote on the second paragraph of Section 1: that &quot;it should be straighforward to extend the two results to countable semigroups with finite-to-one multiplication maps in general&quot;. I don't think this is straighforward at all! The core of the issue is again the same Theorem 1, of Blass and Hindman, saying that a strongly summable ultrafilter has a base of sets \(\mathrm{FS}(x_n)\) where the addition &quot;behaves like disjoint union&quot;. This is a theorem that was only recently generalized to most abelian groups, but fails badly for example in the Boolean group \(([\omega]^{&amp;lt;\omega},\bigtriangleup)\) (those are results of mine, hehe) (and I don't think anyone has any idea of what happens in non-abelian semigroups, though in a recent paper of Hindman and Lakeshia Legette Jones the case of the free semigroup is partially dealt with). In fact, it's possible to construct, on the Boolean group, a strongly summable ultrafilter that's not additively isomorphic to any union ultrafilter, so this is as far as one can get from &quot;sums behaving like disjoint unions&quot; (this is all in here: <a href="http://arxiv.org/abs/1306.5421">http://arxiv.org/abs/1306.5421</a> ). I believe it would be interesting to see if this crazy ultrafilter is rapid or not...
<ul>
<li><strong>David Fernandez</strong>, 2014/02/11<br>
Hi again, Peter.<br>
It’s been some months since I posted my comment above. Now I can say that your result is also true for strongly summable ultrafilters on the Boolean group (I just proved it, and I plan to add it to my preprint linked to above). That, together with your result, takes care of all abelian groups: so rapidity follows from strong summability in any such group (hence in any abelian cancellative semigroup as well).</li>
<li><strong>Peter</strong>, 2014/02/16<br>
David that’s great news! I’m sorry I never got around replying to your earlier comment (let alone think about your question). I’m glad to hear that this side comment turned into an interesting result! By the way, will you be in Bonn for the INFTY conference in March?
<ul>
<li><strong>David Fernandez</strong>, 2014/03/07<br>
No, it looks like I’m not going to that side of the pond anytime soon… but it would be good if we talk (maybe skype, or something) about this sometime (and include David (Chodounski)).</li>
</ul>
</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quiz on public peer review]]></title>
        <id>http://m6c.org/w/2012/04/296/</id>
        <link href="http://m6c.org/w/2012/04/296/">
        </link>
        <updated>2012-04-05T00:16:07Z</updated>
        <summary type="html"><![CDATA[I have been required to complete a &#8220;responsible conduct of research&#8221; training module by the research office at my school. The reason I am commenting is that I was asked to answer the following question &#8220;true&#8221; or &#8220;false&#8221;. This is &#8230; <a href="http://m6c.org/w/2012/04/296/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Carl Mummert</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[One day in Colorado or Strongly summable ultrafilters are rapid]]></title>
        <id>https://www.peterkrautzberger.org/0103/</id>
        <link href="https://www.peterkrautzberger.org/0103/">
        </link>
        <updated>2012-04-02T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Picking up from <a href="https://www.peterkrautzberger.org/0102/">the prelude about micro-contributions</a>, let me tell you the story of a small result I would like to share with you. (Before you frantically scroll down to find the proof, it's not really here but will be in the follow-up post).</p>
<p>Please keep in mind that this is not a mathematical paper (hm... did I really have to write this?). I'll mostly delay (or forget) defining (or referencing) terminology. I hope my explanations will suffice when they are needed but this more of a story than a formal proof. In any case, if you find a notion that's not defined, keep reading or ask for clarification through a comment.</p>
<p>Thankfully, Jana Flašková was kind enough to read through the draft correcting a few mistakes; fortunately, her recollection of this story does not greatly disagree with mine.</p>
<h3>Results have stories, too</h3>
<p>In 2010, I had the pleasure of visiting <a href="https://web.archive.org/web/20121203234019/http://euclid.colorado.edu/~kasterma/blast/index.php">BLAST 2010 [Wayback Machine]</a> in Boulder, Colorado. It was a great experience (I wrote a <a href="https://www.peterkrautzberger.org/0023/">couple</a> of <a href="https://www.peterkrautzberger.org/0024/">blog</a> <a href="https://www.peterkrautzberger.org/0025/">posts</a> back then). One afternoon, I was sitting somewhere on campus with <a href="http://home.zcu.cz/~flaskova/english/">Jana Flašková</a> and she asked me if <a href="https://www.peterkrautzberger.org/0088/">idempotent ultrafilters</a> could be rapid.</p>
<p>My initial reaction was &quot;Of course not!&quot;. My intuition said, rapid ultrafilters are just as bad as Q-points! they have too many gaps! they can't be sums! But Jana insisted. And she was, of course, right. So let me take a step back and talk about these notions.</p>
<h3>P-points, Q-points and sums of ultrafilters</h3>
<p>Coming from set theory, one of the things that initially attracted me to (and annoyed me about) [Algebra in the Stone-Čech compactification](<a href="http://en.wikipedia.org/wiki/Stone%E2%80%93%C4%8Cech_">http://en.wikipedia.org/wiki/Stone–Čech_</a> compactification#Addition_ on_ the_ Stone.E2.80.93.C4.8Cech_ compactification_ of_ the_ naturals) (of \(\mathbb{N}\)) was the fact that those [ultrafilters on \(\omega\)](<a href="http://en.wikipedia.org/wiki/Ultrafilter#Ultrafilters_">http://en.wikipedia.org/wiki/Ultrafilter#Ultrafilters_</a> on_ .CF.89) studied in set theory have (almost) no relevance in the field. The reason (usually) is that those ultrafilters (for example P-points and Q-points) cannot be sums of ultrafilters -- and Algebra in the Stone-Čech compactification is all about sums of ultrafilters (well, or products if you work in an arbitrary semigroup).</p>
<p>This isn't terribly surprising, in the sense that almost <em>nothing</em> is a sum of ultrafilters, i.e., it is well known that</p>
<blockquote>
<p><strong>Folklore</strong> (<a href="http://dx.doi.org/10.1016/0166-8641(91)90074-V">van Douwen</a>?) $ \mathbb{N}^* + \mathbb{N}^* $ is nowhere dense in $ \mathbb{N}^*$ (the Stone–Čech remainder $ \beta \mathbb{N} \setminus \mathbb{N}$).</p>
</blockquote>
<p>So from a [Baire category](<a href="https://en.wikipedia.org/wiki/First_">https://en.wikipedia.org/wiki/First_</a> category) point of view, you shouldn't expect any ultrafilter to be a sum of ultrafilters.</p>
<p>But the reason goes deeper because the argument for this topological observations resembles arguments you frequently see for P- and Q-points. In fact, let's see how you prove this folklore result:</p>
<ul>
<li>consider a basic open set, i.e., take an infinite \(A\subseteq \mathbb{N}\) and induce a basic open set \(\hat A := \{ p \in \beta \mathbb{N}: A\in p\}\)</li>
<li>thin out \(A\) to an infinite \(B \subseteq A\) with larger and larger gaps between the elements of \(B\), i.e., such that \(\lim_ {n \to \infty} b_ {n+1} - b_ n = \infty\) (where the \(b_ n\) form the natural enumeration of \(B\)).</li>
<li>In other words, you make sure that \(B\) has larger and larger gaps between its elements.</li>
<li>Then the induced open set $ \hat B $ misses all sums of free ultrafilters.</li>
</ul>
<p>Why? Well, no sum of free ultrafilters can have a set with these kinds of increasing gaps. Instead, there will always be many small gaps. This simply is due to the natural base of a sum of ultrafilters:</p>
<ul>
<li>A [sum of ultrafilters](<a href="http://en.wikipedia.org/wiki/Stone%E2%80%93%C4%8Cech_">http://en.wikipedia.org/wiki/Stone–Čech_</a> compactification#Addition_ on_ the_ Stone.E2.80.93.C4.8Cech_ compactification_ of_ the_ naturals) \(p+q\) has a base consisting of sets of the form \[\bigcup_ {v\in V} v + W_ v\] where \(V\in p\) and all the \(W_ v \in q\).</li>
</ul>
<p>How does that base help produce small gaps?</p>
<ul>
<li>Take \(v_ 1 \neq v_ 2 \in V\)</li>
<li>then $ W_ {v_ 1} \cap W_ {v_ 2} \in q$</li>
<li>But then \(v_ 1 + (W_ {v_ 1} \cap W_ {v_ 2}) \cup v_ 2 + (W_ {v_ 1} \cap W_ {v_ 2})\) (a subset of our base set) will have infinitely pairs \(v_ 1 +w, v_ 2+w\), hence infinitely many gaps of size at most $\left\vert v_ 2 - v_ 1\right\vert $.</li>
<li>In other words, no set in our base can be in a set with increasing gaps!</li>
</ul>
<p>Ok, I drifted off topic for a minute. What you should take with you from this is that sums have sets that aren't &quot;thin&quot; like \(B\).</p>
<h3>P-points, Q-points, for real this time</h3>
<p>Now back to P-points and Q-points. Why can't they be sums of ultrafilters? Guess what? They always contain &quot;thin&quot; sets!</p>
<p>For Q-points, this is relatively easy. Just look at the set \[ \bigcup_ {n\in \omega} [10^{2n}, 10^{2n+1}).\]</p>
<p>or its complement, whichever is in our Q-point -- they do look very much alike. A <strong>Q-point</strong>, by definition, can turn any finite-to-one function into a one-to-one function on a set in the Q-point. The above partition can be viewed as the finite-to-one function answering &quot;which interval do you lie in?&quot;. But a set where this function is one-to-one, well, such as set shares at most one point with each interval -- hence such a set has \(\lim a_ {n+1} - a_ n = \infty\).</p>
<p>For P-points the argument is different and I hesitate to put it here -- it might do more harm than good since it's unimportant in what follows. But I guess you can decide for yourself if you'd rather skip it.</p>
<blockquote>
<p>Take a set \(A\) in a P-point; let's enumerate it again naturally by $ ( a_ n : n \in \omega) $. Now define a map $ f: A \rightarrow \mathbb{N} $ by \[ f(a_ n) = (a_ {n+1} - a_ n) .\] In other words, by the size of the gap following $ a_ n $.</p>
<p>Since we're dealing with a <strong>P-point</strong>, there's an ultrafilter set \(B\subseteq A\) such that \(f\) restricted to \(B\) is finite-to-one or constant.<br>
It can't be constant, since either $ \bigcup_ {n\in \omega} [10^{2n},10^{2n+1})$ or its complement is in our P-point. So it's finite-to-one -- and this should be enough to verify that our set \(B\) has $ \lim_ {n \to \infty} b_ {n+1} - b_ n = \infty$, right?<br>
Ok, let's take a look. After finitely many steps, the differences will be larger than any prescribed bound (just be careful here, because our function \(f\) compared \(a_ n\) with \(a_ {n+1}\), while here we compare \(b_ n\) with \(b_ {n+1}\) which is not the &quot;successor&quot; in \(A\), but in \(B\) -- but that isn't a problem since the &quot;successor&quot; in \(B\) is at least as far away as the successor in \(A\)). (Hm... there should be an easier argument, maybe? (and less need for parantheses?))</p>
</blockquote>
<p>Anway, I hope I've given some evidence to the claim that the usual crowd of set theoretically interesting ultrafilters turn out to be incompatible with the idea of a sum of ultrafilter. That's somewhat annoying, wouldn't you agree?</p>
<h3>Back to our story</h3>
<p>So sitting in the shade by a pond on a sunny day in Colorado, Jana asked me this question: can idempotent ultrafilters be rapid? And I answered that I wouldn't expect there to be rapid idempotents because the set theoretic properties (rapidity in this case) never turn out to be possible for sums because they would have too many gaps. But Jana replied &quot;yes, they have gaps -- but they do not have to have gaps everywhere!&quot;</p>
<p>At this point, I should probably explain what a <strong>rapid ultrafilter</strong> is, shouldn't I? It's quite easy, really.</p>
<p>If you identity a subset $ A\subseteq \mathbb{N} $ with its natural enumeration \(n\mapsto a_ n\) (as hopefully, you're willing to do at this point), a rapid ultrafilter is simply a (free) ultrafilter that happens to be a <strong>dominating family</strong> (in \(\mathbb{N}^\mathbb{N}\)), i.e., a cofinal family in the partial order \[f\leq^* g \text{ iff } f(n)\leq g(n) \text{ for all but finitely many } n.\] (Since rapid ultrafilters are required to be free, we can drop the &quot;all but finitely many&quot; since we could modify our infinite sets to dominate everywhere but &quot;almost everywhere&quot; is the usual partial order.)</p>
<blockquote>
<p>You could try and check that Q-points are always rapid, but there's a small trick, a change of perspective, a different characterization of Q-points that might trip you up -- oh, and the reverse is <a href="http://dml.cz/dmlcz/701258">not always true</a>.</p>
</blockquote>
<p>So you see, given any function \(f:\mathbb{N} \rightarrow \mathbb{N}\), we find a set \(A\) in the rapid ultrafilter, such that \(f(n)&lt;a_ n\) for all \(n\) (and assuming the \(a_ n\) again form the natural enumeration).</p>
<p>Now, I wasn't completely wrong that rapid ultrafilters must have huge gaps -- just imagine a set dominating the [Ackermann function](<a href="http://en.wikipedia.org/wiki/Ackermann_">http://en.wikipedia.org/wiki/Ackermann_</a> function) or an incomputable function that dominates all computable functions!</p>
<p>But the point Jana was making is that even though for every function \(f\) we need a set \(A\) dominating \(f\), it could &quot;take a break&quot; from dominating. That is, \(a_ n\) could be much bigger than \(f(n)\), say it could be bigger than \(f(2^n)\) -- and suddenly \(a_ {n+1}\) can be very close to \(a_ n\), no need for a gap at all!</p>
<p>So we sat in the Colorado sun and I thought (idealizing my memory ever so slightly here) if there's any chance for a rapid idempotent ultrafilter, then we must be able to construct a strongly summabe ultrafilter that is rapid.</p>
<h3>Strongly summable ultrafilter FTW!</h3>
<p>What are strongly summable ultrafilter, you ask? Well, I've written plenty about FS-sets, but it never hurts to repeat. FS-sets are simple: Take a sequence \((x_ n)_ {n\in \omega}\) in \(\mathbb{N}\) and then take all finite sums of the \(x_ i\) -- but no repetitions allowed! More formally,</p>
<p>\[ FS(x_ n) := \{ \sum_ {i\in s} x_ i : s \in [\omega]^{&lt;\omega}, s \neq \emptyset \}.\]</p>
<p>Now a <a href="https://www.peterkrautzberger.org/0026/"><em>strongly summable ultrafilter</em></a> is an ultrafilter that has <em>a base of such FS-sets</em>, i.e., every set in the ultrafilter contains an FS-set <strong>which is also in the ultrafilter</strong>. The last part is really the key. The <a href="https://www.peterkrautzberger.org/0077/">Galvin-Glazer Theorem</a> tells us that any idempotent ultrafilter has the property that any set in it, contains an FS-set -- but the FS-set will not (in general) be in the ultrafilter! So strongly summable ultrafilter are very special that way. (Another way they are special is that they were the first and still the most important type of idempotent ultrafilters whose existence is independent of ZFC.) They are the purest idempotents if you like which often makes them the simplest to deal with.</p>
<h3>Quick and dirty with CH</h3>
<p>Why would I think that, if anything, I should try and build a strongly summable ultrafilter that is rapid? The reason is quite naive, really: given a function, we can choose an FS-set to dominate it with. At first, this doesn't seem obvious. Sure, the generating sequence can easily be chosen to dominate any given function -- but then all these sums come in and who knows what might happen?</p>
<p>Luckily, we know precisely what happens!</p>
<p>Imagine we have been given the generating sequence \((x_ n)\), with larger and larger gaps. The only problem for the set \(FS(x_ n)\) appears after each \(x_ k\) -- it is followed by the translates of $ x_ k $ by sums of elements below $ x_ k $ before we (presumably) have another big jump to \(x_ {k+1}\). So yes, there's a problem -- lots of elements close together -- <strong>but</strong> we know how many elements are problematic before the next jump, \(2^k\)-many!</p>
<p>In other words, given some (strictly monotone) \(f\) we replace it with \(f \circ 2^n\) (see what I did there?). Then pick a sequence \((x_ n)_ {n\in \omega}\) dominating \(f\circ 2^n\) -- lo and behold, \(FS(x_ n)\) will still dominate \(f\)!</p>
<p>After this thought came up in my discussion with Jana, the initial argument was easy: just assume CH and build a strongly summable ultrafilter that is rapid by the usual transfinite induction!</p>
<h3>Lunch break is over</h3>
<p>The story continues, fortunately enough. After all, the title of this post indicates that all strongly summable ultrafilters are rapid, not just that I could construct one. How did we continue?</p>
<p>After our little proof in the park, I went to a talk and sat down next to Andreas Blass, my supervisor at Michigan. I told him about this fun question and the initial result that under CH some strongly summable ultrafilters are rapid.</p>
<p>I don't remember who was giving the talk but I feel like I must apologize since I might have caused Andreas not to pay enough attention -- right after the talk Andreas told me that he'd just shown that, in fact, an important class of strongly summable ultrafilters is rapid (iirc, he showed that all stable ordered union ultrafilters are rapid, but let's not go there). This clear improvement in turn boosted my interest in re-claiming the result and later that day I found an argument that <strong>all</strong> strongly summable ultrafilters are rapid.</p>
<p>But here is a good point to stop the first post. In the second post, I will give the argument and an additional observation which proved to be far too easy.</p>
<hr>
<p>I hope you enjoyed this a little. I think it is a common theme for small results: If you're an expert in your area (however small that area might be), there are a ton of question that you simply won't think of but nevertheless can answer relatively quickly. Sometimes, I get the feeling that I should be a little ashamed of such results. They come to quickly. There's a meme in popular culture that mathematics has to be produced &quot;the Wiles way&quot;, in secret, laboring for years. We all know that's not accurate at all, but I think some of us prefer to leave that impression. After all, if the argument is sufficiently transparent, it's often hard to tell if took a short or a long time.</p>
<p>Anyway, stay tuned for part 2.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Andreas Blass</strong>, 2012/04/15<br>
Your conjecture, that you caused me to pay insufficient attention to the next BLAST talk, is correct, at least to the extent that I don’t remember what talk that was.
<ul>
<li><strong>Peter</strong>, 2012/04/18<br>
Thanks for supporting my memory somewhat on this :)</li>
</ul>
</li>
<li><strong>Andreas Blass</strong>, 2012/04/15<br>
I like your direct argument that sums can’t be P-points.  As you surely know, but other readers might not, I generally view this fact as a consequence of the fact that a sum, p+q, is the limit, with respect to p, of the translates n+q of q (by finite numbers n).  A P-point, on the other hand, is never a limit point of a countable set of other ultrafilters.  (Indeed, this is the definition of “weak P-point,” and it follows immediately from the characterization of P-points in terms of countable intersections of neighborhoods in beta(N).)</li>
<li><strong>Peter</strong>, 2012/04/18<br>
Thanks, Andreas. I agree that this is more elegant for people who know P-points well enough. I admit I simply didn’t think of it at the time of writing.<br>
Of course, doing it this way would mean discussing the topological definition of addition and also the fact that the \((n+q)_ {n \in \omega}\) actually are different ultrafilters — and this would have complicated things. Oh well, maybe next time :)</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prelude to a small experiment]]></title>
        <id>https://www.peterkrautzberger.org/0102/</id>
        <link href="https://www.peterkrautzberger.org/0102/">
        </link>
        <updated>2012-03-26T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I haven't posted anything in almost two months -- life happened. It's still a bit chaotic and maybe I'll write about it when things calm down. For now, I'm back from a productive trip to Toronto where, among other things, I had the pleasure to reconnect with <a href="http://boolesrings.org/scoskey/">Sam</a>, <a href="http://blog.assafrinot.com/">Assaf</a> and <a href="http://boolesrings.org/mpawliuk/">Mike</a>.</p>
<h3>Meanwhile back at the ranch</h3>
<p>In the mean time, Felix Breuer scooped me and wrote a great piece (better than anything I would have written) entitled <a href="http://blog.felixbreuer.net/2012/02/27/beyondtheorems.html">&quot;Not only beyond Journals, not only beyond papers, but beyond Theorems&quot;</a>. You absolutely <em>must</em> read it. He takes a point I made in several discussions with him and just <em>nails</em> it. So go and read his piece -- don't worry, I'll wait.</p>
<p>You're back? Excellent! Reading Felix's piece, I thought I should try something I've been thinking about for a while. Though I'm arguing (as does Felix) that mathematicians need to move beyond &quot;new result&quot;-papers, I'm not advocating the end of new results. (Or the end of review by peers.) The bane is rather that we write too many papers. I think, paradoxically enough, that we can only overcome this inflation of papers (and its damaging monoculture) by reducing the &quot;least publishable unit&quot; <em>further</em>. We must develop new ways of sharing mathematics that are better adapted to the effective dissemination of research -- while allowing researchers to build a track record.</p>
<h3>Science Online 2012 revisited</h3>
<p>This brought back an idea that I returned with after talking to the altmetrics folks at ScienceOnline2012, in particular <a href="http://total-impact.org/">totalimpact</a>'s <a href="http://twitter.com/#!/jasonpriem">Jason Priem</a> and <a href="http://figshare.com/">Figshare</a>'s <a href="http://twitter.com/#!/figshare">Mark Hahnel</a>.</p>
<p>Figshare is a platform to make all kinds of research results public and, importantly, citeable. They started with scientific figures (duh) but since it's official launch earlier this year went on to more general data (they have a few of the big citizen science projects onboard now), and is really open to everything -- from grant proposals to short research notes to anything. (Figshare also has very interesting <a href="http://www.digital-science.com/">financial backing</a>.) Getting to know figshare made me wonder what mathematical content could be suitable for it.</p>
<p>There's obviously stuff that works: data in applied mathematics and also visualizations and mathematical software packages fit the bill. But for logicians and set theorists none of these are usual. What would fit? The first thing that came to mind was the mathematical analogue of negative experimental data (which figshare is eager to host) -- in other words, counterexamples. What else?</p>
<p>For my second idea, I need to return to Science Online where I had a wonderful long conversation with Jason about the invisible college, new measures for research and other ideas (which I will try to write about in the future). In that conversation, we also discussed the idea of <strong>micro-contributions</strong>, contributions much smaller than a small paper. At first, this seems more important to the sciences -- publishing your data in real time seems a natural progression there and <a href="http://en.wikipedia.org/wiki/Open_notebook_science">open notebook science</a> is already a development in that direction. I think this is also a natural step for mathematicians -- share your research as soon as it's done -- don't worry about the great result but help by making things <em>public</em>. As a mathematical example of open notebook science, you might consider <a href="http://polymathprojects.org/">Polymath</a>, but <a href="http://katlas.math.toronto.edu/drorbn/AcademicPensieve/">Dror Bar-Natan's pensieve</a> is probably a better comparison. You might be afraid to do this, worrying about being scooped or <a href="http://web.archive.org/web/20120707013315/http://publishing.mathforge.org/discussion/76/best-practices-for-journals/">not being able to publish afterwards [Wayback Machine]</a>. But we need to experiment and create more examples that work.</p>
<p>Polymath was wonderful, but has only worked twice so far, once led by Tim Gowers, once led by Terry Tao. It might turn out that Polymath simply does not scale to the &quot;average&quot; researcher. But in any case, there's every reason to continue experimenting on the web. I read a great comparison recently: the state of the 20-year-old web is roughly that of the printing press 100 years after its invention -- that's 1540, mind you, when almost all prints were illegal copies of short pamphlets. Which reminds me of this:</p>
<iframe width="100%" height="382" src="https://www.youtube.com/embed/7miRCLeFSJo" frameborder="0" allowfullscreen=""></iframe>
<h3>So what's this about then?</h3>
<p>Well, this post is supposed to be the prelude to an upcoming double-post which is precisely this -- a micro-contribution, a small result, far smaller than the least publishable unit, nothing big, but at the same time a curious observation which is, I believe, worth recording (if only because it made me question a certain intuition of mine).</p>
<p>This micro-result has been lying around in my notes for almost two years now. At first I thought it might be incorporated into something else, but as it turns out, this never happened. And yet, I'm sitting on it. Sure, the people involved in it know about it, but since it's so small, it would never be published as a paper and thus never appear. I think that's really unnecessary -- I want to make my work public, that's kind of the point, isn't it? And I don't want to be pretentious and waste time finding a way to blow this up into yet another paper that nobody reads. Thus, this experiment.</p>
<blockquote>
<p>A question on the side. Could we have a &quot;journal&quot; for micro-contributions? What would that even look like? Would we need peer-review? What would peer-review look like? Could it simply be done in the comments of a blog or by short &quot;replies&quot; on (a common or different) platforms such as arXiv or figshare?</p>
</blockquote>
<p>Besides making this micro-contribution public I would like to give you the story behind the result. You see, the result is really &quot;micro&quot;. So if I only gave you the proof, we'd be done in a minute. And then you'd have 1-2 pages tops, in the usual brutally short mathematical paper-style writing (only expanded by my silly habit of writing proofs as lists). I mean, don't worry, that version will be there, too, in the end, much like my dream of one day having papers with computer checkable proofs in the appendix. But while I'm trying something new why not try some mathematical storytelling simultaneously?</p>
<p>So before I reach those bare bones of proof, I will take the time to tell you the story of how the result came to be. Not because it is an especially important or impressive story -- neither is the case. In fact, it's rather ordinary and I'm sure every mathematician will have experienced this, probably on a much more significant level than I did. Yet I'd like to try writing about it and it will take me a double post to do so.</p>
<p>Reversely, I hope you, my two readers, will be kind enough to provide some feedback. I could imagine this being in three ways:</p>
<ul>
<li>the mathematical side: is the result correct?</li>
<li>the lyrical side: is the result well written?</li>
<li>the experimental side: is this a concept you could see yourself employing?</li>
</ul>
<p>Finally, I do plan to post the result of all this properly somewhere; you know, as a research note of sorts, with a proper bibliography and so forth. Maybe on figshare, maybe on the arXiv, maybe on github, not sure yet (any thoughts?). In any case, stay tuned for the first post -- the rough drafts are finished, but some fine tuning is still missing.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>fbreuer</strong>, 2012/03/27<br>
Thanks for the mention! I am looking forward to your double-post!<br>
I am all for micro-contributions! With their “open” nature they explore the territory “beyond theorems”, even if they are micro-theorems themselves.<br>
The main challenge I see is that of discoverability. How will we discover relevant micro-contributions if we are already flooded with macro-contributions? Dror Bar-Natan’s pensieve is an interesting example in this regard. On<br>
the one hand it is absolutely brilliant in its radicality! (Just the<br>
thought of putting all my xournal notes online is scary.) On the other<br>
hand, who is going to dig through all these notes to sift out the great<br>
ideas?<br>
I am sure, though, that in the case of your double-post, discoverability will not be much of an issue as your blog gets plenty of readers. (I can tell by the amount of traffic you have sent my way. 😉
<ul>
<li><strong>Peter</strong>, 2012/03/29<br>
Yes, discoverability is an issue (then again, googling or duckduckgoing for idempotent ultrafilters puts some of my stuff on the front page) .<br>
I think we’ll never get enough motivation for a good solution for this without creating and sharing the content that we want to be discovered. So I worry about that first while keeping an eye on the discoverability. Personally, I favor decentralized social networks via tools like wordpress to host the content as well as specialized search engines // aggregators to discover content and the people behind it.</li>
</ul>
</li>
<li><strong>Carl Mummer</strong> 2012/03/28<br>
The “microresult” idea is very similar to the motivation I have for experimenting with online publishing. I agree with many of Felix Breuer’s comments in his blog post, that it is becoming increasingly impossible to keep up with the volume of mathematics (this has been a problem for several decades, of course). But at the same time I think that we don’t publish <em>enough</em>. There are many microresults that we discover, possibly write in a notebook, and then leave because there’s not a good way to fit them into a peer-reviewed paper. These often get passed around as folklore in larger departments, discussed over tea.  After our discussion last night, I’ve started to think about a post for my blog to try to collect my ideas on this.
<ul>
<li><strong>Peter</strong> 2012/03/29<br>
Looking forward to your post on this!</li>
</ul>
</li>
<li><strong>David Roberts</strong> 2012/08/29<br>
Hi Peter, thought I might drop in an example of a microcontribution of mine from a few years back:<br>
<a href="http://golem.ph.utexas.edu/category/2008/01/101_things_to_do_with_a_2class.html#c014559">http://golem.ph.utexas.edu/category/2008/01/101_things_to_do_with_a_2class.html#c014559</a><br>
this is referenced at the nLab page<br>
<a href="http://ncatlab.org/nlab/show/generalized+universal+bundle#universal_category_bundles_subobject_classifiers_26">http://ncatlab.org/nlab/show/generalized+universal+bundle#universal_category_bundles_subobject_classifiers_26</a><br>
This is a mechanism which overcomes to some extent the problem of discoverability. Wikipedia famously has a 'no original research' policy, but the nLab famously takes the opposite approach, and indeed was originally set up to capture what you are calling microcontributions that arose in discussion at the n-category cafe.<br>
As far as the microcontribution itself goes, it was a merely a shift in perspective on my part that made a number of things make sense, and unified a bunch of facts - something that doesn't even deserve a blog post, and would probably fit into a tweet.<br>
In the discussions about moving MathOverflow onto the StackExchange platform (and hence move to currently maintained software!), a number of people were concerned about not losing Brian Conrad's comments on questions. These comments were in fact complete, elegant solutions to problems in algebraic geometry. I would count these as microcontributions in the sense they may not solve a problem that hasn't been solved before, but are approaching Book-status.
<ul>
<li><strong>Peter</strong> 2012/09/24<br>
Oops, I never replied?!? Thanks for the pointer, David!</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bumper sticker]]></title>
        <id>http://www.dorais.org/news/2012-03-24-bumper-sticker.html</id>
        <link href="http://www.dorais.org/news/2012-03-24-bumper-sticker.html">
        </link>
        <updated>2012-03-24T16:38:43Z</updated>
        <summary type="html"><![CDATA[<p>An amazing idea for a bumper sticker from <a href="http://xkcd.com">xkcd</a>:</p>

<p><img src="http://imgs.xkcd.com/comics/formal_logic.png" alt="Formal Logic Bumper Sticker" /></p>

<p>Of course, this has many implications for people driving behind you…</p>]]></summary>
        <author>
            <name>François G. Dorais</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Possibly true. Necessarily funny.]]></title>
        <id>http://www.dorais.org/news/2012-03-18-possibly-true-necessarily-funny.html</id>
        <link href="http://www.dorais.org/news/2012-03-18-possibly-true-necessarily-funny.html">
        </link>
        <updated>2012-03-18T13:38:42Z</updated>
        <summary type="html"><![CDATA[<p>This is the tagline for <a href="http://fauxphilnews.wordpress.com/">fauxphilnews</a>, a hilarious philosophy blog created by Ben Bronner. My favorite entry so far is <a href="http://fauxphilnews.wordpress.com/2012/02/22/kripke-resigns-after-allegations-of-academic-fraud/">Saul Kripke’s resignation after faking results of thought experiments</a>. Check it out…</p>]]></summary>
        <author>
            <name>François G. Dorais</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convergence of ideas]]></title>
        <id>http://www.dorais.org/news/2012-03-11-convergence-of-ideas.html</id>
        <link href="http://www.dorais.org/news/2012-03-11-convergence-of-ideas.html">
        </link>
        <updated>2012-03-11T02:37:30Z</updated>
        <summary type="html"><![CDATA[<p>As a moderator on MathOverflow, I see a lot of interesting interactions between mathematicians. The occasional dramatic situations get discussed profusely by community but very few take the time talk about the pleasant exchanges they have had. Here is one that caught my attention today because it illustrates how it is not uncommon for two mathematicians from distant parts of the world can stumble upon the exact same set of ideas…</p>

<p>Today, <a href="http://mathoverflow.net/users/20598/sean-eberhard">Sean Eberhard</a> asked two interesting questions: <a href="http://mathoverflow.net/questions/90826/intersecting-group-orbits">Intersecting group orbits</a> and <a href="http://mathoverflow.net/questions/90836/intersecting-group-orbits-version-2">Intersecting group orbits, version 2</a>. The first question was answered almost immediately by <a href="http://mathoverflow.net/users/6794/andreas-blass">Andreas Blass</a> with a carefully crafted argument. This is not unusual, Andreas is well-known for answering questions quickly and precisely, both on and off MathOverflow. However, Andreas’s comment after answering explains why he answered so fast:</p>

<blockquote>
  <p>This, along with the projective plane example, was actually going to be in a paper I’m writing. Fortunately, the main topic of the paper is something else, so the paper won’t lose much by omitting this.</p>
</blockquote>

<p>After getting an answer from Andreas, Sean posted his second question. Andreas answered again, with another comment:</p>

<blockquote>
  <p>This is another piece of the planned paper that I mentioned in connection with Sean’s previous question. Maybe the whole paper will gradually appear on MO this way. It’s one way to get it written without my usual delays.</p>
</blockquote>

<p>It appears that Sean and Andreas have been having a lot of common questions and ideas, even if they don’t appear to know each other and live on different continents. Let me conclude this anecdote by seconding one of Sean’s comments:</p>

<blockquote>
  <p>I look forward to reading this paper. :)</p>
</blockquote>]]></summary>
        <author>
            <name>François G. Dorais</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Disqus]]></title>
        <id>http://www.dorais.org/news/2012-03-01-disqus.html</id>
        <link href="http://www.dorais.org/news/2012-03-01-disqus.html">
        </link>
        <updated>2012-03-01T14:26:02Z</updated>
        <summary type="html"><![CDATA[<p>I have just enabled <a href="http://disqus.com/about/">Disqus</a> commenting system. It has lots of nice features, but there are a few bugs we need to fix — that’s part of the <a href="http://boolesrings.org/">Boole’s Rings</a> way…</p>

<p><del>The most obvious issue is that <a href="http://www.mathjax.org/">MathJax</a> currently doesn’t work in comments. I’m hoping that will get fixed very soon, so keep on using <script type="math/tex">\LaTeX</script> in comments even if it’s not pretty for the moment.</del></p>

<p>There are a few other minor issues. Let me know if you encounter an issue, that will help us tune this new plugin.</p>]]></summary>
        <author>
            <name>François G. Dorais</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computable roots of computable functions]]></title>
        <id>http://m6c.org/w/2012/02/computable-roots/</id>
        <link href="http://m6c.org/w/2012/02/computable-roots/">
        </link>
        <updated>2012-02-14T02:06:03Z</updated>
        <summary type="html"><![CDATA[Here are several interesting results from computable analysis: Theorem 1. If $f$ is a computable function from $\mathbb{R}$ to $\mathbb{R}$ and $\alpha$ is an isolated root of $f$, then $\alpha$ is computable. Corollary 2. If $p(x)$ is a polynomial over &#8230; <a href="http://m6c.org/w/2012/02/computable-roots/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></summary>
        <author>
            <name>Carl Mummert</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[If you build it, will they come?]]></title>
        <id>https://www.peterkrautzberger.org/0101/</id>
        <link href="https://www.peterkrautzberger.org/0101/">
        </link>
        <updated>2012-02-06T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Last week, Tim Gowers published another post on the publishing debate entitled <a href="http://gowers.wordpress.com/2012/02/02/abstract-thoughts-about-online-review-systems/">&quot;Abstract thoughts about online review systems&quot;</a>.</p>
<p>There are, as usual, interesting thoughts both in the post and in the comments (including some very nice elitist ones), enough to keep the discussion going for another few weeks.</p>
<p>And yet I can't shake the feeling that this discussion will not lead to the creation of an online review platform -- no matter how I wished otherwise.</p>
<h3>If you build it, they won't come</h3>
<p>Let me start by recalling an earlier experience with introducing technology to academia. While I was working on my PhD in Berlin, there was a big change within the university's administrative technology with respect to course management. I was strongly in favor of this technological update and ended up having repeated arguments with a colleague who was not. This colleague pointed out that the new system relied heavily on a fundamental cultural change among faculty while the university made no effort to facilitate this change. I vividly remember how angry I was about all this since the problems were &quot;clearly&quot; the fault of all these old, lazy professors who didn't care enough for their students to adopt a new tool.</p>
<p>Long after, I came to appreciate my colleague's argument for what it was -- precisely on point. (I don't know what the current state of affairs, but while I was there, the system failed miserably for precisely this cultural reason.)</p>
<p>Coming back to an online review system, I can see the appeal of abstractly designing an online review platform. I don't doubt that the current debate will lead to many interesting models for reviewing platforms -- that's what mathematicians are very good at. But this won't be enough.</p>
<h3>Where is our culture of review?</h3>
<p>The problem isn't that we're lacking a great system. The problem is that nobody reviews other people's work publicly (nor do we have other professionals to do it for us as in the case of science journalism). I don't think that progress can be made with technology alone -- we must improve the <em>culture</em> of review.</p>
<p>It's not that we don't read other people's work, mind you. We do it<br>
all the time! And when we're serious about a paper, we essentially<br>
re-write the damn thing; simplifying, expanding, hoping to get a new<br>
result out of the process.</p>
<p>And yet, you will find very few traces of this activity on the net. We<br>
waste our efforts by not speaking publicly about the reviewing we do<br>
day in and day out. From what I can see via <a href="http://www.mathblogging.org/">mathblogging.org</a>, one or two prominent researcher bloggers do it (not Tim Gowers I should add), as well as a few not-at-all prominent bloggers. In other words, public reviewing hasn't entered our collective culture at all; it's reduced to isolated cases.</p>
<h3>When Nature built it, nobody came</h3>
<p>When it comes to post-publication peer review, the locus classicus is<br>
<a href="http://www.nature.com/nature/peerreview/debate/nature05535.html"><em>Nature</em>'s failed experiment</a> in 2006. They tried an open reviewing process because everybody said they'd like to have more reviews to identify good and interesting work. As it turned out, nobody wanted to actually do the work. So Nature stopped this experiment after five months.</p>
<p>What is particularly strange about this failure is the fact that many science bloggers were already spending a considerable amount of their time writing about peer-reviewed papers.</p>
<h3>If people do it, you can build it</h3>
<p>In the summer of 2007, <a href="http://researchblogging.org/news/?page_id=8">researchblogging.org</a> went online. If you have ever visited a science blog, you might have come across its well known badge (I finally got around to it <a href="https://www.peterkrautzberger.org/0099/">here</a>).</p>
<p>It's a very simple service, really. When you're blogging about a peer-reviewed work, you go and grab a bit of javascript to display a citation. In return, your post is aggregated at <a href="http://researchblogging.org/">researchblogging.org</a>, reaching a much wider audience. Reversely, people interested only in blog posts about peer-reviewed work can find all these posts in one central location.</p>
<p>In short, it's post-publication peer review at its best -- grassroots,<br>
decentralized, open, supporting the independence of authors and scientists, using the crowd for checks and balances.</p>
<p>(Even though I don't know the precise history, it looks to me as if <a href="http://www.f1000.com/">f1000</a> has successfully taken the post-publication peer-review back to the commercial level. Not sure what this development will mean, since f1000 is relatively young.)</p>
<h3>If you build, and some come, is that enough?</h3>
<p>Maybe, I'm wrong. Maybe, Tim Gowers leads us, like a Greek hero, to a brave new reviewing platform. And maybe some top researchers start writing reviews -- finally. And then, I wonder, what will happen?</p>
<p>Will it end like the <a href="http://www.tricki.org/">tricki</a>, with a few high quality items from our heroes that no mere mortal could match? Or will it follow MathOverflow, in need of a lower-level clone like <a href="http://math.se/">math.SE</a>?</p>
<h3>tl;dr</h3>
<p>I guess what I'm trying to say is: the longer this debate revolves around the perfect model, the longer it will take us to actually get our hands dirty and write reviews.</p>
<p>The experiments regarding platforms will continue for much, much longer -- the web is too young to pretend we will find <em>the</em> solution this decade (or century).</p>
<p>Let's focus on the real task: creating a culture of writing about each others work online. An inclusive culture, a sustainable culture, a democratic culture.</p>
<blockquote>
<p>I thank <a href="http://boolesrings.org/scoskey">Sam</a> for editorial feedback.</p>
</blockquote>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A comment on Tim Gowers's blog]]></title>
        <id>https://www.peterkrautzberger.org/0100/</id>
        <link href="https://www.peterkrautzberger.org/0100/">
        </link>
        <updated>2012-01-29T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>I just left an awfully long comment on Tim Gowers's blog. Thanks, François for mentioning <a href="http://gowers.wordpress.com/2012/01/29/whats-wrong-with-electronic-journals/">the new post</a> on twitter! <del datetime="2012-01-30T00:27:21+00:00">Incidentally, it seems that my email is considered spam by Akismet these days, so it will most likely never show up on Gowers's blog.</del> Tim Gowers was very kind and took the trouble of going through his blog's spam folder to retrieve my comment. On top of that he explained what I did wrong -- I had too many links in my piece, silly me. Thank you! I've also added another comment from there where somebody asked me to clarify a few points. I wished there was a system for collecting my comments...</p>
</blockquote>
<p><a href="http://boolesrings.org/krautzberger">First comment</a></p>
<p>Thank you for continuing this discussion. I had feared it would stop after the pledge worked so well.</p>
<p>I must admit that I find myself wondering if the points you raise are going in the right direction.</p>
<p>I got rather uncomfortable when you described the idea of &quot;Breakthroughs in Mathematics&quot;. I don't think that breakthrough papers are the problem -- with your support, such a journal would likely be an instant success.</p>
<p>The problem is rather with average papers. The kind of papers that more and more young researchers find themselves writing not because they want to write them but because they must publish to find a job, to survive an evaluation etc. And of course, these papers must end up at reasonably high impact factor journals because that is what we are reduced to in job applications.</p>
<p>This, I think, is the main problem why the journal system appears broken -- an inflation of papers that has devalued the concept of papers and hence of the only thing we consider in the research section of a mathematician's CV.</p>
<p>I seems that the problem of scientific and mathematical research is not the production of results anymore. Your generation has done a great job at creating more and more PhDs that can write papers a plenty.</p>
<p>Instead of production, the problem is now attention, i.e., identifying the better papers amid the flood of average papers that nobody has time to read. As you described yourself, you were surprised that the Electronic Journal of Combinatorics actually contained a lot of interesting material that you didn't even know about. Have you ever considered writing about interesting papers? And maybe even use <a href="http://www.researchblogging.org/">http://www.researchblogging.org</a> to make this known? Or perhaps use <a href="http://www.papercritic.com/">http://www.papercritic.com</a> to rate the paper? (You could also do this anonymously.)</p>
<p>Instead of more papers (and hence more journals), I strongly believe that we need to focus on new ways of finding good research results and value this as <strong>research</strong> activity. In fact, after your suggestion for a MathOverflow+ArXiv publishing system, <a href="http://teachingintrotocs.blogspot.com/2011/11/journals-conferences-arxiv-my-solution.html">Claire Mathieu</a> had suggested to only publish other people's work -- taking the idea of valuing the identification of good research to a wonderful extreme. There's of course also the much larger debate going on regarding post-publication peer-review (such as <a href="http://www.f1000.com/">f1000</a>) which is precisely about this issue.</p>
<p>The second problem I see is what Michael Nielsen raises in Reinventing Discovery: the modularization of research. The sciences have already experimented very successfully with ways to modularize research from by now classic examples like Galaxy Zoo to more recent ideas <a href="http://whale.fm/">http://whale.fm/</a> and <a href="http://www.figshare.com/">http://www.FigShare.com</a>.</p>
<p>We mathematicians have nothing to offer in this respect.</p>
<p>As you wrote yourself a while ago, the wonderful tricki has failed much like other wikis outside of Wikipedia (whereas other research areas have begun to <a href="http://blog.wikimedia.org/2011/04/06/tenure-awarded-based-in-part-on-wikipedia-contributions/">value Wikipedia contributions as research</a>).</p>
<p>I would even go as far as say that Polymath has failed (even though it was all about publishing papers and not disruptive in that sense). However, there still might be a chance to salvage it if we find a way to scale it away from top research to more average level research, more realistic problems or simply <a href="http://en.wikipedia.org/wiki/Open_notebook_science">open-notebook science</a>.</p>
<p>At the same time, a lot of young mathematicians &quot;grow up&quot; online. But they are still strongly discouraged not to experiment with communicating their mathematics online. Having attended <a href="http://web.archive.org/web/20110826202353/http://scienceonline2012.com/">Science Online 2012</a> last week, I was again shocked by the positive community the scientific online community offers.</p>
<p>The scientific online community embraces the younger generation. (Did you know that young graduate students write at the Scientific American's blog network as equals of experienced scientists and professional science journalists?.) In mathematics, e.g., the MathOverflow community has worked very hard at discouraging even experienced graduate students from contributing (just ask some average graduate student). The scientific online community also offers protection and support by encouraging and developing safe systems for pseudonymous online activities.</p>
<p>As some comments have already indicated, we mathematicians are significantly behind in founding an online community that deserves the name. In particular, our academic societies do not take the online community seriously -- which is somewhat bizarre given the current count of roughly 350 blogs in the research category on <a href="http://www.mathblogging.org/">http://www.mathblogging.org</a>.</p>
<p>Can we find a way to raise awareness of the potential for our community? Can we get to a culture where we value more and more experiments like the tricki, Polymath, mathoverflow until we find enough systems that actually work and everyone can participate meaningfully?</p>
<p>Finally, in a most likely vain attempt at getting back on topic: Can we find a way to use online journals in new ways, to modularize the mathematical research process instead of just copying a 300 year old idea to the web?</p>
<p>Oh dear, this has gotten far too long. I apologize.</p>
<hr>
<p><a href="http://gowers.wordpress.com/2012/01/29/whats-wrong-with-electronic-journals/#comment-14947">Second comment</a></p>
<p>@Marcin Kotowski.</p>
<p>My wording regarding MO was unfortunate. I did not mean to imply graduate students are actively discouraged by the community. However, almost all graduate students I have talked to about this (here at Michigan but also at conferences and workshops) have given me precisely this impression -- they do feel discouraged to participate. This has many reasons and for privacy reasons I don't want to describe individual stories. There's also the &quot;problem&quot; of MO having extraordinary users in some areas (such as my own), making it impossible to participate much (have you ever tried answering a question that Joel Hamkins knows the answer to?). Finally, there are those fields which are not well represented on MO in general, another hindrance for younger researchers.</p>
<p>I do think that MO is an amazing community in many, many ways and something where we are truly ahead of everybody else, really. But that doesn't mean it's <a href="http://ilaba.wordpress.com/2011/03/28/why-im-not-on-mathoverflow/">without flaws</a>.</p>
<p>The second part you quoted was much more general in nature, not just about MO but also other activities such as blogging, wikipedia, tricki, expository writing, reviewing other people's papers, engaging with your community through social media etc.. From my own experience but also from conversations with other postdocs, it is clear that non-tenured folk are discouraged to do anything online -- if you're very good, then it is non-negative for your career.</p>
<p>I've personally heard the advice to &quot;definitely not mention this on your CV&quot;. It boils down to the old &quot;you could have written a paper instead&quot;-argument, really, and it is not going away while hiring committees effectively reduce applicants to impact factors of the journals they publish in. Again, as I said before, this is not about breakthrough mathematics but about &quot;average&quot; research.</p>
<p>Finally, here's a link to a video from <a href="http://blogs.scientificamerican.com/a-blog-around-the-clock/2011/11/03/scio11-blogging-in-the-academy/">Science Online 2011</a> on &quot;blogging in the academy&quot; starting with an introduction from the perspective of MIT. It's quite sobering even if it is only about blogging.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>Carol Hutchins</strong>, 2012/01/29<br>
An important point you are making is the differential between &quot;breakthroughs&quot;  and what one might call the Big Middle.  Let's set aside that there is some tail of really really awful contributions at the other end.<br>
Think of the frogs and birds, per F. Dyson.
<ul>
<li><strong>Peter</strong> 2012/01/29<br>
Thank you, Carol. I'm sure there's a tail of awful contributions. That's why I'm speaking of an attention economy instead of a production economy. We need to share what we think about each others work. On the other hand, I think if we had activities other than writing papers which we could still put in the research section of our CV (such as open reviewing, helping other people make progress in their work), then the pressure to write as many papers as possible could be reduced, leading to fewer awful papers. But nobody can do that if we do not experiment more in this respect.<br>
By the way, I've sometimes seen the argument &quot;but then the cranks take over&quot; which I find hilarious since I've yet to meet a mathematician who cannot spot a crank from a mile away.</li>
</ul>
</li>
<li><strong>Micheal Pawliuk</strong> 2012/02/01<br>
I get the impression from your posts Peter that all mathematicians are terrible presenters and writers. :)<br>
The problem I suppose is that good presentation skills are (unfortunately) often orthogonal to good research skills. I have even heard that some people with particularly strong teaching backgrounds actually have a harder time getting an academic job. (sigh)
<ul>
<li><strong>Peter</strong> 2012/02/03<br>
Mike, unfortunately, I think your observations are on point.<br>
The reason why mathematicians are bad speakers actually has a simple answer — we receive no training and there’s no active discussion in the community on how to present well (just check out the Journal of Number Theory’s youtube channel…). There’s also no feedback for speaker, i.e., nobody tells you what went badly in your talk or how to improve, even if you ask arond. Giving productive feedback is, of course, also a skill to be trained.<br>
The trouble is that most people think you cannot learn this — which is plain wrong. To be a good speaker can be trained, just like anything else.<br>
The observation regarding the job market is, I think, also correct, but for entirely different reasons. This is quite simply a (poor) decision of our community to actively favor the wrong set of skills (or rather, focus on one skill exclusively “paper writing”).<br>
If you look around, the truly great mathematicians (Tim Gowers being a formidable example) are very good teachers and speakers. I think it is a misconception in our community that this skill is not important to further mathematical research; a misconception most likely originating from the fact that such skills could not be documented/evaluated until very, very recently.
<ul>
<li><strong>Izabella Laba</strong> 2012/02/07<br>
There are truly great mathematicians who are not good expositors at all. I’m not sure that it would serve anyone’s interests to post names on a public blog, but they’re in Gowers’s league, research-wise. I’ve come to think that there might just be no correlation at all.<br>
I’m all for recognizing a wider range of skills and contributions. I just don’t think that we should expect everyone to have every skill and make every type of contribution in the book. We have to wear a lot of hats already as it is.
<ul>
<li><strong>Peter</strong> 2012/02/07<br>
I don't know if there's no correlation. I'd like to think that the very best, the extraordinary mathematicians are good expositors but I have no data to support this. Ultimately, I think, it comes down to values of the community -- I would call someone with a lesser &quot;new results&quot; record the greater mathematician if they are a great expositor. What good are results if nobody can understand them (and why we don't value people who make them understandable)? For example, I find it hard to call Perelman anything near great; his results, yes, but the mathematician, the member of our community? Another example would be Grothendieck, thanks to <a href="http://sbseminar.wordpress.com/2010/02/09/grothendiecks-letter/">this letter</a>.<br>
I also fully agree with you that nobody should have to make every type of contribution. In fact, I hope for the exact opposite! People should contribute the best way they can. However, they can't as long as the community does not value all types of contributions. I see a monoculture where only people who can produce the right kind of &quot;new results&quot; papers will get into the &quot;right&quot; journals and, ultimately, get the jobs. And I worry that it is not a sustainable culture.
<ul>
<li><strong>Izabella Laba</strong> 2012/02/07<br>
I’m thinking of someone in particular who, research-wise, is at the absolute top of several fields of mathematics. I do wish that his papers were easier to read. But we still read them (even if it takes an effort) and use his ideas (and there’s an abundance of them, and they’re often unexpected and have far-reaching consequences, so it’s all worth the time we invest in it). He has been incredibly influential in many areas and has developed a huge following. To me, there’s no question about either his greatness or being a valuable member of the community. Sometimes you can’t have it all.<br>
On the other hand, I really would like to see expository work better valued. Right now, if someone writes an article making X’s unreadable but important work accessible to the community, this is dismissed as “just expository” and therefore lesser work, unless the author manages to attach some minor new result to it whereupon the paper gets upgraded immediately to the “research” category. I don’t think that this is right.
<ul>
<li><strong>Peter</strong> 2012/02/07<br>
I see your point. What might help is a culture of seeking co-authors to remedy such deficits (if I was daring, I’d suggest this as referee of such a paper but that’s most likely too late in the game).<br>
In set theory, Saharon Shelah seems similar to the researcher you describe. Reading a Shelah paper can be very painful, but reading a Shelah-Goldstern or Shelah-Blass paper usually isn’t (of course, with 1000+(!) papers Shelah has many, many co-authors for other practical reasons).<br>
Oh, and I wholeheartedly agree with you that we should value expository work seriously!</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>Joel David Hankins</strong> 2012/02/02<br>
Peter, I’m unsure whether to take your remark in the second comment as criticism or as joking praise… I would think that vigorous participation on MO by a logic user such as myself or Andreas Blass (or Emil, Carl, Francois, etc. etc.) would be seen as fundamentally encouraging of a vigorous logic activity there.
<ul>
<li><strong>Peter</strong> 2012/02/03<br>
Joel, I mean it as both criticism and praise. Praise, obviously, for giving fantastic answers.<br>
But it is also criticism. I see mathoverflow activity as something that adds to the research reputation of, in particular, untenured faculty. In fact, I sincerely hope that activities such as mathoverflow will soon find their rightful place in the research section of people’s CV. (And I’m baffled that not even Anton is getting the recognition he deserves — mathoverflow has probably created more impact than an entire year of Inventiones papers.)<br>
The problem I see is that nobody else has a chance of building a reputation by <em>answering</em> questions because of power users such as yourself.<br>
This is not a specific logic/set theory problem, since I’ve seen colleagues in other fields make the same observation. It’s probably easier to spot in a small field such as set theory.<br>
I think it would help if there was a culture of less hurry on MO. Why not leave a question unanswered for a day or two even if you have an answer? The question is hardly life-and-death… But younger people (such as graduate students, postdocs) might get a chance to take a first step into the community.<br>
I’m not saying that there is a solution — there might very well not be. In fact, when I say that MO deserves to be in the research section of a CV, I don’t mean that it should be the only thing there. We need many, many more platforms to allow researchers to contribute in other forms than old-fashioned papers.<br>
I should add, this isn’t about me. There are other reasons why I don’t participate on MO anymore (though I like reading it).
<ul>
<li><strong>Joel David Hamkins</strong> 2012/02/04<br>
But surely a major part of the attraction of MO is its vitality, the energetic participation by knowledgeable users. My view is that its mildly competitive nature, from a sociological design perspective, is absolutely key to its success.</li>
<li><strong>Peter</strong> 202/02/04<br>
I wasn't trying to describe why MO is attractive to some of its users. I was trying to describe why it isn't attractive to others. <a href="http://ilaba.wordpress.com/2011/03/28/why-im-not-on-mathoverflow/">Izabella Laba</a> had a discussion with yet different reasons a while ago.<br>
But yes, I disagree with your view that the competitive nature is key to MO's success. It may have been in the past, but I think it can become damaging in the future.</li>
</ul>
</li>
</ul>
</li>
<li><a href="http://qedinsight.wordpress.com/2012/02/16/both-students-and-professors-need-certification-and-the-elsevier-boycott/">Pingback</a> 2012/02/16</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Groups in $\beta \mathbb{N}$]]></title>
        <id>https://www.peterkrautzberger.org/0099/</id>
        <link href="https://www.peterkrautzberger.org/0099/">
        </link>
        <updated>2012-01-26T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Well, if you haven't read <a href="https://www.peterkrautzberger.org/0098/">my recent introspection</a>, consider yourself warned: the video below is, in my humble opinion, a rather poor talk I gave at our Logic Seminar here at the University of Michigan.</p>
<iframe src="https://player.vimeo.com/video/35611686" width="100%" height="375" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
<p>Nevertheless, I would like to offer a short transcript of the proof involved, just for posterity and to improve the talk.</p>
<p>This is a also my first ever post attempting to get something on <a href="http://researchblogging.org/">researchblogging.org</a>. Namely, the results I was giving the talk about are by <a href="http://dx.doi.org/10.1007/BF02573448">Neil Hindman and John Pym, 1984</a>.</p>
<p>It's a funny thing. Last year, <a href="http://gowers.wordpress.com/2011/10/31/how-might-we-get-to-a-new-model-of-mathematical-publishing/">Tim Gowers created quite a discussion</a> about reforming publishing.</p>
<p>What strikes me as odd, though, is the fact that mathematicians are not aware that the tools he described largely exist already, e.g., in form of <a href="http://www.researchblogging.org/">researchblogging.org</a> (and more recently <a href="http://www.papercritic.com/">papercritic.com</a>). So we find ourselves more like that failed Nature experiment nobody of post publication peer review -- everybody wants to have it but nobody wants to do it. Oh well, let's set an example instead?</p>
<h3>Groups in \(\beta \mathbb{N}\)</h3>
<p>As far as I know only a few things are known of the groups in \(\beta \mathbb{N}\).</p>
<p>The most famous result is probably Zelenyuk's Theorem</p>
<blockquote>
<p><strong>Theorem (Zelenyuk, 1997)</strong> There are no non-trivial finite groups in \(\beta \mathbb{N}\). More generally, if \(G\) is a group without non-trivial finite subgroups, then \(\beta G\) contains no non-trivial finite subgroups.</p>
</blockquote>
<p>This is a somewhat difficult result in the sense that there's no easy proof written up anywhere and some of the technical details are messy even though they are not complicated (though I can't imagine how to come up with those).</p>
<p>In any case, <a href="http://dx.doi.org/10.1007%2FPL00005907">Zelenyuk's result</a> seems to have been the only important results since the paper by Hindman and Pym from 1984.</p>
<p>On the side, a very important open question in extension to Zelenyuk's Theorem is whether \(\beta \mathbb{N}\) can have any non-idempotent elements of finite-order (I stated this <strong>incorrectly at the end of my talk</strong> as &quot;non-trivial finite semigroups&quot; -- catch me giving an example of a finite semigroup in the middle of the talk where I state that you'll find lots of idempotents in \(\mathbb{N}\), say \(e, f\), with \(e+f =f +e =f\) -- perfect two element semigroup right there. Of course, nobody caught that; it was a bad talk after all).</p>
<p>This open question has <a href="http://www.papercritic.com/mendeley-pub/4dca14d0-c665-11df-a164-0024e8453de6">funny consequences</a> in Ramsey Theory in the form of a very intuitive partition theorem but it originally showed up in <a href="http://doi.org/10.1112/jlms/s2-46.3.463">Dona Strauss's seminal result</a> that continuous homomorphisms from \(\beta \mathbb{N}\) to \(\mathbb{N}^\star\) must have finite image. If such images are always constant, there won't be a non-trivial finite-rank element that isn't idempotent (the contraposition is easier: if you find one, map 1 to it and extend homomorphically).</p>
<h3>The main theorem</h3>
<p>Anyway, let's turn to the theorem I actually want to give you the proof of here.</p>
<blockquote>
<p><strong>Theorem (Hindman, Pym 1984)</strong><br>
If \(e\) is a minimal idempotent in \(\beta \mathbb{N}\), then the maximal group of \(e\) contains the free group on \(2^{2^\omega}\)-many generators.</p>
</blockquote>
<p>That's in stark contrast to Zelenyuk's theorem -- we have an incredible amount of groups, as complicated as it gets you might say.</p>
<p>Some thoughts before I go through the proof.</p>
<ul>
<li><strong>What is the maximal group?</strong> Every idempotent has a maximal group associated with it, i.e., the largest group that contains the idempotent as identity. This is simply the union of all groups containing the idempotent -- if you have two groups, then the semigoup generated by their union is again a group, just write down the inverses.</li>
<li><strong>What is a minimal idemoptent?</strong> It's a special kind of idempotent. There are many ways to characterize minimal idempotents. In this proof, the characterization \(e + \beta \mathbb{N} + e\) is used, so let's stick to that, shall we? Another way is to say &quot;lies in a minimal left ideal&quot; (whatever that is).</li>
<li><strong>How do we proof that something is a free group on that many generators?</strong> Well, we just need to do it for finitely many at a time.</li>
</ul>
<p>When I looked up this proof in the Hindman&amp;Strauss book I was really surprised how easy it was. I mean, it wasn't really easy. It was given in greater generality than I will present it here. And it also assumes a lot of things about \(\beta \mathbb{N}\). But those assumptions are all standard, stuff you would learn in a course on the matter. So really, the proof is not that hard, easily done in an hour (as the video shows, well, sort of shows).</p>
<h4>Proof.</h4>
<p>The proof is relatively easy in the sense that we're simply able to describe the group. The key for proving that it is a free group is to connect it to the most important subsemigroup of \(\beta \mathbb{N}\) called \(\mathbb{H}\).</p>
<p>But let's go.</p>
<ul>
<li>Let \(A:= \{ 2^n: n\in \omega\}\) -- simply the powers of 2.</li>
<li>Then \(A^\star := \beta A \setminus A\), the free ultrafilters on \(A\), is a set of cardinality \(2^{2^\omega}\). (this is standard stuff on \(\beta \mathbb{N}\))</li>
<li>Then \(e + A^\star + e\) generates a free group!</li>
</ul>
<p>We're done. Right? RIGHT? Just kidding, we'll prove it, too.</p>
<blockquote>
<p>But let's pause for a second. The powers of two crop up frequently and we'll see again why in a minute. But it is surprisingly simple to describe how we get the result. It's almost like this is an exercise for students from this point onward. Which shouldn't detract from the ingenuity of coming up with this simple idea in the first place. Of course, this also makes the result somewhat unsatisfying -- you just picked some clever subset of \(\mathbb{N}\), looked at the free ultrafilters on it and you're done. Where's the magic? Where do we go from here? It is so elegant, it is too elegant, it does not offer anything to dig into, expand later, create new results from.</p>
</blockquote>
<p>Let's check first that this makes sense.</p>
<ul>
<li>$e + A^\star + e $ can actually generate a group since \(e\) is a minimal idempotent, so \(e+ A^\star +e \subseteq e + \beta \mathbb{N} + e\), the maximal group of \(e\). This is the only (but critical) point where we use minimality.</li>
</ul>
<p>Next, we need to connect to one of the most important structures in this field \[\mathbb{H} := \{ p \in \beta \mathbb{N} : (\forall n) 2^n\mathbb{N} \in p\}.\]</p>
<ul>
<li>\(e+A^\star + e \subseteq \mathbb{H}\) -- this is clear since \(\mathbb{H}\) is a semigroup (a standard result), all idempotent ultrafilters lie in \(\mathbb{H}\) (another standard result) and \(A^\star \subseteq \mathbb{H}\) (ok, at least that is easy to check, \(2^n \in A \cap 2^n\mathbb{N}\) after all).</li>
</ul>
<blockquote>
<p>I cannot stress how much I think this is important. To be able to connect to \(\mathbb{H}\) is a brilliant idea since many, many results rely on using the (in many ways much simpler) structure of \(\mathbb{H}\).</p>
</blockquote>
<ul>
<li>To show that \(e+ A^\star + e\) actually generates a free group, we take finitely many elements, say \((q_i: i&lt;n)\), from \(A^\star\) and show that \((e+q_i+e : i&lt;n)\) generate free group.</li>
</ul>
<p>Here we run into the usual notational difficulty of free groups -- writing different things by the same notation. To avoid confusion with our \(q_i\) but to keep similarity, let's take \((Q_i : i&lt;n)\) to denote generators of an actual free group \(F\).</p>
<ul>
<li>The plan: define a map \(h: \beta \mathbb{N} \rightarrow F\) so that \(e\) maps to the identity and \(e+q_i+e\) maps to \(Q_i\) and somehow this is a homomorphism (at least where it counts).</li>
<li>Unfortunately, this isn't quite possible -- we need to expand \(F\).</li>
<li>But (another standard fact) we can: choose a compact topological group \(F' \supseteq F\). We'll build a map as above into \(F'\)!</li>
</ul>
<p>Ok, let's take a step back. What do we want to do? Map \(e+q_i+e\) to \(Q_i\) by a map on \(\beta \mathbb{N}\). Again, \(\mathbb{H}\) comes to the rescue!</p>
<p>It is often useful to consider \(\mathbb{N}\) as an FS-set, namely \(FS(2^n)\). This is closely connected to \[\mathbb{H} = \{ p: (\forall n) 2^n \mathbb{N} \in p\} = \{ p: (\forall n) FS_{k>n}(2^k) \in p\}.\]</p>
<p>If we think of \(\mathbb{N}\) as \(FS(2^n)\), then it becomes clear how we should start -- especially, if we (standard fact, yet again) are aware of the partial semigroup operation on FS-sets &quot;sums with disjoint support&quot;. Anyway, without further ado:</p>
<ul>
<li>Pick pairwise disjoint \(A_i \in q_i\) partitioning \(A\), i.e., \[ \dot \bigcup_{i &lt; n} A_i = A.\]</li>
<li>Then define a map as follows.</li>
<li>Map \(2^n\) to \(Q_i\) if and only if \(2^n \in A_i\) -- this is well defined.</li>
<li>Extend this map to \(FS(2^n)\) by mapping \(\sum_ {i\in s} 2^i\) to \(\prod_ {i\in s} Q_i\) -- as product in the natural order.</li>
<li>Extend this map continuously to \(\beta \mathbb{N}\).</li>
</ul>
<p>Alright. The extension to finite sums and then to \(\beta \mathbb{N}\) is really totally standard (yes, another standard-fact kind of thing).</p>
<p>But the idea of a disjoint union is so simple and elegant! Why didn't you think of this yourself? (Well, in my case, I was 5 at the time this was published, so I guess I'm somewhat excused).</p>
<ul>
<li>By another standard fact, extensions in this manner are homomorphic when restricted to \(\mathbb{H}\) -- this is a general thing about so-called partial semigroups.</li>
<li>However, then \(h(e)=h(e+e) = h(e)+ h(e)\), so it must be mapped to the identity of \(F'\), i.e., of \(F\).</li>
<li>And it's a homomorphism.</li>
<li>So we're done!!!</li>
</ul>
<p>Well, you say, that was easy.</p>
<p>Ok, maybe you won't say that, but trust me, it is. Take your time and go through it again and ask a question in the comments. All we did was look at the set of powers of 2 and used it to generate our generators. Then we used the connection to \(\mathbb{H}\) to define a homomorphism to the free group in a straight forward fashion. That's two steps, plus arguably a lot of standard knowledge.</p>
<p>Of course, I must admit that I don't fully know how standard that knowledge was in 1984. For one thing, partial semigroups were not yet named as such (that would take another 8 years). I don't know if this was the first occurrence of such partial semigroups extensions from \(2^n\) to \(FS(2^n)\). But for us in the here and now, this powerful and strange theorem should not be considered hard anymore.</p>
<p>Despite my poor talk.</p>
<hr>
<p><span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rft.jtitle=Semigroup+Forum&rft_id=info%3Adoi%2F10.1007%2FBF02573448&rfr_id=info%3Asid%2Fresearchblogging.org&rft.atitle=Free+groups+and+semigroups+in+%CE%B2N&rft.issn=0037-1912&rft.date=1984&rft.volume=30&rft.issue=1&rft.spage=177&rft.epage=193&rft.artnum=http%3A%2F%2Fwww.springerlink.com%2Findex%2F10.1007%2FBF02573448&rft.au=Hindman%2C+N.&rft.au=Pym%2C+J.&rfe_dat=bpr3.included=1;bpr3.tags=Mathematics">Hindman, N., &amp; Pym, J. (1984). Free groups and semigroups in βN <span style="font-style: italic;">Semigroup Forum, 30</span> (1), 177-193 DOI: <a href="http://dx.doi.org/10.1007/BF02573448">10.1007/BF02573448</a></span></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mostly, I'm a terrible speaker]]></title>
        <id>https://www.peterkrautzberger.org/0098/</id>
        <link href="https://www.peterkrautzberger.org/0098/">
        </link>
        <updated>2012-01-24T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>They say, ignorance is bliss.</p>
<p>As I wrote in a comment recently, almost all mathematicians are bad speakers for almost all audiences. It seems to me that most people would agree. But in blissful ignorance, we don't worry about our own shortcomings and continue to give terribly bad talks. We don't know just how bad we are.</p>
<p>Right now, I'm encoding some more talks from the Michigan Logic Seminar. I gave the last couple of talks last term and the first one this term just yesterday, so going through the camcorder and google+ footage, I cannot escape the fact that my own performance is mostly quite miserable.</p>
<iframe src="https://player.vimeo.com/video/35029059" width="100%" height="375" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
<p>I talk too fast, I write to chaotically (not just my handwriting, but my structuring), I fail to favor communication over precision.</p>
<p>But at least now I know. And I can improve. And I do. Because these recordings exist.</p>
<iframe src="https://player.vimeo.com/video/32109926" width="100%" height="375" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
<p>'Tis not a folly to be wise.</p>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>becky</strong>, 2012/01/24<br>
You’re your own worst critic, P! If you think that writing is chaotic, you haven’t seen certain unnamed profs lecture. (Also, you just tricked me into watching [the first 48 minutes of] that talk.)
<ul>
<li><strong>Peter</strong> 2012/01/24<br>
Becky, thank you for your kind words. I apologize for tricking you. I’ll repay in sushi 😉</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Live blogging from #scio12]]></title>
        <id>https://www.peterkrautzberger.org/0097/</id>
        <link href="https://www.peterkrautzberger.org/0097/">
        </link>
        <updated>2012-01-19T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>So, I will attempt to live blog from <a href="https://web.archive.org/web/20110826202353/http://scienceonline2012.com/">Science Online 2012</a>. This means this post will get updated instead of writing many posts.</p>
<h3>Wednesday evening</h3>
<p>Getting to RDU was easy, direct flight, all good. Once there I hooked up with <a href="http://libguides.libraries.claremont.edu/profile.php?uid=9233">Sam Kome</a>, a librarian, who was kind enough to both share a room without ever meeting me -- and had even organized a ride into town.</p>
<p>Since we had an hour or so while waiting for more car sharers to fly in, I got my first impression of what I've only read about: everybody you'll meet at Scio12 will be simply awesome to talk to! And then you only meet more of them...</p>
<p>The rest of the evening was more quiet than for others (just search twitter for #drunksci), since Sam and I both needed to grab a bite to eat which didn't stop us from continuing our discussion of pretty much everything.</p>
<h3>Thurdsay morning</h3>
<p>With not too much sleep, I jumped on the shuttle bus and was immediately welcomed into a conversation about liquor making (you know, your regular scientist conversation at 8:30am) -- way to start the day.</p>
<p>The conference center is really nice, great swag stuff -- very different from the usual, will write more at a later point. But, of utmost importance, there was good coffee! And good food.</p>
<p>And then meeting people just continues -- and of course, you run into these Germans, they are simply everywhere. Now I'm sitting in Mireya Mayor's keynote after very good (because short) opening remarks by the organizers and the NC chancellor. So that's it for now, hoping to write more on how I handle the complicated, far too interesting schedule later.</p>
<h3>Thursday the actual morning sessions</h3>
<p>The morning sessions were simply amazing. First, there was the Defence against the Dark Arts session on cybersecurity which took a number of frequent turns, using the unconference style effectively thanks to fantastic hosts, Liz Neeley and Khadijah M. Britton. Lunch was a continuation of the session with great conversations with Brian Glanz from OpenScience and someone from PLoS Biology whose name I can't remember right now.</p>
<p>After lunch there was the only true to the heart mathematics section hosted by Maria Droujkova from the Math Future network (which is more about educators than researchers). I think I was at least somewhat helpful in this unfortunately very small session and I got to hear about lots of great projects that Maria knows and that have passed me by so far (links and other stuff will have to wait until after Scio12 ends).</p>
<p>And then the little pleasures happen such as walking out into the sun and walking right into the wonderful Tim Skellett (oh that was actually just before the math session, but nevertheless a short but great pleasure).</p>
<p>After some more coffee intake, off I went to the Risky Topics session hosted by the ever absolutely fantastic Scicurious and Kate Clancy. At this point it's worth mentioning that the conference has 60% women and 40% men (roughly); I can't help think that this is one reason why it has such a great atmosphere. The session itself was difficult for me. Mathematical blogs, which are somewhat of my specialty simply do not run into the problem of Risky Topics as scientists do. We don't run into evolution denial, climate change denial or the worrying case where members of the state legislature complain about sexual health studies of the transgender communities simply for fear of all things different.</p>
<p>So I listened and learned and grew in my admiration for these science bloggers, the degree of earnest hard work, the painful honesty and openness to criticism combined with relentless risk taking on behalf of the common good; it is, quite simply, astounding. And all too short.</p>
<p>The final session I attended was about data visualization, a topic I frequently followed, in particular the frequent banter between statistician bloggers and dataviz bloggers. This session was a workshop and I learned a little bit even if there were some technical problems that prevented the second half of it.</p>
<h3>Thursday evening</h3>
<p>Quick quick off to the shuttle bus, to the hotel, freshen up, hop on the bus and off to the reception at the North Carolina Museum of Natural History. There was not enough food, but good beer and a really fascinating museum to wander about. Special thanks to the High Schoolers that presented live reptilia and could even deal (conversationally speaking) with a triple weird person like me -- mathematician, German and from Michigan ;)<br>
Luckily, Cynthia Graber knew someone local who took us to a delicious Pizza place to feed both stomach and soul -- with lots more of good conversation. Which takes us back to the Hotel and the Hotel Bar for a final drink and more conversations with more fantastic people and now it's half past 1 and I really don't know what I'm writing about anymore other than tomorrow I'll be presenting Booles' Rings and <a href="http://mathblogging.org/">Mathblogging.org</a> in two of the Tech Demo sessions. Good night from Raleigh.</p>
<h3>Where was I?</h3>
<p>As you can see, I totally failed on the &quot;live&quot; part of this post. The reasons include sleep-deprivation, information overload and general scio12-awesomeness that was far beyond my n00bish live-blogging skillz. So I will try to quickly summarize what I actually did Friday-Sunday so that I have a base for a more reflecting blogpost later on.</p>
<h3>Friday</h3>
<p>Needless to say that the good coffee and bagel and fruit situation was critical after a reduced sleep cycle. Friday was terrible in the sense that there were too many great sessions in parallel, for example:</p>
<ul>
<li>Blogging Science While Female</li>
<li>Making Book on E-books: How to write a science or medical e-book and publish and sell it online</li>
<li>Scientists and Wikipedia</li>
<li>Teaching Core Competencies in Science: Solving Algebraic and Word Problems</li>
<li>The Next Generation of Bloggers</li>
<li>The Semantic Web Understanding audiences and how to know when you are <em>really</em> reaching out</li>
</ul>
<p>That's <strong>one</strong> session! Even with 75 minutes, you couldn't switch to all of them. That is the horror of scio12-awesomeness.</p>
<p>Alright, anyway, for the first session it was easier, I went to Martin Fenner's and Euan Adies's session on alternative metrics of scholarly activity. It was probably the most fantastic one for me. Not just because I'm a silly little fanboy when it comes to Martin's work, but also because the session presented so many tools, and, above all, the people behind them. And yet, the depressing fact of the conference for me: most of these tools are right now useless for mathematics since we mathematicians are so bad at talking about our own and each others work.</p>
<p>For the second session I chose the Wikipedia session with Greta Munger and Dario Taraborelli. That was really insightful since I've been thinking a lot about writing on wikipedia (and how all researchers should and how we need to find ways to evaluate such activity as research). Again, the session was fantastic, lots of interesting stories, a lot of insights into the internal workings of the wikipedia community and both positive and negative experiences of other researchers. And above all, many great conversations with Dario before and afterwards (even though I'd been blathering about wikipedia and scholars before realizing that he's actually working for the Wikimedia Foundation...).</p>
<blockquote>
<p>I'm already regretting not finding the time to liveblog. I can use the schedul to remember what the sessions were like, but the in-between, the people you suddenly find yourself in conversation with (did I mention that I told the extroverted-mathematicians-your-shoes joke and it was tweeted by somebody and re-tweeted?), the people that just find you and talk to you. All of that was fantastic and the overload is so great that I fear I'll forget almost all of them.</p>
</blockquote>
<p>For the final session of the morning, I went to Danielle Lee's session on broadening the representation of underrepresented populations in online science. This session was full of strong stories and practical advice on how to be an ally. Having just recorded this year's Marjorie Lee Browne Colloquium and having wondered about a new initiative in Canada to increase mathematical skills of first nation Canadians through story telling, I really valued this session.</p>
<p>For lunch, I had planned to get together with Maria Droujkova but the tour started sooner than expected, so instead I had plenty of time to chat with Roland Krause, one of the few Germans at Scio12. Repeating myself, yet another great conversation.</p>
<h3>The Tech Blitzes</h3>
<p>After lunch, it was time for my own contributions. First, I gave a presentation of Booles' Rings. Unfortunately, there hadn't been room for me to present in the demo session &quot;Credit, Identity &amp; Making Science Available&quot;, but the crowd in the &quot;Doing Science!&quot; session was quite kind. I think I totally sucked, to be honest. I mean, I had 15 minutes and I wanted to have space for actual questions, asking people what they think of the ideas behind Booles' Rings, what their best practices are etc. So I think I rushed (nervousness didn't help) and after talking about the state of academic homepages in mathematics, I checked the time -- and had run through a ton of stuff in under 5 minutes... Oh well... In any case, there was only a little bit of tech to be demoed, mostly I showed off Joel's site as an example on how to present your papers the right way as well as Sam's test installation with the ostatus plugin which will soon offer real time interaction with status.net-like microblogging services. As much as I sucked, the crowd was very kind; I got a few questions and a few words of appreciation and encouragement for our work here.</p>
<p>I spend some time in the Credit&amp;Identity session which was nothing short of amazing. VIVO looks great, ALM too, papercritic realizes Tim Gowers' ideas for arxiv+MO and Annotum is (as you all can see) a powerful tool that we need to use more.</p>
<p>Finally, I went to the &quot;Blogs&amp;Science Communication&quot; session to give my demo of <a href="http://mathblogging.org/">mathblogging.org</a>. That was a little odd... When I came in, the demos were already behind schedule. The schedule already seemed strange -- a 15min break before the last 15min session of the entire day (which was mine)? The reason was obviously to control spill-over of the session before -- Huffington Post demoing their new science section. However, the moderation was unfortunately unable to handle the situation. I was ok with it going overtime since there was a lot of discussions (that's what an unconference should do).</p>
<p>But the HuffPo editor used the entire 15min break as part of her presentation and then continued to have private chats for another 5 minutes before I kindly asked her (and others) to take it elsewhere. I really would have liked some support from the moderator... Maybe they could've given HuffPo the last 15minutes + 90minutes to the banquet? I must admit I was mostly sore because it was the HuffPo. If it had been some cool independent project, I'd probably have been super supportive...</p>
<p>In any case, my presentation went much better, I demoed the site, talked a little about the difficulties of supporting a community that doesn't quite exist yet and I also showed off a mock-up of the re-design we've been working on. Again, the feedback was very positive in the session but in particular outside of the session. For example, I later had a short chat with someone from the Library of Congress who was working on digital preservation of blogs and other sources; very interesting discussions (I do keep repeating myself, don't I).</p>
<p>Coming up next: the banquet and evening.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[After the common room, how about the seminar room?]]></title>
        <id>https://www.peterkrautzberger.org/0096/</id>
        <link href="https://www.peterkrautzberger.org/0096/">
        </link>
        <updated>2012-01-11T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>The most impressive community on the (specifically mathematical) intertubes is <a href="http://mathoverflow.net/">MathOverflow</a>. Not only because <a href="http://boolesrings.org/dorais">François</a> is <a href="http://mathoverflow.net/users/2000/francois-g-dorais">one of the moderators</a> and <a href="http://boolesrings.org/hamkins">Joel</a> is the <a href="http://mathoverflow.net/users/1946/joel-david-hamkins">#1 power user</a> or because it has introduced many mathematicians to the unexplored possibilities of using the web for mathematics. No, despite it's many positive influences on mathematics (and despite some negative aspects), MathOverflow's true strength lies in the fact that its users and moderators have <a href="http://math.stackexchange.com/">paved</a> the <a href="http://cstheory.stackexchange.com/">way</a> for a <a href="http://physics.stackexchange.com/">series</a> of <a href="http://stats.stackexchange.com/">similar</a> sites on other topics, both at stackexchange (partly <a href="http://area51.stackexchange.com/categories/7/science">in beta</a>) but also <a href="http://www.or-exchange.com/">independently</a> -- a feat that cannot be overestimated in its long term impact on the way we and other scientists do research on- or off-line.</p>
<h3>The 24/7, online, all encompassing common room</h3>
<p>The way I understand it (and I'm sure François or somebody else will correct me) MathOverflow had a simple question at heart: can we move the departmental common room to the web, create one great common room open to all mathematicians? The goal is to facilitate the same kind of professional exchanges: asking colleagues for references, insights and general advice in our everyday work as mathematicians, researchers, educators -- after all, our toughest problems are often somebody else's easy exercises.</p>
<h3>An interesting project</h3>
<p>Last week, I saw an announcement at <a href="http://ldtopology.wordpress.com/2012/01/03/bar-natan-dancso-paper-comes-with-seminar-and-video/">Low Dimensional Topology</a> that Dror Bar-Natan will host <a href="http://www.math.toronto.edu/drorbn/papers/WKO/">an interesting experiment</a> next term. It's a great idea: take a paper in progress, turn it into a class, add a seminar for the background and combine everything with video recordings.</p>
<p>Last week I also happened to be in Boston where the <a href="http://jointmathematicsmeetings.org/">Joint Mathematics Meetings</a> were held. Even though I was there by chance, there was plenty of time and opportunity to meet people who were attending (such as François and <a href="http://www.felixbreuer.net/">Felix</a>) which gave me an impression of this (for better or worse) enormous conference. This combination made me think whether it isn't time to take another step in taking our scientific community online. After the common room, let's move the seminar room online, making our seminars available to everyone interested!</p>
<h3>Video killed the radio star</h3>
<iframe width="100%" height="390" src="https://www.youtube.com/embed/Iwuy4hHO3YQ" frameborder="0" allowfullscreen=""></iframe>
<p>Here at Michigan, I've been recording all seminar talks last term (most already <a href="http://vimeo.com/pkrautzberger">available online</a>) so as to allow students who could not attend to still catch up as much as possible. Since I've been <a href="http://www.math.fu-berlin.de/w/Math/WhatIsSeminar">doing such recordings</a> on and off for a number of years now, it's become rather easy, giving me ample opportunity to experiment further and broadcast live.</p>
<p>As a highlight I once managed to broadcast <a href="http://www.math.lsa.umich.edu/seminars/SpecLectures/ziwet.html">Hugh Woodin's Ziwet lectures</a> in 2010 (with extremely poor audio), but I also used the experience to connect people to the seminar. As usual, this gets easier with time thanks to the advances in technology.</p>
<h3>Broadcasting a seminar in 5 minutes</h3>
<p>One of the obvious candidates is Skype which, by now, everybody should've used at least once for a collaboration. I've used it once or twice for broadcasting a seminar, but Skype turned out to be too limited -- at most one person can be connected unless you use Windows and pay extra; besides the video quality isn't good enough for reading a blackboard (unless, of course, you pay extra for HD services).</p>
<p>So I turned to services such as <a href="http://www.justin.tv/">Justin.tv</a>. It <a href="https://www.peterkrautzberger.org/0038/">works fine</a> (I used it successfully for the Ziwet lectures). But I always needed a high-quality camcorder to get good results and the whole thing lacks the interactivity of a seminar.</p>
<p>Then a few months ago, Google started its new social network and released an extension of its video chat (horribly called &quot;hangouts&quot;) that offers video conferencing with up to 10 people for free.</p>
<iframe width="100%" height="390" src="https://www.youtube.com/embed/QN38vHZjWXw" frameborder="0" allowfullscreen=""></iframe>
<p>After playing around with it for a while, I got my hands on a $40 HD-webcam (even though there's no HD in g+, the webcam has a much better quality, in particular the audio). Lo and behold, it works reasonably well. Well enough anyway that I felt secure enough to broadcast it all the way to Japan a couple of weeks ago when <a href="http://boolesrings.org/scoskey">Sam</a> was in town and Andrew Brooke-Taylor could enjoy his talk (even though it was 6am in Kobe).</p>
<p>Google seems to continue to experiment with their tool, too, and now there's a beta version you can select upon starting a hangout (&quot;with extras&quot;). This new version adds google docs integration as well as screen sharing. You can write notes collaboratively (even some basic math via their decent equation tool that will accept \alpha etc) and offers a whiteboard. But the screensharing adds a more general way of sharing notes, slides, papers etc (and did I mention a chat and generally the efficient way of switching between speakers? I guess I sound like a fanboy at this point anyway...)</p>
<p>More importantly, the beta hangout can be made public for viewing so that even though only 10 people can participate actively and many more can view it. It's really quite amazing.</p>
<h3>To settheorytalks and beyond!</h3>
<p>Before Booles' Rings, Sam and I had started <a href="http://settheorytalks.wordpress.com/">settheorytalks</a> just after the Young Set Theory Workshop in Bonn last year. By now we have a reasonable amount of regulars that post their announcements efficiently via email with little technical burden on them.</p>
<p>It would be wonderful to extend this idea. The natural candidates are, of course, the departments. If only all departments would offer some kind of syndication that we could aggregate, I'm sure we could set up a decent tool in virtually no time.</p>
<p>Once a decent aggregator is in place, the key would be to get people to take a leap and broadcast their seminars.</p>
<p>So my question to you: would you consider trying this?</p>
<iframe width="100%" height="390" src="https://www.youtube.com/embed/jBDF04fQKtQ" frameborder="0" allowfullscreen=""></iframe>
<hr>
<p><em>Comments</em></p>
<ul>
<li><strong>saf</strong>, 2012/01/12<br>
Personally, I don’t think I will find the time to watch seminar videos, but I would really love to have access to some lecture notes. More specifically, let me propose the following (rather modest) extensions of the beautiful STT (settheorytalks) project :
<ol>
<li>Every announcement of a seminar talk at STT will be followed by a comment with any available talk materials (slides, notes, videos..)</li>
<li>The (full) name of the involved speaker in an announcement would be added as a tag.</li>
<li>Every set theory meeting/special-session/etc would be (a) announced at STT (in an appropriate category), and (b) the post will be updated at one point to contain all available slides from the talks given at that session. Otherwise, a year after a session, we may end up with a dead website such as in the case of the recent Logic Colloquium in Paris:<br>
<a href="http://www.logic2010.org/special_sessions">http://www.logic2010.org/special_sessions</a></li>
</ol>
<ul>
<li><strong>Peter</strong>, 2012/01/12<br>
Saf, I do understand the feeling that it’s not worth your while to watch seminar talks. My gut reaction however is: because most talks suck. Maybe recordings tend to become stale (or disappear). But so do papers. Then again, maybe it will help somebody somewhere (at a small college with no seminar culture) to find a recording much later; it could definitely help a hiring committee to get an actual impression of a candidate, even a series of impressions of a researcher growing as teacher, communicator, collaborator (yes yes, I know, committees are busy evaluating impact factors these days, there’s not time for such nonsense…).<br>
But that is not my main point here anyway. My point is that you don’t ever have to watch a recorded video — you can be at the seminar, anywhere in the world, live, asking questions, interacting, discussing. Then again, we might just have different preferences. I get very little out of written lecture notes, I get a lot of out of direct discussions and interaction. In that sense, I’m arguing for a more diverse form of mathematical communication.<br>
However, I also find conferences to be overrated. The quality of talks is usually abysmal, no matter which level (there was a wonderful suggestion at My Biased Coin for “invited non-speaker” — great idea, says it all really). The reason for the lack of quality seems to be that talks are just presentations, born from a time where you just had to get your results out there instead of communicating them, a time where communication was expensive and time at conferences was a precious resource, for you could not otherwise interact with people in person. A time, where a 20, 15, 10 minutes time slot seemed reasonable (My CS Prof wrote about a CS conference with a session for 5min talks by grad students and postdocs on the market…).<br>
What if there was simply a permanent “conference” in terms of weekly video broadcasts? Oh wait…<br>
What I’m trying to say is that just as in publishing, the restrictions for “conferencing” are rapidly becoming a thing of the past. With a little effort on both sides, you could join any talk (or any other form of meeting) in the world — a webcam and a good internet connection, that’s it. I’m not saying that conferences are going away. I think they should change considerably, I hope they become more like barcamps, unconferences etc — like good seminar meetings really.<br>
Finally, I really like your suggestions for settheorytalks — I would love to have that kind of information there and I admit that I haven’t been good at posting updates about Michigan. But from my experience, it has already been difficult to get people to post (which is done by adding an email address to the usual announcement mail). So, as much as I agree with you that this would be great, this “modest” extension is asking a lot from a lot of people. I’m not sure Sam and I can convince on our own 😉
<ul>
<li><strong>Ben Webster</strong>, 2012/01/13<br>
I can verify that we’ve used a couple of online talk videos in our hiring process. It is indeed helpful to just be able to call up video of the person speaking.
<ul>
<li><strong>Peter</strong>, 2012/01/15<br>
Ben, great to hear that first hand!</li>
</ul>
</li>
<li><strong>saf</strong>, 2012/01/14<br>
Personally, if I would like to learn of recent results, I would prefer to read the slides of a talk, rather than watching a video (or online attending) the talk in which the same slides were delivered. Of course, this does not apply to blackboard talks, or to talks delivered by exceptionally good speakers.<br>
Anyway, different people have different preferences, and as professor Webster confirmed, there are also other values for online talk videos.<br>
Thus, let us work in parallel: I’ll work on extending STT, and you’ll explore the most recent video possibilities.
<ul>
<li><strong>Peter</strong>, 2012/01/15<br>
Ah! Another misunderstanding. I only ever think of real seminar meetings, i.e., chalkboard talks with actual conversation — not aseptic presentations or reading-my-lecture-notes-out-loud lectures; seminar in the original sense.<br>
In my experience almost all mathematicians are bad speakers for almost all audiences — and we definitely do not receive any training. But I have yet to meet a mathematician who isn’t good at answering questions they know the answers to.<br>
I’m also not just talking about recent results. Or rather, not recent results of the speaker. I think we’re underestimating the waste in mathematics; people read papers all the time, but share their insights into new results only in extremely small circles if at all. Recording those (in any which way) would help very much — and deserves more recognition.<br>
But otherwise — yes! Let’s work in parallel. I think more notes, immediately online, would be a blessing. And wordpress makes it very easy to put notes online after all…
<ul>
<li>
<p><strong>Micheal Pawliuk</strong>, 2012/01/15</p>
<blockquote>
<p>“In my experience almost all mathematicians are bad speakers for almost all audiences — and we definitely do not receive any training. But I have yet to meet a mathematician who isn’t good at answering questions they know the answers to.”</p>
</blockquote>
<p>+1. I think that often the speaker’s goal is to produce an air-tight proof of result X. For the most part this seems doomed from the start. The speaker lays down 10 or so new definitions then proves some technical lemmas then glues them together. This seems utterly impossible to follow. There is just too much information and intuition missing. Speakers often forget that they have been thinking about a concept for more than the 30 minutes that the audience has.<br>
That being said, I’m attending seminars as a graduate student so maybe I am not the target audience. :)</p>
</li>
<li>
<p><strong>Peter</strong>, 2012/01/16<br>
I think you’re spot on. But there’s always two sides. I have experimented with something I picked up from Eric Mazur’s peer instruction method: sending my material to the seminar ahead of time. I had hoped to have a conversation rather than a presentation. But people didn’t find the time to read anything, so it didn’t really work.<br>
In general, I think we need to get to a level where seminars are about exchanges. Somebody once wrote that in the near future, the smartest person in room will be the room, i.e., the collective. At the same time there won’t be a “most knowledgeable person” either since encyclopedic knowledge is most easily outsourced (as it is already today for a lot of content thanks to wikipedia). Instead, the gain will be in connecting the intelligence of people in a different way. This appeals to me, if only for its democratic nature.</p>
</li>
<li>
<p><strong>saf</strong>, 2012/01/18<br>
Sam has just added me as an STT contributor. I’ve already added tag names for speakers, and resurrected the “conference” category: <a href="http://settheory.mathtalks.org/category/conferences/feed/">http://settheorytalks.wordpress.com/category/conferences/feed/</a></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>Micheal Pawliuk</strong>, 2012/01/15<br>
Great post Peter! I’ve been thinking about these types of collaboration issues lately. Here are two articles to think about:<br>
<a href="http://nathanson.files.wordpress.com/2010/06/indivcollab1.pdf">Why individuals will be the ones to make big mathematical discoveries</a>. An argument against Gower’s “Polymath” project.<br>
<a href="http://www.ams.org/notices/201009/rtx100901132p.pdf">Why collaboration is good</a> and how graduate students can become more collaborative.
<ul>
<li><strong>Peter</strong>, 2012/01/16<br>
Thanks for the links. I can’t follow Nathanson’s arguments against Polymath. On the one hand, it seems likely that we’ll see a surge of problems that require a distributed approach — just like other scientific areas. On the other, we haven’t even tried to study what does and what doesn’t work with respect to massive collaborations. The criticism sounds a lot like arguing that the first mechanical computers couldn’t really calculate faster than humans or that early chess programs couldn’t beat amateurs. We’re only at the beginning.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Representing Booles' Rings at Science Online 2012]]></title>
        <id>https://www.peterkrautzberger.org/0095/</id>
        <link href="https://www.peterkrautzberger.org/0095/">
        </link>
        <updated>2011-12-26T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>At the end of January, I'll be at <a href="https://web.archive.org/web/20110826202353/http://scienceonline2012.com/">Scio12</a>! Science Online is that super awesomesauce (un)conference where all the hipster science bloggers hang out -- and also those fantastic little companies working on the future of doing science on <em>teh internetz (tm)</em>.</p>
<p>As a science-blog lurker, I read the blogging coverage of <a href="https://web.archive.org/web/20111202083218/http://scio11.wikispaces.com/">Scio11</a>, getting not just a little jealous. It seemed to attract a great crowd and a very positive atmosphere. This year, I finally &quot;applied&quot;, not only attending but actually representing two projects I'm involved in -- <a href="http://boolesrings.org/">Booles' Rings</a> and <a href="http://www.mathblogging.org/">Mathblogging.org</a>. I almost missed the opportunity because I hadn't been reading as many science blogs as I used to, instead reading more and more mathematical blogs for our <a href="http://mathblogging.org/">Mathblogging.org</a> Weekly Picks.</p>
<p>Speaking of which, only thanks to <a href="http://mathblogging.org/">Mathblogging.org</a> did <a href="http://math-frolic.blogspot.com/2011/10/math-at-science-online-2012.html">I read about</a> their shortage of math related topics in time to contact one of the godfathers of scienceblogging, <a href="http://coturnix.org/">Bora Zivkovic</a>. The wonderful Maria Droujkova from the <a href="http://mathfuture.wikispaces.com/">Math Future group</a> will be there, too, but <a href="https://web.archive.org/web/20111214180652/http://scio12.wikispaces.com/Program+draft">that's about it</a>. It's a bit of a shame; I know the name does not imply it, but I really would have liked to have seen <a href="http://www.mathoverflow.net/">MathOverflow</a> represented since that's a math related net-thing way ahead of the scientists for a change. Oh well, next year.</p>
<p>Now Science Online is an <a href="http://en.wikipedia.org/wiki/Unconference">unconference</a> -- no talks in the traditional sense, but a focus on discussions (which, incidentally, would seem a very sensible approach to mathematics conferences really). I'm giving two tech demos, one for each project. Those will be very short (I'm designing for 5 minutes given my tendency to babble) and hopefully I'll be able to make enough sense for people to ask questions and offer their opinions.</p>
<p>Now that the year is coming to an end, I'm getting more and more excited -- I'm thinking about the demos in earnest and there are all those little things Sam and I want to fix before Scio12...</p>
<p>I'll keep you updated here and I hope I can count on your feedback if I get around to preparing something I can put up here (lots of ifs there...). Of course, I'll have my first attempt at tweeting a conference -- we'll see how that goes ;)</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hanging out with Sam]]></title>
        <id>https://www.peterkrautzberger.org/0094/</id>
        <link href="https://www.peterkrautzberger.org/0094/">
        </link>
        <updated>2011-12-21T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><a href="http://boolesrings.org/scoskey/hangout-subgroups-of-z/">Sam already wrote</a> about the g+hangout that he hosted last Saturday and I wanted to jot down some of my own thoughts on the experience. I thoroughly enjoyed the whole thing and I've been looking for good imagery to describe it. I only came up with two, but maybe you can help me with that in the comments.</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Reinhold_Messner">Reinhold Messner</a> going on an small hike with a group of amateur friends.</li>
<li>A good <a href="http://en.wikipedia.org/wiki/Go_(game)">go player</a> playing a high-handicap game against a weaker opponent.</li>
</ul>
<p>It is always a pleasure to join people to think about a problem, but I was surprised how much fun it was when I already knew I could solve the problem. This probably had something to do with the fact that I hadn't thought about this particular topic since essentially my <em>Vordiplom</em> (after 2 years at university). This brings me to my first image. Just like a professional mountaineer on an amateur-level hike, I knew I wouldn't have to worry about being dangerously out of my depth (though I stumbled myself one or two times). However, this didn't make me enjoy doing mathematics with the others any less than Messner would enjoy any hike in good company, being challenged every once in a while and taking in the majestic nature surrounding us.</p>
<p>Equally intriguing was the interaction with the other participants. A Go player will play a high handicap game against a weaker opponent not because she wants to show off her strength, but because it levels the playing field and makes it enjoyable for both sides. Sam did a wonderful job at facilitating the exploration as well as the condensation of ideas, much like placing handicap stones at just the right level. That way, all parties involved could enjoy the artistic process that is doing mathematics.</p>
<h3>Coda</h3>
<p>I would suggest this idea to anyone -- join such an interaction, at least once in a while! It is also yet another great example of how the internet allows us to connect to people and activities that might not be as readily available locally. Finally, it's another example of the great potential the net offers for researchers to engage with a community of people that have dabbled in mathematics at some point in their lives but now have few chances to interact with math, let alone professional mathematicians. We can help people to keep their interest in mathematics alive and kicking while having fun ourselves -- if that's not worth it, I don't know what is.</p>
<hr>
<p><em>Comments</em>.</p>
<ul>
<li><strong>sam</strong>, 2011/12/22<br>
Glad you enjoyed it! For me the joy is not that you know you can solve the problem, but rather that you know you will solve some problem. It’s a little better if you’re not sure what the outcome will be exactly.
<ul>
<li><strong>Becky!</strong>, 2011/12/24<br>
Please tell me at least one moustache was involved.
<ul>
<li><strong>Peter</strong>, 2011/12/24<br>
Hehe… no, unfortunately no moustaches (or the current reindeer thing).</li>
</ul>
</li>
</ul>
</li>
<li><strong>Micheal Pawliuk</strong>, 2012/01/10<br>
I totally agree with you Peter; group problem solving is very satisfying. Your comments kind of remind me of the paradox of expertise: “The more you know about a subject area the harder it is for you to explain the basics”. So with that in mind the type of problems you and Sam were working on might actually be a challenging exercise.<br>
(Also, your link to Sam’s writeup is broken.)
<ul>
<li><strong>Peter</strong>, 2012/01/10<br>
Thanks, Mike. I fixed the link.<br>
As much as I agree that most specialists are unable to explain the basics of their field, I think this is not a sign of expertise but lack thereof. It’s much like playing the piano; if you cannot play a piece slowly then you cannot really play it (even though playing faster will hide your errors from most listeners).<br>
It was more like being a taxi driver visiting an unfamiliar city.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The recent publishing debate -- the IMU's blog continues]]></title>
        <id>https://www.peterkrautzberger.org/0093/</id>
        <link href="https://www.peterkrautzberger.org/0093/">
        </link>
        <updated>2011-12-16T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>My <a href="https://www.peterkrautzberger.org/0092/">last post</a> has seen quite a lot of visitors (my stats look miserable now that there was such a spike...). But hardly anybody left a comment (thanks to those who did -- much appreciated!). Did people find it irrelevant, not worth commenting on? Or did everybody just nod and pass on? I'm confused... (and yes, it's either or).</p>
<p>Anyway, in case you didn't see it: the IMU's &quot;Blog On Journals&quot; is continuing with its <a href="http://blog.mathunion.org/journals/?no_cache=1&amp;tx_t3blog_pi1%5BblogList%5D%5BshowUid%5D=24&amp;tx_t3blog_pi1%5BblogList%5D%5Byear%5D=2011&amp;tx_t3blog_pi1%5BblogList%5D%5Bmonth%5D=12&amp;tx_t3blog_pi1%5BblogList%5D%5Bday%5D=14&amp;cHash=4cc259744b2132a1a30cbb0cf1188028">third post, by Peter Olver</a> &quot;Beyond Journals&quot;. The post is a bit odd, no links, not even to <a href="http://www.ams.org/notices/201108/rtx110801124p.pdf">his piece</a> in the Notices, which is odd since this post is more like a teaser for that piece (or else I didn't get the point -- perfectly possible).</p>
<p>In any case, I did get all excited -- they are serious about this &quot;BLOG&quot; thing! Not that I was too surprised. I actually received an email from a moderator for my own comment and I also had a nice exchange with another moderator, <a href="http://www.vimeo.com/33615260">Nalini Joshi</a>!, on google+ (unfortunately John Baez didn't post this publicly -- thanks to David Roberts for re-sharing it), describing some of the organisational and technical difficulties of the IMU blog. In other words, I have the impression that at least some of the people involved are taking this very seriously and are aware that there is a community on the web that could be built upon.</p>
<p>And then I started to write another long comment on Olver's post, titled &quot;Not Beyond Journals, Beyond Papers!&quot; (guess where it led me), and then I refrained from posting the comment on their blog and then I thought I should post it here and then I went back to leave a short comment but didn't because it felt like off-topic trolling. And then I realized that I'm doing the same thing I did last time. So what's the point??</p>
<hr>
<p>There is so much to say! I think there are so many issues surrounding this debate that will change our community forever. We could come out of it fixing the causes (not just the symptoms) of some serious issues, we could also end up making decisions that will lead to the rapid decline of our community.</p>
<p>I'd love to discuss this more here, but it is a lot of work. My thoughts are still unrefined, in need of discussion. It would make it much easier with a bit of feedback. You know... what's it called again? ... ah yes, now I remember, <em>peer review</em>.</p>
<hr>
<p><em>Comments</em>.</p>
<ul>
<li><strong>Ben Webster</strong>, 2011/12/17<br>
It’s hard to comment (at least for me) because the subject is so overwhelming. Breaking the power of publishers over mathematics journals is a project I can wrap my head around: progress is slow, but we’re moving in the right direction, and I can think of concrete steps to take.<br>
But ending the tyranny of the paper…I sympathize with the arguments, but it’s very difficult to imagine the transition. It’s going to involve a lot of unpleasant fighting with deans.
<ul>
<li>
<p><strong>Peter</strong>, 2011/12/19<br>
Ben — thank you very much for your comment. I understand your reservations.<br>
The “problem” is that, I think, there is no problem when it comes to journals if we stay with papers only. Journals work fine for papers — there’s little reason to change, I think, certainly not enough reason to bring about significant change as is discussed elsewhere; maybe open access will happen, but then again we already have massive open access through the arXiv.<br>
I do admit that I’m blissfully unaware of the problem of fighting with deans. Inexperienced that I am (especially in the American system), I think if the mathematical community accepts other activities as research (such as the case of Wikipedia-activity getting a humanities prof tenure), then the deans cannot really argue — if any reviewer will tell the dean that you have done superawesomesauce research activity then you have done superawesomesauce research activity. (I mean, what has a higher “impact factor” then wikipedia anyway).<br>
But I’m not idiotic (I hope), which is why I wrote that the professional societies, i.e., the organised part of our community, the political arm of our community, must invest in research on how to evaluate such activities, must define best practice, must join with the other sciences in developing data-analysis tools for messy content like mathoverflow-, wikipedia-, blog-activity. Incidentally, we are thinking about new features for mathblogging.<br>
I promise to write more on why I think “Beyond papers” is the way to go and how easy it is to justify such a change. Maybe I can convince you — I mean, if I can’t even convince you… gee… that’d be a bummer.</p>
</li>
<li>
<p><strong>Ben Webster</strong>, 2011/12/19<br>
Right, I don’t want to be too Eeyore about this; deans are for the most part reasonable people (ours was just telling us last week to do more innovative stuff online). I think maybe a bigger danger than actual deans is the “dean in our head” just as the most common kind of censorship is self-censorship; whether any particular dean will accept that we were writing on MathOverflow rather than writing papers or not, we all fear the worst case scenario where they will not. So I think those of us who don’t have tenure end up in the cycle where we say “Yeesh, I don’t have time to imagine going beyond papers…I have papers to write!” Speaking of which…</p>
</li>
<li>
<p><strong>Ben Webster</strong>, 2011/12/20</p>
<blockquote>
<p>I think if the mathematical community accepts other activities as research, then the deans cannot really argue.</p>
</blockquote>
<p>This is also a really dangerous way of looking at things. The people who hold the purse strings don’t have to listen to you, let alone accept what you say at face value, nor are they likely to suffer much in the way of negative consequences if they don’t. Look at what’s happening in Britain or Canada.<br>
Now, most people in funding agency and university administration really do mean well and want to see good research done; I don’t think their existence means we can’t move beyond papers. It just means we have to keep a careful eye on how to show that we really are doing good research as we move beyond them.</p>
<ul>
<li><strong>Ben Webster</strong>, 2011/12/20<br>
Damn it. Screwed up the italics in the comment above, and apparently I can’t go back and edit it.
<ul>
<li><strong>Peter</strong>, 2011/12/21<br>
I took the liberty of fixing that.</li>
</ul>
</li>
<li><strong>Peter</strong>, 2011/12/21<br>
I’ve been following that development (cf. <a href="https://web.archive.org/web/20120101215413/http://www.mathblogging.org/weekly-picks">http://www.mathblogging.org/weekly-picks [Wayback Machine]</a>). You’re absolutely right that we need to convince the funding agencies — and the deans! All I’m saying is that first we need to convince the community.<br>
It is shocking what is happening — especially on the scale (country, not university — whatever happened to that Dutch pure mathematics department they were shutting down?). I’m a burned child in this respect — doing my PhD in Berlin where the strong logic community has been destroyed completely within 10 years because the tenured people were incapable to engage in the politics.<br>
I would argue (in a draft on this very server…) that the situation in the UK and Canada is a failure of the leadership of our community (or communities, then again, have you heard about <a href="http://sites.williams.edu/Morgan/2011/09/22/nsf-division-of-mathematical-and-statistical-sciences/">the proposed name change at the NSF</a>?).<br>
But this only strengthens my conviction. You might argue that someone engaging in academic politics is not doing research, but you shouldn’t be able to argue that they don’t help getting research done. Again we need to value other ‘research activities’ than we currently do — and we need to support the people that are good at those activities even if it means they are not quite as good as other people at producing the kind of papers we’re valuing right now.</li>
</ul>
</li>
</ul>
</li>
<li><strong>François</strong>, 2011/12/19<br>
I do think there is a problem: just like “publishing” no longer implies “print media,” the term “academic publishing” no longer implies “academic paper.” I think Ben is right on when he blames the “dean in our head.” The reason why there is basically only one accepted academic medium is some form of self-censorship. Progress is much slower in the Ivory Tower than anywhere else. Academic papers were already great progress over what was before, and they have already evolved to overcome problems of the (now distant) past. You are right, though, that the next step in academic publishing will probably need a new Gutenberg…<br>
As for journals, I think we have reached a critical point. The fundamental reason is probably the huge gap between progress in academia and progress in the publishing industry. The latter have been developing a lot of very successful models for publishing. Although we are a rather small target, they apply these models to us too. These models are usually blind to our particular needs since they weren’t designed to do that at all. Can you think of a non-academic reason why free access to information is that important? Maybe you can, but I can’t and neither can the publishing industry…<br>
PS: Your first and last paragraphs reminded me of<br>
<a href="http://www.smbc-comics.com/index.php?db=comics&amp;id=2461">this comic</a>.
<ul>
<li><strong>François</strong>, 2011/12/19<br>
(Read “antepenultimate paragraph” instead of “last paragraph.” The horizontal line messed up my count.)</li>
<li><strong>Peter</strong>, 2011/12/21<br>
François, thanks for the comment!<br>
I think there is progress elsewhere. The life sciences have a few acceptable non-paper research activities, e.g., gene database curation. There is also a discussion regarding data curation in general, which is also present in applied mathematics (Igor Carron writes about it frequently at Nuit Blanche). So I think this discussion is beginning.<br>
I also think that when it comes to “other research activities”, we might not be as different from the sciences and the humanities as we might think (exposition comes to mind). Certainly, the scientists (at least the bloggers among them) are just as unhappy about the publishing system as mathematicians are so we could join forces.<br>
Regarding the publishing industry. Besides the commercial publishers there are the academic publishers. I remember hearing from Oxford University Press something along the lines of “we survived the invention of the printing press, we’ll survive the invention of the internet” — that’s what we should talk about (because, let’s be honest, we profit from this system — abusing publishing as cash cows for our professional societies).<br>
Will it mean that some publishers will make significantly less money? Maybe. But I’m certain that there will be other ways to make money (just like open source does not mean you can’t make money).<br>
PS: SMBC is always awesome. I should have added that I felt my beyond-papers comment was so far off-topic that it felt like trolling.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The recent publishing debate -- The economic power of publishers]]></title>
        <id>https://www.peterkrautzberger.org/0092/</id>
        <link href="https://www.peterkrautzberger.org/0092/">
        </link>
        <updated>2011-12-12T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>I have been trying to find the time to continue <a href="https://www.peterkrautzberger.org/0090/">my</a> <a href="https://www.peterkrautzberger.org/0091/">posts</a> on the publishing debate, discussing the other posts from the original timeline. Suffice it to say, I've not yet given up getting around to it... But there were two posts in the last couple of days that made me want to write something.</p>
</blockquote>
<p>If you follow me on <a href="http://twitter.com/pkrautz">twitter</a>, you might have seen my remarks on the IMU's strange attempt at entering the blogosphere. A couple of weeks ago, they started a <a href="http://blog.mathunion.org/journals/?no_cache=1">Blog on Mathematical Journals</a>. It's not a blog about writing, but about commenting. The first post (which, horror horribilis, was named <a href="http://blog.mathunion.org/journals/?no_cache=1&amp;tx_t3blog_pi1%5BblogList%5D%5BshowUid%5D=13&amp;tx_t3blog_pi1%5BblogList%5D%5Byear%5D=2011&amp;tx_t3blog_pi1%5BblogList%5D%5Bmonth%5D=11&amp;tx_t3blog_pi1%5BblogList%5D%5Bday%5D=18&amp;cHash=70d9d8e130f02e026e83e8797eddcde2">BLOG on Mathematical Journals</a>) was aimed at getting comments on the IMU's development of a journal ranking to battle the dominance of impact factors. I was under the impression it's not really working out -- 28 comments in three weeks from the mathematical community of the entire world(!) just seems a little unimpressive. Then again, the only way I heard from it was via the EMS news blog (of course through <a href="http://mathblogging.org/">mathblogging.org</a>), go figure.</p>
<p>But this week, the IMU surprised me with a <a href="http://blog.mathunion.org/journals/?no_cache=1&amp;tx_t3blog_pi1%5BblogList%5D%5BshowUid%5D=17&amp;tx_t3blog_pi1%5BblogList%5D%5Byear%5D=2011&amp;tx_t3blog_pi1%5BblogList%5D%5Bmonth%5D=12&amp;tx_t3blog_pi1%5BblogList%5D%5Bday%5D=07&amp;cHash=bb9177d8192db5b5756aca088ea79677">follow up post</a>, which, as promised, was possible for the discussion of specific related topics. It is titled &quot;What might be done about high prices of journals?&quot;.</p>
<p>I starting writing a comment over there, but for several reasons decided not to post it. But this is a topic that is related to what I see to be at the center of the publishing debate so I parked it in the ongoing draft here. So here it is:</p>
<blockquote>
<p>It seems to me that the pricing issue cannot be solved as long hiring decisions are almost exclusively based on the publication track record in traditional journals (and even worse on the metrics of those journals).</p>
<p>In other words, when it comes down to it, we only value researchers by the metrics of the traditional journals they've published in. This gives the publishers incredible power over the development of our community and there's no conceivable reason why for-profit publishers wouldn't use this power to maximize their profits.</p>
<p>I think the mathematical community needs to spend time and money on finding ways to evaluate other activities of researchers.</p>
<p>For example, wikipedia has de facto a peer review system, especially the &quot;Good Articles&quot;. It's not as easy to evaluate a wikipedia author, but an active author offers a lot of activity to evaluate them by and there is <a href="http://blog.wikimedia.org/2011/04/06/tenure-awarded-based-in-part-on-wikipedia-contributions/">precedent for considering this a research activity</a>.</p>
<p>Similarly for MathOverflow and other research-level Q&amp;A sites. The so-called reputation points are a poor metric per se, but they nevertheless indicate an activity that is worth evaluating, i.e., a high &quot;reputation&quot; indicates at the very least a high activity, an amount of data that could be used to evaluate a researcher.</p>
<p>The best thing about these new platforms of academic activity is: we can get started right away! On the one hand, mathematicians can (and should) invest time in making their efforts outside of traditional journal publishing more apparent, in particular on their professional homepage. On the other hand, the professional societies should start taking the web serious, support and invest in new ways of doing research online and, above all, investigate the development of standards for evaluating such activities.</p>
</blockquote>
<p>So why am I writing this now? Well, Noam Nisan <a href="https://plus.google.com/u/0/115326791063817065868/posts/LPcfboGHSPn">mentioned</a> <a href="http://socialmediacollective.org/2011/12/11/scholarly-publishing/">a powerful rant by Danah Boyd</a> with many interesting comments (if only because people there aren't shocked that (social) media activity might be worthwhile for researchers).</p>
<p>So I just left a comment at <a href="https://plus.google.com/u/0/115326791063817065868/posts/LPcfboGHSPn">Noam Nisan's g+ post</a> (repeating some of the above).</p>
<blockquote>
<p>I very much agree with your comment there &quot;... but the current system will stay unless we develop an alternative to this grading, an alternative to which there is an incremental transition path&quot;</p>
<p>However, many alternatives already exist, I think -- from MathOverflow to Wikipedia to blogging to video lectures.</p>
<p>What seems to be missing is</p>
<p>a) ourselves considering our own non-standard research activities as research activities (e.g. <a href="http://blog.wikimedia.org/2011/04/06/tenure-awarded-based-in-part-on-wikipedia-contributions/">http://blog.wikimedia.org/2011/04/06/tenure-awarded-based-in-part-on-wikipedia-contributions/</a> )</p>
<p>b) tools to analyze the data generated by non-standard activities (e.g. MO reputation points is a poor metric, but the actual questions and answers of a user are an incredibly rich source)</p>
<p>I also think that we should try not to replace the monoculture of journal publications with a different monoculture (say MO or Gowers's arxivMO-idea) -- it's too easy to game one system.</p>
<p>Instead, valuing many activities will allow people to find more activities they excel in without the pressure to excel in all of them.</p>
</blockquote>
<p>Any thoughts on this?</p>
<hr>
<p>Addendum Dec22: <a href="https://plus.google.com/u/0/103404025783539237119/posts/LzYYrHKVzsd">John Baez</a> encouraged me to post my comments on the IMU's blog after all (and I saw this morning that he also <a href="http://golem.ph.utexas.edu/category/2011/12/what_might_be_done_about_high.html">encouraged the n-Category Cafe</a> crowd). I extended it a bit due to the comments already visible. But it's not yet through the moderation process... So, here it is:</p>
<blockquote>
<p>It seems to me that the pricing issue cannot be solved as long hiring decisions are almost exclusively based on the publication track record in traditional journals (and, even worse, on the metrics of those journals).</p>
<p>In other words, when it comes down to it, we only value researchers by the metrics of the traditional journals they’ve published in. This gives the publishers incredible power over the development of our community and there’s no conceivable reason why for-profit publishers wouldn’t use this power to maximize their profits.</p>
<p>The pressure to publish is immense and getting published has turned into a game rather than an effort of communication -- with many adverse effects to a functioning community.</p>
<p>None of the comments so far have addressed the issue that the monoculture of &quot;publishing papers&quot; is limiting the way a scientific community can develop. Journals used to be a necessary evil to enable a minimal degree of communication within a community that is spread around the globe. But now the community is fully connected, in real time, and there is no difficulty to stay in touch with any researcher as long as they use the internet to some degree. In turn, we can now communicate every detail of our academic work effortlessly; not just individual papers, but refereeing, student interaction, Q&amp;A's, video lectures, expository writing, research exchanges, live-broadcasting talks and seminars etc</p>
<p>I think the key problem is that we need to find ways reduce the pressure to publish the traditional way. The only way this is possible is if we find a way to publish less.</p>
<p>Therefore we need to spend time (and money) on finding ways to evaluate other activities of researchers.</p>
<p>For example, wikipedia has de facto a peer review system, especially the “Good Articles”. It’s not as easy to evaluate a wikipedia author, but an active author offers a lot of activity to evaluate them by and there is <a href="http://blog.wikimedia.org/2011/04/06/tenure-awarded-based-in-part-on-wikipedia-contributions/">precedent</a> for considering this a research activity.</p>
<p>Similarly for MathOverflow and other research-level Q&amp;A sites: The so-called reputation points are a poor metric per se, but they nevertheless indicate an activity that is worth evaluating, i.e., a high “reputation” indicates at the very least a high activity, an amount of data that could be used to evaluate a researcher.</p>
<p>Fortunately, these new platforms of academic activity allow us to get started right away.</p>
<p>the one hand, mathematicians can (and should) invest time in making their efforts outside of traditional journal publishing more visible, in particular on their professional homepage and their CVs (in the research section, that is!)</p>
<p>On the other hand, the professional societies should start taking the activity of mathematicians on the web seriously. They could support and invest in new ways of doing research online and, above all, investigate the development of standards for evaluating such activities.</p>
<p>===<br>
I thank John Baez for encouraging me to make this comment.</p>
</blockquote>
<hr>
<p><em>Comments</em>.</p>
<ul>
<li><strong>Igor Carron</strong>, 2011/12/12<blockquote>“…. it’s too easy to game one system…”</blockquote>
the question is really what kind of point system can be put in place in order to avoid most gaming.
* **sam**, 2011/12/12
  I agree with Peter: it is probably a theorem that any point system can be gamed. Even in sports, where betting is a big motivation to be fair, there are still a lot of problems. Think about the BCS.
  * **François**, 2011/12/12
    That theorem would be Arrow’s Theorem. The theorem boils down to the fact that ultrafilters on finite sets are always principal, so the only system that can’t be gamed would be the one where the Monarch of Mathematics decides everything.
</li>
<li><strong>Peter</strong>, 2011/12/12<br>
Igor, for me the “can’t be gamed” is a more of a positive side-effect. The main thing is: we really need to value more than journal papers.<br>
I understand that historically, journals allowed for a minimal amount of communication between researchers in a time when actual communication was not feasible. But this has changed now — with very little effort can we now contact any researcher anywhere anytime, in real time, live, with video, with online whiteboards, in public via broadcasts or one-on-one.<br>
This finally allows us to communicate our entire research activites — results as well as reviews, refereeing, Q&amp;A’s, student interactions, mailing list activities, wikipedia activity, video lectures, code examples, expository notes, research exchanges — everything.<br>
Your amazing efforts at Nuit Blanche are the perfect example that it is possible to present an entire research area, always up to date, always dynamic, always changing. It’s an amazing work — yet it is not valued less than a single paper in a glamour mag.<br>
I think we need to move beyond from the minimalistic monoculture that is the journal system. Papers can be great and their will always be an important place for them.<br>
But we need to develop tools to actually evaluate the content people create outside of journals. I remember the amazing TED talk you linked to on Nuit Blanche — what they do for TV and twitter could mean a lot for research communication on social networks.
<ul>
<li><strong>Igor Carron</strong>, 2011/12/12<br>
Peter,<br>
I absolutely agree that as soon as we have more discussions taking place electronically, we will be able to develop more tools that can provide a more accurate image of the contribution to some areas of research.<br>
I am really convinced that focusing on the peer review process is the way to unleash these conversations, hence the need to figure out how a Q&amp;A could be construed as least gamable as possible, even though I agree, all processes can be gamed eventually.
<ul>
<li><strong>Peter</strong>, 2011/12/12<br>
Hm… I think we do disagree on something. I’m not sure.<br>
Something to clarify: it’s clear that research succeeds only if peers look carefully at each others work. So all ideas that I spew out are always under the assumption that feedback from peers is involved (peer review has the unfortunate connotation of “peer-reviewed journals” which limits the scope of peer review).<br>
That being said: I think we need to have many, many more ways that the community will officially consider research activities.<br>
A Q&amp;A-site of any kind has its dangers — The Accidental Mathematician wrote about it. (As you know I don’t like the idea of a centralized site, I favor independence + aggregation but I’ll actively support any project.)<br>
As an example, here’s my personal problem with MathOverflow: there are too many(!) top researchers in my field active on MO — I never get to a question before they do! It makes it near impossible to get any reputation points myself and, much worse, to experience the incredibly positive exchanges happening on MO.<br>
Another example: we should start valuing peer review! The referee’s side that is. And teaching. And exposition. And history. And work with students. And Q&amp;A sites.<br>
It used to be that we couldn’t communicate and aggregate information on these activities very well. So we only had journals.<br>
But now we’re still only valuing papers even though we could value much more — and I think it is bad for the development of our community that only people that can play the journal-game, i.e., can produce enough good-looking papers in a short amount of time, are able to get jobs.<br>
Is it impossible that we are loosing excellent researchers because they cannot (or refuse to) play the journal game at the pace that is expected of them but who excel at other activities that help maintain a functioning research community?<br>
Then again, the way the funding development is going in the UK and Canada, there might just not be any pure mathematics left in a generation or two — that will allow for a fresh start eventually…<br>
—<br>
Ok, I got a little carried away here. I agree with you: peer-to-peer interaction should be the focus. Peer review of papers and preprints would be a substantial first step.<br>
So we should write more about our own papers on blog-like websites — and we should seek out the opportunity to comment on other people’s sites. I don’t think we need a new platform for that.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Santo D'Agostino</strong>, 2011/12/12<br>
I agree with you wholeheartedly, Peter. For the health of the community, we need to value other activities beyond the narrow few that are now recognized. And teaching, and activities that support good teaching, ought to be included in a way that is beyond just lip service. (At the university at which I last taught, there are a number of superb teachers who will never be promoted to full professor because their research record is not up to the level judged appropriate, forget about what else they have done for students and the rest of the university community.)<br>
Part of the problem is that everyone is busy nowadays, and we judge by what can be measured easily. We count publications, weighting them by which journals they appear in, rather than assess the overall quality of research, because it’s easier to do, and we can thereby avoid arguments. We foist the same injustices on students, for the same reasons, grading them because it’s easy to do, even though a single number is a ridiculous assessment.<br>
Another argument that a number of peole have made is that citizens have already paid for research via their taxes, and so it’s not right that they are made to pay again for aceess to the published results.
<ul>
<li><strong>Peter</strong>, 2011/12/12<br>
Thank you for comment, Santo. I absolutely agree that we’re not valuing teaching enough. This is very damaging in the long term for our research community — how can we expect talented students to become interested in mathematics when we wait until graduate level to show them actual mathematics? It might be that mathematics used to have a singular intellectual attraction among all scientific fields — I think this is not the case anymore, other fields offer a similar level of complexity and beauty. Therefore, we need to actively seek out the most talented students. Initiatives regarding women and minorities in mathematics have shown that we’re missing out on very talented people by ignoring those that do not show the kind of interest in mathematics we’re used to seeing.<br>
Of course, an even bigger problem with not appreciating good teachers and their methods is the effect it has on students that are supposed to have mastered some mathematical skill to pursue other careers — here, the lack of appreciation of good teachers is effecting our societies as a whole and, most dramatically, the students who suffer through our curricula.<br>
You are right to point out that everybody is busy and that any change will take a huge effort, both in work and money. I do think that this is connected to the publish-or-perish pressure — if nothing else counts, I understand that people ignore everything else. But I think we can start nonetheless.<br>
On the one hand, I think individual researchers can start by making their work visible — and help each other do so! Booles’ Rings is precisely based on this idea (so is <a href="http://mathblogging.org/">mathblogging.org</a>). On the other hand, the professional societies seem a natural starting point for investigating broader standards and best practice; they might, however, have serious conflicts of interests because of their current revenue models.<br>
Finally, I also agree that publicly funded research should be open access — I have yet to meet a mathematician who does not feel that way.</li>
</ul>
</li>
<li><strong>Santo D'Agostino</strong>, 2011/12/12<br>
Bravo for your efforts on several fronts, Peter. And best wishes for continued success.
<ul>
<li><strong>Peter</strong>, 2011/12/12<br>
Thank you for your kind words, Santo. It’s all a team effort, with Sam here at Booles’ Rings and with Felix and Fred at <a href="http://mathblogging.org/">mathblogging.org</a>. I’ll be sure to pass your compliments along :)</li>
</ul>
</li>
<li><strong>François G. Dorais</strong>, 2012/01/16<br>
This <a href="http://www.nytimes.com/2012/01/17/science/open-science-challenges-journal-tradition-with-web-collaboration.html?_r=0">New York Times article</a> is of interest.</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The recent publishing debate -- Nisan's posts]]></title>
        <id>https://www.peterkrautzberger.org/0091/</id>
        <link href="https://www.peterkrautzberger.org/0091/">
        </link>
        <updated>2011-11-27T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p><a href="https://www.peterkrautzberger.org/0090/">The original post</a> was getting longer and longer so I split it up.</p>
</blockquote>
<p>To refresh your memory,</p>
<ul>
<li>Nov 2 <a href="http://agtb.wordpress.com/2011/11/02/the-problem-with-journals/">Algorithmic Game-Theory/Economics // Noam Nisan</a>: The problem with journals</li>
<li>Nov 3 <a href="http://agtb.wordpress.com/2011/11/03/the-good-things-about-journals/">Algorithmic Game-Theory/Economics // Noam Nisan</a>: The good things about journals</li>
</ul>
<p>I read these posts only after Gowers's and a few other posts. But I found them very interesting so I thought I'd write about them next.</p>
<h3>Noam Nisan's posts</h3>
<p>The first is a short post replying to a &quot;nothing is wrong&quot;-comment at Gowers's first post. Nisan is making a wonderful point regarding the major functions that journals are supposed to fulfil: dissemination, verification and attention allocation. These used to be the major selling points, but I think he's right when he points out that journals are failing on all three right now.</p>
<p>Let me point out two details: first, Nisan mentions the increase in &quot;worthless&quot; papers. I think this is a critical issue. Second, just like Tim Gowers, he mentions the lack of recognition of books, surveys and other &quot;non-papers&quot; as he calls them. If you read my first post, you won't be surprised that this resonates strongly with me.</p>
<p>Nisan's second post is equally interesting pointing out what he thinks is good about journals: the community behind journals, the idea of peers reviewing peers and the hierarchy.</p>
<p>Another detail I'd like to highlight: Nisan points out that there is no incentive to referee well in the current system since it is not considered something I'd add to the list of &quot;non-papers&quot; that we need to recognize (in fact, <a href="https://www.peterkrautzberger.org/0067/">I already have</a>).</p>
<hr>
<p>These two posts were the reason to scrap my first draft -- many things I wanted to say, Noam Nisan wrote up quickly and elegantly.</p>
<h4>One</h4>
<p>The first post is strong and clear: the journals are failing at the very core of their mission. Just like Gowers, Nisan makes a very small point that I would highlight, especially, since he also seems to abandon it later: The biggest trouble with our current system is that we value nothing but &quot;new&quot; results. I believe this development is damaging mathematics.</p>
<p>There's pressure to publish as many papers as you can, no matter the quality. That is, not the journal system is broken, but the function the mathematical research community has assigned to it: to evaluate researchers on the academic job market. Because it is the only measure we accept, we are stuck in an intellectual monoculture. And this monoculture leads to a mass of poorly written papers, &quot;get it past the referee&quot;-kind of papers, only designed to game the hiring system.</p>
<p>I think if we want to reduce the negative aspects of the publishing system, we must find a way to reduce this pressure of publishing as many &quot;new&quot; results as possible. We need more alternatives, outside both the &quot;new&quot; scope as well as the &quot;paper&quot; scope.</p>
<h4>Two</h4>
<p>The second post really confused me. I'm totally onboard with the first two points Nisan makes: any future projects should include as many researchers as possible and the best method to verify results is to have as many researchers look at them as possible.</p>
<p>But then comes the weirdest thing: a celebration of the oligarchical structure of scientific communities.</p>
<p>The journal system is an oligarchical one: small editorial boards are in tight control of the most prestigious journals. They decide what is worthy of publication and thereby who will be a respected and successful researcher. There are no checks or balances in this system.</p>
<p>When it comes to organizing our community we seem stuck. I understand that until 20 years ago communication was too difficult to allow a more democratic approach to the community's organization. But this has changed! Now we are a fully connected community thanks to the internet.</p>
<p>I think, many people fear that average researchers will suddenly have the same chance to make an impression as their prize winning colleagues. It seems that more people worry about cranks and everyday, mediocre research &quot;diluting&quot; top research. However, the people who worry about this are the very ones who easily prevent it: I never met a mathematician who couldn't tell a crank from a real mathematician or a good from a better result. We know these things and we feel strongly about them. Why are we so worried?</p>
<p>Consider the following quotes from Nisan's second post.</p>
<blockquote>
<p>When one thinks of web-based reputation systems, one shudders at the thought of papers being evaluated by popular vote rather than by trusted experts. [...] any “decisions”, rankings, or scores must take into account the identity of the recommender/voter/referee/commenter, giving more weight to those with higher reputation.</p>
</blockquote>
<p>Besides reminding me of <a href="http://en.wikipedia.org/wiki/Prussian_three-class_franchise">this</a>, MathOverflow has already shown that this is a straw man argument; quality has prevailed. It is precisely the top researchers who easily gain a high reputation. If you want to say something bad, then maybe that they can get away with inappropriate questions and that they have &quot;fans&quot; voting up anything they write -- the same kind of bias we see in the journal system.</p>
<p>If you want to see a real problem with MO, here's one: if you're a logician, you really don't stand a chance to ever post an answer given that Joel, Andreas and François are so active. And indeed, you find people like <del datetime="2011-11-28T05:01:14+00:00"><a href="https://twitter.com/andrescaicedo/status/140942468660211712">Andres and</a></del> Carl to be more active on <a href="http://math.se/">math.SE</a> than MO these days. That's why we need more alternatives everywhere.</p>
<hr>
<p>The real issue I see is laziness: journals (and MO) filter for us, they take away the burden of being an informed, active member of our community. A lot of people seem reluctant to leave this <a href="http://en.wikiquote.org/wiki/Immanuel_Kant#What_is_Enlightenment.3F_.281784.29">self-caused immaturity</a>. After all, filtering is hard, forming an opinion is hard, organizing a community is hard. I think it is vital for our community to make the effort, there's too much to be gained if we do, so much to be lost if we don't.</p>
<p>Let me finish on a positive note. Imagine all mathematical content (all of it, every single paper, note and drawing) was available on an open social network.</p>
<p>Now watch the TED talk by Deb Roy from 11:00 onwards (HT to <a href="http://nuit-blanche.blogspot.com/2011/11/low-rank-language-acquisition.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+blogspot%2FwCeDd+%28Nuit+Blanche%29">Igor Carron</a>).</p>
<p>If you're worried about MO's reputation points, imagine such a data analysis for the actual content. Are you still worried we won't be able to identify exceptional contributors?</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The recent publishing debate -- a timeline]]></title>
        <id>https://www.peterkrautzberger.org/0090/</id>
        <link href="https://www.peterkrautzberger.org/0090/">
        </link>
        <updated>2011-11-26T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>In the last 3 weeks I have written a couple of drafts about the debate that finally hit the mathematical blogosphere <a href="http://gowers.wordpress.com/2011/10/31/how-might-we-get-to-a-new-model-of-mathematical-publishing/">through Tim Gowers's blog</a> (I don't know how much he is aware of similar, ongoing discussions in the scientific blogosphere beyond his Michael Nielsen link but in case my <del datetime="2011-11-27T00:00:22+00:00">one</del> two readers are not, <a href="http://scientopia.org/blogs/ethicsandscience/2011/11/05/scientific-authorship-guests-courtesy-contributions-and-harms/">here are two</a> you <a href="http://scientopia.org/blogs/drugmonkey/2011/11/11/a-thought-exercise-for-readers/">should add to your feed reader</a>).</p>
<blockquote>
<p>/begin{shamelessplug}<br>
Unfortunately, the mathematical blogosphere is not visible enough to ensure that people actually see this debate -- simply because there's not enough visibility even if <a href="http://www.mathblogging.org/">mathblogging.org</a> tries to <a href="http://mathblogging.wordpress.com/2011/11/09/weekly-picks-36/">help</a> <a href="http://mathblogging.wordpress.com/2011/11/16/weekly-picks-37/">with this</a> a <a href="http://mathblogging.wordpress.com/2011/11/24/weekly-picks-38/">little</a>.<br>
/end{shamelessplug}</p>
</blockquote>
<p>After getting stuck in one draft after another, I would like to try to writing something, rather than nothing: so let me start by giving an overview on all the posts that I have seen since Tim Gowers's first post on the subject.</p>
<h3>Establishing a time line</h3>
<ul>
<li>Oct 31 <a href="http://gowers.wordpress.com/2011/10/31/how-might-we-get-to-a-new-model-of-mathematical-publishing/">Gowers's Weblog // Timothy Gowers</a>: How might we get to a new model of mathematical publishing?</li>
<li>Nov 2 <a href="http://agtb.wordpress.com/2011/11/02/the-problem-with-journals/">Algorithmic Game-Theory/Economics // Noam Nisan</a>: The problem with journals</li>
<li>Nov 3
<ul>
<li><a href="http://agtb.wordpress.com/2011/11/03/the-good-things-about-journals/">Algorithmic Game-Theory/Economics // Noam Nisan</a>: The good things about journals</li>
<li><a href="http://geomblog.blogspot.com/2011/11/life-in-crowd-sourced-research-world.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed:+TheGeomblog+%28The+Geomblog%29">The Geomblog // Suresh Venkatasubramanian</a>: life in a crowd-sourced research world</li>
<li><a href="http://blog.computationalcomplexity.org/2011/11/journals.html">Computational Complexity // Lance Fortnow</a>: Journals</li>
<li><a href="http://gowers.wordpress.com/2011/11/03/a-more-modest-proposal/">Gowers's Weblog // Timothy Gowers</a>: A more modest proposal</li>
</ul>
</li>
<li>Nov 10 <a href="http://nuit-blanche.blogspot.com/2011/11/blowing-up-peer-review-bubble.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed:+blogspot/wCeDd+(Nuit+Blanche)">Nuit Blanche // Igor Carron</a>: Blowing up the Peer-Review Bubble</li>
<li>Nov 13 <a href="http://teachingintrotocs.blogspot.com/2011/11/journals-conferences-arxiv-my-solution.html">A CS Professor // Claire Mathieu</a>: Journals, Conferences, Arxiv: my solution.</li>
<li>Nov 14 <a href="http://ilaba.wordpress.com/2011/11/14/random-thoughts-on-publishing-and-the-internet/">The accidental Mathematician // Izabella Laba</a>: Random thoughts on publishing and the inte--rnet.</li>
<li>Nov 17 <a href="http://nuit-blanche.blogspot.com/2011/11/long-tail-of-post-peer-review.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+blogspot%2FwCeDd+%28Nuit+Blanche%29">Yet another blogging mathematician // Adam Bohn</a>: Publishing/Perishing.</li>
<li>Nov 18 <a href="http://nuit-blanche.blogspot.com/2011/11/long-tail-of-post-peer-review.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+blogspot%2FwCeDd+%28Nuit+Blanche%29">Nuit Blanche // Igor Carron</a>: The Long Tail of Post-Peer-Review Publishing: Reproducible Research as a Side Effect.</li>
<li>Nov 20 <a href="http://nuit-blanche.blogspot.com/2011/11/to-serve-science.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+blogspot%2FwCeDd+%28Nuit+Blanche%29">Nuit Blanche // Igor Carron</a>: To Serve Science.</li>
<li>Nov 24 <a href="http://nuit-blanche.blogspot.com/2011/11/wrath-of-our-discontent.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+blogspot%2FwCeDd+%28Nuit+Blanche%29">Nuit Blanche // Igor Carron</a>: The wrath of our discontent.</li>
</ul>
<p>That's a lot and one of the reasons why this post was stuck in the draft mode -- there was always another post to read (Addendum on Nov 28: <a href="http://nuit-blanche.blogspot.com/2011/11/tim-gowers-model-of-mathematical.html">Igor Carron pointed out</a> that he hadn't read Tim Gowers's posts). The great thing about wordpress is that all my drafts remain in the versioning system, including my rants -- who knows if I ever find the time to revisit them...</p>
<p>Since I didn't read them in chronological order, I won't write about them in chronological order, but I'll start with Tim Gowers's posts.</p>
<h3>Gowers's posts</h3>
<p>At first, I was disappointed at Tim Gower's first post. He describes a Mathoverflow-for-papers idea. That didn't quite blow me away, to tell the truth, but it's ok -- at least he suggests something and starts a discussion!</p>
<p>What annoyed me slightly more (but again, not greatly) was his list of potential objections. They are all non-points for me -- and to Gowers himself if you read his arguments against them. But I felt they changed the discussion into a discussion of these points rather than a the original questions &quot;what could a system look like?&quot; and &quot;how do we get there?&quot;.</p>
<p>What you could take away from Gowers's first post is the question &quot;Why don't we try a mathoverflow for papers?&quot;.</p>
<hr>
<p>The second post is a very different read. My problem with it is mostly the selection of comments he replies to -- but I can hardly blame Tim Gowers for discussing only comments from people he takes seriously (well, I will, actually).</p>
<p>The new proposal isn't really much different from the old one in practice, but it addresses said comments. The main change is to get rid of everything disruptive from the first proposal so that the service might be broadly accepted. The new concept is simply a service to check each others preprints.</p>
<p>For me, the most interesting part of that post is the list of people that Tim Gowers listens to.</p>
<hr>
<p>Here's what I found odd (and ultimately disappointing) about the posts.</p>
<h4>One</h4>
<p>The first post looked like a test balloon. Gowers seemed to say: &quot;I'd love to discuss this topic, here's an idea, I want to do this here rather than in print, and I want your input&quot;.</p>
<p>But the second post indicates that he only wanted to get some feedback to tweak his specific idea -- and he doesn't want to listen to anyone he doesn't already trust. If he had said that in the first place, I wouldn't have been disappointed.</p>
<p>Imagine he would have said: &quot;let's do a polymath-like project -- how many different ways can you think of to reinvent the publishing system?&quot;, now that would have been something!</p>
<h4>Two</h4>
<p>I wrote that, at first, I was disappointed. The reason was the lack of inspiration -- &quot;yet another stackexchange site&quot;, and that's it.</p>
<p>What had given me hope was the afterthought. In the very last lines Gowers points to the single biggest problem I see in research: &quot;real&quot; research means &quot;new&quot; results in peer-reviewed journals which means that we continue to live in an intellectual mono-culture, valuing only one type of accomplishment.</p>
<p>As simple as his first proposal was, at least it had some disruptive potential! Just imagine if all these &quot;not real research&quot; papers -- surveys, expositions etc -- would wind up on top of the heap! That could actually question the leadership within our research community, a leadership that is solely decided upon the current publishing system and no other abilities.</p>
<p>But, alas, all the disruptive potential was eliminated in the second post. Instead, we're left with a project that fixes what peer-review is supposed to accomplish. The community does for free what the publishers should organize and pay for: actual, in-depth peer-review.</p>
<p>Finally, however, I realized that it's silly of me to expect Timothy Gowers or any other researcher of a similar position to suggest something truly disruptive. After all, the system worked and works for him -- and similarly for anybody else he listens to.</p>
<p>Let me end by stressing that despite my criticism, I find it quite wonderful that Tim Gowers has yet again managed to have the mathematical blogosphere catch up with the scientific one on one more important debate.</p>
<blockquote>
<p>Since the original post was getting longer and longer, I will post this now and continue later.</p>
</blockquote>
<hr>
<p><em>Comments</em>.</p>
<ul>
<li><strong>François</strong>, 2011/11/27<br>
Thanks for posting this timeline. It was hard to keep track of everything after a while.
<ul>
<li><strong>Peter</strong> 2011/11/27<br>
Glad to hear it’s useful.</li>
</ul>
</li>
<li><a href="http://logic.dorais.org/archives/630">Pingback</a>, 2011/12/13</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The single greatest influence]]></title>
        <id>https://www.peterkrautzberger.org/0089/</id>
        <link href="https://www.peterkrautzberger.org/0089/">
        </link>
        <updated>2011-11-20T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Note: this is an old draft that I finally finished; there's a line to indicate the major break between the original half and the additional part (not that the first part wasn't rewritten a little, too).</p>
</blockquote>
<p>Yesterday, when hearing the news that Steve Jobs passed away I stumbled upon <a href="https://www.youtube.com/watch?v=UF8uR6Z6KLc">his speech at Stanford</a> from 2005. To be honest, I was a little disappointed but I guess it says something about him that even this mediocre speech left something behind: it made me think about different influences on my life, in particular, the influences on my development as a mathematician.</p>
<p>I was surprised to realize who I believe to be the single greatest influence on my development as a mathematician. You'd expect something like &quot;that one math teacher&quot; (which would be <a href="http://www.beethoven-gymnasium.de/personen-und-organisation/lehrerkollegium/detail/lehrerid/2/">this one</a>) or maybe &quot;my first logic professor&quot; (which would be <a href="http://www.mathematik.uni-muenchen.de/~donder/">this one</a>). Then of course, you could say &quot;my PhD advisors&quot; (which would be <a href="http://page.mi.fu-berlin.de/sabine1k/">her</a> and <a href="http://www.math.lsa.umich.edu/~ablass/">him</a>).</p>
<p>But that's not the case. Don't get me wrong, all of them had a serious impact on my development and without them I wouldn't have come this far.</p>
<p>If I ask myself who the single greatest influence on me as a researcher was, then I must say: Stefanie Frick. (Funny, I can't even google her properly, <a href="http://genealogy.math.ndsu.nodak.edu/id.php?id=129281">oh well</a>).</p>
<p>Steffi was a student with <a href="http://www.math.uni-hamburg.de/home/geschke/">Stefan Geschke</a> in Berlin and <a href="http://www.cs.bgu.ac.il/~kojman/">Menachem Kojman</a> in Be'er Sheva and she got her PhD about a year ahead of me. Unfortunately, she left research after her PhD. I still take the fact that nobody stopped her as a sign that the mathematical community values the wrong qualities in mathematicians (but this is another draft waiting to be completed).</p>
<hr>
<p>After I had finished my Diplom in Munich, I was pretty much a formalist. I didn't understand mathematics at all, especially I didn't understand what it meant to be a mathematician (which is about as different as understanding art is from <a href="https://www.youtube.com/watch?v=U3kKjGKp9rA">being an artist</a>).</p>
<p>But I was quite good at manipulating formulas. Good enough in any case to be able to find a poorly financed PhD grant after moving to Berlin. And this is where I encountered Steffi.</p>
<p>Steffi was my opposite. I had a hard time understanding anything she wrote or said because she didn't give me what my formalist mind needed to push formulas around. She seemed not to care at all about what I thought mathematics was about: formal proofs.</p>
<p>She was raw intuition.</p>
<p>Constantly pouring all her heart and mind and soul into her mathematics -- it was shocking and, frankly, I couldn't handle it.</p>
<p>I was annoyed! She was not giving me the details I needed, she was not giving enough formalisms. Instead, she was drawing pictures, she was talking like a waterfall; it was one giant stream of mathematical consciousness and I was drowning.</p>
<p>But I was fascinated. I had never encountered any mathematician like her before and I haven't since.</p>
<p>It took me a long time to realize that it wasn't her, but me that was missing something, something fundamental. So I tried to find out -- and I still try every day, struggling to learn what it really is to be a mathematician.</p>
<p>Having spent time with Steffi transformed me more than anything. She and her way of doing mathematics forced me to fundamentally re-evaluate what being a mathematician meant to me. Without the painful growth that followed this experience, I would never have made anything.</p>
<p>I haven't been in touch in while, but thank you, Steffi!</p>
<hr>
<p><em>Comments</em>.</p>
<ul>
<li><strong>sam</strong>, 2011/11/22<br>
This is a very nice post. This also happened to me (though I can’t pinpoint the precise moment) and probably happened to many of us. It’s the experience of being told how to solve a problem without actually being told any of the steps you would do to write a proof.
<ul>
<li><strong>Peter</strong> 2011/11/22<br>
Thanks for your comment Sam. You make it sound so mundane 😉 But yes, I assume all mathematicians encounter this at some point, most likely much earlier than me.<br>
But we don’t talk about it and I think non-mathematicians are often not aware of this. I’d love to hear more of these stories from other people.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Idempotent Ultrafilters, an introduction (Michigan Logic Seminar Nov 09, 2011)]]></title>
        <id>https://www.peterkrautzberger.org/0088/</id>
        <link href="https://www.peterkrautzberger.org/0088/">
        </link>
        <updated>2011-11-15T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Because of a power outage at the department my talk <a href="http://settheory.mathtalks.org/michigan-logic-seminar-7/">announced for October 29th</a> was postponed by a week.</p>
<iframe src="https://player.vimeo.com/video/32109926" width="100%" height="375" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
[Idempotent Ultrafilters: An Introduction (University of Michigan Logic Seminar 2011-11-08)](http://vimeo.com/32109926) from [Peter Krautzberger](http://vimeo.com/pkrautzberger) on [Vimeo](http://vimeo.com).
<p>Here are transcripts of my notes (as well as the originals at the end).</p>
<h3>Hindman's Theorem</h3>
<blockquote>
<p><strong>Hindman's Theorem</strong> If \(\mathbb{N} = A_ 0 \dot\cup A_ 1\), then \(\exists j \exists (x_ i)_ {i\in \omega}\) such that \[FS(x_ i) \subseteq A_ j.\]</p>
</blockquote>
<p>Imagine you'd like to prove this with an ultrafilter: \[p \in \beta \mathbb{N} \Rightarrow \exists j A_ j=:A \in p.\]</p>
<p>What do we need? We will build \((x_ i)\) inductively!</p>
<p>Pick \(x_ 0 \in A\) -- we can't really choose better than that (except maybe by shrinking the set first).</p>
<p>If we're looking for our result, we need</p>
<ul>
<li>\(x_ 1 \in A\) such that \(x_ 1, x_ 0\) and \(x_ 0+x_ 1 \in A\).</li>
<li>i.e. \(x_ 1 \in -x_ 0 + A\).</li>
<li>so we need \(-x_ 0 + A \in p\)!</li>
</ul>
<p>In other words, we need \(x_ 0 \in \\{ x: -x+A \in p \\}\) to begin with, i.e., \(\\{ x: -x+A \in p \\} \in p\) -- for any \(A\in p\)!</p>
<p>Galvin in 1970: \(p \in \beta \mathbb{N}\) is almost left-translation invariant iff \(\forall A\in p: \\{ x : -x +A\in p\\} \in p\).</p>
<p>Is this enough?</p>
<ul>
<li>Pick \(x_ 0 \in A \cap \\{ x: -x+A \\} \in p\)</li>
<li>Then choose \(x_ 1 \in -x_ 0 + A \cap A\).</li>
</ul>
<p><strong>But</strong> to continue the process, we need more!</p>
<p>We need \(x_ 2\) such that:</p>
<ul>
<li>\(x_ 2 \in A\) -- \(A\in p\), check</li>
<li>\(x_ 0 + x_ 2 \in A\) -- \(x_ 2 \in -x_ 0 +A \in p\), check</li>
<li>\(x_ 1 + x_ 2 \in A\) -- \(x_ 2 \in -x_ 1 + A \in p\) -- possible if we picked \(x_ 1 \in \\{x: -x+A\in p\\} \in p\), check.</li>
<li>\(x_ 0 +x_ 1 + x_ 2 \in A\) -- \(x_ 2 \in -(x_ 0+x_ 1) +A \in p\)???</li>
</ul>
<p>What does this mean? \(-(x_ 0 +x_ 1) + A = -x_ 1 + (-x_ 0 +A)\) by associativity.</p>
<p>Ah! But we have seen this before!</p>
<p>We needed \(x_ 1 \in \\{ x: -x + (-x_ 0 +A) \in p\\}\), so we needed \(\\{ x: -x + (-x_ 0 +A) \in p\\}\in p\)!</p>
<p>But that's ok!! \(-x_ 0 + A \in p\) &amp; \(\forall B\in p: \\{x : -x+B \in p \\} \in p\)!</p>
<h3>How do we get to the end?</h3>
<ul>
<li>
<p>Inductively, assume we have \(x_ 0,\ldots, x_ n\) with \(FS(x_ 0,\ldots, x_ n) \subseteq A\) <strong>and</strong> \[\bigcap_ {z \in FS(x_ 0,\ldots,x_ n)} -z + A \in p.\]</p>
</li>
<li>
<p>Pick \(x_ {n+1}\) from \[( \bigcap_ {z \in FS(x_ 0,\ldots,x_ n)} -z + A ) \cap A \cap \\{ x: -x+ (\bigcap_ {z \in FS(x_ 0,\ldots,x_ n)} -z + A) \in p\\}\] -- this intersection is in \(p\)!</p>
</li>
<li>
<p>Note that \[-x_ {n+1} + ( \bigcap_ {z \in FS(x_ 0,\ldots,x_ n)} -z + A \cap A)\] \[= \bigcap_ {z \in FS(x_ 0,\ldots,x_ n)} -x_ {n+1} (-z + A) \cap -x_ {n+1} A \in p.\]</p>
</li>
<li>
<p>So \[\bigcap_ {z \in FS(x_ 0,\ldots,x_ {n+1})} -z + A =\] \[\bigcap_ {z \in FS(x_ 0,\ldots,x_ n)} (-z + A) \cap \bigcap_ {z \in FS(x_ 0,\ldots,x_ n)} (-(z+x_ {n+1}) + A) \cap (-x_ {n+1} +A\] which is in \(p\) -- as desired.</p>
</li>
</ul>
<h2>Question: Do &quot;almost left-translation invariant&quot; ultrafilters exist?</h2>
<p>Glazer, ~1975: Yes of course! These are the idempotent ultrafilters! We know these exist since Ellis 1958.</p>
<h3>What does this mean?</h3>
<ul>
<li>
<p>\((\mathbb{N}, +)\) is a semigroup</p>
</li>
<li>
<p>\(\mathbb{N}\) is discrete, so \(\beta \mathbb{N}\), the Stone-Čech compactification of \(\mathbb{N}\) exists, in fact \(\beta \mathbb{N} \cong\) the set of ultrafilters on \(\mathbb{N}\) with a topological basis \(\hat A = \\{ p \in \beta \mathbb{N} : A \in p \\}\) for \(A\subseteq \mathbb{N}\).</p>
</li>
<li>
<p>\(\beta \mathbb{N}\) is compact (exactly by the Boolean Prime Ideal Theorem)</p>
</li>
<li>
<p>\(\beta \mathbb{N}\) is Hausdorff (\(p\neq q \Rightarrow \exists A\in p, B\in q: A\cap B = \emptyset\)).</p>
</li>
<li>
<p>\(\beta \mathbb{N}\)has a semigroup structure extending \((\mathbb{N}, +)\)</p>
<ul>
<li>From \(\beta (\mathbb{N} \times \mathbb{N}\):</li>
<li>\(p,q \in \beta \mathbb{N}\mapsto p \otimes q \in \beta(\mathbb{N}^2)\)
<ul>
<li>try \((A\times B)_ {A\in p, B\in q}\) -- not an ultrafilter</li>
<li>if you try to prove ultraness:</li>
<li>\(\bigcup_ {a\in A} \\{a\\} \times B_ a\) for some \(A\in p\), all \(B_ a \in q\)</li>
<li>generates an ultrafilter!</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Then \(p + q = + (p\otimes q)\)</p>
<ul>
<li>i.e., generated by \(\\{ \bigcup_ {a \in A} a + B_ a : A\in p, B_ a \in q\\}\) [check: \(n+k = +(n \times k)\)]</li>
</ul>
</li>
<li>
<p>Properties</p>
<ul>
<li>\(\forall q\in \beta \mathbb{N}: \rho_ q: \beta \mathbb{N} \rightarrow \mathbb{N}, p \mapsto p+q\) is continuous.
<ul>
<li>Why? \(X\in p+q\) iff \(\exists A\in p \exists (B_ a)_ {a \in A} , B_ a \in q: \bigcup_ {a\in A} a+ B_ a \subseteq X\) iff \(\\{a: -a + X \in q\\} =: X^{-q} \in p\).</li>
<li>But \(X^{-q}\) only depends on \(q\)!</li>
</ul>
</li>
</ul>
</li>
<li>
<p>associativity: check it -- use \[\bigcup_ {a\in A} a+ (\bigcup_ {b\in B_ a} b + C_ b)= \bigcup_ {c\in \bigcup_ {a\in A} a+ (\bigcup_ {b\in B_ a} a+ b)} c + C_ c.\] The first set is in \(p+(q+r)\), the second in \((p+q)+r\).</p>
</li>
</ul>
<h3>Now remember: what did Galvin need?</h3>
<p>\[(\forall A \in p) \{ x: -x+A \in p\}\in p\]</p>
<p>I.e., \(A\in p \Rightarrow A^{-p} \in p \Rightarrow A \in p+p\), so \(p \subseteq p+p\)<br>
I.e. \(p+p = p\) (since ufs)</p>
<blockquote>
<p><strong>Ellis 1958</strong> \((X,\cdot)\) compact, Hausdorff, right-topological semigroup \(\Rightarrow \exists x\in X: x\cdot x =x\).</p>
</blockquote>
<p><em>Proof.</em></p>
<ul>
<li>Think: \(x\cdot x = x \Rightarrow \\{x\\}\) is a closed semigroup - a minimal one!</li>
<li>\(\\{ Y \subseteq X: Y \mbox{ compact, non-empty, semigroup} \\}\)</li>
<li>By Zorn's Lemma, $\exists $ minimal, non-empty, compact semigroup \(Y\).</li>
<li>Think: that should be \(\left\vert Y \right\vert = 1\)!</li>
<li>We'll show \(\forall y \in Y: y\cdot y = y\) (therefore \(Y = \\{y\\}\) by minimality)</li>
<li>How? We only have continuity and associativity</li>
<li>\(Y \cdot y = \rho_ y [Y]\) compact, non-empty</li>
<li>\((Y\cdot y) \cdot (Y\cdot y) \subseteq Y\cdot y\), i.e., a semigroup.</li>
<li>By minimality of \(Y\), \(Y\cdot y = Y\)</li>
<li>Great! We'd expect that if \(y\cdot y = y\)</li>
<li>\(Y\cdot y = Y \Rightarrow \exists z \in Y: z\cdot y = y\).</li>
<li>Then \(\\{ z \in Y : zy=y\\} = \rho^{-1}_ y (y) \subseteq Y\)</li>
<li>\((z_ 0 z_ 1) y = z_ 0 (z_ 1 y) = z_ 0 y= y\), i.e., semigroup.</li>
<li>compact? Yes \(\rho^{-1}_ y[ \\{y\\}]\) closed.</li>
<li>\(Y\) minimal, so \(\\{z \in Y: zy=y \\} = Y \Rightarrow y\cdot y = y\).</li>
</ul>
 <figure>
   <a href="https://www.peterkrautzberger.org/assets/2011/idpotUFumich1.jpg">
     <img alt="Part 1 Idempotent Ultrafilters" src="https://www.peterkrautzberger.org/assets/2011/idpotUFumich1.jpg">
   </a>
   <figcaption>
    Part 1 Idempotent Ultrafilters, an introduction (Michigan Logic Seminar Nov 09, 2011)
   </figcaption>
 </figure>
 <figure>
   <a href="https://www.peterkrautzberger.org/assets/2011/idpotUFumich2.jpg">
     <img alt="Part 2 Idempotent Ultrafilters" src="https://www.peterkrautzberger.org/assets/2011/idpotUFumich2.jpg">
   </a>
   <figcaption>
    Part 2 Idempotent Ultrafilters, an introduction (Michigan Logic Seminar Nov 09, 2011)
   </figcaption>
 </figure>
 <figure>
   <a href="https://www.peterkrautzberger.org/assets/2011/idpotUFumich3.jpg">
     <img alt="Part 3 Idempotent Ultrafilters" src="https://www.peterkrautzberger.org/assets/2011/idpotUFumich3.jpg">
   </a>
   <figcaption>
    Part 3 Idempotent Ultrafilters, an introduction (Michigan Logic Seminar Nov 09, 2011)
   </figcaption>
 </figure>
 <figure>
   <a href="https://www.peterkrautzberger.org/assets/2011/idpotUFumich4.jpg">
     <img alt="Part 4 Idempotent Ultrafilters" src="https://www.peterkrautzberger.org/assets/2011/idpotUFumich4.jpg">
   </a>
   <figcaption>
    Part 4 Idempotent Ultrafilters, an introduction (Michigan Logic Seminar Nov 09, 2011)
   </figcaption>
 </figure>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[epub, mathjax and the iPad -- another attempt]]></title>
        <id>https://www.peterkrautzberger.org/0087/</id>
        <link href="https://www.peterkrautzberger.org/0087/">
        </link>
        <updated>2011-10-17T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>It's a funny thing. I don't even own an iPad. But a lot of people are interested in <a href="https://www.peterkrautzberger.org/0064/">getting an epub file with mathjax working</a> on the iPad.</p>
<p>Why is that? Well, as far as I could find out the iPad remains the only &quot;hardware&quot; that does not block javascript within an epub file (epub uses html for its content but javascript is designated &quot;should not&quot; in the epub2 standard). Of course it's really the software, iBooks, but mentioning the iPad will be much better SEO. ;)</p>
<p>Incidentally, the only other software I know that is not blocking javascript is the fantastic <a href="http://calibre-ebook.com/">Calibre</a>. Calibre's reader seems to not care at all about enforcing the epub standard, it just render everything it finds (but I'll get to that later).</p>
<h2>So what happened?</h2>
<p>A while ago, after an email exchange which is now <a href="http://groups.google.com/group/mathjax-dev/browse_thread/thread/1190dc76b7b88a02?hl=en">mostly available online</a>, I finally created an epub with a complete mathjax installation. Unfortunately, it was a fluke. The file was was not reliably rendered on the iPad, most likely because of its size (MathJax has 30.000 files for ~20MB unzipped). So <a href="http://www.math.union.edu/~dpvc/">Davide Cervone</a> suggested to cut down on unnecessary files which iBooks should not need.</p>
<p>This led to a result that rendered reliably -- unfortunately it rendered in a most irritating fashion: half a line below the intended one, writing happily across any other text on the next line, trailing out of the margin etc. That's far from perfect, obviously.</p>
<p>In the mean time, Davide was able to use my epub file to run some tests -- and <a href="http://groups.google.com/group/mathjax-dev/browse_thread/thread/1190dc76b7b88a02/ed1882e29659678c?hl=en&amp;">yesterday told us</a> that things are looking much better now that he can work on the issues.</p>
<p>Of course, iOS5 was released last week. It's not clear to me if iBooks already supports epub3, but I know that Safari now supports (some) MathML so there's a chance that iBooks would (since it uses the webkit variant of Safari to render html). So when I had a quick chance last Friday to get my hands on a friend's freshly updated iPad, I cooked up a quick test file and it rendered; it wasn't perfect but not totally bad either. With my luck, of course, this will also be a fluke and I won't know before I get my hands on that iPad again...</p>
<p>In the mean time, and for posterity, here's how I create epub files. (for the Pros: get ready to laugh at a dilettante).</p>
<h2>The tools</h2>
<p>Get your hands on</p>
<ul>
<li><a href="http://www.mathjax.org/">MathJax</a> (duh!)</li>
<li><a href="http://johnmacfarlane.net/pandoc/">pandoc</a> or <a href="http://www.juliansmart.com/">ecub</a></li>
<li><a href="http://calibre-ebook.com/">calibre</a></li>
</ul>
<p>That's it. (Well, unless you don't know what those are and how to use them -- I won't cover how to install and run these).</p>
<p>All but ecub is open source, ecub is at least free for personal use -- and of course everything runs on Linux, MacOS and Windows (I mostly use linux and sometimes a Mac; I can't make guarantees for Windows).</p>
<h2>Creating a minimal epub file with pandoc</h2>
<p>I love pandoc (ecub was a great help, too, more about that later) so I'll focus on it.</p>
<p><a href="https://www.peterkrautzberger.org/0070/">As you may know</a>, here at Booles' Ring I write using markdown and MathJax. I use pandoc whenever I want to convert this kind of content into something else (like LaTeX). But pandoc (as its name suggest) can handle much more.</p>
<p>So hit it! Take your favorite test html file (<a href="https://www.peterkrautzberger.org/0082/">I use this post</a>).</p>
<pre><code class="language-bash">  pandoc test.html -o test.epub
</code></pre>
<p>That should give you a working epub file -- it ain't fancy, but it'll do for testing. Be warned that pandoc does not check if your (x)html actually validates. Since the iPad is picky about having valid epub files you should double check (I totally failed the first time and it took me ages to remember this...).</p>
<p>Fortunately, you installed calibre which includes a binary of epub-fix from the <a href="http://code.google.com/p/epub-tools/">epub-tools</a> by the fabulous people over at <a href="http://threepress.org/">threepress</a>.</p>
<p>So you find the epub-fix binary and run</p>
<pre><code class="language-bash">  epub-fix --epubcheck test.epub
</code></pre>
<p>If epub-fix finds errors, fix them: go into the epub file (which is just a zip file) and fix the (most likely html) file that throws an error; in the post I use, the html should complain about a part of the vimeo embedding.</p>
<p>When epub-fix is happy, send the file over to the iPad for a test spin (I use Dropbox for ease of sync). If even a simple test file does not work, throw your epub into <a href="http://threepress.org/document/epub-validate">threepress's online validator</a> just to be sure.</p>
<p>Oh, one more thing: remember to always delete your file from iBooks before your load its updated version. In my experience, iBooks does not update the file when something with the same metadata is already in the iBooks library (or maybe just sometimes, I don't know, just watch out for that).</p>
<h2>Slimming down mathjax</h2>
<p>Well, right now we have a nice epub. But if you view it anywhere it will have your typical LaTeX commands all over the place -- we need to add mathjax!</p>
<p>Davide Cervone gave me some advice to reduce a mathjax installation to a mere 1.3MB.</p>
<ul>
<li>remove the MathJax/fonts/HTML-CSS/TeX/eot, svg, and png directories</li>
<li>remove the two OFT-files that start with &quot;MathJax_Win&quot; (guess why...)</li>
<li>remove the MathJax/unpacked, test, and docs directories</li>
<li>If you are only using TeX input (not MathML), then use the TeX-AMS_HTML-full configuration file.</li>
<li>In that case, remove the MathJax/jax/input/MathML, MathJax/jax/output/NativeMML directories, the MathJax/extensions/mml2jax.js and MathJax/extensions/jsMath2jax.js .</li>
<li>remove the &quot;FontWarnings&quot; and &quot;v1.0-warnings&quot; extensions, as well as all the configuration files you are not using.</li>
<li>remove the MathJax/jax/output/HTML-CSS/fonts/STIX directory</li>
</ul>
<p>Now that your MathJax installation is small and tidy, just copy the remaining files into a suitable folder (how about &quot;mathjax&quot;?) inside the epub -- an epub file is simply a zip file after all.</p>
<p>While you're at it, you should add a suitable MathJax configuration to the html files in your epub file. If you're using my post from above, you should add</p>
<pre><code class="language-html">  &lt;script type=&quot;text/x-mathjax-config&quot;&gt;  
    MathJax.Hub.Config({  
      tex2jax: {  
      inlineMath: [ ['$','$'], [&quot;\\(&quot;,&quot;\\)&quot;] ],  
      displayMath: [ ['$$','$$'], [&quot;\\[&quot;,&quot;\\]&quot;] ],  
      processEscapes: true  
      },  
    });  
  &lt;/script&gt;  
  &lt;script type=&quot;text/javascript&quot; src=&quot;mathjax/MathJax.js?config=TeX-AMS_HTML-full&quot;&gt; &lt;/script&gt;
</code></pre>
<p>If you don't use dollar signs for inline math, just take the last line.</p>
<h2>Fixing your epub.</h2>
<p>After this copying, we'll have to repair our epub file. An important fact about epub: all files must be listed in the manifest (OPF) file. Since we don't want to do that manually, we use epub-check again.</p>
<pre><code class="language-bash">  epub-fix --unmanifested --epubcheck test.epub
</code></pre>
<p>The &quot;unmanifested&quot; option (you guessed it) will ensure that all files will be added to the manifest. Beware: don't try this on a full MathJax! Epub-fix will slow down after the first 1.000 files...</p>
<p>Now transfer your file to the iPad and low and behold some mathjax will render! Of course, you'll find that this is not working: the rendering is broken right now. (As mentioned earlier, Davide is working on it)</p>
<h2>iOS5 to the rescue?</h2>
<p>Now this post gets flaky. As I wrote earlier, I have only had one test run with an iOS5 iPad, so this might not work. But the process is worthwhile documenting.</p>
<p>As I said above, the thing about iOS5 is that Safari and hence iBooks finally has some MathML support.</p>
<p>Since pandoc is incredibly versatile you won't be surprised that it can produce MathML and that it is aware of MathJax. So all we have to do is modify our earlier command.</p>
<pre><code class="language-bash">  pandoc test.html --mathml -o test.epub
</code></pre>
<p>This way, the html now has mathml instead of the LaTeX commands. Just shoot this over to your iPad and see how it renders. What I remember from my quick test with my post mentioned earlier was that some characters would render twice (which I had seen with that unreliable full install of MathJax I mentioned earlier). Also, MathJax's support for commands like \color obviously won't work without adding MathJax again.</p>
<p>Alternatively, you could try using MathJax's mathml-rendering and see what happens (I hope to test that next week).</p>
<h2>But what if I want to have it all?</h2>
<p>As I wrote, I also created an epub file that had a full mathjax install inside of it. This is a terrible idea because a) it rendered only sometimes on the iPad b) every other ebook viewer rejected it or crashed.</p>
<p>But if you cannot resist (or want to modify my approach), here's the a hurried how-to. Since epub-fix will come to a grinding halt adding 30.000 files to a manifest, use ecub instead.</p>
<p>Start ecub and use the new-project wizard, it's pretty self-explanatory. Two points might be worth pointing out:</p>
<ul>
<li>At &quot;Choose import method&quot; you'll want &quot;from an existing html file&quot;.</li>
<li>At &quot;Convert text files&quot; check only &quot;add any HTML file found&quot; and &quot;Also find files in folders under your project folder&quot; (this step will take a short while).</li>
</ul>
<p>After you're back at the main window, you'll still need to &quot;compile&quot; your epub file. This will take a <strong>long</strong> time. So long, in fact, you'll think ecub is hanging. To convince yourself that it isn't go to the project folder you designated in the wizard and watch the 30.000 files be copied into the folder and then watch content.opf grow in size (end result is ~3.5MB).</p>
<h2>Where do we stand?</h2>
<p>So for now, we have two broken ways to display mathematical content in an epub file on the iPad: use slimmed down MathJax or use MathML directly. Neither works perfectly but the key point is: they work in principle. Now we can look into the specifics to make things work better. Davide is looking into the mathjax side of things and with webkit (hence Safari, hence iBooks) there's reason to hope that mathml support will improve, too.</p>
<p>Of course, what I really want is an Android reader with javascript or mathml support...</p>
<p>And that's it for today. Any questions?</p>
<hr>
<p>Addendum</p>
<p>Here are two files at your disposal.</p>
<ul>
<li><a href="http://dl.dropbox.com/u/4999562/flat_slimmathjax_ecub.epub">An epub with a slim mathjax installation</a> (created with ecub).</li>
<li><a href="http://dl.dropbox.com/u/4999562/flat_mathml_pandoc.epub">An epub with mathml, no mathjax</a> (created with pandoc).</li>
</ul>
<hr>
<p><em>Comments</em>.</p>
<ul>
<li><strong>Thilo</strong>, 2011/10/21<br>
Hello there!<br>
Just a quick question, which eBook-readers have you tried? I’ve got an iriver Story HD and would like to know whether you tried it or its predecessor( same name without the “HD”).<br>
Best regards,<br>
Thilo
<ul>
<li><strong>Peter</strong>, 2011/10/31
<ul>
<li>Thilo, sorry for the late reply. As the title says, this was all about the iPad. As far as I know, there is not a single epub reader software or “hard”ware (i.e., software running a dedicated device) that supports either mathml or javascript.<br>
Nevertheless, I have tried android and (other) ipad apps — none of them worked.</li>
</ul>
</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Grigorieff forcing collapsing the continuum]]></title>
        <id>https://www.peterkrautzberger.org/0086/</id>
        <link href="https://www.peterkrautzberger.org/0086/">
        </link>
        <updated>2011-10-16T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>This is a short technical post, more a note-to-self so that I know where to look this up if I ever need it again. It is also somewhat of a correction of something I said during my talk in Toronto in June.</p>
<h3>Grigorieff forcing</h3>
<p>If you don't remember, here's the quick and dirty (i.e. traditional) way to define Grigorieff (or Gregorieff depending on your choice of latinization) forcing: it consists of partial functions on \(\omega\) which are defined on a &quot;small&quot; set, i.e., a set in the dual ideal of a filter. For simplicity, let's focus on ultrafilters. asd s</p>
<blockquote>
<p><strong>Grigorieff Forcing</strong> Given a ultrafilter \(U\) on \(\omega\), let \[\mathbb{P}_U = \{ f: A \rightarrow \omega : \omega \setminus A \in U \}.\]<br>
Partially order such functions by \(f\leq g\) iff \(f \supseteq g\), i.e., \(f\) has more information.</p>
</blockquote>
<p>You can think of Grigorieff conditions as perfect binary trees with complete branching on an ultrafilter set and &quot;parallel movement&quot; elsewhere. But I said quick and dirty is enough here, so let's not worry too much.</p>
<p>Grigorieff forcing is famous for being the forcing that Shelah used for the first model without P-points. One of the reasons this is possible is as follows.</p>
<blockquote>
<p><strong>Theorem (Shelah)</strong> If \(U\) is a <a href="http://en.wikipedia.org/wiki/Ultrafilter#Ultrafilters_on_.CF.89">P-point</a>, then \(\mathbb{P}_U\) is proper and \(\omega^\omega\)-bounding. In particular, \(\mathbb{P}_U\) does not collapse \(\omega_1\).</p>
</blockquote>
<p>Last week, David Chodounsky let me know that Bohuslav Balcar showed him the following &quot;folklore&quot; result.</p>
<blockquote>
<p><strong>Optimality</strong> If \(U\) is not a P-point, then \(\mathbb{P}_U\) collapses the continuum.</p>
</blockquote>
<p>This result is mentioned in Jech's Multiple Forcing book, but without proof and I have never seen one published. (Which, to tell the truth, is the reason I thought it was wrong but more about that later).</p>
<h4>a proof</h4>
<ul>
<li>If \(U\) is not a P-point, then there exists a partition \(\bigcup_{n \in \omega} I_n\) such that every \(A\in U\) intersects infinitely many \(I_n\) in an infinite set.</li>
<li>In particular, no \(I_n \in U\) and, without loss, all \(I_n\) are infinite.</li>
<li>In the ground model \(V\), let's enumerate each \(P(I_n)\) as \((A^\alpha_n)_{\alpha &lt; \mathfrak{c}}\) (bijectively).</li>
<li><strong>First observation</strong> The generic \(\dot G \subseteq \omega\) has \[\Vdash I_n \cap \dot G \in V\] for every \(n\).
<ul>
<li>Fix \(n\).</li>
<li>Since \(I_n\notin U\), we can decide any condition \(f\) arbitrarily on \(I_n\).</li>
<li>In other words, there's a dense set of conditions \(g\) with \(dom(g) \supseteq I_n\).</li>
<li>But any condition in this dense set forces what we want, i.e., \(g \Vdash \dot G \cap I_n = g^{-1}(1) \cap I_n\) -- which is a set in the ground model.</li>
</ul>
</li>
<li>So let \(G\) be a generic over \(V\).</li>
<li><strong>Second observation</strong> In \(V[G]\), we can define a map \(H: \omega \rightarrow (2^\omega)^V\), mapping \(n\) to \(\alpha\) with \(A^n_\alpha = G \cap I_n\).
<ul>
<li>Check that this is possible because this intersection is a ground model set, hence appears in the enumerations we fixed earlier.</li>
</ul>
</li>
<li><strong>Third Observation</strong> \(H\) is cofinal.
<ul>
<li>Given any \(\alpha\), we want to find \(n\) such that \(H(n) > \alpha\).</li>
<li>For a density argument, fix any condition \(f\).</li>
<li>Since \(dom(f)\) is a small set, we can find \(n\) such that \[\left\vert I_n \cap \omega \setminus dom(f) \right\vert  = \omega.\]</li>
<li>Therefore, we can find \(A \subseteq I_n \cap \omega \setminus dom(f)\) such that \(A \cup f^{-1}(1) = A^n_\beta\) for some \(\beta > \alpha\).</li>
<li>Extend \(f\) to all of \(I_n\) such that \(f^{-1}(1) = A\).</li>
<li>Then \(f \Vdash \dot G \cap I_n = A^n_\beta\) -- as desired.</li>
</ul>
</li>
</ul>
<h3>An honest mistake</h3>
<p>David and I thought we had a proof that Grigorieff forcing with a stable ordered union ultrafilter is proper and \(\omega^\omega\)-bounding. This is, of course, impossible -- and with this knowledge we could find the mistake in our proof. We still think that &quot;morally&quot; speaking there should be an analogue forcing for the union filter world. But that's a different story.</p>
<hr>
<p><em>Comments</em>.</p>
<ul>
<li><strong>François</strong>, 2011/10/16<br>
That's a neat argument! I always find situations like this where you only show that \(cf(\mathfrak{c}^V) = \omega\) a little strange. Is there any hope to get a nice surjection from \(\omega\) onto \(\mathfrak{c}^V\)?<br>
(There is a small typo where you have \(2^\mathfrak{c}\) instead of \(2^\omega\) or \(\mathfrak{c}\).)
<ul>
<li><strong>Peter</strong>, 2011/10/16<br>
Well, Andreas thought of one when I talked to him about this but writing this post I felt it didn't work (I'll ask again).<br>
He wanted to enumerate \(P(I_n) / fin\) instead of \(P(I_n)\) but I didn't see how this helps, i.e., I don't see how \(f\) can be extended to be equal mod fin to \(A^n_\alpha\).<br>
(Thanks, I'll fix the typo.)</li>
<li><strong>François</strong>, 2011/10/17<br>
Right, that trick would work if you knew that \(\operatorname{dom}(f) \cap I_n\) is finite for some \(n\), but I don't see why that would be the case...
<ul>
<li><strong>Peter</strong>, 2011/10/20<br>
Ah! I forgot to update this -- Francois, Andreas fixed it. It's not hard, really: instead of a regular enumeration just pick a map so that the power set of every infinite subset of \(\omega\) has full range. Proceed as in the proof and after finding \(n\), choose the subset with number \(\alpha\).
<ul>
<li><strong>François</strong>, 2011/10/21<br>
Full range?
<ul>
<li><strong>Peter</strong>, 2011/10/29<br>
Surjective range. Inductively build a map \(P(\mathbb{N}) \rightarrow \mathfrak{c}\) in such a way that for every infinite \(A \subseteq \mathbb{N}\), we get that the restriction of our map to \(P(A)\) is still surjective.<br>
Then we can use the above argument: as before we find an \(I_n\) where our condition has left out an infinite set. Now pick from the power set of that infinite set a suitable candidate for \(\alpha\) -- done.<br>
Does that make more sense?</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A posting on wordpress-for-scientists]]></title>
        <id>https://www.peterkrautzberger.org/0085/</id>
        <link href="https://www.peterkrautzberger.org/0085/">
        </link>
        <updated>2011-10-15T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>I just finished <a href="http://groups.google.com/group/wordpress-for-scientists/browse_thread/thread/f263df8e98cb440a?hl=en">a long posting at the mailing list/google group Wordpress For Scientist</a>. This was spawned by today's meeting with Sam and <a href="http://boolesrings.org/blog/2011/08/16/citations-two-new-plugins-to-try/">this week's trouble with the papercite plugin</a>. We really need to find a different solution. So I'm hoping both for a discussion here at Booles' Rings as well as some help from the smart people on the mailing list.</p>
</blockquote>
<p>Hello.</p>
<p>I was hoping for some advice and discussion regarding citation related plugins.</p>
<p>Since this has gotten a little longer: I will first describe the problem and then add some questions.</p>
<p>Over at <a href="http://boolesrings.org/">boolesrings.org</a> we have had some problems this week. At Booles' Rings we're experimenting with wordpress for academic homepages (of mathematicians). We're essentially trying to find out what is useful and/or necessary for an academic web presence via wordpress.</p>
<p>Obviously, citations are important for documenting our own work and writing about other people's work.</p>
<p>Since we're all mathematicians, there's the strong need for bibtex import which is why papercite is popular -- it makes the move from BibTeX to wordpress very easy. Unfortunately, papercite is very buggy and we would like to replace it.</p>
<p>We're faced with the question:</p>
<h3>What do we need a citation plugin to do?</h3>
<p>Practically speaking,</p>
<ol>
<li>bibtex import (but no dependence/sync)
<ul>
<li>We have to start somewhere and that's where most people (in mathematics) come from.</li>
</ul>
</li>
<li>personal IDs for shortcode use
<ul>
<li>we're human and we like to write ThatFamousPaper instead cryptic ids<br>
(I think mathematical writing is very different from scientific writing in this respect -- papers can be holy objects...)</li>
</ul>
</li>
<li>a GUI to look up/search for new citations
<ul>
<li>Sometimes, you barely remember the paper's title.</li>
<li>DOIs are cumbersome to look up anyway</li>
<li>Searching multiple sources (google scholar, mendeley, mathscinet, pubmed) would be nice while writing a post</li>
<li>Maybe even links-to-citation functionality when quoting online sources (blogs, mathoverflow etc)</li>
</ul>
</li>
<li>Reversibility
<ul>
<li>the citation in html (in a post) should include some form of metadata that can be processed automatically (pingbacks, aggregation, citation counts etc)</li>
</ul>
</li>
</ol>
<h3>QUESTION 1: Do we have such a plugin?</h3>
<p>1b) What plugins have which functionality?</p>
<ul>
<li>Kcite is excellent when you have the DOI (well, depends on the DOI actually)</li>
<li>bibtex-importer does a great job using links giving a local search GUI -- but shoudn't citations be pages or a taxonomy?</li>
<li>papercite offers the familiarity of keeping on as we do in LaTeX</li>
<li>wpcitulike, bibliplugin seem to offer good external reference sources</li>
<li>zotpress seems to have almost everything, but requires zotero</li>
<li>teachpress and scholarpress have too much overhead<br>
1c) is there a plugin that uses Mendeley's api?</li>
</ul>
<h3>QUESTION 2: How do we want citations to work?</h3>
<p>Ok, this is in hopes for a discussion. My amateur thoughts.</p>
<ul>
<li>reference management should be done by professionals not through personally hacked bibtex files (we mathematicians have a bad habit...)</li>
<li>references should be stored professionally, i.e., in the wp-database or in a professional outside tool (mendeley, zotero, citeulike) (take papercite as a terrible example relying on some random bibtex file somewhere)</li>
<li>even if an outside tools is used, actually referenced citations should always be stored in the database.</li>
<li>citations should be hardcoded into the post (when I review a preprint, I don't want the reference to change to the published version later)</li>
</ul>
<p>Well, this has become more of a blog post... I guess I'll cross post it at <a href="http://boolesrings.org/krautzberger">boolesrings.org/krautzberger</a>...</p>
<p>In any case, I hope I made a little bit of sense. Any help is greatly appreciated!</p>
<p>Best,<br>
Peter.</p>
<hr>
<p><em>Comments</em>.</p>
<ul>
<li>
<p><strong>François</strong>, 2011/10/15<br>
I hadn’t noticed zotpress before. I just downloaded the standalone version of zotero to experiment. The fact that it is both standalone and a browser plugin makes it much more attractive than its counterparts. So far, I’m actually impressed by its features. However, the bibtex it exports isn’t up to my standards and it clearly doesn’t understand tex at all. Sigh!<br>
I wonder what kind of responses you will get from question 2. Do you think that the citation needs across sciences is uniform enough to come up with a definite answer?</p>
<ul>
<li><strong>Peter</strong>, 2011/10/15<br>
Francois, about uniformity. I think there’s a misunderstanding. The mailing list I posted this too is about using wordpress (for scientists). So that question is more about how other (more professional) people in that community see it.<br>
So yes, I even think we <em>must</em> find common ground for the technical aspects of making a citation in wordpress (hard-coded vs dynamic for example). We want to be serious about this, no?
<ul>
<li><strong>François</strong>, 2011/10/15<br>
There was no misunderstanding. My uniformity question was precisely that: I have no idea if physicists, chemists, or paleontologists need the same things I do. I’m much more hopeful that we, at Booles’ Rings, can find some common ground…<br>
I don’t really understand all hard-coding issue you present, but that might be a lack of enlightenment about the possibilities. If the references come from a local database, then they won’t change unless you explicitly change them. External databases may change. However, doi are directly linked to the publisher, so if something there changes, you probably do want that change to occur. Other sources can be less reliable (e.g. user updated databases) but I wouldn’t use those under any circumstances.<br>
As far as we’re concerned and as far as published works are concerned, a tool that just extracts the relevant info using MR Lookup would be fantastic.
<ul>
<li><strong>François</strong>, 2011/10/15<br>
Maybe there was a misunderstanding… Did you mean to ask “How do you want citations to work?” instead of “How do we want citations to work?”?
<ul>
<li><strong>Peer</strong>, 2011/10/15
<ul>
<li>I’m not sure what you mean with “what I need”. I was thinking about the technical realization of citations in wordpress — how would they differ? Citations on paper also have strict standards.</li>
<li>I don’t want to find a solution just for Booles’ Rings.</li>
<li>The hardcoding problem is that once papercite breaks or the bibtex file you uploaded is manipulated or deleted, your posts have no citation information anymore. (Also, check out the front page and how bad your own posts look there because the widget reads only the source.)</li>
<li>MR is bad because it’s paywalled.</li>
<li><strong>François</strong>, 2011/10/15<br>
Trying to match your bullet points…
<ul>
<li>Paper citations have (sometimes strict) standards that must be met. Why would BR be any different? Both are final output media after all…</li>
<li>Why not? That’s all I need…</li>
<li>I still don’t understand the issue. How would a paper citation be changed in a way that I can’t predict (or postdict, in the case of local file changes)?<br>
The widget issue is not at all the same. It has to do with wordpress and how it loads various plugins. I actually find the raw output desirable from time to time so I can see what other people are doing to shape their posts.</li>
<li>MathReviews is paywalled, but I think MR Lookup is free (or some part of it is free). That’s why you actually get useful information (not the review) when looking up an MR number.</li>
<li><strong>Peter</strong>, 2011/10/15<br>
Regarding the third point.<br>
With papercite any change in the bibtex file will effect your content — whether intended or not.<br>
I can empathize with wanting to know how other people do things, but that can’t have higher priority than content integrity. Asking seems better practice (but also, separate access to the source is conceivable).<br>
“Hard-coded” is more reliable, efficient and is better to export. It should be the default.
<ul>
<li><strong>François</strong>, 2011/10/15<br>
I’ve just confirmed that MR Lookup is indeed free though the functionality is limited compared to full math reviews.
<ul>
<li><strong>Peter</strong>,2011/10/15<br>
Nice! Reference? You do need access to find the reference numbers?<br>
<strong>François</strong>, 2011/10/15<br>
Sorry, I should have included those links in my last comment:<br>
<a href="http://www.ams.org/mrlookup">MR Lookup</a><br>
<a href="http://www.ams.org/mathscinet/help/mr_lookup_help.html">MR Lookup Help</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Joel David Hamkins</strong>, 2011/10/15<br>
Peter, I don’t agree with the last bullet on question 2. I would think that we would want all our citations whenever we make them to be updated to the best/current version of the paper without our having to do anything. If you are reviewing a preliminary version of a paper, just say so in the review. Meanwhile, your readers will want to read the updated/corrected version, regardless of your review.</p>
<ul>
<li><strong>Peter</strong>, 2011/10/15<br>
Joel, I’m happy to disagree. Technically speaking, if I give you, say, a DOI of a preprint, that DOI should be (wherever it was created) linked to the published version. But that doesn’t change my citation — I didn’t cite the other version and I want integrity in my posts.<br>
This of course does not exclude some fancy technology that comes with both a static and dynamic aspect.</li>
<li><strong>François</strong>, 2011/10/15<br>
I don’t understand the issue here. How can you get a doi for a preprint?
<ul>
<li><strong>Peter</strong>, 2011/10/15<br>
Good point. I should have said:
<ul>
<li>Example arxiv: if the paper is updated, I still want to link to the old version, if a link to a published version is added (as arxiv now requests), it should still link to the preprint</li>
<li>Example local: if there’s a local database and an entry is manually changed to a published version</li>
<li>Example publisher: if the paper is updated (say because of criticism later), if the paper is retracted, I still want to link to the original</li>
<li><strong>Peter</strong>, 2011/10/15<br>
Also, I should have said GUID instead of DOI.
<ul>
<li><strong>François</strong>, 2011/10/15<br>
Trying to match your bullet points…
<ul>
<li>The arxiv includes all revisions and the pointers to the print version (if any) are very clear. I still don’t see the problem.</li>
<li>Why wouldn’t you want that update to occur?</li>
<li>Retractions don’t erase the papers, they amend them (in a very negative way). The doi should still point to the actual paper. (Lookup the rules for doi, they are very strict.) In any case, if the doi also includes info on the retraction, that is desirable information.</li>
<li><strong>Peter</strong>, 2011/10/15<br>
Take a paper I read last winter. The original preprint is terrible, the changes in the updated version extensive. I would want to link to the one I write about. What doesn’t make sense about that?<br>
(Thanks for the info on DOIs. I’m not an expert — that’s why I wrote to the other mailing list)
<ul>
<li><strong>Joel David Hamkins</strong>, 2011/10/15<br>
I still disagree about updating the citations. Your “integrity in posts” makes sense in the very rare kind of case you describe, but by far the usual case will mean that your links will often be pointing at an expired version of the article, when readers would greatly prefer to have the published version. This is often not available at the arxiv, and often no indication given there where to find it. In my opinion, this is one thing that papercite gets right: it provides links to all the versions that are present in the bibtex entry. This method seems to preserve what you want (the arxiv link is still there), while also making DOI available if that information is available.
<ul>
<li><strong>Peter</strong>, 2011/10/15<br>
I agree that it’s a rare case. I agree that the abstract reference-entity should be structured in such a way that it can survive an update (like bibtex). I agree that more information in the metadata is better.<br>
I would still want to be able to keep my intended citation, i.e., even if the reference-entity changes and, say, there’s an automatic update changing the metadata in the post’s html, I would want my citation to make it clear what was referenced at the time of writing. (Did I mention that I loathe shortcodes?)<br>
I guess I am worried about how to implement this. To accept honest historic inaccuracies seems much better.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Joel David Hamkins</strong>, 2011/10/15<br>
Here are a few things I would like in a citation tool:</p>
<ul>
<li>citation objects can be created and managed with GUI, managed something like how links,pages and posts are in WP.</li>
<li>these citation objects can be updated by means of an uploaded bibtex file, that is, without having to edit them individually</li>
<li>one can insert citation objects into posts and pages, and control how they appear</li>
<li>flexible options for how the citation appears by default</li>
<li>citation objects can be upgraded to have a full post-like status, where one can add text and abstract and discussion, etc.</li>
<li>reverse bibtex file generation, so that one can download a bibtex file of all or selected parts of the citation database.</li>
<li><strong>sam</strong>, 2011/10/16<br>
Joel: I think this is needed as well. Peter and I would like to try to write such a plugin (by combining several existing plugins) but it will take some time.<br>
Meanwhile, I think we will have to phase out the use of papercite. For folks using just a few inline references, I think it’s ok but should be treated as very fragile. For Joel, sadly, I think this means replacing all of the shortcodes with the static html…</li>
</ul>
</li>
<li>
<p><strong>Peter</strong>, 2011/10/15<br>
Joel, I like those features.<br>
But I’m more interested in the abstraction level.</p>
<ul>
<li>no matter how you make it look, there must be metadata to allow clean identification/reconstruction of citations.</li>
<li>the content integrity must not be compromised — if I cite a paper, then the only way to change the resulting metadata should be to edit the post.</li>
<li>you shouldn’t (have to) mess with a bibtex file — that should be generated out of a professional reference manager and a professional reference database.<br>
Ideally, I would like to add to wordpress a generic interface to connect to a real reference manager. In the mean time, we’ll look into the other part: a reference manager type interface.<br>
I would also like to add: there are three different issues as far as I see at the moment.</li>
<li>presenting our own work vs citing in our online writing
<ul>
<li>our own work should really be pages or their own wp-taxonomy</li>
<li>formal citations should be nothing but links (citations are pointers) (the writing surrounding a citation is a different matter)</li>
</ul>
</li>
<li>citation storage/handling locally
<ul>
<li>I would love a good wordpress gui element</li>
<li>database storage</li>
</ul>
</li>
<li>interacting with reference mangement outside of wordpress
<ul>
<li>I feel that “real” reference management should lie outside of my wordpress installation, with a professional tool/service.</li>
<li>I would love to have a search interface within wordpress (just as I have it in my reference manager)</li>
<li>I would prefer that search interface to update my external tool first and then import it via an import interface<br>
I wish I had time for this…</li>
</ul>
</li>
<li><strong>François</strong>, 2011/10/15<br>
There are too many bullet points for me to try to match them… I hope you can make sense of the following…<br>
Are there any professional reference managers? In the case of print media, yes: MR and ZBL do a great job for math (and so do others). For non-print media, there is no reliable source. Just look at MO cite bibtex output. We had to implement triple redundancy to make sure that we were understood. Even then, we still had to cheat some with the author info since we don’t require users to use their real names. The whole thing is ridiculous, and we can’t hope to fix that right away…<br>
As far as presenting the bibliographic info, I really like what papercite does. With a single click, you can get the original bibtex (with all the ignored fields). Even if that’s not enough info for you in that case, that’s usually enough info to lookup what you’re missing.</li>
<li><strong>Peter</strong>, 2011/10/15<br>
I don’t know what MO cite bibtex refers to.<br>
With reference managers I only meant tools like Mendeley. Mendeley, Google scholar, MS Academic Search are growing databases.<br>
I personally don’t like papercite’s output. For me, a reference should be nothing but a link. But who cares, anything goes in looks — as long as reliable metadata is available.</li>
</ul>
</li>
<li>
<p><strong>Peter</strong>, 2011/10/15<br>
Wow, I must admit this is my first lengthy discussion as a host. It’s quite exhausting and I feel that I’m not making myself very well understood. It’s hard…<br>
I have learned so far that I need to stress my focus on the abstract layer.<br>
How should references (i.e., bibtex-like things) be stored, added, updated, looked up. I cannot shake the feeling that researchers should not create reference-entities directly — ever. We should rely on professionals.<br>
But this is probably one of the biggest issues about moving scientific activity online. So I shouldn’t be surprised that it’s hard…</p>
<ul>
<li><strong>Joel David Hamkins</strong>, 2011/10/15</li>
</ul>
<blockquote>
<p>researchers should not create reference-entitities directly – ever”</p>
</blockquote>
<p>Almost all of my bibtex entries for my own papers are born, created by hand by me, before the article exists in any form except as an (incomplete, in progress) file on my computer. But I need to create the bibtex entry because the paper is being cited in another paper I am writing, or in a grant proposal or whatever. So in this case, there seems to be no alternative to creating the entry myself. And then it is gradually updated, first by adding the arxiv entry when it is contributed there, and then when it is accepted at the journal, etc. Eventually, I suppose, the professionally prepared bibtex entry is available, such as by the journal, but these often don’t include the arxiv data and other data that I might want. So by hand I combine the data together in my bibtex entry.</p>
<ul>
<li><strong>Peter</strong>, 2011/10/15<br>
Thanks Joel, that’s a very good. point. At first I wanted to write “presenting our own work is different”, but you say much more. The new generation of services like Mendeley, Google Scholar, MS Academic Search seem to get this problem — they try to catch all sources/version of an article. I guess that’s why I like them.</li>
</ul>
</li>
<li>
<p><strong>Peter</strong>, 2011/10/16<br>
In case the discussion continues, let me stress that my post here was intended for a different audience: not us here at Booles’ Rings but the experts over at the wp4scientist mailing list.<br>
In one comment, Francois pointed out my confusing choice of words “what do we need a citation plugin to do”. This was aimed at that audience.<br>
If you are interested in the much bigger problem of citations in the online world let me throw in some links.<br>
<a href="http://blogs.plos.org/mfenner/2011/03/07/the-trouble-with-bibliographies/">http://blogs.plos.org/mfenner/2011/03/07/the-trouble-with-bibliographies/</a><br>
<a href="http://scholarlyhtml.org/">http://scholarlyhtml.org/</a><br>
<a href="http://blogs.plos.org/mfenner/2011/02/14/how-to-use-citation-typing-ontology-cito-in-your-blog-posts/">http://blogs.plos.org/mfenner/2011/02/14/how-to-use-citation-typing-ontology-cito-in-your-blog-posts/</a><br>
We should discuss practical solutions for citations on Booles’ Rings. But there’s also a much bigger, abstract issue in the background, one that develops quickly — and I will always have that one on my mind, too.</p>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Formal proofs are our democracy]]></title>
        <id>https://www.peterkrautzberger.org/0084/</id>
        <link href="https://www.peterkrautzberger.org/0084/">
        </link>
        <updated>2011-10-08T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Reading papers can lead to horrible acts. Today, I felt like mutilating <a href="http://en.wikiquote.org/wiki/Winston_Churchill#Post-war_years_.281944_-_1955.29">a famous quote</a>.</p>
<figure>
    <img alt="Sir Winston Churchill" src="https://www.peterkrautzberger.org/assets/2011/Sir_Winston_S_Churchill.jpg">
  <figcaption>
   Sir Winston Churchill. Source: Library of Congress, via <a href="http://en.wikipedia.org/wiki/File:Sir_Winston_S_Churchill.jpg">Wikipedia</a>.
  </figcaption>
</figure>
<blockquote>
<p>Many forms of communicating mathematics have been tried and will be tried in this world of sin and woe. No one pretends that formal proofs are perfect or all-wise. Indeed, it has been said that formal proofs are the worst form of communicating mathematics except all those other forms that have been tried from time to time.</p>
</blockquote>
<p>When I come up with a mathematical result, I have the strong urge to share it, to communicate it. As a trained mathematician, I resort to the established mode of communication, formal proof.</p>
<p>This has two problems.</p>
<h3>Formalizing is tricky</h3>
<p>On the one hand, I <del datetime="2011-10-08T15:30:12+00:00">might</del> will make a mistake formalizing my thoughts. Of course, we mathematicians are in the terrible habit of finding that perfectly acceptable (have you noticed that there are <a href="http://retractionwatch.wordpress.com/category/by-subject/math-retractions/">no retractions</a> in mathematics because of mistakes?). Almost all the time, even though a formal proof might be wrong or incomplete, it's considered fixable and the result &quot;essentially&quot; correct (case in point: Perelman). It seems a majority agrees that there's much more to a mathematician's result than what might be written on paper.</p>
<p>In the same vein but much worse is the effect of formal proof on mathematical writing. Most papers are badly written and most proofs are written the wrong way around (like \(\varepsilon\)-\(\delta\) proofs that start with a choice of \(\delta\)) or badly structured in other ways. It seems a lot of people are not aware that a formal proof is a miserable tool for communicating mathematics and has to be used <a href="http://www.math.upenn.edu/~ghrist/preprints/ATSN.pdf">very carefully</a> to facilitate communication. Such care would, of course, clash with the all-encompassing publish-or-perish pressure that has led to the terrible style of &quot;getting the least publishable unit passed a referee with minimal effort&quot;.</p>
<p>All of the above is really just one big problem and luckily it is one that could be fixed by a functioning scientific community (unluckily, it most likely won't be fixed).</p>
<h3>Formalizing is impossible</h3>
<p>The second problem however seems intrinsic and unsurmountable.</p>
<figure>
    <img alt="Moby Dick attacking a skiff" src="https://www.peterkrautzberger.org/assets/2011/Moby_Dick_p510_illustration.jpg">
  <figcaption>
   <q>Both Jaws, like enormous shears, bit the craft completely in twain. — Page 510.</q> Source: <a href="http://en.wikipedia.org/wiki/File:Moby_Dick_p510_illustration.jpg">Wikipedia</a>.
  </figcaption>
</figure>
<p>Formal proofs cannot capture what I think when I think mathematics. The problem is that I cannot share my mathematical insights in their entirety since they are a complex combination of rational and emotional thought, intuitions, memory, successful failures and so on.</p>
<p>There might be a way to overcome this problem. Then again, there might be a better form of government than democracy.</p>
<hr>
<p><em>Comments</em>.</p>
<ul>
<li>
<p><strong>sam</strong>, 2011/10/08<br>
To me, &quot;formal proof&quot; means something even stronger: that it is written in a formal logic and that a simple computer can verify it.  Since this is out of the question for 99% of mathematics, the only thing we can do is choose a target audience and make ourselves as clear as possible to that audience.<br>
After that, it doesn't seem to me that there are any rules, only guidelines.  For instance, if you want to write &quot;a similar argument can be used to show...&quot; then go ahead, as long as it's really the case!</p>
<ul>
<li><strong>Peter</strong>, 2011/10/09<br>
Sam, I guess I should have written &quot;proof&quot; instead of &quot;formal proof&quot; so as not to lead logicians astray ;)<br>
What I'm after is a different. The concept of communicating mathematics among mathematicians is currently reduced to writing down proofs (and barely verifiable proofs as <a href="https://boolesrings.org/scoskey/peer-review-failure/">you pointed out</a>).<br>
But I think that's a bad situation. It is almost as bad as if describing a work of Picasso by saying &quot;he drew a black line here, then a red one there, then shaded some yellow in that area etc&quot; or by describing Bach's Cello Suite No 1 in terms of sheet music. It does not facilitate communication, understanding.<br>
I think the complexity of contemporary mathematics needs more than proofs. Proofs are a bad tool even if they are the best we have.
<ul>
<li><strong>sam</strong>, 2011/10/09<br>
Maybe we should start a list of things that are missing from a purely theorem-proof style exposition. Motivation and history would certainly be on the list. But I would also include a discussion of how to find the proof. Sometimes this is easy to extract from an argument, but not always.
<ul>
<li><strong>Peter</strong>, 2011/10/10<br>
Sam, that’s a fantastic idea!</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Felix Breuer</strong>, 2011/10/10<br>
Hi Peter! I share your critical view of &quot;formal&quot; proofs as a tool for communicating mathematics on many levels. If I understand you correctly, then &quot;all ways of communicating mathematics suck - formal proofs just suck less&quot;, which is why we use them. (That quote originally referred to the mail client mutt.) However, I do not think that formal proofs are the way to communicate mathematics that &quot;sucks least&quot;.<br>
While teaching <a href="http://blog.felixbreuer.net/2011/08/23/visualising-numbers-part1.html" rel="nofollow">my course</a>, I have put in a great deal of work to make every proof intuitively convincing and I like to believe that I have been at least occasionally successful. Of course, sometimes what was &quot;intuitive&quot; to me, was not intuitive at all to my students. In these cases, however, substituting a formal proof for my intuitive explanation was no help at all.<br>
I view &quot;formal&quot; proofs as one end of a spectrum, with &quot;handwaving&quot; being the other end. In a good proof, the &quot;formal version&quot; and the &quot;handwaving intuition&quot; will be close together, and so the proof will communicate both the correctness of the assertion in question as well as provide some intution that it is true. Coming up with good proofs is much harder even than coming up with proofs at all! So in many cases, all you can do is pick a point somewhere in the middle of this interval.<br>
You may want to err on the side of formality in two cases: 1) You want to make sure that nobody can say your result is false. (This is what happens often in research talks and papers. 2) Your intuition about the subject is so far away from your audience's intution that communication becomes too error prone. (Using formalism is the only way that you can avoid misunderstandings.)<br>
I think there are many &quot;good proofs&quot; out there and I believe that many classic text-book proofs can be made &quot;better&quot; in this sense. However, I am thinking about geometry, mostly, which is close to human intuition to begin with. In set theory, I can well imagine that formalism truly is mathematics' &quot;democracy&quot;.<br>
I just came across a nice quote by Joe Hurd that summarizes these sentiments nicely: &quot;Mathematics is no more about formulas than astronomy is about telescopes.&quot; See <a href="http://www.gilith.com/research/talks/ignite2010.pdf" rel="nofollow">here</a>.</p>
<ul>
<li><strong>Peter</strong>, 2011/10/10<br>
Felix, so many ideas in this stream of yours. It might make a new post to reply to all of them.<br>
Let me first defend semi-formal proofs as they are common in papers. They serve their purpose much like experimental data in science: they are neutral, “objective” (well, not really either — just like experimental data…). I want to get rid of them as little as I want to get rid of democracy. But I wouldn’t mind putting them in the appendix.<br>
I got somewhat confused by your use of “proof” in your comment — it appears in all kinds of contexts. As you know I despise the whole “proofs from the book” idea. But I like hand-waving (especially yours). You also wrote that it’s hard to come up with good proofs. I agree! But I’m more after what Sam mentioned: additional tools that help bridge the gap between us.<br>
What I really want is to counteract the phenomenon you describe: students having to fall back to a formal proof because their intuitions are not on par with yours yet. How silly is it that we teach students formalized proofs instead of building their intuitions? Much like school, we’re doing it backwards. Understanding one result truly is worth more than cramming a hundred results.<br>
PS: I took the liberty of editing your comment (some obvious typos).
<ul>
<li><strong>Felix Breuer</strong>, 2011/11/04<br>
Just had a great discussion with two of my students! We spent an hour trying to come up with the right picture for illustrating <em>one</em> theorem. That is the way to go! :)<br>
So, yes, I agree completely: We should focus on building students’ intuition!</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Becky!</strong>, 2011/10/11<br>
Wow, the mobile version of this site is looking awesome, P.!<br>
Anyway, Will and I were just talking about something similar Sunday afternoon. It is really frustrating when papers have errors in them (that we grad students are too dumb to catch ^^;). PDFs of the original papers should link to errata or something… It can’t be that difficult to do, can it? Maybe I’m just naive.</p>
<ul>
<li><strong>Peter</strong>, 2011/10/11<br>
Thanks for the feedback Becky :)<br>
I think you’re making a very good point. You’re right that PDFs could easily include errata. Maybe we’re too eager in that it was hard enough to get jstor running and processing errata (if they actualy exist in a sensible form) might still be too much to ask.<br>
But that this is also the case with current papers is, I think, just another sign that publishing industry is still stuck in 1990. So even if it’s naivity it is more than called for since it reflects what’s possible today (and has been for a decade).</li>
</ul>
</li>
<li>
<p><strong>Thilo</strong>, 2011/10/17<br>
I would like to add a quote and a personal viewpoint. The quote is by the late third Earl Russell(Mysticism&amp;Logic&amp;other essays/Mathematics&amp;Metaphysicians) and goes like that:</p>
<blockquote>
<p>It is not easy for the lay mind to realize the importance of symbolism in discussing the foundations of mathematics, and the explanation may perhaps seem strangely paradoxical. The fact is that symbolism is useful because it makes things difficult. What we wish to know is, what can be deduced from what. Now, in the beginnings, everything is self-evident; and it is very hard to see whether one self-evident proposition follows from another or not. Obviousness is always the enemy to correctness. Hence we invent some new and difficult symbolism, in which nothing seems obvious.<br>
To me this seems to be true not only when speaking about the foundations of mathematics(which is what Russell did) but in fact in a far more general sense. My impression is that it is far more difficult for the right side of my brain to explain some mathematical insight to the left side than for the left side to explain it to someone else(‘s left side ;-)). However how do you communicate if not by language which seems to be pretty inherently linear and not holistic. So in a sense I think there is a problem here which we cannot solve without severe changes to our brain-organisation. I also think that this time-consuming process of translation of a linguistic description of a mathematical fact into a picture and back is really at the heart of the training of a mathematician. My impression also is that in cases where intuition and formalism are somewhat not on a par, i.e. one has proof but not a “nice” proof I find the result all the more interesting.</p>
</blockquote>
<p>Apart from this slight criticism I tend to fully agree with what has been said.<br>
Also I would be interested in what exactly you, Peter, mean by “I despise the whole “proofs from the book”-idea. I would like to know whether I agree or disgree with you.<br>
Disclaimer: I’m not a neurologist and apologize for any misinterpretations resluting from misunderstandings.</p>
<ul>
<li><strong>Peter</strong>, 2011/10/17<br>
Thanks for the comment, Thilo. As I wrote, proofs are the best we have — but they often suck which, I think, reflects a fundamental flaw not random chance.<br>
Regarding your question, I do hope to write about the whole beauty/elegance/proofs-from-the-book topic sometime.<br>
PS: I edited your comment to reflect which part is a quote.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flat ultrafilters follow-up]]></title>
        <id>https://www.peterkrautzberger.org/0083/</id>
        <link href="https://www.peterkrautzberger.org/0083/">
        </link>
        <updated>2011-09-29T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>There are a couple of reasons to write a quick follow-up post to the <a href="https://www.peterkrautzberger.org/0082/" title="Flat Ultrafilters (Michigan Logic Seminar Sept 21, 2011)">notes for my talk on flat ultrafilters</a>.</p>
<h3>Small addenda included</h3>
<p>I updated <a href="https://www.peterkrautzberger.org/0082/">the notes</a> a little. Nothing much, some bad pictures and some comments.</p>
<h3>Video recording is online</h3>
<p>I uploaded my talk to vimeo -- find it embedded below or <a href="http://vimeo.com/29738390">look it up on vimeo</a>.</p>
<iframe src="https://player.vimeo.com/video/29738390" width="100%" height="375" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
<p><a href="http://vimeo.com/29738390">Flat Ultrafilters (2011/09/21 University of Michigan Logic Seminar)</a> from <a href="http://vimeo.com/user2937952">Peter Krautzberger</a> on <a href="http://vimeo.com/">Vimeo</a>.</p>
<h3>Flat ultrafilters and the Katetov order</h3>
<p>There's one thing worth stressing though. Remember <a href="https://www.peterkrautzberger.org/0082/" title="Flat Ultrafilters (Michigan Logic Seminar Sept 21, 2011)">when I wrote</a> that it's a little cheating to say that a flat ultrafilter is simply an ultrafilter on \([\omega]^{&lt;\omega}\) that extends a certain filter?</p>
<p>Instead of cheating, I should have talked about the <strong>Katetov order</strong>. Usually, the Katetov order is defined for ideals, but let me give the formulation for filters.</p>
<blockquote>
<p><strong>Definition</strong> If \(F,G\) are filters on \(X\). Then \(F\leq_K G\) if there exists a map \(f:X \to X\) such that (the filter generated by) \(f[G] \supseteq F\).</p>
</blockquote>
<p>For ultrafilters, this is of course the same as the Rudin-Keisler order. But for filters it is more general. If you confuse it with near coherence of filters, remember that near coherence asks only for coherence (the union generates a filter), not inclusion of the image (also, near coherence allows only finite-to-one functions).</p>
<p>In any case, we can now formulate flatness very easily. The key is the important filter that Farah, Philips and Steprans had identified in their construction for flat ultrafilters.</p>
<blockquote>
<p><strong>The flatness filter</strong> Let's define the flatness filter \(F\) on \([\omega]^{&lt;\omega}\) to be the filter generated by<br>
\[X_n := \{ s\in [\omega]^{&lt;\omega}: |s|\geq n\ \}\]<br>
for all \(n \in \omega\) as well as<br>
\[X_f := \{s \in [\omega]^{&lt;\omega}: (\forall i &lt; |s|) f(s_i) &lt; s_{i+1} \}\]<br>
for \(f\in \omega^\omega\) increasing with \(f(0)>0\) -- where \((s_i)_{i \in |s|}\) is the natural enumeration of \(s\).</p>
</blockquote>
<p>Then it's easy to formulate flatness:</p>
<blockquote>
<p><strong>Flat ultrafilter</strong> An ultrafilter \(p\) (on some countable set) is flat if \(p\geq_K F\).</p>
</blockquote>
<p>Why is this true? The work with the original definition (simplifying the flatness scale) gave us something along the lines of &quot;\(p\) is isomorphic to an ultrafilter that extends \(F\)&quot; -- but together with the observation that Rudin-Keisler successors of flat ultrafilters are flat, we get the above.</p>
<p>Now this reformulation is not just the result of trying to understand (and simplify) the original definition. It also makes a few observations absolutely immediate. Let me jot down a few without proof</p>
<ul>
<li>Since \(F \geq_K Fr \otimes Fr\) (where \(Fr\) is the Fréchet filter on \(\omega\)), no flat ultrafilter can be a P-point.</li>
<li>Similarly, \(F\geq \otimes_n Fr\) and so this must hold for every flat ultrafilter.</li>
<li>In particular, this tells that there are infinitely many skies in the ultrapower of \(\omega\) of a flat ultrafilter.</li>
</ul>
<p>And so forth. But that's for another post if I get around to it.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flat Ultrafilters (Michigan Logic Seminar Sept 21, 2011)]]></title>
        <id>https://www.peterkrautzberger.org/0082/</id>
        <link href="https://www.peterkrautzberger.org/0082/">
        </link>
        <updated>2011-09-25T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Remember how our about page says that <a href="http://boolesrings.org/about/">Booles' Rings is about best practices</a> for an academic homepage? Ok, let's try one: making notes to talks available.</p>
<h2>Some introductory remarks</h2>
<blockquote>
<p>Skip this section if you only want mathematics.</p>
</blockquote>
<p>Wednesday, I gave a short talk about flat ultrafilters at our Logic Seminar here at the University of Michigan (as <a href="http://settheory.mathtalks.org/michigan-logic-seminar/">announced on Set Theory Talks</a>, the talk was recorded and the video <del datetime="2011-09-29T15:47:26+00:00">will be online eventually</del> is <a href="http://vimeo.com/29738390">now online</a>).</p>
<hr>
<iframe src="https://player.vimeo.com/video/29738390" width="100%" height="375" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
<p><a href="http://vimeo.com/29738390">Flat Ultrafilters (2011/09/21 University of Michigan Logic Seminar)</a> from <a href="http://vimeo.com/user2937952">Peter Krautzberger</a> on <a href="http://vimeo.com/">Vimeo</a>.</p>
<hr>
<p>When <a href="http://www.fields.utoronto.ca/programs/scientific/10-11/set_theory/">I visited Toronto in</a> June, <a href="http://www.math.yorku.ca/~ifarah/">Ilijas Farah</a> introduced me to this somewhat strange new type of utrafilter on \(\omega\). My talk this week was mostly about the results from a [2009 paper by Ilijas Farah, N. Christopher Philips and Juris Steprans](<a href="http://www.math.yorku.ca/~ifarah/Ftp/208_">http://www.math.yorku.ca/~ifarah/Ftp/208_</a> 2009_ 448_ OnlinePDF.pdf) [cite source='doi']10.1007/s00208-009-0448-z[/cite], but some of what I am going to write are insights I gained while discussing this notion with François Dorais and Andreas Blass. So, actually, this post is attempting another best practice: notes from reading a paper.</p>
<p>I would like to explain something about the result that P-points are not flat. When I started looking at [their paper](<a href="http://www.math.yorku.ca/~ifarah/Ftp/208_">http://www.math.yorku.ca/~ifarah/Ftp/208_</a> 2009_ 448_ OnlinePDF.pdf) with Francois Dorais, we first re-proved that selective ultrafilters are not flat -- instead of the (possibly stronger) functional analytic result from the paper we used the combinatorial definition of flat ultrafilters. Then we worked on improving that proof and, with Andreas's help, got it to work for P-points.</p>
<p>Only after all of this happened did we notice that at the very end, [the paper](<a href="http://www.math.yorku.ca/~ifarah/Ftp/208_">http://www.math.yorku.ca/~ifarah/Ftp/208_</a> 2009_ 448_ OnlinePDF.pdf) had already announced that they have a proof that P-points are not flat. Last week, Ilijas kindly send me <a href="http://db.tt/O2kyK0m">some slides</a> with further results on flat ultrafilters; even though the proof for P-points isn't in there I would guess from the formulation on the slides that our proofs are essentially the same.</p>
<p>Long story short, the proof &quot;P-points are not flat&quot; below is &quot;our&quot; proof even though the result (and most likely the proof) should be credited to at least Steprans (according to <a href="http://db.tt/O2kyK0m">the slides</a>).</p>
<p>I will focus on my own interpretation of these notions, i.e., my rephrasing of the definition of flat ultrafilters; they might look different from what you'll find in [their paper](<a href="http://www.math.yorku.ca/~ifarah/Ftp/208_">http://www.math.yorku.ca/~ifarah/Ftp/208_</a> 2009_ 448_ OnlinePDF.pdf) even though it is formally the same notion.</p>
<p>Alright, nuff said. My talk was designed to first sketch the main functional analysis result of their paper. So the first two sections will be void of much explanations or proofs. But they motivate why the notion of flat ultrafilter is as strange as it is -- it simply came out of those considerations.</p>
<h2>Some functional analysis</h2>
<p>Let \(H\) be a (the) separable, infinite dimensional Hilbert space, i.e., \[H\cong l_ 2(\omega) = \{ s: \omega \rightarrow \mathbb{C}, \sum_ {n\in \omega} \left\vert s_ n\right\vert ^2 &lt; \infty \}.\]</p>
<p>Then \(B(H)\) is the space of bounded, linear operators, i.e.,</p>
<p>\[ B(H) = \{ T: H\rightarrow H: T \mbox{ linear }, (\exists M)(\forall v\in H) \left\Vert Tv\right\Vert  \leq M\left\Vert v\right\Vert  \},\]</p>
<p>and \(K(H)\) the space of compact operators</p>
<p>\[K(H) = cl( \{ T \in B(H): T[H] \mbox{ finite dimensional } \}).\]</p>
<p>Finally, the [Calkin Algebra](<a href="http://en.wikipedia.org/wiki/Calkin_">http://en.wikipedia.org/wiki/Calkin_</a> algebra) is the quotient \(C(H) = B(H) / K(H)\).</p>
<p>Farah, Philips and Steprans were interested in the relative commutant of subalgebras \(A\subseteq B\): \[F_ A(B) = \{ a\in A: (\forall b\in B) ab=ba \}.\]</p>
<h2>The relative commutant in the ultrapower</h2>
<p>If $p \in \beta \omega $ is an ultrafilter, we can consider the norm-ultrapowers of \(B(H)\) and \(C(H)\) which I'll denote by \(B(H)^p, C(H)^p\). That is \[ B(H)^p = \ell_ \infty(B(H) / \{c \in \ell_ \infty(B(H)): \lim_ p \left\Vert c\right\Vert  = 0\}.\] (Similarly for \(C(H)^p\).)</p>
<p>Kirchberg had shown that \(F_ {C(H)^p}(C(H)) = \mathbb{C} \cdot 1\) regardless of \(p\) and asked it the analogous statement might be true of \(B(H)\).</p>
<p>As a response, Farah, Philips and Steprans showed that \(F_ {B(H)^p}(B(H))\) depends on the choice of \(p\) (under CH); the results from [their paper](<a href="http://www.math.yorku.ca/~ifarah/Ftp/208_">http://www.math.yorku.ca/~ifarah/Ftp/208_</a> 2009_ 448_ OnlinePDF.pdf) relevant to this talk are as follows.</p>
<blockquote>
<p><strong>Theorem</strong> ([Farah, Philips, Steprans](<a href="http://www.math.yorku.ca/~ifarah/Ftp/208_">http://www.math.yorku.ca/~ifarah/Ftp/208_</a> 2009_ 448_ OnlinePDF.pdf))</p>
<ul>
<li>
<p>If \(p\) is a <em>flat</em>  ultrafilter (see below), then \(F_ {B(H)^p}(B(H)) \neq \mathbb{C} \cdot 1\).</p>
</li>
<li>
<p>If \(p\) is selective, then \(F_ {B(H)^p}(B(H)) = \mathbb{C} \cdot 1\); in particular, selective ultrafilters are not flat.</p>
</li>
<li>
<p>Flat ultrafilters exist under ZFC.</p>
</li>
<li>
<p>It was announced that P-points are not flat.</p>
</li>
</ul>
</blockquote>
<p>Curious fact: under CH all ultrapowers of \(B(H)\) are isomorphic (via model theoretic arguments). Yet, by the above, if we take a flat and a selective ultrafilter, no such isomoprhism can map \(B(H)\) to \(B(H)\) (or else the relative commutants would be isomorphic). This is an odd situation.</p>
<blockquote>
<p>If you look at the recording you will, as usual, see lots of confusion on my part. In particular, I remembered that the first result in the theorem was an equivalence. It turned out that the paper does not say so and this is an open question. In my defence, the slides did give it as an equivalence.</p>
</blockquote>
<p>I'll only give the proofs of the last two statements as well as some further observations on flat ultrafilters.</p>
<h2>Flat ultrafilters</h2>
<p>What are flat ultrafilters? Well, let's first introduce the assisting structure of a flatness scale, a set of sequences in \([0,1]\).</p>
<blockquote>
<p><strong>Definition</strong><br>
A <em>flatness scale</em>  H is a countable subset of \[\{ h:\omega \rightarrow [0,1]: h(0) =1, \lim_ {i \rightarrow \infty} h(i)=0 \}.\]</p>
</blockquote>
<p><strong>Addendum</strong> Nothing spectacular so far -- a flatness scale is just a bunch of sequences converging to \(0\). As such they can have some wild behavior along the way -- but flat ultrafilters tame them.</p>
 <figure>
     <img alt="flatness scale" src="https://www.peterkrautzberger.org/assets/2011/flatness-scale.jpg">
     <figcaption>
       A flatness scale
     </figcaption>
 </figure>
<p>The original definition of flat ultrafilters is then phrased as follows.</p>
<blockquote>
<p><strong>Definition</strong> [[Farah, Philips, Steprans](<a href="http://www.math.yorku.ca/~ifarah/Ftp/208_">http://www.math.yorku.ca/~ifarah/Ftp/208_</a> 2009_ 448_ OnlinePDF.pdf)]<br>
An ultrafilter \(p\) is <em>flat</em>  if there is a flatness scale \(H = (h_ n: n\in \omega)\) such that for every increasing $f: \omega \rightarrow \omega $ with \(f(0) > 0\)<br>
\[\lim_ {n\to p} \left\Vert (h_ n - h_ n \circ f)\right\Vert _ \infty = 0.\]<br>
In other words, for every \(f\) as above and every \(\varepsilon>0\), we have \[\{n\in \omega: \sup_ i \left\vert h_ n(i) - h_ n(f(i))\right\vert  &lt; \varepsilon \} \in p .\]<br>
We then say that \(H\) is a <strong>flatness scale for p</strong>.</p>
</blockquote>
<p>One of the goals was to find out how I can best think about the notion of flat ultrafilters.</p>
<p><strong>Addendum</strong> What to make of this? The first observation is that flat ultrafilters have a flatness scale such that, given \(\varepsilon\), almost all of the sequences (with respect to the ultrafilter) drop by at most \(\varepsilon\). That's slow, but it's even slower! The functions \(f\) in the definition should be thought of as vastly increasing (think: dominating family) and they code huge intervals of the form \([n,f(n)]\). But even given those vast intervals, still almost all sequences of the flatness scale drop only by \(\varepsilon\) on such long intervals. In other words, they never really drop by much, yet they converge to \(0\).</p>
<figure>
    <img alt="flat ultrafilter" src="https://www.peterkrautzberger.org/assets/2011/flatness-ultrafilter.jpg">
    <figcaption>
      A flat ultrafilter flattening a map
    </figcaption>
</figure>
<p>One of the things I found irritating was to think of them as ultrafilters on \(\omega\). Thankfully, the enumeration of \(H\) does not matter much. In other words, I don't have to think of \(p\) as an ultrafilter on \(\omega\) that just happens to come with a map to a flatness scale \(H\) -- I can really think of \(p\) to be an ultrafilter on \(H\). So allow me to re-phrase.</p>
<blockquote>
<p><strong>Definition</strong> [reformulation] Given a flatness scale \(H\) and an ultrafilter \(p\) on \(H\), we say that \(p\) is <em>flat</em> , if for every increasing \(f:\omega\to\omega\) with \(f(0) > 0\) and every \(\varepsilon>0\), \[\{ h \in H: \sup_ i \left\vert h(i) - h (f(i))\right\vert &lt; \varepsilon \} \in p .\]<br>
In other words, \[\lim_ {p} \left\lVert h - h \circ f)\right\rVert_ \infty = 0.\] Here \(\lim_ p\) is the usual limit along the ultrafilter \(p\).</p>
</blockquote>
<p>You might wonder if we're not loosing too much information -- after all, the original definition did not forbid repetitions. We'll see later that this is not a problem. For now, I will simply stick to the reformulation.</p>
<p>First there's an obvious question about how complicated a flatness scale can be. So let me show you [their construction](<a href="http://www.math.yorku.ca/~ifarah/Ftp/208_">http://www.math.yorku.ca/~ifarah/Ftp/208_</a> 2009_ 448_ OnlinePDF.pdf) of flat ultrafilters.</p>
<h2>Constructing Flat Ultrafilters</h2>
<h3>A simple observation</h3>
<p>For the construction of flat ultrafilters, the key observation is as follows: all we have to do is <strong>find a flatness scale</strong> \(H\) such that the sets \[X_ {f,\varepsilon} = \{h \in H : \sup_ i\left\vert h(i) - h (f(i)\right\vert  &lt; \varepsilon \}\]<br>
are <strong>infinite</strong> for every increasing \(f:\omega\to\omega\) with \(f(0) > 0\) and every \(\varepsilon > 0\).</p>
<p>Once we have this, we get the finite intersection property for free since \[X_ {\max(f_ 1,f_ 2),\min(\varepsilon_ 1,\varepsilon_ 2)} \subseteq X_ {f_ 1,\varepsilon_ 1} \cap X_ {f_ 2,\varepsilon_ 2}.\]</p>
<p>In other words, any ultrafilter \(p\) containing all the sets \(X_ {f,\varepsilon}\) is flat -- witnessed by the flatness scale \(H\).</p>
<p>Luckily, It turns out that there is an extremely simple flatness scale with this property.</p>
<blockquote>
<p><strong>Proposition</strong> [[Farah, Philips, Steprans](<a href="http://www.math.yorku.ca/~ifarah/Ftp/208_">http://www.math.yorku.ca/~ifarah/Ftp/208_</a> 2009_ 448_ OnlinePDF.pdf)] There is a flatness scale \(H\) such that the set<br>
\[X_ {f,\varepsilon} = \{h \in H : \sup_ i \vert h(i) - h(f(i)\vert  &lt; \varepsilon \}\]<br>
is infinite for every increasing \(f:\omega\to\omega\) with \(f(0) > 0\) and every \(\varepsilon > 0\).</p>
</blockquote>
<p><strong>Proof</strong></p>
<ul>
<li>
<p>Consider the finite subsets of \(\omega\), \([\omega]^{&lt;\omega}\).</p>
</li>
<li>
<p>We can think of \(s\in [\omega]^{&lt;\omega}\) as encoding a simple step function, dropping by $1/\vert s\vert $ at each of the elements of \(s\); in other words, we define \(h_ s : \omega \rightarrow [0,1]\) by<br>
\[ h_ s(i) = 1- \frac{\vert s\cap i\vert }{\vert s\vert }.\]</p>
</li>
<li>
<p>Clearly, \(H_ S := \{ h_ s: s \in [\omega]^{&lt;\omega} \}\) is a flatness scale (starting at \(1\) and converging to zero, in fact being eventually zero).</p>
</li>
<li>
<p>Now imagine we're given some increasing \(f:\omega\to\omega\) with \(f(0) > 0\) as well as some \(\varepsilon >0\).</p>
</li>
<li>
<p>Then we can easily find infinitely many \(s \in [\omega]^{&lt;\omega}\) with the following properties:</p>
<ul>
<li>\(1/\vert s\vert  &lt; \varepsilon\)</li>
<li>With the natural enumeration of \((s_ i)_ {i\in \vert s\vert }\) of \(s\), \[s(i+1) \geq f(s(i))\] for each $i &lt; \vert s\vert $.</li>
</ul>
</li>
<li>
<p>But this means that for all \(i\), \[h_ s(f(i)) \geq h_ s(i+1) = \frac{1-\vert s\cap (i+1)\vert }{\vert s\vert }.\]</p>
</li>
<li>
<p>It follows that \(\sup_ i \vert h_ s(i) - h_ s(f(i))\vert  \leq 1/\vert s\vert  &lt; \varepsilon\).</p>
</li>
<li>
<p>Since we can find infinitely many such \(s\), the sets \(X_ {f,\varepsilon}\) are all infinite.</p>
</li>
</ul>
<p>Combining this with the previous observation we have.</p>
<p><strong>Corollary</strong> ([Farah, Philips, Steprans](<a href="http://www.math.yorku.ca/~ifarah/Ftp/208_">http://www.math.yorku.ca/~ifarah/Ftp/208_</a> 2009_ 448_ OnlinePDF.pdf))<br>
There is a flat ultrafilter via the above flatness scale \(H_ S\). (Let's keep that name.)</p>
<h2>Some easy observations</h2>
<p>Let's try to get a feel for what we can actually expect from a flat ultrafilter.</p>
<p>For example, a <strong>flat ultrafilter must be non-principal</strong> -- otherwise the flatness scale is just one map and it's easy to find \(f:\omega \rightarrow \omega\) that drops faster than a single sequence \(h\)!</p>
<h3>Flatness scales are simple</h3>
<p>The above results from [Farah, Philips and Steprans](<a href="http://www.math.yorku.ca/~ifarah/Ftp/208_">http://www.math.yorku.ca/~ifarah/Ftp/208_</a> 2009_ 448_ OnlinePDF.pdf) is surprising: at first since the flatness scale is extremely simple! It's only natural to ask how complicated flatness scales can really be. Luckily, it's always this easy!</p>
<blockquote>
<p><strong>Proposition</strong> If \(p\) is flat, then \(H_ S\) as above is a flatness scale for \(p\).</p>
</blockquote>
<p><strong>Proof</strong></p>
<ul>
<li>
<p>Assume we have a flatness scale for \(p\), say \(H = (h_ n: n\in \omega)\) with some fixed enumeration of \(H\).</p>
</li>
<li>
<p>We can define another flatness scale as follows: simply choose \(h'_ n(i)\) to be a multiple of \(1/n\) closest to \(h_ n(i)\), i.e., minimize $\vert h_ n(i) - j/n\vert $.</p>
</li>
<li>
<p>Clearly, \(h'_ n \in H_ S\).</p>
</li>
<li>
<p>Then \((h'_ n : n\in \omega)\) (and hence \(H_ S\)) is a flatness scale for \(p\)!</p>
<ul>
<li>For \(f,\varepsilon\) as in the defintion for flatness, we know \[\{ n: \sup_ i \vert h_ n(i) - h_ n(f(i)\vert  &lt; \varepsilon / 3 \} \in p.\]</li>
<li>But \(\vert h'_ n(i) - h'_ n(f(i))\vert  \leq \vert  h_ n(i) - h_ n(f(i)\vert  + 2/n\).</li>
<li>Since all but finitely many \(n\) have \(1 / n &lt; \epsilon / 3\) we have \[\{ h_ n: \sup_ i \vert h'_ n(i) - h'_ n(f(i)\vert  &lt; \varepsilon \} \supseteq^* \{ h_ n: \sup_ i \vert h_ n(i) - h_ n(f(i)\vert  &lt; \varepsilon / 3 \}.\]</li>
<li>In other words, both sets lie in \(p\) -- as desired.</li>
</ul>
</li>
</ul>
<p>The above proposition tells us that we can now think of flat ultrafilters as simply living on \([\omega]^{&lt;\omega}\), extending a certain filter -- I don't know about you, but for me that's much easier to picture. We can, therefore, re-phrase our definitions.</p>
<blockquote>
<p><strong>Definition revisited</strong>. An ultrafilter \(p\in \beta( [\omega]^{&lt;\omega}) \cong \beta \omega\) is flat if for all \(f:\omega \rightarrow \omega\) with \(f(0)>0\) and \(\varepsilon>0\),<br>
\[\{ s \in [\omega]^{&lt;\omega}: \sup_ i \vert h_ s (i) - h_ s(f(i))\vert  &lt; \varepsilon \} \in p .\]</p>
</blockquote>
<p>We're still sort of hiding the fact that we can vary the bijection between \([\omega]^{&lt;\omega}\) and \(\omega\). But I still think this phrasing simplifies things a little.</p>
<h3>Convergence in the colums</h3>
<p>The next important observation is that in each coordinate \(i\), the values of the flatness scale at \(i\) for a flat ultrafilter must converge to \(1\) (along the ultrafilter).</p>
<blockquote>
<p><strong>Lemma</strong> If \(p\) is flat, then \(\lim_ {s\rightarrow p} h_ s(k) = 1\) for all \(k \in \omega\).</p>
</blockquote>
<p><strong>Proof</strong></p>
<ul>
<li>
<p>Suppose \(\lim_ {s\to p} h_ s(k) &lt; 1 - \varepsilon\) for some \(k \in \omega\) and \(1> \varepsilon > 0\).</p>
</li>
<li>
<p>In other words, \(X := \{ s: h_ s(k) &lt; 1 - \varepsilon \} \in p\).</p>
</li>
<li>
<p>Pick some \(f:\omega\to\omega\), increasing with \(f(0) = k\) (note \(k > 0\) since \(h_ s(0) = 1\)).</p>
</li>
<li>
<p>Then<br>
\[ \sup_ i\vert h_ s(i) - h_ s (f(i)) \vert  \geq \vert h_ s(0) - h_ s(k)\vert  = 1 \geq \varepsilon \]<br>
for every \(n \in X\).</p>
</li>
<li>
<p>In other words, $ X \subseteq { s \in [\omega]^{&lt;\omega}: \sup_ i \vert h_ s (i) - h_ s(f(i))\vert  \geq \varepsilon }$</p>
</li>
<li>
<p>But this contradics \(\{ s \in [\omega]^{&lt;\omega}: \sup_ i \vert h_ s (i) - h_ s(f(i))\vert  &lt; \varepsilon \} \in p\).</p>
</li>
</ul>
<h2>A proof that P-points are not flat.</h2>
<blockquote>
<p>In [their paper](<a href="http://www.math.yorku.ca/~ifarah/Ftp/208_">http://www.math.yorku.ca/~ifarah/Ftp/208_</a> 2009_ 448_ OnlinePDF.pdf) Farah, Philips and Steprans announced that P-points are not flat. Francois, Andreas and I overlooked that statement and re-proved the result as follows. (See also the comments at the beginning as well as later.)</p>
</blockquote>
<p>Suppose for this section that \(p\) is a flat \(P\)-point as witnessed by \(H_ S\).</p>
<p>As the first step, we will improve the p-convergence from earlier to actual convergence, i.e., \(p\) contains \(H\subseteq H_ S\) that satisfies \(\lim_ {s\in H} h_ s(k) = 1\) for every \(k\).</p>
<p>In the second step, we will show that no ultrafilter can have such a flatness scale.</p>
<blockquote>
<p><strong>Lemma</strong> If \(p\) is a flat P-point, then \(p\) contains \(H\subseteq H_ S\) that satisfies \(\lim_ {s\in H} h_ s(k) = 1\) for every \(k\).</p>
</blockquote>
<p><strong>Proof</strong></p>
<ul>
<li>Since \(\lim_ {s\to p} h_ s(k) = 1\) for all \(k\) we know that \[X_ {k,l} := \{ s: h_ s(k) \geq 1 - 2^{-l} \} \in p,\] for all \(k,l \in \omega\).</li>
<li>Since \(p\) is a P-point, we find \(H \in p\) such that \(H \subseteq^* X_ {k,l}\) for all \(k, l \in \omega\).</li>
<li>But that means precisely that \(H\) has \(\lim_ {s\in H} h_ s(k) = 1\) for every \(k\).</li>
<li>Of course, restricting to \(H\) does not change the fact that \[\lim_ {n\to p} \sup_ i\vert h_ s(i) - h_ s(f(i))\vert  = 0\] holds for every increasing function \(f:\omega\to\omega\) with \(f(0) > 0\) -- so we're done.</li>
</ul>
<p>We may thus suppose that our original flatness scale satisfies \(\lim_ {n\to\infty} h_ n(k) = 1\) for every \(k\). But this is impossible for any ultrafilter!</p>
<blockquote>
<p><strong>Lemma</strong> No ultrafilter \(p\) has a flatness scale \(H\) with \(\lim_ {h\in H} h(k) = 1\).</p>
</blockquote>
<p><strong>Proof.</strong></p>
<ul>
<li>
<p>Else, for any fixed \(\color{red}k\), there are only finitely many \(\color{blue}h\) such that \(h(k) &lt; 3/4\).</p>
</li>
<li>
<p>For these finitely many \(\color{blue}h\), there is a common \(\color{violet}\ell\) (depending only on \(\color{red}k\)) such that \(\color{blue}h(\color{violet}\ell) = 0\), and thus \(h(m) =0\) for all \(m \geq \color{violet}\ell\).</p>
</li>
<li>
<p>In other words, we can define \(\color{violet}f:\omega\to\omega\) be an increasing function with \(\color{violet}f(0) > 0\) such that if \(h(k) &lt; 3/4\) then \(h(\color{violet}f(k)) = 0\).</p>
</li>
<li>
<p>Since \(H\) is a flatness scale, we have that \[\{h : (\forall k)(h(k) - h(\color{violet}f(k)) \leq 1/4)\} \in p.\]</p>
</li>
<li>
<p>So pick one of those \(\color{blue}h\), i.e., with \(\color{blue}h(k)-\color{blue}h(\color{violet}f(k)) \leq 1/4\) for all \(k\).</p>
</li>
<li>
<p>For this fixed \(\color{blue}h\) we can, of course, find the first \(\color{red}k\)such that \(\color{blue}h(\color{red}k) &lt; 3/4\). (Note that \(\color{red} k > 0\) since \(\color{blue}h(0) = 1\).)</p>
</li>
<li>
<p>Since \(\color{blue}h(\color{red}k-1) \geq 3/4\) and \(\color{violet}f(\color{red}k-1) \geq \color{red}k\), we see that \[\color{blue}h(\color{blue}k-1) - \color{blue}h(\color{red}k) \leq \color{blue}h(\color{red}k-1) - \color{blue}h(\color{violet}f(\color{red}k-1)) \leq 1/4\] by our choice of \(h\).</p>
</li>
<li>
<p>Therefore, \(\color{blue}h(\color{red}k) \geq 1/2\).</p>
</li>
<li>
<p>By choice of \(\color{violet}f\), we have that \(\color{blue}h(\color{violet}f(\color{red}k)) &lt; 1/4\) and hence \(\color{blue}h(\color{red}k) - \color{blue}h(\color{violet}f(\color{red}k)) > 1/2 - 1/4 = 1/4\) -- which contradicts our choice of \(h\)!</p>
</li>
</ul>
<h2>Flat ultrafilter and rapidity</h2>
<p>Since selective ultrafilters are not flat, I was for the longest time under the impression that Q-points and, more generally, rapid ultrafilters might be connected.</p>
<p>(Un)fortunately, this is not the case. An easy argument yields flat but rapid ultrafilters.</p>
<blockquote>
<p><strong>Proposition</strong> If \(p\) is flat and \(p \leq_ {RK} q\), then \(q\) is flat. By contraposition, if \(q\) is not flat, then \(p\) is not flat.</p>
</blockquote>
<p><strong>Proof.</strong></p>
<ul>
<li>If \(H_ S\) is a flatness scale for \(p\) and \(g:[\omega]^{&lt;\omega} \rightarrow [\omega]^{&lt;\omega}\) with \(g(q)=p\), then \(H_ {g[S]}:=\{ h_ {g(s)} :s \in \omega^{&lt;\omega} \}\) is a flatness scale for \(q\).
<ul>
<li>Given \(f\) and \(\varepsilon\), simply calculate \[\{ s : \sup_ i \vert h_ {g(s)}(i) - h_ {g(s)}(f(i))\vert  &lt; \varepsilon \} = g^{-1} [ \{ s : \sup_ i \vert h_ s(i) - h_ s(f(i))\vert  &lt; \varepsilon \}] \in q. \]</li>
</ul>
</li>
</ul>
<p>This is all we need.</p>
<blockquote>
<p><strong>Proposition</strong> If there exists a rapid ultrafilter, there exists an ultrafilter both flat and rapid.</p>
</blockquote>
<ul>
<li>Take \(p\) rapid, and \(q\) flat.</li>
<li>Then \(q \otimes p\) is rapid and flat
<ul>
<li>Flat, since \(q\otimes p \geq_ {RK} q\).</li>
<li>By a folklore exercise, if \(p\) is rapid, then any \(q\otimes p\) is rapid.</li>
</ul>
</li>
</ul>
<blockquote>
<p>That's about all I actually covered in my talk. There might be a continuation at a later point.</p>
</blockquote>
<hr>
<p><strong>2011/09/29</strong> I added some badly drawn pictures and additional comments (preceded by &quot;Addendum&quot;)</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hindman’s Theorem, partial semigroups and some of my most lacking intuitions (part 7)]]></title>
        <id>https://www.peterkrautzberger.org/0081/</id>
        <link href="https://www.peterkrautzberger.org/0081/">
        </link>
        <updated>2011-09-21T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Hm, my writing process is slowing down a little (and on top of that I forgot to publish this draft) and there are other posts that I really want to write. I'm not really sure how I will proceed, but let's keep pushing a little further for now. <a href="https://www.peterkrautzberger.org/0080/">Last time</a> I tried to build a bridge from central sets via idempotent ultrafilters back to partial semigroups. This is one of the key points of this series: connecting central sets and partial semigroups.</p>
</blockquote>
<h2>Back to partial semigroups</h2>
<p>Here we are, lots of great results in our back, yet missing the perfect correspondence between Ramsey-type theorems and partition regular sets (or put differently, ultrafilters). I started out with the notion of (adequate) partial semigroups and now, I think, is the time to return to it.</p>
<p>I believe that a notion of partial semigroup could help solve this mysterious question. The goal of this entire series is to investigate a potential relationship between partial semigroups and central sets.</p>
<h3>Minimal partial semigroups</h3>
<p><a href="https://www.peterkrautzberger.org/0077/">I tried to convince you earlier</a> that FS-sets are partial semigroups. They are, in fact, the minimal partial subsemigroups of \((\mathbb{N},+)\). Why is this? It's by a rather simple induction argument</p>
<ul>
<li>Say \((S,\cdot)\) is an adequate partial semigroup.</li>
<li>Take any \(s_ 0\in S\).</li>
<li>Inductively, \(FP(s_ 0,\ldots, s_ n)\) has all products defined.</li>
<li>Pick \(s_ {n+1} \in \bigcap_ {t \in FP(s_ 0,\ldots,s_ n)} \sigma(t)\) (<a href="https://www.peterkrautzberger.org/0076/">remember those \(\sigma(t)\)?</a>) -- since \(S\) was a partial semigroup, this intersection will never be empty.</li>
<li>Then all finite products of the \((s_ i : i\in \omega)\) are defined.</li>
<li>In other words, \(FP(s_ i) \subseteq S\) in the fullest sense.</li>
</ul>
<p>I don't think I ever mentioned that &quot;to include an FS-set&quot; (or FP-set) has an established abbreviation; such sets are called <em>IP-set</em> .</p>
<blockquote>
<p>Most people will find it important to point out that &quot;IP&quot; does not abbreviate &quot;idempotent&quot; (for idempotent ultrafilters) but was originally meant to abbreviate &quot;infinite parallelepiped&quot; (which makes sense if you think of FS-sets in vector spaces until you realize that this still means &quot;includes an infinite parallelepiped&quot;).</p>
</blockquote>
<p>So it seems that we could add some general nonsense by saying &quot;partial semigroup&quot; instead of &quot;IP-set/includes and FS-set&quot;. Unfortunately, this is not the case. Even though every partial semigroup contains and FS-set, not every set that contains an FS-set has a (compatible) partial semigroup structure.</p>
<blockquote>
<p>Oh dear, I just notice something and I hope I haven't made this mistake too often. I'm talking about FS-sets and \((\mathbb{N},+)\) here. So when I write &quot;partial semigroup&quot; for \(A\subseteq \mathbb{N}\), then I mean &quot;partial subsemigroup&quot; in the sense that the usual addition restricted to \(A\) forms a partial subsemigroup (as is the case for FS-sets). Oh well, I guess this series is getting too long after all and I'm beginning to loose track of what I've already written. I hope you might just enjoy reading it anyhow.</p>
</blockquote>
<h2>Weak partial semigroups</h2>
<p>I think the key to partial semigroups will be to weaken the notion further. I think I will call those &quot;weak partial semigroups&quot; (even though I'd love to call them &quot;very partial semigroups&quot;...).</p>
<blockquote>
<p>What I'm about to do is, I think, somewhat bad style. Let me alleviate this by some comments. Of course, the ideas in this series do not come out of nowhere. They stem from my studies in this area over the last 5 years (gee, has it really been that long?). Because of this, they are based on structures that you can frequently encounter in this area. So if you know the research area you will hopefully find all of this very familiar and think &quot;why does he make such a fuss about this standard thing?&quot;. That's great! And if you're not, rest assured there's a method to my madness. I'm not sure I will get there anytime soon, but there's still hope.</p>
</blockquote>
<p>In my silly demonstration above that partial semigroups contain FS-sets you may have noticed that we didn't really see strong associativity -- especially, since we're starting with a full semigroup anyway and have no worries about associativity.</p>
<p>What was however crucial is finite intersection property. And that's already all there is to this &quot;new&quot; notion.</p>
<blockquote>
<p><strong>Weak partial (sub)semigroup</strong> If \((S,\cdot)\) is a semigroup, then \(A\subseteq S\) is a <em>weak partial subsemigroup</em>, if the restriction of the partial semigroup operation to \(A\) is adequate, i.e., the sets of the form<br>
\[ \sigma_ A(a) := \{ b\in A : a\cdot b \in A\}\] generate a filter.</p>
<blockquote>
<p>Note: I just made up that \(\sigma_ A(a)\) notation to possibly help your understanding by making the connection to \(\sigma(a)\).. I will get to a more classical formulation in a second.</p>
</blockquote>
</blockquote>
<p>In other words, the operation restricted to (a partial operation on) \(A\) is, to some extent, a partial semigroup. We might not have the luxury of full associativity: a, b,c, abc, ab might be in such an A, but not bc (this actually happens in real life btw) -- so we cannot compare \(a(bc)\) with anything, in particular not with \((ab)c\).</p>
<p>But for any \(a\) we will find many (a filter set of) \(b\)'s and for each of those \(b\)'s we will find a filter set of \(c\)'s such that \(a,b,c,ab,bc, abc \in A\). That's pretty good, don't you think?</p>
<blockquote>
<p>I'm not sure what I'll do next. There are many paths to choose at this point. I'm not sure which one is best and I might just settle for the one that seems most easily self-contained. But don't worry even if the next post is on a different topic.</p>
</blockquote>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hindman’s Theorem, partial semigroups and some of my most lacking intuitions (part 6)]]></title>
        <id>https://www.peterkrautzberger.org/0080/</id>
        <link href="https://www.peterkrautzberger.org/0080/">
        </link>
        <updated>2011-09-15T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>I know, I know, it's part 6 already. <a href="https://www.peterkrautzberger.org/0079/">Last time</a> I finally formulated the Central Sets Theorem. This part will just be a small bridge. But at least you'll finally know why on earth I am writing this, i.e., what big open question I'm actually trying to build some intuitions for.</p>
</blockquote>
<h2>Central Sets and ultrafilters</h2>
<p>Before we can move on in this series I should tell you a little bit about the relationship between ultrafilters and central sets -- and finally give you something close to a definition.</p>
<p>If you <a href="https://www.peterkrautzberger.org/0077/">already believed me</a> that idempotent ultrafilters exist, you might also believe me that there's a special kind of idempotent ultrafilters, they are called <strong>minimal idempotents</strong>. The reason for the name &quot;minimal&quot; is a partial order on idempotents coming from ring theory. Yet again, we'll skip the definition -- I would first have to convince you that \(\beta \mathbb{N}\) is actually a semigroup and, again, I don't want to go there right now.</p>
<p>In any case, there are those idempotent ultrafilters which are minimal idempotents. As <a href="https://www.peterkrautzberger.org/0078/">I mentioned before</a>, Hillel Furstenberg had introduced the notion of central set via recurrence in dynamical systems. It took a couple of years until <a href="http://dx.doi.org/10.1090/S0002-9947-1990-0982232-5">in 1990 Vitaly Bergelson and Neil Hindman</a> helped establish that centrality can be framed extremely well in terms of ultrafilters.</p>
<blockquote>
<p><strong>Theorem (Bergelson, Hindman)</strong> \(A\subseteq \mathbb{N}\) is <em>central</em> iff \(A\) is in a minimal idempotent ultrafilter.</p>
</blockquote>
<p>This was, I think, quite a crazy and beautiful result at the time and its simplicity is still stunning (although, arguably, you won't agree since I didn't give you the complicated definition in terms of dynamics).</p>
<p>This leaves us with the following situation:</p>
<ul>
<li>central sets and minimal idempotents correspond neatly and</li>
<li>we have a Ramsey-type theorem (the Central Sets Theorem) that central sets fulfil</li>
</ul>
<p>This is not as optimal as it could be! If you remember, we were even better off with Hindman's Theorem:</p>
<blockquote>
<p>A set is contained in an idempotent ultrafilter if and only if it &quot;satisfies&quot; Hindman's Theorem (i.e., includes an FS-set).</p>
<p><strong>In fact</strong>, a set is an FS-set if and only if it is contained in an idempotent ultrafilter.</p>
</blockquote>
<p>Hindman's Theorem and idempotent ultrafilters corresponded directly. The unfortunate situation for central sets is that (as far as I know) no version of the Central Sets Theorem is able to accomplish a correspondence of the form</p>
<blockquote>
<p><strong>Wanted</strong> &quot;A set is included in a minimal idempotent ultrafilter (i.e., is a central set) if and only if it fulfills the following Central Sets Theorem&quot;</p>
</blockquote>
<p>This would be the dream, I think. And this is, in a manner of speaking, the whole point of this series. How can we get to this? As you may have guessed, I believe partial semigroups can help shed light on this. So I will return to them in the continuation.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hindman’s Theorem, partial semigroups and some of my most lacking intuitions (part 5)]]></title>
        <id>https://www.peterkrautzberger.org/0079/</id>
        <link href="https://www.peterkrautzberger.org/0079/">
        </link>
        <updated>2011-09-08T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p><a href="https://www.peterkrautzberger.org/0078/">Last time</a>, I left you hanging -- I promised the Central Sets Theorem, but only bothered you with some more stuff on partial semigroup, i.e., condensations. Let me make it up to you.</p>
</blockquote>
<h2>The Central Sets Theorems</h2>
<p>So what is this mysterious theorem that, even though ergodic in origin is so close to the heart of algebra in the Stone–Čech compactification? It is not easy to formulate, but luckily <a href="https://www.peterkrautzberger.org/0078/">I kept bugging you</a> with \(\mathbb{F}\) and condensations, so we are well prepared.</p>
<p>Since there are many different versions of the theorem as it has been improved and generalized over the last 30 years, the most general formulations are quite something to process. As you might remember, this series started out as an expository piece, so let's write down a very simple version first, even weaker than the very first version proved by Fürstenberg (but who knows, maybe that's the version he first noticed). Remember that central sets are some kind of partition regular sets (that I haven't even properly defined yet but who cares).</p>
<blockquote>
<p><strong>Central Sets Theorem (simple version)</strong> Let \(A\subseteq \mathbb{N}\) be a central set. Imagine I'm giving you some abitrary \(FS(x_n)\). Then you can find a \(FS(a_n) \subseteq A\) and \((s_n: n\in \omega)\) in \(\mathbb{F}\) such that<br>
\[ FS(a_n + \sum_{i\in s_n} x_i) \subseteq A. \]<br>
Just to repeat: if we set \(y_n = \sum_{i\in s_n} x_i\), then<br>
\[ FS(a_n + y_n) \subseteq A. \]</p>
</blockquote>
<p>This is quite odd, no? Even though the sequence \((x_n : n\in \omega)\) has nothing to do with \(A\), the central set can &quot;gobble it up&quot;. As is to be expected, \(A\) cannot &quot;gobble it&quot; up all of it, but there's a full condensation that can be translated into \(A\) in a rather peculiar fashion. Somehow, \(A\) is able to reproduce a shifted version of the algebraic structure of the FS-set.</p>
<p>Well, it gets even better. The original theorem allows us to &quot;iterate&quot; this result in a strong way.</p>
<blockquote>
<p><strong>Central Sets Theorem (less simple version)</strong> Let \(A\) be a central set. This time, I'm giving you finitely many \(FS(x_n^0),\ldots FS(x_n^k)\). Not only can you get the above version for each sequence, but you can get them &quot;together&quot;:</p>
<p>You can find a single \(FS(a_n) \subseteq A\) and a single \((s_n: n\in \omega)\) in \(\mathbb{F}\) such that for all $ j &lt; k$ simultaneously \[ FS(a_n + \sum_{i\in s_n} x_i^j) \subseteq A. \]<br>
Again repeat: if we set \(y_n^j = \sum_{i\in s_n} x_i^j\), then for all \(j&lt;k\)<br>
\[ FS(a_n + y_n^j) \subseteq A. \]</p>
</blockquote>
<p>The crucial strength is that all the \(y_n^j\) are constructed using the one fixed sequence of \(s_n\)'s -- regardless of the given sequences! That's crazy! Even though the sequences \((x_n^j)\) are completely unrelated, we will find condensations uniformly and translate by the same sequence of \(a_n\)'s.</p>
<p>Ok, maybe this difference is a bit subtle at first, but it is quite potent. For example, we immediately get van der Waerden's Theorem!</p>
<blockquote>
<p><strong>van der Waerden's Theorem (sort of)</strong> If \(A\) is central and some \(l\in \omega\) given, we can find an an arithmetic progression of length \(l\) in \(A\), i.e., there exists \(a\in A\) and \(d\in \mathbb{N}\) such that \[ a, a+d, \ldots, a+ l\cdot d \in A.\]<br>
In fact, we can find the increment \(d\) in any prescribed FS-set!</p>
</blockquote>
<p>This last sentence is kind of cool: you want the increment to be a multiple of 10? 42? A gazillion? No problem!</p>
<p>Let's derive this from the Central Sets Theorem. I know it's a bit meaningless without having seen the proof of the Central Sets Theorem (which is, by the way, very elegant using ultrafilters and I hope I'll get around to it)</p>
<p><strong>Proof.</strong> Well, the &quot;in fact&quot; should be taken as a hint. So I give you some length \(l\) for the arithemetic progression and as well as one FS-set, say \(FS(x_n)\); you want to find an arithmetic progression in \(A\) by some increment \(d\in FS(x_n)\).</p>
<p>In other words, you're trying to make \(d, 2d, \ldots, d \cdot l\) work. The idea is to look at the sequences \((j\cdot x_n: n \in \omega)\) to apply the version of the Central Sets Theorem that allows for finitely many FS-sets.</p>
<p>What does it give you? Well, you get a lot of \(a\in A, s\in \mathbb{F}\) (a sequence/FS-/FP-set whatever, but let's just take one of each) such that<br>
\[a + \sum_{i \in s} j\cdot x_i = a +j \sum_{i\in s} x_i \in A\] for each $j &lt; l $ -- oh but that's an arithmetic progression with increment \(d= \sum_{i\in s} x_i\), so we're <strong>done</strong>!</p>
<p>Look at how much more we have, though. We can predescribe the FS-set to pick from, we get an FS-set (induced by the FP-set) we get an FS-set of starting points and so forth.</p>
<p>This was but a first taste. The Central Sets Theorem can be pushed much further. With some restrictions a central set can &quot;gobble up&quot; infinitely many FS-sets, it can be proved for commutative semigroups and, in a much more complicated version, for non-commutative semigroups. But we'll stop here for now.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hindman's Theorem, partial semigroups and some of my most lacking intuitions (part 4)]]></title>
        <id>https://www.peterkrautzberger.org/0078/</id>
        <link href="https://www.peterkrautzberger.org/0078/">
        </link>
        <updated>2011-09-07T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Well, I hope you didn't miss me while I was on my first summer vacation in three years. So let's continue this series. If you remember, <a href="https://www.peterkrautzberger.org/0077/">part 3</a> consisted mainly of the observation that FS-sets have a partial semigroup structure induced by \(\mathbb{F}\) as well as me telling you that there's a immediate correspondence between FS-sets and idempotent ultrafilters.</p>
</blockquote>
<p>I'm slowly getting where I wanted to head all along with this series. When I write &quot;my most lacking intuitions&quot; in the title, I have my intuitions about central sets in mind. They are most lacking, I assure you. But with this series I wanted to clear my head a little. So let's head down the rabbit hole, no questions asked.</p>
<h2>Towards the Central Sets Theorem</h2>
<p>The Central Sets Theorem was conceived by <a href="http://en.wikipedia.org/wiki/Hillel_F%C3%BCrstenberg">Hillel Fürstenberg</a>. I know relatively little about its history so I am still amazed by the fact that anyone could come up with it -- it's such a strange creature. Fürstenberg proved it for \(\mathbb{Z}\) (but I'll keep considering \(\mathbb{N}\), the two situations are equivalent anyway). The notion of centrality has its origins in ergodic theory -- unsurprisingly for Furstenberg. As fascinating and fruitful as the connection between ergodic Ramsey theory and Algebra in the Stone–Čech compactification is, I don't plan to introduce the technology in this series, because it will take us too far from the path I have in mind (mind you, I haven't even introduced the semigroup structure on \(\beta \mathbb{N}\), so really, I shouldn't introduce the ergodic point of view of which I know far less).</p>
<p>Fürstenberg devised the notion of <strong>central set</strong> (for subsets of \(\mathbb{N}\)) which was determined by recurrence phenomena in dynamical systems. Again, I don't want to discuss the dynamical point of view but I'll give the ultrafilter characterization later. The key for a connection to Ramsey theory was simple.</p>
<blockquote>
<p><strong>Theorem (Fürstenberg)</strong> Central sets (whatever they are) are partition regular.</p>
</blockquote>
<p>Whatever central sets are (sorry for being temporarily mysterious), it is shocking how much algebraic structure central sets have to offer -- which is what the Central Sets Theorem is all about. It took a while and until Neil Hindman and Vitaly Bergelson made the connection between the algebraic/ultrafilter side and the ergodic side apparent. Nevertheless, the precise level of the algebraic closure of central sets is still a mystery. And this mystery is the reason for this series.</p>
<h2>A detour: FP-sets and their condensations</h2>
<p>One thing we should do before formulating the theorem is the following. What does an FS-set mean in the context of \(\mathbb{F}\)? Generally speaking, in a (partial) semigroup we have FP-sets (&quot;finite products&quot; instead of &quot;finite sums&quot;): given a sequence \((x_n: n\in \omega)\) we write</p>
<blockquote>
<p>\[ FP(x_n) = { \prod_{i \in s} x_i: s \in \mathbb{F} }. \]</p>
</blockquote>
<p>Of course, in the partial semigroup scenario, we should also think of this as a statement restricted to defined products. However, usually (e.g., in Hindman's Theorem) all products will be defined. Also, in the non-commutative case (which I wholeheartedly ignore in this series), this notation is supposed to be read &quot;in order&quot;, i.e., the products are in the natural order of \(s \subseteq \omega\).</p>
<p>For a crucial example, consider \(\mathbb{F}\) itself.</p>
<p>If we have a sequence \((s_n : n\in \omega)\) in \(\mathbb{F}\) such that the \(s_n\) are pairwise disjoint, then the FP-set will be just fine -- all products are defined in our partial semigroup.</p>
<p>This is a critical example also because we can transfer such partial subsemigroups easily: If \(FP(s_n) \subseteq \mathbb{F}\) and we have some \(FS(x_n) \subseteq \mathbb{N}\), then we can consider \(y_n := \sum_{i\in s_n} x_i\). As long as the \(s_n\) are pairwise disjoint, we get</p>
<blockquote>
<p>\[ FS(y_n) \subseteq FS(x_n).\]</p>
</blockquote>
<p>So we have a partial subsemigroup of \(FS(x_n)\) induced by a partial subsemigroup of \(\mathbb{F}\)!</p>
<p>And this is actually a typical phenomenon thanks to Hindman's Theorem. Remember,</p>
<blockquote>
<p><strong>Hindman's Theorem</strong> If we partition an FS-set into finitely many pieces, one piece will contain an FS-set.</p>
</blockquote>
<h3>Condensations and Intuitions</h3>
<p>There's one important question when it comes to developing an intuition: what should we expect when we partition again and again? One typical phenomenon is the following: if we take some \(FS(x_n)\) and partition into two pieces where one piece contains exactly the elements of the generating sequence \({ x_n : n \in \omega }\). By Hindman's Theorem, one part of the partition will contain an FS-set -- but that's not going to be \({ x_n : n \in \omega }\)! Consider the case \(x_n = 2^n\), then \({ 2^n : n \in \omega }\) certainly does not contain an FS-set, it does not even satisfy Schur's Theorem!</p>
<p>So what happens in this case? Well, we can easily describe many FS-sets in the other part of the partition; e.g., take every other generator and add: \(y_n= x_{2n} +x_{2n+1}\). Then \(FS(y_n)\) is good for the second part of the partition.</p>
<p>More generally, we could take any pairwise disjoint \((s_n : n\in \omega)\) in \(\mathbb{F}\), just make sure that no \(s_n\) is a singleton. Then as above, \(FP(s_n)\) induces an FS-subset of \(FS(x_n)\) -- which will lie completely in the &quot;large&quot; part of the partition.</p>
<blockquote>
<p>A word of caution: in a certain sense, partitions as the one above are unusually simple because one part does not contain an FS-set. In general, you should expect all parts to contain FS-sets (for example, when separating different idempotent ultrafilters). Nevertheless, I would say that a huge chunk of arguments regarding <a href="https://www.peterkrautzberger.org/0026/">strongly summable ultrafilters</a> relies on such &quot;simple&quot; partitions -- so they are extremely useful.</p>
</blockquote>
<p>The point I'm trying to make is that whenever we repeatedly partition an FS-set, Hindman's Theorem will give us homogeneous FS-sets -- but you should expect the elements in the generating sequence to be sums of <em>many</em> elements of the original generators!</p>
<blockquote>
<p>This is why a sequence \((y_n: n \in \omega)\) in some \(FS(x_n)\) with \(FS(y_n)\subseteq FS(x_n)\) is called a <strong>condensation</strong> of \((x_n :n \in \omega)\) -- because generally speaking <em>many</em> elements from \(x_n\) are condensed into one of the \(y_n\) (of course, some \(x_n\) might just be dropped completely). The term &quot;condensation&quot; is also used in arbitrary (partial) semigroups.</p>
</blockquote>
<p>Oh and to be absolutely clear:</p>
<blockquote>
<p>Sequences in \(\mathbb{F}\) are <strong>always assumed to be pairwise disjoint</strong> (so that they are pairwise compatible in our partial operation)</p>
</blockquote>
<p>Alright, that's enough for this part, I think. Next time, I'll finally talk about the Central Sets Theorem.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hindman’s Theorem, partial semigroups and some of my most lacking intuitions (part 3)]]></title>
        <id>https://www.peterkrautzberger.org/0077/</id>
        <link href="https://www.peterkrautzberger.org/0077/">
        </link>
        <updated>2011-08-25T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Ok, time for part 3. We're not close to an end but I must apologize that I won't be able to post in the next week. But let's recap. In the <a href="https://www.peterkrautzberger.org/0075/">first part</a> I simply explained why semigroups are not partition regular and in the <a href="https://www.peterkrautzberger.org/0076/">second part</a> I wrote about FS-sets and, finally, introduced partial semigroups. One of the headings promised that partial semigroups will help us talk about FS-sets.</p>
</blockquote>
<h2>Are we there yet?</h2>
<p>At this point you might also ask why I talked about partial semigroups so much when I wanted to give you an easy description of FS-sets.</p>
<p>Well, it's because I did. FS-sets <strong>are</strong> partial semigroups, in fact, they are a lot like \(\mathbb{F}\)!</p>
<p>Why? Because for a sequence \((x_i: i &lt; N)\) (for some \(N\leq \omega\))</p>
<p>\[FS(x_n) := { \sum_{i \in s} x_i: s \in \mathbb{F} }.\]</p>
<p>So we have an induced partial operation on \(FS(x_n)\).</p>
<blockquote>
<p>A word of warning: an FS-set can have more structure than \(\mathbb{F}\) induces -- just look at \(FS(2^n) (= \mathbb{N})\) or in a different form, look at \(FS(n)\) -- same set, but much messier when it comes to the relationship between the generating sequence and the sets of finite sums!</p>
</blockquote>
<p>In general, we cannot assume that each element of an FS-set has a unique description via some \(s\in \mathbb{F}\) nor can we assume that the \(\mathbb{F}\)-induced operation captures all allowable sums. So, really, the whole affair is far from optimal!</p>
<p>Nevertheless, if we look at the partial semigroup operation on an FS-set induced by \(\mathbb{F}\), we get a very natural partial semigroups structure with plenty of structure, even if we don't catch all aspects.</p>
<p>From this point of view, we could re-phrase Hindman's Theorem as follows.</p>
<blockquote>
<p><strong>Hindman's Theorem (bad version)</strong> Partial semigroups are partition regular.</p>
</blockquote>
<p>This is, of course, a most horrible example of <a href="http://en.wikipedia.org/wiki/Abstract_nonsense">general nonsense</a>: hiding a concrete structure by using an abstract notion. We're not getting an arbitrary kind of partial semigroup, we're getting FS-sets, plain and simple.</p>
<p>The reason why I am writing this exposition is that, as much as I believe the preceding paragraph, I think there could something valuable in this formulation: if we could develop the notion of partial semigroup, we might just end up solving one of the big unknowns in this field. But before I can take you in that direction, we need to talk about ultrafilters.</p>
<h2>Ultrafilters on semigroups</h2>
<p>When it comes to infinite (and sometimes even finite) Ramsey-type theorems, it is often easy (or at least nice) to give a proof via <a href="http://en.wikipedia.org/wiki/Ultrafilter">ultrafilters</a>. The reason is very simple: if we partition a set into finitely many piece, an ultrafilter contains exactly one of the pieces. This allows for a simplistic strategy: construct the right kind of ultrafilter and it will do all the work for you!</p>
<p>In case of FS-sets and Hindman's Theorem there is an even closer relation to ultrafilters, idempotent ultrafilters to be exact. I don't want to prove anything here, so whatever idempotent ultrafilters are, they are a special kind of ultrafilter on semigroups (but <a href="http://en.wikipedia.org/wiki/Ellis%E2%80%93Nakamura_lemma">one that exists in ZFC</a>). They come up in the most popular proof of Hindman's Theorem, the so-called Galvin-Glazer Theorem (so-called since neither of them were involved in getting the proof published and the way I'll write it it's really Galvin's).</p>
<blockquote>
<p><strong>Galvin-Glazer Theorem</strong> If \(p \in \beta \mathbb{N}\) is an idempotent ultrafilter, \(A\in p\), then \(A\) contains an FS-set.</p>
</blockquote>
<p>Hindman's Theorem is then an immediate corollary.</p>
<p>I love the odd history of Hindman's Theorem, so allow me to digress. Around 1970 Galvin actually had the proof but didn't know if idempotent ultrafilters existed (and he had a different name because he was thinking about them the &quot;wrong&quot; way). Then in 1972 Hindman used CH and, assuming &quot;his&quot; theorem, built an ultrafilter as Galvin needed. Then in 1974 Hindman proved &quot;his&quot; theorem combinatorially. Yet in 1975 Galvin met Glazer who told him that idempotents exist (which, looked at the &quot;right&quot; way had been known since the 1958!).</p>
<p>Coming back to the relation between FS-sets and ultrafilters, there's also a reverse:</p>
<blockquote>
<p>If \(A\) contains an FS-set, then \(A\) is in an idempotent ultrafilter.</p>
<p>In other words, \(A\) contains an FS-set iff \(A\) is in an idempotent ultrafilter.</p>
</blockquote>
<p>Again, the proof is not important right now (don't worry I'll probably get back to it later). What is important is that, in this sense, the structure of FS-sets and idempotent ultrafilters is immediately connected.</p>
<p>And the point, in fact the point of this whole series, is that this relationship is missing for stronger algebraic Ramsey Theorems.</p>
<blockquote>
<p>If you read this far, my thanks. I won't be able to post anything next week, but there's more to follow (and written but not yet prepped for posting). So stay tuned!</p>
</blockquote>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hindman’s Theorem, partial semigroups and some of my most lacking intuitions (part 2)]]></title>
        <id>https://www.peterkrautzberger.org/0076/</id>
        <link href="https://www.peterkrautzberger.org/0076/">
        </link>
        <updated>2011-08-24T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Yesterday I finally <a href="https://www.peterkrautzberger.org/0075/">started this short series</a> with some small thoughts regarding partial semigroups. If you don't remember, all I did yesterday was to explain why semigroups are not, in general, partition regular using a simple partition of \(\mathbb{N}\). I was trying to keep your hopes up by pointing out Schur's Theorem.</p>
</blockquote>
<h2>So how far can we push?</h2>
<p>There are essentially two paths to choose from here. The next step in a decent text book would probably tell you about <a href="http://en.wikipedia.org/wiki/Van_der_Waerden's_theorem">van der Waerden's Theorem</a> (1927), <a href="http://en.wikipedia.org/wiki/Rado%27s_theorem_(Ramsey_theory)">Rado's Theorem</a> (1970) or the <a href="http://en.wikipedia.org/wiki/Folkman's_theorem">Folkman-Rado-Sanders Theorem</a> (Sanders being the first to publish it in his PhD thesis (<del datetime="2012-08-23T21:14:57+00:00">1969</del>1968, see Jon Sanders's comment below) but usually the last to be mentioned because Folkman had some &quot;private communication&quot; with Graham and Rothschild).</p>
<p>The first two theorems lead down a different path, towards partition regular matrices which, from the point of view of Schur's Theorem, could be described as &quot;getting more linear combinations&quot;. The last one on the other hand could be described as &quot;getting some algebraic closure&quot; and this is where we came from in the last post. But I would like to skip ahead or else we'll still be sitting here <del datetime="2011-08-24T13:25:58+00:00">tomorrow</del> next week.</p>
<p>Let me get back to talking to you about <a href="http://en.wikipedia.org/wiki/Hindman%27s_theorem#Hindman.27s_Theorem">Hindman's Theorem</a>. Skipping its curious history, let's see where Schur left us. We have sums of two elements -- very often. But what about three? Or any finite number? Well, we know that repetition is a problem -- after all, that's what prevented subsemigroups from being a partition regular notion. So we have to drop repetitions. What does that leave us with? Distinct sums.</p>
<blockquote>
<p><strong>FS-set</strong> Given a sequence \((x_n: n&lt;N)\) (with \(N \leq \omega\), but we're really intersted in \(\omega\)) let's denote the set of distinct finite sums of elements from this sequence by \(FS(x_n)\), i.e., \[FS(x_n) = \{ x_{i_0} + \ldots x_{i_k} : i_0, \ldots i_k&lt;N \mbox{ pairwise different} \}.\]</p>
</blockquote>
<p>So we collect all results of summing elements from our sequence without doing any repetitions. Fair enough. This seems to be as far as we can get without getting at an actual subsemigroup.</p>
<p>If we're really trying to look at this structure, we should do a reality check. How rich are such sets? Well, first of all, \(FS(2^n) = \mathbb{N}\), so, yeah, they can be pretty rich. On the other hand, you have the potential of huge gaps -- \(FS(10^n)\) has \(1, 10, 11, 100, 101, 110, 111, 1000\) and so forth -- immense gaps will appear, but at each new element from the sequence, we'll see a large cluster of numbers at relatively close distance. That's not bad given our counterxample for subsemigroups.</p>
<p>The surprising thing is that this property -- to contain an FS-set -- is actually partition regular. And this is exactly what Hindman showed in 1974.</p>
<blockquote>
<p><strong>Hindman's Theorem</strong> FS-sets are partition regular.</p>
</blockquote>
<p>What a great theorem! All we had to do was drop repetitions and we immediately get partition regularity. That's a good deal. And yet, it begs the question: can we formalize the kind of algebraic closure appearing in an FS-set?</p>
<h2>Is there an easy way to describe FS-sets?</h2>
<p>The thing with FS-sets is that they look awefully like subsemigroups. You can almost always add two elements together. And not just those from the underlying sequence. Given an element of an FS-set, all but finitely many elements for the underlying sequence can be added to it.</p>
<p>But also when we have two different sums chances aren't too bad that we can add them -- the only restriction is that the two sums must have been built from pairwise different elements from the underlying sequence.</p>
<p>Thankfully, we can describe this messy business efficiently by introducing one of my favorite and one of the most important structures: \(\mathbb{F}\).</p>
<p>What is \(\mathbb{F}\)? Following other researchers (especially <a href="http://www.math.lsa.umich.edu/~ablass/">Andreas Blass</a>) I will denote the finite non-empty subsets of \(\omega\) by \(\mathbb{F}\).</p>
<blockquote>
<p>\[ \mathbb{F} := [\omega]^{&lt;\omega} \setminus \{ \emptyset \}.\]</p>
</blockquote>
<p>Why on earth would I introduce a new notation for such a standard set-theoretic object, you ask? Well, mostly because I didn't -- others did. But it makes sense becaus our interest is in a certain algebraic structure on \(\mathbb{F}\). (Personally, I also like the blackboard boldface F -- it's pretty.)</p>
<p>So what structure? There already exists a very well known and important algebraic structure on \([\omega]^{&lt;\omega}\) -- the group operation of symmetric difference \(\Delta\). This operation gives us the countable Boolean group: every element is its own inverse, i.e., we're talking about \(\otimes_{i \in\omega} \mathbb{Z}_2\) here.</p>
<p>On the other hand, \([\omega]^{&lt;\omega}\) has a very (I mean <strong><em>very</em></strong>) natural semigroup operation: taking the union, \(\cup\). This operation is, of course, as far away from being a group operation as seems possible; every element is idempotent!</p>
<p>It's not historically relevant (as far as I know), but the part that is interesting here is the &quot;intersection&quot; of these operations, i.e., when these two different operations agree.</p>
<p>Yes, I am making all this fuss just to talk about disjoint unions. You'll say, that's ridiculous! Disjoint unions are <em>easy</em>! Well, you're right. And that's exactly the point, actually. Addition is such a pain! It is subtle and messy (all that carrying over). Disjoint unions are soooo much easier, right?</p>
<blockquote>
<p>(Right. Just you wait.)</p>
</blockquote>
<p>So what about disjoint unions? Isn't that a pretty tough restriction? If I was trying to do the usual mathematicians-love-obfuscation thing, I could probably make big deal out of the fact that restricting our operations to disjoint unions eliminates all multiples (which is, like, super important, because I was, like, talking about that all the time, right??? -- that is, of course, getting it backwards, so don't think that way, please!).</p>
<p>The thing that is interesting is that disjoint unions still have a kind of associativity law (warning: I'm going to use \(\cdot\) now -- don't freak out -- but we're not <del datetime="2011-08-24T14:33:02+00:00">in Kansas</del> in \((\mathbb{N},+)\) anymore)</p>
<blockquote>
<p>\[ (a \cdot b) \cdot c = a \cdot (b \cdot c)\]<br>
in the sense that, if one side is defined, so is the other and they are equal.</p>
</blockquote>
<p>Of course, &quot;they are equal&quot; is not the point here -- after all, we have restricted a (semi)group operation -- so for us the key should be: if one side is defined then so is the other. In other words, our operation is relatively rich.</p>
<p>This is what <a href="http://www.math.lsa.umich.edu/~ablass/bbh.pdf">Bergelson, Blass and Hindman</a> dubbed &quot;strong associativity&quot; for in their seminal paper. Altogether, a set with a partial operation satisfying strong associativity, they called a <strong><em>partial semigroup</em></strong>.</p>
<p>We have a slight problem though: the empty operation would vacuously be strongly associative, so &quot;rich&quot; was really an exaggeration. That's why you'd always want to assume that there's really something going on. A pretty natural richness condition (which disjoint unions have) is the following.</p>
<blockquote>
<p>Given finitely many elements, there's another one that can be multiplied to any of them.</p>
</blockquote>
<p>We might not be able to multiply two elements, but at least each element has some of elements it can be multiplied with.</p>
<p>What we're looking at is simply a finite-intersection-property. Namely, the family of sets &quot;can be multiplied with \(x\)&quot; has the finite intersection property. (What we really want is the infinite finite intersection property, but that's not too important right now.) For historical reference, if we have this, it's called a <em>adequate partial semigroup</em> -- and we're not interested in anything else.</p>
<blockquote>
<p>Technically, we will need to say from where we multiply. I usually prefer &quot;from the right&quot; and write the set as \(\sigma(x) := \\{ y : x\cdot y \mbox{ defined } \\}\).</p>
</blockquote>
<h2>Are you messing with me (again)?</h2>
<p>After I have forced this new notion upon you, here's the thing: every partial semigroup can be extended to a semigroup. All you have to do is to add one element, say \(U\), which takes all the &quot;undefined&quot; values and otherwise acts as a multiplicative zero, i.e., \(a \cdot U = U \cdot a = U\). It's easy to check that, thanks to strong associativity, this operation is really associative.</p>
<p>What's the point then? Partial semigroups have a huge advantage: they allow us to focus on the part of our algebraic semigroup structure that is important for us. Just like disjoint unions are the important structure for \(\mathbb{F}\) because they eliminate, e.g., the irrelevant idempotency of individual elements under \(\cup\). In addition, we will see that partial subsemigroups are much more abundant and, in my eyes, one key for understanding Hindman's Theorem and its generalizations.</p>
<p>In the next part I will try to convince you that partial semigroups are indeed a good answer to the question &quot;What kind of of structure is flexible enough to be survive partitioning&quot;?</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hindman's Theorem, partial semigroups and some of my most lacking intuitions (part 1)]]></title>
        <id>https://www.peterkrautzberger.org/0075/</id>
        <link href="https://www.peterkrautzberger.org/0075/">
        </link>
        <updated>2011-08-23T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>If you remember, <a href="https://www.peterkrautzberger.org/0073/">I mentioned</a> that I was working on a post on some research and it was getting out of hand. Well, it is still not finished, but long enough to start posting a series of posts.</p>
</blockquote>
<p>It's no secret that I love the mathematical world surrounding <a href="http://en.wikipedia.org/wiki/IP_set#Hindman.27s_Theorem">Hindman's Theorem</a>. Recently, I have been revisiting an old draft of mine. To get back into it, I want to jot down some informal notes about one of the research directions I think are worth pursuing -- even though I have no proof of this (pardon the pun). At the heart of this line of thought lies the notion of partial semigroups and, especially, my ideas for weaker forms of that notion. To fully make sense of it I have to take you from the elementary algebraic structures to less known structures to ultrafilters on those and finally to filters related to all of this.</p>
<p>But let me start at the beginning so that you can still enjoy reading a little bit of what I want to express without being lost after 5 minutes.</p>
<p><a href="http://en.wikipedia.org/wiki/IP_set#Hindman.27s_Theorem">Hindman's Theorem</a> is a typical Ramsey-type theorem, i.e., it tells us about a certain richness in some fixed mathematical structure (such as a graph in the original <a href="http://en.wikipedia.org/wiki/Ramsey%27s_theorem">theorem by Ramsey</a>), a richness which is <a href="http://en.wikipedia.org/wiki/Partition_regular">partition regular</a>:</p>
<blockquote>
<p><strong>Partition regular notions of richness</strong> If the structure is partitioned in to finitely many pieces (equivalently colored with finitely many colors), one piece (color) will have this kind of richness.</p>
</blockquote>
<p>More concretely, Hindman's Theorem is about algebraic structures, namely, semigroups. Semigroups, if you don't remember, are simply sets with an associative operation</p>
<p>\[ (a \cdot b) \cdot c = a \cdot (b \cdot c).\]</p>
<h2>semigroups? that's easy! subsemigroups!</h2>
<p>If you are looking for partition regular notions and you meet a semigroup, you can, of course, ask yourself:</p>
<blockquote>
<p>Are semigroups partition regular?</p>
</blockquote>
<p>(Un)fortunately, that's not going to work.</p>
<p>To give you a counterexample, let's look at the natural numbers, \(\mathbb{N}\), with the usual addition. Unlike <a href="http://en.wikipedia.org/wiki/Semigroup#Special_classes_of_semigroups">other research into semigroups</a>, almost all of the work in this Ramsey-theoretic area is connected to \(\mathbb{N}\).</p>
<p>Ah, I just noticed: I have made a mistake. If you're a set theorist and \(\mathbb{N} = \omega\), then actually, this is going to work because \(0\) generates a subsemigroup (\(\{0\}\)), so whenever we partition \(\omega\), one part will include a subsemigroup. (more generally, monoids will do this and even more generally, semigroups with idempotent elements.)</p>
<p>Oh well. But that's &quot;clearly&quot; not the point (especially if you're a set theorist). You'll most likely be interested in large, hopefully infinite structures -- and in any case, you're not interested in trivial solutions by idempotent elements...</p>
<p>To get back to our example, we'll ignore \(0\) by adopting the convention most people in this area use:</p>
<p>\[\mathbb{N} = \omega \setminus \{0\}\]</p>
<h2>subsemigroup #Fail.</h2>
<p>Subsemigroups have a nice property: they contain sets of 'multiples'. Given any element in the subsemigroup, we find all its 'multiples' since we can add it to itself repeatedly. Of course, for \((\mathbb{N},+)\) this really means we're talking about multiples in the natural sense.</p>
<p>If we have (thanks to the heading of this section) the suspicion that semigroups are not partition regular, we need to find a partition such that no part contains a set of multiples.</p>
<p>When I was lying in bed a couple of days ago, falling asleep but trying to put the ideas together for this post , it took me a while to come up with a partition. Since at the end I was actually asleep, I don't really remember how I got there. So I'm afraid I can't lead you to it, cannot communicate what intuitions about partitions of natural numbers came up in the process. If I would venture a guess, I probably just remembered the solution for a more complicated (i.e., weaker) structure. Not a grand revelation, I admit.</p>
<p>So how do we do this? Well, the thing about multiples is that they are evenly spaced. So if the parts of our partition have a large interval missing, say larger than some given number \(a\), then that number's multiples will 'hit' that interval, i.e., there'll be a multiple of \(a\) in that interval, not in our part of the partition.</p>
<p>So if we partition \(\mathbb{N}\) into quickly increasing intervals, say for simplicity</p>
<p>\[ [1,10), [10,100), [100,1000) \ldots\]</p>
<p>we can do the following: Collect every other interval, i.e.,</p>
<p>\[A_0 := \bigcup_{i\in \omega} [10^{2i},10^{2i+1})\]</p>
<p>and make \(A_1\) its complement \(A_1 = \bigcup_{i\in \omega} [10^{2i+1},10^{2i+2})\).</p>
<p>Then both \(A_0\) and \(A_1\) have increasingly large gaps, arbitrarily large gaps.</p>
<p>Now if we had a number in \(A_0\), then it will lie in one of the intervals. But it's multiples cannot skip the next interval -- it's far too big for that. I mean, if you start in \([100,1000)\), then you're best chance really is \(999\) -- and of course \(1998\) is far from being in the interval \([10000,100000)\)... Of course the same argument goes through for any other number (and also for \(A_1\)), just look at the highest multiple still in the interval and then double it.</p>
<p>In other words, for any given number, not all multiples lie in the same part of the partition, i.e., neither \(A_0\) nor \(A_1\) contain a set of multiples -- in particular, neither contains a subsemigroup of \(\mathbb{N}\) -- #Fail.</p>
<h2>I'm not just messing with you</h2>
<p>Now you can ask yourself if this hope for partition regular structures within semigroups was all but a dream and there's simply no algebraic structure that survives.</p>
<p>Luckily there's evidence dating back all the way to 1917 guaranteeing that at least <em>a tiny little bit</em> of algebraic structure will survive partitioning. <a href="http://en.wikipedia.org/wiki/Schur%27s_theorem#Ramsey_theory">Issai Schur proved</a> that if you partition \(\mathbb{N}\) into finitely many pieces, you will always find two numbers \(x,y\) such that \(x, y\) and \(x+y\) are in the same piece. (Of course, you'll find infinitely many such pairs.)</p>
<blockquote>
<p>It's not important, but the proof is quite simple actually, using Ramsey's Theorem (the original thing). Given a coloring of \(\mathbb{N}\), use that coloring to define a coloring of all unordered pairs of natural numbers: give \(\{x,y\}\) (with \(x &lt; y\)) the color of \(y-x\). By Ramsey's Theorem, there exists a homogeneous infinite set. Pick any three numbers \(x &lt; y &lt; z\) in that homogeneous set. Then \(z - y, z - x\) and \(y - x\) all have the same color -- which solves our problem, since \(z-y + y-x = z-x\) -- and notice how associativiy comes into play.</p>
</blockquote>
<h3>Outlook</h3>
<p>In the next post, I'll try to point out how far we can push this search for algebraic structures.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What's in a name]]></title>
        <id>https://www.peterkrautzberger.org/0074/</id>
        <link href="https://www.peterkrautzberger.org/0074/">
        </link>
        <updated>2011-08-22T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>This is a slightly idolized recollection how we came to adopt the name Booles' Rings.</p>
</blockquote>
<p>When <a href="http://boolesrings.org/scoskey">Sam</a> and I began looking seriously into the idea of wordpress for mathematicians we also started thinking about names. I immediately thought of one of the most unique science blogging networks -- <a href="http://occamstypewriter.org/">Occam's Typewriter</a>.</p>
<h3>Science bloggers are the cool kids</h3>
<p>When <a href="http://occamstypewriter.org/">Occams' Typewriter</a> opened its gates I was right in the middle of a love affair with scientific blogging. <a href="http://www.scientopia.org/">Scientopia.org</a> has been my favorite network ever since they started but when it comes to the name Occam's Typewriter is <em>the shit</em> (including their Latin motto).</p>
<p>I tried to convince (or rather bully) Sam that we need to come up with a similarly cool name. Around the same time Sam and I started looking I had just added <a href="http://thonyc.wordpress.com/">The Renaissance Mathematicus</a> to my blogroll -- and soon after to <a href="http://www.mathblogging.org/">mathblogging.org</a> (needless to say, I got to know him through <a href="http://scientopia.org/blogs/guestblog/2011/02/28/ich-bin-ein-gastblogger-i-road-to-the-renaissance-or-one-thing-leads-to-another/">his guest blogging at scientopia</a>. The Renaissance Mathematicus has a faible for polymaths and at one point wrote <a href="http://thonyc.wordpress.com/2011/06/27/a-lover-of-paradoxes/">a beautiful piece about Augustus De Morgan</a>.</p>
<h3>Intersections and Unions</h3>
<p>My immediate thought was: let's do something with <a href="http://en.wikipedia.org/wiki/De_Morgan's_laws">De Morgan's Law</a>! That's like <a href="http://en.wikipedia.org/wiki/Occam%27s_razor">Occam's razor</a>, right? That should be possible.... Eventually, I turned to wikipedia for inspiration and found out about De Morgan's &quot;Society for the Diffusion of Useful Knowledge&quot; and about his son's and his role in the founding of what later became the London Mathematical Society. In other words, lots of interesting stuff -- and plenty of motivation to name this project after him.</p>
<p>Unfortunately, neither of Sam nor I could come up with a good name based on De Morgan. And so we jumped back into the seas of information to find inspiration.</p>
<p>Luckily, <a href="http://en.wikipedia.org/wiki/George_Boole">George Boole</a> is listed on wikipedia as &quot;influence&quot; of De Morgan. Hm... Boole... <a href="http://en.wikipedia.org/wiki/Boolean">So many names</a> popped into our heads. Boolean algebra, Boolean group, Boolean ring, Boolean network even (which I found on wikipedia). Everybody knows Boole!</p>
<p>So I read up on him -- and was intrigued.</p>
<h3>To be universal</h3>
<p>Our project might appear to be nothing more than a blogging network of (mostly) set theorists. But our goals are more general: to establish an open platform, helping people to experiment with their academic homepage run on wordpress, independent of any one server hosting their own data on their own servers or whatever they want to.</p>
<p>From this perspective, the site should have a name that appeals beyond the realm of research mathematicians. De Morgan's &quot;Diffusion&quot; offers much in that respect, but I began to like Boole even more.</p>
<h3>Meet the Booles</h3>
<p>To appeal to a wider audience, our name should relate to more than mathematical logic. Thankfully, George Boole's <a href="http://en.wikipedia.org/wiki/George_Boole">entry at wikipedia</a> has quite a bit of information on his family. So let's check what the Booles have to offer.</p>
<p>George himself needs little introduction. Interestingly enough, in his own life time he was famous for his books on differential equations which developed the symbolic method and which later turned into his foundational development of symbolic logic and, in hindsight, the computer sciences. Very interesting was the description of his character as extremely modest, never seeking fame.</p>
<ul>
<li>changing the fundamental view on how to write mathematics <strong>check</strong></li>
<li>modest in character <strong>check</strong></li>
</ul>
<p>Most important is George's wife, <a href="http://en.wikipedia.org/wiki/Mary_Everest_Boole">Mary Everest Boole</a> (niece of <a href="http://en.wikipedia.org/wiki/George_Everest">George Everest</a>). She worked on didactics and mathematics education.</p>
<ul>
<li>mathematics education <strong>check</strong></li>
<li>success despite discrimination <strong>check</strong>.</li>
</ul>
<p>Mary and George had four daughters but George unfortunately died the same year their youngest was born.</p>
<p>The eldest daughter, Mary Ellen Boole, married mathematician Charles Howard Hinton who coined the term <a href="http://en.wikipedia.org/wiki/Tesseract">tesseract</a> and has a <a href="http://en.wikipedia.org/wiki/Hinton%27s_polytope#Omnitruncated_5-cell">polytope named after him</a> thanks to his work on visualization of 4 dimensional geometry.</p>
<ul>
<li>geometry and visualization <strong>check</strong></li>
</ul>
<p>I couldn't find much on Margaret Boole except of, of course, her son and physicist <a href="http://en.wikipedia.org/wiki/Geoffrey_Ingram_Taylor">Geoffrey Ingram Taylor</a>.</p>
<ul>
<li>applied mathematics &amp; physics <strong>check</strong></li>
</ul>
<p><a href="http://en.wikipedia.org/wiki/Alicia_Boole_Stott">Alicia Boole Stott</a> worked in geometry, self-taught but so successfully that she received an honorary doctorate from the University of Groninen -- and she gave us the the term &quot;polytope&quot;.</p>
<ul>
<li>geometry <strong>check</strong></li>
<li>overcoming discrimination <strong>check</strong></li>
<li>international collaborations <strong>check</strong></li>
</ul>
<p>To round things up Lucy Boole Everest was the first female professor of chemistry in England and collaborated with her nephew Geoffrey Ingram Taylor.</p>
<ul>
<li>extending to the sciences <strong>check</strong></li>
<li>collaborations across fields <strong>check</strong></li>
</ul>
<p>Finally, <a href="http://en.wikipedia.org/wiki/Ethel_Lilian_Voynich">Ethel Lilian Boole Voynich</a> became an author, most notably of <a href="http://en.wikipedia.org/wiki/The_Gadfly">The Gadfly</a>. She was married to <a href="http://en.wikipedia.org/wiki/Wilfrid_Michael_Voynich">Wilfrid Michael Voynich</a> of Voynich-manuscript fame.</p>
<ul>
<li>rebellious nature <strong>check</strong></li>
</ul>
<p>Quite an interesting family.</p>
<h3>Boolean, Boole's, Booles'</h3>
<p>With all this we thought the family Boole would make an excellent namesake. Of course, George Boole's name usually appears as &quot;Boolean&quot; in mathematics. To make a distinction we first turned to Boole's, then, to stress that we have more in mind, to Booles'.</p>
<p>Our project is aimed to be as wide as their interests.</p>
<p>Next came the question which structure to pick. We chose to take our inspiration from Boolean rings since it has, well, a certain ring to it. It is the most open natured word of the bunch -- less mathematical than algebra, less exclusive than group or network.</p>
<p>It is a simple and elegant word with many associations. From <a href="http://en.wiktionary.org/wiki/ring">wiktionary</a>:</p>
<blockquote>
<p><strong>ring</strong> A circumscribing object, (roughly) circular and hollow, looking like an annual ring, earring, finger ring etc.</p>
</blockquote>
<p>Finally, Rings not Ring: inclusive, not exclusive, extendable, not restrictive, multi-faceted. That's our goal.</p>
<blockquote>
<p>Booles' Rings -- roughly circular.</p>
</blockquote>
<p>Hey, that's a good line ;)</p>
<hr>
<p><em>Comments</em>.</p>
<ul>
<li><strong>Thony Christie</strong>, 2011/08/22<br>
Hi Peter thanks for the name check the several links and the friendly comments. Really enjoyed your story of your search for a blog collective name. You really should read Desmond MacHale's Boole biography it's one of the best science biographies that I've ever read.
<ul>
<li><strong>Peter</strong>,  2011/08/22<br>
Thanks for your comment. I finally found a copy but summer is fleeting... As I wrote on Twitter, Booles' Rings is not really a blog collective. It's more about investigating the potential of wordpress as a platform for modern researcher homepages. (Not that this will stop us from writing in a more blogesque style ;) )</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A short reflection on google+]]></title>
        <id>https://www.peterkrautzberger.org/0073/</id>
        <link href="https://www.peterkrautzberger.org/0073/">
        </link>
        <updated>2011-08-19T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Today I spent a lot of time on writing a longer piece about some mathematics. It grew completely out of proportion and it'll take me a few more <del datetime="2011-08-20T00:45:03+00:00">minutes</del> hours to finish.</p>
<p>Other things have been keeping me busy but I really, really want to write something...</p>
<p>So google+. <a href="https://plus.google.com/102694188490946876191/">I like google+</a>, I must admit. It's a nice addition to <a href="http://twitter.com/#!/pkrautz">twitter</a> (which I have slowly taken to, especially for <a href="http://twitter.com/#!/mathblogging">mathblogging.org</a>). But google+ has one big problem (and one huge opportunity): its bizarre names policy. I think it is one of the great accomplishments of our societies that we have a culture where anonymity is not only legal, but protected under many circumstances (such as journalistic sources) and embraced as a crucial tool to protect those that need protection from the majority.</p>
<p>This accomplishment does not only extend to the public sphere but to private companies, especially those that create public places such as social networks or other platforms; this is why no store can deny me to enter or exit or even to buy something just because I'm not handing over some identification (unless it is legally necessary, say, for buying alcohol). This is an invaluable right we need to defend and it is why companies like google or facebook should not have the right to restrict their services to people who they think have the &quot;right&quot; names.</p>
<p>I think, actually, the solution is simple: regulation. I hope the EU will do it but it won't happen unless we put it on the agenda and support those who do. If you want to read more, much smarter people than me have written about it, e.g., there's <a href="http://www.zephoria.org/thoughts/archives/2011/08/04/real-names.html">Danah Boyd's post</a> I rediscovered today thanks to <a href="http://jilliancyork.com/2011/08/19/the-danger-in-privatizing-our-publics/">Jillian York</a>. I'd love to hear what you think about this.</p>
<p>But what led me to writing this post was something else entirely. Remember my <a href="https://www.peterkrautzberger.org/0070/">post about markdown</a>? <a href="https://plus.google.com/106537123721037364937/posts/KHQf3p9BFxW">Martin Fenner shared it</a> via google+ (which led to a nice conversation) and then <a href="https://plus.google.com/109571428431344987877">Matias Piipari</a> picked it up (sadly, not public) which led to more conversation. What is interesting to me is the statistics that came along with it. Suddenly, 50 views (yes, not a lot, but enough for me) and, what's even more interesting, 15 spam comments! Thanks to akismet, these were all caught... So to you co-boolesring'lers: make sure you have your spam service in order.</p>
<p>In any case, have a great weekend.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Wordpress in a VM]]></title>
        <id>https://www.peterkrautzberger.org/0072/</id>
        <link href="https://www.peterkrautzberger.org/0072/">
        </link>
        <updated>2011-08-10T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>When you're using wordpress, it comes in handy to have an installation to play around with. When I first joined the <a href="http://groups.google.com/group/wordpress-for-scientists">Wordpress for Scientists Google Group</a>, I promised to write a tutorial. Well, it took me a bit to find the time, but Booles' Rings helped me get back to this.</p>
<p>This tutorial is very rudimentary for now, but leave a comment and I'll gladly clarify things (and add more screenshots etc).</p>
<h3>The tools</h3>
<p>I'm lazy, so to get a nice preconfigured, downsized ubuntu with wordpress nicely set up, you head over to <a href="http://www.turnkeylinux.org/">turnkeylinux.org</a> and get their <a href="http://www.turnkeylinux.org/wordpress">wordpress appliance</a>. More precisely, you'll want the version for a virtual machine (VM) (click the picture to see my cursor hovering in the right place...).</p>
<figure>
    <a href="https://www.peterkrautzberger.org/assets/2011/turnkey.png">
      <img alt="screenshot of Turnkeylinux.org" src="https://www.peterkrautzberger.org/assets/2011/turnkey.png">
    </a>
</figure>
<p>Just download and unzip it somewhere helpful. You might want to remember the standard passwords for the machine mentioned on the download page (or at least remember where to find them).</p>
<p>Next we get our actual virtual machine. As an open source fan, I would suggest <a href="http://www.virtualbox.org/">virtualbox</a> which comes in two free versions, one free as in beer (with extras you won't need) and one free as in speech. Don't worry that the turnkey image you just downloaded is officially for <a href="http://www.vmware.com/">VMware</a> -- virtualbox is just as fine.</p>
<p>The nice thing about virtualbox is, of course, that it's available for linux, macos and windows. So pick your poison <a href="http://www.virtualbox.org/wiki/Downloads">from their download section</a> and install it.</p>
<h2>Creating a virtualmachine</h2>
<p>Well, as Jarvis says, do what you do best and link to the rest. I mean, You could just start up virtualbox and hit the &quot;new&quot; button and see how it goes. You could also take a look at <a href="http://www.virtualbox.org/manual/ch01.html#gui-createvm">the section in the manual</a>. Don't be afraid -- it's actually well written and concise.</p>
<p>But you could also consult this full fledged <a href="http://developer.mindtouch.com/en/docs/mindtouch_setup/010Installation/Installing_VMware_image_on_VirtualBox">tutorial</a> filled with screenshot goodies for every step (it's written for something intriguingly called &quot;mindtouch&quot;).</p>
<p>What, you're still reading this? Alright! In that case, after starting virtual box the main window should look something like this.</p>
<figure>
    <a href="https://www.peterkrautzberger.org/assets/2011/vbox.png">
      <img alt="screenshot of Turnkeylinux.org" src="https://www.peterkrautzberger.org/assets/2011/vbox.png">
    </a>
    <figcaption>
    <a href="http://www.mikefal.net/2011/03/24/virtualization-at-home/">Mike Fal, cc-by-nc</a>
    </figcaption>
</figure>
<p>So you</p>
<ul>
<li>hit the &quot;New&quot; button</li>
<li>choose a name</li>
<li>choose ubuntu 32bit as the vm's operating system</li>
<li>choose the vmdk file from the turnkeylinux as your hardrive (which means you'll have to &quot;add&quot; it to virtualbox's harddisk-file-list first, but I trust you'll figure that step out)</li>
</ul>
<p>For everything else, take the default settings.</p>
<h2>Network settings</h2>
<p>After the maching was created you might want to change the networking settings (the standard settings didn't work for me). In my experience a &quot;host-only&quot; network is the easiest solution (unless you want to connect to the vm's wordpress installation from outside your host machine).</p>
<p>Just go to the settings of the vm you just created, switch to the &quot;network&quot; section and change the active network controller's &quot;Attached to&quot; setting to &quot;host only adapter&quot;. This should look something like this:</p>
<figure>
    <a href="https://www.peterkrautzberger.org/assets/2011/vbox2.png">
      <img alt="screenshot of Turnkeylinux.org" src="https://www.peterkrautzberger.org/assets/2011/vbox2.png">
    </a>
    <figcaption>
    <a href="http://www.mikefal.net/2011/03/24/virtualization-at-home/">Mike Fal, cc-by-nc</a>
    </figcaption>
</figure>
<p>This way, the network is only a virtual one between your host operating system and your virtual machine.</p>
<h2>And off she goes</h2>
<p>Now just fire up the vm, i.e., hit the &quot;Power&quot; button, and get accustomed to switching in and out of the VM (virtualbox will tell you how). Turnkeylinux will possibly ask you some basic questions and maybe run an update.</p>
<p>At the end of the process you should find the VM displaying a blue text console gui with the IP adress of the machine.</p>
<p>Open a browser on your host, open the ip and experiment away!</p>
<blockquote>
<p>Credit: the last two screenshots are licensed under cc-by-nc by <a href="http://www.mikefal.net/2011/03/24/virtualization-at-home/">mikefal.net</a> (I can't run virtualbox on the machine I'm writing this...).</p>
</blockquote>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[About page for Booles' Rings]]></title>
        <id>https://www.peterkrautzberger.org/0071/</id>
        <link href="https://www.peterkrautzberger.org/0071/">
        </link>
        <updated>2011-08-07T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I just published a first draft of an <a href="http://boolesrings.org/about/">about page for Booles' Rings</a>.</p>
<p>If you have any comments, please leave them here.</p>
<hr>
<p><em>Comments</em>.</p>
<ul>
<li><strong>sam</strong>, 2011/08/08<br>
Great work. You definitely summarized much of what I was thinking, and expressed some things in a way that I couldn’t have.  I really like the emphasis that there is so much in the daily life of a mathematician, and our traditional public selves (papers and minimal homepage) only capture a small part.<br>
Some other things that we could mention (or not):
<ul>
<li>We of course still include publications, so that we can expand upon them for non-expert readers, and receive feedback much more quickly than the traditional process.</li>
<li>A bit more about the future.  We of course have to discuss this a lot more, but some things we surely can agree on.  For instance, we want to offer more social features, more instructional features, etc.<br>
To be continued!</li>
<li><strong>Peter</strong>, 2011/08/10<br>
Sam, thanks for your comment. I agree that “making more out of your publication”  should be in there. Don’t know how to phrase it yet.<br>
I’d love more social features but it’s going to be difficult without tools to hack  ;-)</li>
</ul>
</li>
<li><strong>Felix</strong>, 2011/08/11<br>
Hi Peter!<br>
I am curious about joining Booles’ Rings. One thing I wouldn’t want to do without, however, is my own domain name. Will Booles’ Rings support custom domain names sometime in the future?<br>
Of course, supporting custom domains would entail a significant amount of work. So I understand if you do not want to go there just yet.<br>
As far as policy is concerned, I think custom domains would fit Booles’ Rings very well, though. If researchers are to “take charge of their online presence” then taking charge of their URL is a very important part of that. Also, custom domains fit the decentralized philosophy of Booles’ Rings, especially if you say “we will encourage each other to make use of the fact that we can leave and move our content to our own independent server for even greater independence”. But of course these policy decisions are not mine to make.<br>
In any case, I am curious to see how your experiment turns out! Good luck!
<ul>
<li><strong>Peter</strong>, 2011/08/11<br>
Felix, as I said in our conversation earlier today, we'll have to discuss this. But if you don't insist, I don't want to do this in the comments. I'll send an email.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why markdown, not $\rm\LaTeX$?]]></title>
        <id>https://www.peterkrautzberger.org/0070/</id>
        <link href="https://www.peterkrautzberger.org/0070/">
        </link>
        <updated>2011-08-03T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Coming from \(\rm\LaTeX\) and its text-editor driven writing style, working with wordpress can seem a step back -- after all, most people, if they get excited about \(TeX\), very much despise the wysiwyg approach to writing.</p>
<h3>Its greatest strength, its greatest weakness</h3>
<p>One solution is to continue working with \(\rm\LaTeX\) regardless. This is possible. There are tools to convert \(\rm\LaTeX\) to html such as tex4ht and more specific tools for converting to wordpress such as latex2wp and latex-to-wordpress (yes, two distinct projects). The problem, from what I can grasp about the technical side, is that \(\rm\LaTeX\) is only good at one thing: producing material typset for print -- dvi, ps, pdf. Of course, \(\rm\LaTeX\) is really, really good at that. But converting to other forms of publication seems to be its weakness.</p>
<p>When it comes to the web (and especially wordpress) it is useful to approach writing with a multitude of formats in mind. This is, in my opinion, a natural point of view for any researcher; our works are intended to become public and it serves our interests best if it is easy to view them whichever way is best for the person viewing it -- be it in print, on an ebook reader, a giant display or a tiny smartphone screen. With this in mind it seems better to write in a format that can be easily converted to other forms. The alternative could, of course, be to rely on specialized viewing software capable of adapting print output to such extreme circumstances. To me this seems rather absurd, espcially with respect to compatibility with future technologies.</p>
<p>Now if you are trained in the art of \(\rm\LaTeX\) anyway you probably appreciate its (rather special) take on separating structure from content. So for the writing for the web a similar approach makes sense. And this is where markdown and other lightweight markup languages come into the picture.</p>
<h3>Light as a feather, strong as steel</h3>
<p><a href="http://en.wikipedia.org/wiki/Lightweight_markup_language">Lightweight markup languages</a> are a beautiful tool. They focus on two objectives: simple syntax and human readability. The first ensures a mulititude of conversion tools but the second one is historically even more important since their history goes at least back to the text consoles of the 80s.</p>
<p>Personally, I love the aesthetics of these markup languages. The human readability is pure pleasure. I think every experienced \(\rm\LaTeX\) user can agree that, much like any code, reading \(\rm\TeX\), especially somebody elses \(\rm\TeX\) can be its own private little hell. The syntax is complicated, cumbersome and cluttered -- and that's just the plain old \(\rm\LaTeX\) syntax without the added horror of thousands of packages and personal style files...</p>
<p>Instead, <a href="http://daringfireball.net/projects/markdown/">markdown</a> for example is always readable (well, structurally anyway...). It excels at separating content from structure. It is fast to learn and to write (much faster than \(\rm\LaTeX\)) and all this at essentially no cost compared to plain text writing.</p>
<p>Markdown is also incredibly strong. Thanks to programs such as the amazing <a href="http://johnmacfarlane.net/pandoc/">pandoc</a>, you can, after your actual writing is done, convert it to anything you want -- open office documents, \(\rm\LaTeX\), html, epub etc. So when you're interested in &quot;typesetting&quot;, you can choose your tools for further processing -- or just leave it to the professionals.</p>
<h3>Reduce to the max</h3>
<p>But markdown and its cousins do not come without drawbacks. You do not have the amount of options you have in \(\rm\LaTeX\), you don't have your extra packages, your private little hacks for typesetting at your disposal. You're forced to author your work with structural elements that can only be described as elementary (unless you move to middleweight languages like asciidoc or know some html wizardry).</p>
<p>I have experimented with \(\rm\LaTeX\) a lot over the years. I love typesetting and the potential of visually ingenious mathematical typesetting that helps the understanding of the reader. I often dream of meeting an Edward Tufte of mathematics -- no luck so far.</p>
<p>When I started writing on the web, I began employing simpler and simpler tools for writing mathematics. At first, because there was no other way (presenting mathematics online before MathJax was very hard) and after a while because writing is hard. Damn hard. And any technical distraction seemd unwarranted.</p>
<p>The minimal style forced upon you by a tool like markdown makes one thing crystal clear: nothing will save you when you write badly. No fancy diagrams, no clever equation numbering, no colorful plots.</p>
<p>I believe this reduction has helped me become a better writer, mathematical and otherwise. When there's your word and your word alone to convey a mathematical idea, a line of thought, a delicate proof, you will find the core of your mathematical writing talent, the true heart of how you write your mathematics well.</p>
<h3>But what about mathematics?</h3>
<p>So I invite you to try out markdown or one of its cousins. They are easy to learn, great to work with and easy to convert to whatever ends your writing leads.</p>
<p>If you choose markdown and you write mathematical content you may have already had the experience of combining these when you posted on mathoverflow, math.stackexchange or other stackexchange communities. The textbox they use combines markdown and mathjax. In that sense, mathematics is extremely easy to handle. You just write \(\rm\TeX\) code as you're used to with the restriction of the (ever growing) set of mathjax commands.</p>
<p>If, like me, you like to write 'offline' there's no reason not to. A good friend of mine has written a wonderful little text editor called <a href="http://www.inkcode.net/qute">Qute</a> that allows you to write markdown and mathjax on Mac/Linux/Windows with ease. It gives you the pleasure of editing plain text files with human readable markup while producing a live preview of the content. On top of that you profit from his uncanny talents of producing visually brilliant (and healthy) interfaces. Give it a try. Needless to say that this piece was written on Qute.</p>
<h3>Where to go from here</h3>
<p>I'm not saying that any of the lightweight markup languages are the end all and be all -- they are not. I am saying that \(\rm\LaTeX\) isn't either (even though it is treated as such). What I attempted with this little piece is to open you up to the possiblity that your writing, and your mathematical writing at that, can benefit greatly from using tools that are backward compatible to whatever writing tools you feel safe with while allowing your writing to expand, intrinsically for yourself as well as toward reaching a greater variety of form.</p>
<p>And I cannot tell you how much I would enjoy hearing about your experience should you try it out.</p>
<hr>
<p><em>Comments</em>.</p>
<ul>
<li><strong>Felix</strong>, 2011/08/24<br>
Thanks for the mention of <a href="http://www.inkcode.net/qute" rel="nofollow">Qute</a>! Of course, this is one of my favorite topics, so I cannot resist adding a few points. :)<br>
I totally agree that lightweight markup languages have great potential. But for my taste Markdown is a bit too lightweight. I think <em>some</em> layout can help a great deal when communicating an idea, and here lightweight markup languages such as Textile can offer a bit more power without sacrificing readability.<br>
I would also like to point out that while these lightweight markup languages are great for writing they are <em>not</em> that easy to transform from a programmer's point of view - XML and especially Lisp's S-expressions are much more amenable to transformation. As a result lightweight markup languages are not that easily <em>extensible</em>.<br>
TeX was built to be extensible. In fact, AFAIK, Knuth intended for TeX to be a programming language for writing document formatting languages. Only, users just used TeX directly. And this resulted in the mess (La)TeX users are currently in. One reason for the headaches LaTeX packages frequently cause is that - for a markup language - TeX is very <em>bad</em> at separating content from layout. In fact, TeX is not a markup language at all, but a programming language - an imperative one, even! As Joris van der Hoeven put it once (IIRC): TeX is a great programming language, but a terrible file format.<br>
The web standards - XML, CSS, XSLT - excell at separating content from layout. There is one language for <em>writing</em> the document (XML), a separate (functional) language for <em>programming</em> extensions to the language (XSLT) and a convenient language for styling documents (CSS). The downside, of course, that this beautiful separation of concerns came at the expense of human readability - or at least human <em>write</em>ability.<br>
But one should be aware that XML was never intended to be written by hand. There were always supposed to be editors that did the job for you! Only, these editors never reached the critical mass necessary to change the way people write. Nonetheless, editors that are WYSIWYG <em>and</em> extensible <em>and</em> make the structure of the document transparent to the user are possible. If you have never used <a href="http://www.texmacs.org/" rel="nofollow">TeXmacs</a>, you should try it out! I think, in the long run, structured WYSIWYG editors are the way to go. In the meantime, I think writing markup is the way to go, and as we have to do it by hand, the language should be lightweight.<br>
This leaves the issue of extensibility. This is of course only an issue for power users - but LaTeX users who write their own stylesheets fall in this category. Also, extensibility becomes an issue, e.g., when integrating Markdown with TeX syntax.<br>
I think the best way to go is to empower people to cook up their own markup languages (so they can <em>write</em> documents in any way they see fit) and to give them the tools to develop the compilers necessary to transform their documents into any other format (so they can <em>publish</em> documents in standard formats). <a href="http://tinlizzie.org/ometa/" rel="nofollow">OMeta</a> is one example of such a tool. It put special emphasis on extensibility and the <a href="http://www.vpri.org/pdf/tr2010004_steps10.pdf" rel="nofollow">STEPS</a> project of <a href="https://web.archive.org/web/20121020134318/http://www.viewpointsresearch.org/">VPRI [Wayback Machine]</a> has demonstrated that it can be used to write nontrivial compilers in few readable lines of code. (Of course, at this point, you may call me crazy. Encouraging <em>authors</em> to write <em>compilers</em>! Seriously!?! Well, (La)TeX is doing the same thing! Only we should try to do it better.)<br>
Well, I will stop for now. :) But I will blog about this in the future.</li>
<li><strong>Felix</strong>, 2011/08/24<br>
One more concrete question: Have you ever used pandoc to convert Markdown + TeX to PDF? If yes, what exact workflow did you use? What were your experiences?<br>
(I am asking, because I noticed that printing MathJax-formatted TeX from webbrowsers often sucks.)
<ul>
<li><strong>Mclearc</strong>, 2012/03/15<br>
the current version of pandoc (1.9.1.2) seems to integrate latex commands pretty seamlessly into its markdown and then passes them through to pdflatex or whathaveyou. Anything between “$$” will be treated as TEX math. And I regularly incorporate header/footer info as well as other little bits and bobs into my markdown. If all you’re doing is sending it to PDF it should work seamlessly from the command line. No need to even open TexShop (or whatever).</li>
</ul>
</li>
<li><strong>Peter</strong>, 2011/08/24<br>
@Felix, thanks for your long and detailed comment. Fascinating to read your comment on the technical aspects of TeX.<br>
Regarding the “markdown is too light”. I must disagree with you. I stand by what I wrote: if you cannot write well with markdown+MathJax, you cannot write well. Simple as that. This does not mean that there isn’t a point to refined typesetting as a final step. But this step should be done in cooperation with professionals, not on our own (the arrogance!).<br>
Personally, I have read too many papers hiding bad writing behind fancy diagrams. I have had too many conversations about hipster TeX packages that give teh-awesomsauce-TM!!!11!eleventy!1! — you will remember that I was once just like that…<br>
I know it is easy to be blinded by the technology and I think it appeals greatly to many mathematicians. I sympathize with the feeling. If you invest so much time in mastering these tools and, above all, into finding ways to express you ideas with them, it’s hard to admit that this actually does not facilitate communication with others.
<ul>
<li><strong>Felix</strong>, 2011/08/26<br>
@Peter: I agree that professional typesetting is something every text can benefit from (I you can afford it) and that you have to work on your <em>writing</em> no matter what <em>layout</em> skills you have. I think layout is still relevant, though. Just a few days ago, I read a classic book by Minkowski which was all &quot;Fließtext&quot; without any modern layout at all - and this was simply hard to parse, for me! But I like the way you use a subtle CSS styles together with Markdown's blockquotes on your blog to emphasize text blocks. This may well be all I need.<br>
I have to protest against your diss'ing diagrams though. :) I frimly believe that mathematics would benefit a lot, if people tried harder to visualize the objects they are dealing with and to communicate their visual intuition. If I thought otherwise, I would not have just started a <a href="http://blog.felixbreuer.net/2011/08/23/visualising-numbers-part1.html" rel="nofollow">lecture series</a> on the subject. But maybe I am just too focused on visualization and that's why I could never get my arms around set theory... ;)</li>
</ul>
</li>
<li><strong>Peter</strong>,  2011/08/24<br>
Oh, and something like<br>
<code>pandoc -f markdown -t latex –mathjax</code><br>
works quite well.</li>
<li><a href="http://ptsefton.com/2011/10/18/worddown-word-to-html5-conversion-tool.htm">Pingback</a>, 2011/10/18</li>
<li><strong>John Baker</strong>, 2012/03/06,<br>
Thanks for your thoughtful remarks.  I wish I had come across them before working through a project to convert WordPress Blogs to LaTeX+PDF and EPUB and MOBI formats:<br>
<a href="http://wp.me/pDcwA-EC">http://wp.me/pDcwA-EC</a><br>
In the process I stumbled upon pandoc and markdown and even though I am a longtime LaTeX user I completely agree with your points.<br>
One additional point in markdown’s favor is it’s inherent archival quality. As long as we can edit text files we can read it. This is not true of binary formats, ODT, DOCX and even PDF.  In my  lifetime I’ve already experienced “bit-loss” due to ever changing word processing files.  For a format to survive over the long run (centuries) it has to be human readable, open and beyond the control of software companies and governments.
<ul>
<li><strong>Peter</strong>, 2012/03/08<br>
I agree, the archival value is impressive even though I’m not as worried about stability of open formats, HTML in particular.</li>
</ul>
</li>
<li><strong>Carl Mummert</strong>, 2012/03/13<br>
In my opinion, the main thing that MathJax lacks is not layout.  I typically just ignore the layout when I write in LaTeX, although the typesetting will still end up much better than in a web browser. The main thing that I don’t get from MathJax is automatically numbered theoremlike environments and a way to refer back to them by name in the source code of my article. This is also the main problem that Microsoft Word has, by the way.  I can live with the bad typesetting in a browser, but it is a real step backward to have type “Theorem 1″ directly into my source code, as if I am using a typewriter.
<ul>
<li><strong>Peter</strong>, 2012/03/13<br>
My perspective is a little different.<br>
On the one hand, ref and label work in version 2.0. But theorem environments do not exist (and  might never arrive) because MathJax focuses on mathematics, not text.<br>
From my point of view, it is actually better to keep the two separated. I would prefer to have an html source that does not rely on MathJax to do something as simple as have a number next to a theorem.<br>
Which doesn’t mean I don’t want theorem numbering. It just needs to come from somewhere else, preferably in pre-production, i.e., use tex4ht to generate html+mathml and have MathJax render it or extend the markdown syntax or choose a higher level markup language etc.
<ul>
<li><strong>Carl Mummert</strong>, 2012/03/13<br>
Mental error – when I wrote “MathJax”, I meant “Markdown”. At the moment when I write HTML text on my blog I have to type the numbers manually myself, and as far as I can tell Markdown would have the same problem. I have been looking into using XSLT to fix this but it’s a steep learning curve.</li>
<li><strong>Peter</strong>, 2012/03/14<br>
Ah, ok!<br>
Do you need more than CSS counters? I mean, if you want to do it properly, you theorems should have their own css and then <a href="https://developer.mozilla.org/en/CSS_Counters">https://developer.mozilla.org/en/CSS_Counters</a> will get you some counters.
<ul>
<li><strong>Carl Mummert</strong>, 2012/03/16<br>
With CSS counters, is it possible to reference the counter somewhere else in the HTML, as the ref command would do in latex?  Of course this could all be implemented in JavaScript instead of CSS or XSLT, and since MathJax is already using JavaSscript that may be a better way to go. My spring break is coming up, so I may have some time to try this out.
<ul>
<li><strong>Peter Krautzberger</strong>, 2012/03/16<br>
iiuc, you should be able to add arbitrary content via css, in particular counters and anchors.<br>
I can’t help but say that this is asking for more than what LaTeX does (without the help of packages) — it’s a sore point in many discussions that people want MathJax to do work that LaTeX doesn’t…As I said, MathJax most likely won’t ever add this because it’s not a math issue, it’s a general authoring problem that should be solved elsewhere. (Well, actually, thanks to the sponsor AMS desiring it, MathJax 2.0 offers ref and label so Davide might be convinced to add this and people can always write their own extensions of MathJax…)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="https://stevencarlislewalker.wordpress.com/2012/07/21/two-beautiful-things-mathjax-markdown/">Pingback</a>, 2012/07/21</li>
<li><a href="http://fransdejonge.com/2013/11/pandoc-markdown-over-straight-latex/">Pingback</a>, 2013/11/07</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[And now the continuation...]]></title>
        <id>https://www.peterkrautzberger.org/0069/</id>
        <link href="https://www.peterkrautzberger.org/0069/">
        </link>
        <updated>2011-07-30T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Alright, Booles' Rings is set up and I'm trying to import my old posts from <a href="http://peter.krautzberger.info/">http://peter.krautzberger.info</a>. Jekyll was fun, but Wordpress has more potential. So let's start something new.</p>
<hr>
<p><em>Comments.</em></p>
<ul>
<li><strong>sam</strong>, 2011/08/03<br>
Here’s to a fantastic new experience!</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Shelah's Model without P-points-- part 9]]></title>
        <id>https://www.peterkrautzberger.org/0068/</id>
        <link href="https://www.peterkrautzberger.org/0068/">
        </link>
        <updated>2011-07-19T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Read more about this series at <a href="https://www.peterkrautzberger.org/0056/">the first post</a>.</p>
<h2>Part 9: the main lemma ctd.</h2>
<p>In short:</p>
<ul>
<li>Destroying P-points in any further \(\omega^\omega\)-bounding extensions.
<ul>
<li>Second and final part of the proof.</li>
</ul>
</li>
</ul>
<figure>
    <a href="https://www.peterkrautzberger.org/assets/2011/pg_0009.jpg">
      <img alt="screenshot of page 9" src="https://www.peterkrautzberger.org/assets/2011/pg_0009.jpg">
    </a>
</figure>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0009.pdf">Part 9 as PDF</a></p>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0009.xoj">Part 9 as Xournal-source</a></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Mathematician's Homepage  — can it be more?]]></title>
        <id>https://www.peterkrautzberger.org/0067/</id>
        <link href="https://www.peterkrautzberger.org/0067/">
        </link>
        <updated>2011-07-17T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>Yesterday I went on a rant about Keith Devlin's homepage and twitter. That was, like all rants, a little unfair on him. I guess idols are always more disappointing. However, although the rant was triggered by that one tweet it had been building up over the last week because I was writing a longer piece for various reasons. So here it is.</p>
</blockquote>
<p>I'm enamoured with mathematical blogs. Ever since we started <a href="http://www.mathblogging.org/">mathblogging.org</a>, I browse through a lot of blog posts each day and I'm thrilled: the creativity and quality of their content is simply amazing, every day.</p>
<h2>Old-school is just old</h2>
<p>And yet, hardly any mathematician I personally know keeps a blog. But almost all of them keep a homepage. And usually it is abysmal.</p>
<p>You probably know what I'm talking about. All those handwritten html pages from the late 90s using all sorts of html-evils that have long been discarded (tables, frames, puffy cloud mosaic gif backgrounds).</p>
<p>If you're lucky, the homepage will have a cv, some self archived papers (ranked by vanity impact factor of the journals) and possibly teaching material, if you're unlucky, papers are posted as an impossible to compile TeX variant and not stored on the <a href="http://arxiv.org/">arXiv</a> (&quot;'cause it's too hard...&quot;). If you're really out of luck, you'll find bizarre personal interests, genealogies, baby pictures and breakfast habits.</p>
<p>Of course, you can get away with almost anything if your content is fantastic (cf. <a href="http://www.math.rutgers.edu/~zeilberg/">Doron Zeilberger</a>). But most people's websites are a complete waste and an insult to anyone visiting them.</p>
<p>Why such harsh words?</p>
<p>An elementary web design paradigm says there are only two scenarios: either you want to reach your visitor or your visitor wants to reach you. If a page is designed under the first scenario, it must draw the visitor in, usually with clear, simple design that immediately conveys to the visitor why they should spend more time on your page. Under the second scenario your visitor wants something from you. Then, and only then, can you ask them to 'work harder', jump through some menus, wade through long content etc.</p>
<p>So the criticism is simple: these old-school homepages follow the second scenario where they should follow the first. And this is, whether intentional or not, an unnecessary insult.</p>
<h2>The true social network is the www</h2>
<p>Ever since I read this quote (I think it was on <a href="http://www.netzpiloten.de/">netzpiloten.de</a> but had no luck googling...), I cannot get it out of my head:</p>
<blockquote>
<p>&quot;The true social network is the world wide web.&quot;</p>
</blockquote>
<p>What a statement! Read it again.</p>
<blockquote>
<p>&quot;The true social network is the world wide web.&quot;</p>
</blockquote>
<p>I cannot get enough of it. One more time.</p>
<blockquote>
<p>&quot;The true social network is the world wide web.&quot;</p>
</blockquote>
<p>The thing is, I truly believe this.</p>
<p>Instead of centralized, company controlled social network we need to take charge of our online identities and set up our personal websites to serve as a hub for our exchanges with other people, online and offline. That way, we are in full control of what we share with whom and for how long.</p>
<p>I'm intentionally phrasing this very abstractly because there is neither a simple nor a permanent solution. Whatever technology can be used for this right now, it will most likely be obsolete in 5 years. But one thing is clear: we need more advanced tools than mere handwritten html (unless you are an hmtl5 wizard).</p>
<h2>Technology independence</h2>
<p>The best reason for switching from some external social network to your own page running a modern web technology is independence. You're in full control of your data, you're in full control of your technology. Whatever technology you choose, you'll never have to be locked in again. Given an open source technology you can upgrade to whatever, whenever -- no more begging some company to implement a feature. You find a better technology, you switch; no harm done.</p>
<p>Take me as an example. I started with a shitty html website on my university user page, ripping off a <a href="http://web.archive.org/web/20110923164756/http://page.mi.fu-berlin.de/deiser/">senior colleague's page [Wayback Machine]</a>, replacing his name, office etc. with mine. After a while I added a simple <a href="http://www.oddmuse.org/">oddmuse</a> wiki on the side for teaching and organizing research notes. After a while, I started <a href="http://thelazyscience.blogspot.com/">a blog on blogspot.com</a> using tex4ht to create mathml-driven posts. After a while blogspot didn't cut it anymore (<a href="http://www.mathjax.org/">MathJax</a> came out but its cdn didn't exist), I switched to a &quot;static blog generator&quot;, <a href="http://jekyllrb.com/">jekyll</a>, and MathJax, hosted on my personal domain. After a while I changed the server from a regular web host to <a href="http://appspot.com/">Google's app engine</a> (for convenience and speed). And soon I'll be switching to <a href="http://ww.wordpress.org/">wordpress</a> the server will then be using <a href="http://bitnami.org/">BitNami</a> on <a href="http://aws.amazon.com/">Amazon's web service</a>.</p>
<p>As harsh as I put it above, I actually think the authors of most handwritten html pages feel the same way about technology lock-ins as I do. It's only that they're experiencing a completely different kind of lock-in: laziness. It can be <em>hard</em> to switch to something new. I can almost hear them... &quot;I can control everything through my beloved vim/emacs&quot;. It is a lot like saying: I can typeset my mathematics so beautifully using movable types in my garage, why would I use a computer system like TeX...</p>
<p>In other words technology independence also requires a conviction to improve and change the technology. This might, in fact, be the bigger problem.</p>
<h2>The scientific &quot;community&quot;</h2>
<p>The reason to switch is easy: Scientists and especially mathematicians stand to gain incredibly from a modern homepage with modern web technology because it has reached a level that enables us to make the &quot;scientific community&quot; a (virtual) reality.</p>
<p>The term &quot;community&quot; always struck me as inappropriate. The closest I ever felt to being part of a community was as a student in the early years of getting my Diplom. I was part of a cohort of fellow students, meeting many times a week, exchanging ideas, working on problems, helping each other out scientifically and also spending quality social time together.</p>
<p>The classical German PhD model I suffered through is the opposite, really. It was following the master/disciple model, in effect isolating a PhD candidate from almost everyone outside their work group. Creating and investing in a community was essentially discouraged. For example, I remember the opposition we encountered when we started a What-is-Seminar in Berlin; professors either ridiculed or directly opposed the idea of a grad-student-only seminar aimed at building a better community among PhD students across research areas. Well, the seminar is still going strong even after the original organizers left Berlin.</p>
<p>The point is: the scientific community is not anywhere near to being a reality. Beyond the dominant &quot;community&quot; that are personal friendships and collaborations, it is a weird combination of short visits (say, to give a talk at a seminar), conferences and a dysfunctional publish-or-perish system.</p>
<p>In short, scientific-social connections are not transparent, difficult to keep running and depend on pedigree more than shared interests. There is no such thing as a real community because people are, in general, not connected to each other. Communication among researchers, the quintessential part of community is severely lacking.</p>
<h2>Making scientific community a reality</h2>
<p>The web, on the other hand, is the perfect tool to communicate and connect. Using modern web technology you can keep track of content, activities, meet up for text, audio and video interaction. You can communicate any level of research activity, from teaching to schedules to explanatory text to collaborations to real time interaction. Any variant, any speed any combination.</p>
<p>The web is the true social network since it allows but never forces you to be connected, and the immersion into the social interaction can be varied to any degree you feel comfortable. The technology for this is freely available (free as in freedom) and it only keeps getting better and better.</p>
<p>What is lacking is only the number of researchers taking the web seriously, taking themselves on the web seriously.</p>
<p>The advantage for mathematicians lies in the much higher potential compared to the natural sciences. Due to the abstract nature and the mostly text driven research, mathematicians have been using the net to for as long as it exists. From mailing lists to <a href="http://arxiv.org/">arXiv.org</a> from Mathscinet to Mathoverflow, the net is not only an essential but, more importantly, an established tool. And yet, the developments of the last decade seem not to have caught on; blogging, video sharing, social networks and microblogging are used by very few researchers in their research related activities.</p>
<h2>The potential of Wordpress</h2>
<p>The question becomes: How can we convince a significant amount of researchers to take their online identity into their more active hands? For this we need a technology that is reliable, simple to set up and customize. Right now, I think <a href="http://en.wikipedia.org/wiki/Content_management_system">content management systems</a> are the best technology available; and my favorite is <a href="http://www.wordpress.org/">Wordpress</a>.</p>
<p>Wordpress is usually not considered a CMS, but a blogging engine. Yet, it has developed into a versatile tool that can take things far beyond mere text publication. It's power is its open source nature and the simplicity of extending it via plugins -- of which there are a countless number. On top of that, there is the Wordpress For Scientists group that focuses on researcher relevant developments.</p>
<h2>The missing link, literally</h2>
<p>The reason to prefer a blogging engine is simple: everybody supports <a href="http://en.wikipedia.org/wiki/Trackback">trackbacks</a>. Trackbacks are a very old feature amongst blogging engines. The basic idea is as follows: if you're writing a blog post and somebody else picks up the topic and writes about it, it would be nice for you to know about this, to know that you have, in effect, inspired somebody to be creative. Since the second author will usually link to your post when picking it up, the blogging engines developed trackbacks as a way to exchange this information automatically. That is, the first blog would be informed automatically via the webserver of the second blog's trackback mechanism that a certain post was picked up by somebody else.</p>
<p>For a scientist, this is, of course all too familiar, since the today's publication metrics feature citation indices heavily. Of course, <a href="http://www.johndcook.com/blog/2010/06/23/write-only-articles/">the average number of readers of a scientific paper is 5</a> (and the median is 1) and those readers will most likely not cite the paper.</p>
<p>But this low number does not mean much in terms of the scientific community. Often reading a paper will lead to a conversation with other researchers, most likely a <a href="http://settheorytalks.wordpress.com/">short talk in your local seminar</a> and definitely some rewriting on the reader's part; so the reach is much higher. And yet, this information is neither available nor considered significant at all, even though it is a much bigger part of &quot;doing research&quot;.</p>
<p>After all, research is about failing. We read a paper, we rewrite it to make it understandable, we try to apply what we learn from it to other problems. And almost all the time, nothing comes from it. This failure has no place in our shiny-new-results journal tradition (please don't think I don't know that there are historic reasons for the current system. I do know; it just does not make it less bad now).</p>
<p>So, as a researcher, I dream of an online community that allows me to collect all interactions with my research: reading, criticizing, bashing, ranting, re-writing, improving, destroying. And a community that values my own activities.</p>
<h2>Are we there yet?</h2>
<p>Coming back to Wordpress and trackbacks, their potential becomes clear: making use of trackbacks and other linkback technologies could be the key for scientific communication online. Yes, there isn't yet a perfect technical solution, yes it requires an effort on.</p>
<p>But if we started to use wordpress and regular trackbacks to publish our research activities right now, we all could already gain a huge part of the kind of information we keep wasting in the current system. We could get a chance to learn, improve, defend, humble or enjoy our own research together with everybody else. As a community. Finally.</p>
<h2>Only one question remains</h2>
<p>Are you ready to start?</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dear Keith Devlin]]></title>
        <id>https://www.peterkrautzberger.org/0066/</id>
        <link href="https://www.peterkrautzberger.org/0066/">
        </link>
        <updated>2011-07-16T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><strong>Edit, July 2015</strong> Please note that below is a stupid piece of trolling. I leave it because it's been public too long anyway and to remind me not to troll. Far too late but my apologies to Keith Devlin.</p>
<h2>Dear Keith Devlin,</h2>
<p>I love your work. Really, I do. So please don’t take this rant the wrong way. I promise I’ll shut up after this one rant, I just really need to get this off my chest.</p>
<h3>\begin{rant}</h3>
<p>Do you know what work of yours I read first? No, it wasn’t your fancy new Fibonacci book. It wasn’t even the Math Gene book even though it really changed my way of thinking about mathematics. It was, in fact, “A weak version of \(\diamondsuit\) which follows from $ 2^{\aleph_0} &lt; 2^{\aleph_1} $”.</p>
<p>I’m guessing you wouldn’t have guessed that. This was the very first research paper I read and my first seminar talk as a Diplomkandidat in Munich (many, many moons ago). It literally changed my life because it marked my final “conversion” to set theory, and – much, much more importantly – indirectly introduced me to my partner. So, when I say I love your work, believe me, I really mean it. (which is probably the reason why I’m ranting so hard…)</p>
<h3>Seriously, what are you doing online?</h3>
<p>You’re very active on the interwebs and intertubes. That’s awesome because too few mathematicians of your calibre are. But have you looked at <a href="http://www.stanford.edu/~kdevlin/">your homepage at Stanford</a> recently? I mean, you probably haven’t (a box with blue-grayish background, bright red border and purple text?).</p>
<p>You’re website is stuck in the 90s.</p>
<p>The thing is: you are doing awsome stuff! You’re giving away lots of information: you’re letting people know where you’re giving lectures, you’re sharing videos, sharing research. That’s exactly what I hope for when I visit a scientists homepage. But…</p>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2011/youre-doing-it-wrong.jpg">
    <img alt="Picard facepalm with 'You're doing it wrong'" src="https://www.peterkrautzberger.org/assets/2011/youre-doing-it-wrong.jpg">
  </a>
  <figcaption>
  Via <a href="http://troll.me/">troll.me</a>
  </figcaption>
</figure>
<p>This might sound silly, but web technology has actually advanced since 1998. It now allows you to share content in such a way that people do not have to look up your homepage every other day to check whether there’s something new. It also allows people to connect with you and makes it easy for them to share your content with a much wider audience.</p>
<h3>Hipster webs</h3>
<p>The thing is you <em>should</em> know better. You write on your homepage that you have a <a href="http://twitter.com/#!/nprmathguy">twitter account</a> and <a href="http://devlinsangle.blogspot.com/">a blog</a>. That’s so Web 3.0! Well, unfortunately, it isn’t, because, well, you’re doing it wrong.</p>
<p>First off, you don’t even properly link to either of these on your homepage. Then your blog is not a blog. It’s a magazine column that has an rss feed. It is not a log and, more importantly, it does not allow for discussions, which is the essence of blogging. So, in reality, it’s just another website that happens to have an rss feed. That’s not a bad thing – it’s just not a blog.</p>
<p>And then there’s your twitter account. Did you know that your replies are not that visible in your subscriber’s streams unless you put something in front of the @? What’s left is a lot of advertisement… and this morning, you even got the self-advertising wrong!</p>
<p>I mean, <a href="https://twitter.com/profkeithdevlin/status/92214106823737344">in this tweet</a> you actually seem to try to hide the fact that, once more, you’re essentially advertising your new book. Now, I’m fine with good advertising. But don’t hide it and, for goodness’ sake, <a href="http://www.npr.org/2011/07/16/137845241/fibonaccis-numbers-the-man-behind-the-math">include a bloody link</a>! I mean, you’re advertising <strong>your</strong> segment on NPR about <strong>your</strong> book and I still have to google to actually listen to it?</p>
<p><strong>You really expect me to?</strong></p>
<p>As they say, the web has no fury like a nerd scorned (or something like that).</p>
<h3>\end{rant}</h3>
<p>So, please, install <a href="http://www.wordpress.org/">wordpress</a> on your homepage and <a href="http://mathforum.org/blogs/max/126/">join conversations</a> on twitter. It makes life so much better.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why I back Relatively Prime]]></title>
        <id>https://www.peterkrautzberger.org/0065/</id>
        <link href="https://www.peterkrautzberger.org/0065/">
        </link>
        <updated>2011-07-14T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>On of the pleasures of running <a href="http://www.mathblogging.org/">mathblogging.org</a> is that you get to find out about immensely creative people working on new ways to make use of the web for mathematics.</p>
<h2>ACME Science</h2>
<p>Only a few weeks ago, I rediscovered <a href="http://acmescience.com/">Samuel Hansen’s ACME Science podcast</a>. I remember stumbling upon it very early on when we started building the database for <a href="http://mathblogging.org/">mathblogging.org</a> but for the longest time couldn’t see how a podcast could fit.</p>
<p>It did, however, keep popping back up because <a href="http://travelsinamathematicalworld.blogspot.com/">Samuel Hansen’s friend and Math/Maths podcasting co-host Peter Rowlett</a> was included in our database from the very start (simply because I had been following his blog).</p>
<h2>Relatively Prime</h2>
<p>So what’s Relatively Prime? Well, you should probably <a href="http://www.acmescience.com/2011/07/relatively-prime-stories-from-the-mathematical-domain-the-kickstarter/">head over to ACME Science to watch the promo video</a>. Don’t worry, I’ll still be here when you’re back. Can’t wait? Ok, very short version. Relatively Prime is Samuel Hansen’s Kickstarter project to make a podcast series about mathematicians and their work, interviewing people in person. In a way, I’d say he wants to take <a href="http://acmescience.com/category/shows/scc-shows">Strongly Connected Components</a> to the next level – but it’ll be much more, I think.</p>
<p>SSC is one of the best on the web that I know. The idea is simple, interviews with interesting mathematicians – nothing new, right? Since Samuel Hansen is not exactly working for the BBC World Service, glamour mathematicians are not on his list. And somehow that’s exactly what makes his show excellent: He has a knack for choosing interview partners that you would not expect to find in any main stream (scientific) media.</p>
<p>Of course, it’s Hansen who really makes these interviews work. His podcasts are a perfect example of the incredible (and mostly still undiscovered) potential of how mathematicians can connect; on every level, trough the net. That’s the stuff we built <a href="http://mathblogging.org/">mathblogging.org</a> for!</p>
<p>I have only one criticism: more female mathematicians would not hurt the show. Maybe Relatively Prime will surprise me even more?</p>
<h2>Now you go and back it!</h2>
<p>The great thing about kickstarter is you can give on the level you’re comfortable giving. Since you ask, of course I chose my backing level to maximize vanity under the restraints of my financial means ;) But so can you! There are 20 days left to get this project funded – <a href="http://www.kickstarter.com/projects/386612592/relatively-prime-stories-from-the-mathematical-dom">so head over there and pledge some money</a>!</p>
<p>EDIT: Samuel Hansen corrected me <a href="https://twitter.com/Samuel_Hansen/status/91651901497679872">via twitter</a>: Relatively Prime will be audio only. I think I got it wrong because of the promo video. But who cares, it’s going to be awesome either way!</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Epub and mathematics]]></title>
        <id>https://www.peterkrautzberger.org/0064/</id>
        <link href="https://www.peterkrautzberger.org/0064/">
        </link>
        <updated>2011-07-13T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>A while ago <a href="http://blogs.plos.org/mfenner/2011/01/23/beyond-the-pdf-%E2%80%A6-is-epub/">Martin Fenner had written about the BeyondPDF workshop</a> and <a href="http://blogs.plos.org/mfenner/2011/02/01/epub-wordpress-plugin-released-today/">released his epub export plugin for wordpress</a> and <a href="http://blogs.plos.org/mfenner/2011/02/04/discussing-wordpress-for-scientists/">started the Wordpress For Scientist Google group</a>.</p>
<p>I had joined that group right away and had wanted to do some experiments for a while now. I have been falling in love with wordpress more and more and I will probably switch rather sooner than later. Then <a href="http://www.neverendingbooks.org/ebook-geometry-and-the-absolute-point-v0-1">last week Lieven le Bruin released some of his posts as PDF</a> and, upon my comments, also experimented with epub. But the discussion on his blog brought back the issue of mathematics in epub.</p>
<p>By the way, I’m also starting another experiment – writing a paper collaboratively using wordpress! This will hopefully mean I can share more experiences. The main tool for this is <a href="http://johnmacfarlane.net/pandoc/">pandoc</a> – a great tool for document conversion, especially if, like me, you love <a href="http://daringfireball.net/projects/markdown/">markdown</a>. Pandoc will eventually help me convert markdown to LaTeX (for the final touches). I’ll write more about that at some other point.</p>
<p>Anyway, today I finally got around to experimenting with epub and wrote the following lines on the google group.</p>
<blockquote>
<p>Hi.<br>
I have been experimenting with Martin’s epub-export plugin and, as a mathematician, can’t really be happy. There seems to be no good way to export mathematics in the sense that I (and most others online) are too used to LaTeX syntax and MathJax these days.<br>
From what I understand, the current situation is that the epub standard has a “should not”-rule for javascript inclusion and almost all applications block javascripts.<br>
This might possibly change in the future since the epub3 draft contains a “could”-rule for javascript. From a math(jax) point of view, javascript would solve a lot of issues. So I had wanted to experiment for some time and finally got around to it – so I thought I should share this.</p>
<p>A while ago I found <a href="http://www.pigsgourdsandwikis.com/2011/06/javascript-accepted-in-ibookstore.html">a promising story about javascript in epub</a>. In particular, javascript seems to work in the iPad’s ebook app.<br>
Today, I tried to use this knowledge to create some easy mathematics in epub and testing this with a friend’s iPad.</p>
<ul>
<li><a href="http://www1.chapman.edu/~jipsen/mathml/asciimath.html">Asciimathml</a> inclusion “just worked” in the sense that adding the javascript file and adding the suitable line in the header of my test epub’s chap1.xhtml worked in the iPad app.</li>
<li><a href="http://docs.mathjax.org/en/latest/configuration.html#loading-mathjax-from-the-cdn">MathJax inclusion via the CDN</a> worked – that’s great news, since it keeps the file small (but somewhat disturbing since it means all kinds of evils are possible via external javascript)</li>
<li>MathJax inclusion in the epub file failed. This is unfortunate. The size of the epub increases significantly (and the process takes ages with the 30.000 mathjax files), but from what I understand the file limit is 2GB, not 16MB…</li>
</ul>
<p>So I have three questions:</p>
<ol>
<li>Could anybody try to reproduce this?</li>
<li>Does anybody have thoughts on the problem of actual inclusion of mathjax?</li>
<li>Does anybody know an ebook reader outside of the ipad that tolerates javascript?</li>
</ol>
<p>Thanks for any suggestions! Peter.</p>
</blockquote>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Shelah's Model without P-points-- part 8]]></title>
        <id>https://www.peterkrautzberger.org/0063/</id>
        <link href="https://www.peterkrautzberger.org/0063/">
        </link>
        <updated>2011-07-11T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Read more about this series at <a href="https://www.peterkrautzberger.org/0056/">the first post</a>.</p>
<h2>Part 8: the main lemma</h2>
<p>In short:</p>
<ul>
<li>Destroying P-points in any further \(\omega^\omega\)-bounding extensions.
<ul>
<li>First part of the proof.</li>
</ul>
</li>
</ul>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2011/pg_0008.jpg">
    <img alt="screenshot of page 8" src="https://www.peterkrautzberger.org/assets/2011/pg_0008.jpg">
  </a>
</figure>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0008.pdf">Part 8 as PDF</a></p>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0008.xoj">Part 8 as Xournal-source</a></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Shelah's Model without P-points-- part 7]]></title>
        <id>https://www.peterkrautzberger.org/0062/</id>
        <link href="https://www.peterkrautzberger.org/0062/">
        </link>
        <updated>2011-07-01T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>My apologies for the blogging hiatus. Let’s continue.</p>
<p>Read more about this series at <a href="https://www.peterkrautzberger.org/0056/">the first post</a>.</p>
<h2>Part 7: switching filters</h2>
<p>In short:</p>
<ul>
<li>From \(u\) to \(\{ \omega \} \otimes u\).</li>
</ul>
<figure>
    <a href="https://www.peterkrautzberger.org/assets/2011/pg_0007.jpg">
      <img alt="screenshot of page 7" src="https://www.peterkrautzberger.org/assets/2011/pg_0007.jpg">
    </a>
</figure>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0007.pdf">Part 7 as PDF</a></p>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0007.xoj">Part 7 as Xournal-source</a></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Shelah's Model without P-points-- part 5]]></title>
        <id>https://www.peterkrautzberger.org/0060/</id>
        <link href="https://www.peterkrautzberger.org/0060/">
        </link>
        <updated>2011-06-02T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Read more about this series at <a href="https://www.peterkrautzberger.org/0056/">the first post</a>.</p>
<h2>Part 5: properness</h2>
<p>In short:</p>
<ul>
<li>Basic Properties:
<ul>
<li>Grigorieff forcing and the Sacks variant are proper (part 1)</li>
</ul>
</li>
</ul>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2011/pg_0005.jpg">
    <img alt="screenshot of page 5" src="https://www.peterkrautzberger.org/assets/2011/pg_0005.jpg">
  </a>
</figure>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0005.pdf">Part 5 as PDF</a></p>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0005.xoj">Part 5 as Xournal-source</a></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Shelah's Model without P-points-- part 6]]></title>
        <id>https://www.peterkrautzberger.org/0061/</id>
        <link href="https://www.peterkrautzberger.org/0061/">
        </link>
        <updated>2011-06-02T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Read more about this series at <a href="https://www.peterkrautzberger.org/0056/">the first post</a>.</p>
<h2>Part 6: properness ctd.</h2>
<p>In short:</p>
<ul>
<li>Basic Properties:
<ul>
<li>Grigorieff forcing and the Sacks variant are proper (part 2)</li>
</ul>
</li>
</ul>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2011/pg_0006.jpg">
    <img alt="screenshot of page 6" src="https://www.peterkrautzberger.org/assets/2011/pg_0006.jpg">
  </a>
</figure>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0006.pdf">Part 6 as PDF</a></p>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0006.xoj">Part 6 as Xournal-source</a></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Shelah's Model without P-points-- part 4]]></title>
        <id>https://www.peterkrautzberger.org/0059/</id>
        <link href="https://www.peterkrautzberger.org/0059/">
        </link>
        <updated>2011-05-30T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Read more about this series at <a href="https://www.peterkrautzberger.org/0056/">the first post</a>.</p>
<h2>Part 4: \(\omega^\omega\)-bounding</h2>
<p>In short:</p>
<ul>
<li>Basic Properties:
<ul>
<li>Grigorieff forcing and the Sacks variant are \(\omega^\omega\)-bounding</li>
</ul>
</li>
</ul>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2011/pg_0004.jpg">
    <img alt="screenshot of page 4" src="https://www.peterkrautzberger.org/assets/2011/pg_0004.jpg">
  </a>
</figure>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0004.pdf">Part 4 as PDF</a></p>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0004.xoj">Part 4 as Xournal-source</a></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Shelah's Model without P-points-- part 3]]></title>
        <id>https://www.peterkrautzberger.org/0058/</id>
        <link href="https://www.peterkrautzberger.org/0058/">
        </link>
        <updated>2011-05-28T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Read more about this series at <a href="https://www.peterkrautzberger.org/0056/">the first post</a>.</p>
<h2>Part 3: More Strategy and Shelah’s “crucial fact”</h2>
<p>In short:</p>
<ul>
<li>Basic Properties:</li>
<li>a strategy for \(\omega^\omega\)-bounding — continued.</li>
<li>The “crucial fact” for Grigorieff and Sacks forcing (that’s what Shelah calls it)</li>
</ul>
<figure>
    <a href="https://www.peterkrautzberger.org/assets/2011/pg_0003.jpg">
      <img alt="screenshot of page 3" src="https://www.peterkrautzberger.org/assets/2011/pg_0003.jpg">
    </a>
</figure>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0003.pdf">Part 3 as PDF</a></p>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0003.xoj">Part 3 as Xournal-source</a></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Shelah's Model without P-points-- part 2]]></title>
        <id>https://www.peterkrautzberger.org/0057/</id>
        <link href="https://www.peterkrautzberger.org/0057/">
        </link>
        <updated>2011-05-22T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Read more about this series at <a href="https://www.peterkrautzberger.org/0056/">the first post</a>.</p>
<h2>Part 2: Definitions and Strategy</h2>
<p>In short:</p>
<ul>
<li>The P-point game</li>
<li>Basic Properties:
<ul>
<li>a strategy for \(\omega^\omega\)-bounding.</li>
</ul>
</li>
</ul>
<figure>
  <a href="https://www.peterkrautzberger.org/assets/2011/pg_0002.jpg">
    <img alt="screenshot of page 2" src="https://www.peterkrautzberger.org/assets/2011/pg_0002.jpg">
  </a>
</figure>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0002.pdf">Part 2 as PDF</a></p>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0002.xoj">Part 2 as Xournal-source</a></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Shelah's Model without P-points-- part 1]]></title>
        <id>https://www.peterkrautzberger.org/0056/</id>
        <link href="https://www.peterkrautzberger.org/0056/">
        </link>
        <updated>2011-05-19T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>To get some research back into this blog, I will, over the course of the next few weeks, post some handwritten notes about a couple of well-known results by Shelah: the model without P-points, the model with a unique selective ultrafilter and the model with a unique P-point.</p>
<p>These notes were written for <a href="http://settheory.mathtalks.org/university-of-michigan-logic-seminar/">my recent series of talks at the UofM’s Logic Seminar</a> here in Ann Arbor and came out of an ongoing collaboration with David Chodounsky from Prague. The source for this presentation is Shelah’s <a href="http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.pl/1235419814">Proper and Improper Forcing</a>.</p>
<p>The notes were written using <a href="http://xournal.sourceforge.net/">Xournal</a>.</p>
<h2>Part 1: Basic Definitions</h2>
<p>In short:</p>
<ul>
<li>Definitions
<ul>
<li>Grigorieff forcing</li>
<li>Sacks forcing with a filter</li>
<li>P-filter, P-point</li>
<li>non-meagre filter</li>
</ul>
</li>
</ul>
<figure>
<a href="https://www.peterkrautzberger.org/assets/2011/pg_0001.jpg">
  <img alt="screenshot of page 1" src="https://www.peterkrautzberger.org/assets/2011/pg_0001.jpg">
</a>
</figure>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0001.pdf">Part 1 as PDF</a></p>
<p><a href="https://www.peterkrautzberger.org/assets/2011/pg_0001.xoj">Part 1 as Xournal-source</a></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What a day]]></title>
        <id>https://www.peterkrautzberger.org/0055/</id>
        <link href="https://www.peterkrautzberger.org/0055/">
        </link>
        <updated>2011-05-12T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h2>What makes for a good birthday?</h2>
<ul>
<li>Cambridge in spring</li>
<li>everybody calling to wish a happy birthday</li>
<li>having a reason to go to <a href="http://dicksonbros.com/">Dickson Brothers</a></li>
<li>spending the day working on some research at <a href="http://petsipies.com/">Petsi Pies</a></li>
<li>understanding a proof by Saharon Shelah</li>
<li>finding out that the most recent “bug” on <a href="http://www.mathblogging.org/">mathblogging.org</a> is not critical.</li>
<li>sitting in the garden behind Barker Court</li>
<li>simplifying an argument of Shelah</li>
<li>being off for dinner with friends</li>
</ul>
<p>Nice.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Young Set Theory Workshop 2011]]></title>
        <id>https://www.peterkrautzberger.org/0054/</id>
        <link href="https://www.peterkrautzberger.org/0054/">
        </link>
        <updated>2011-03-30T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>It’s been a while. In case you were wondering where the heck I have been these last two months, check out <a href="http://www.mathblogging.org/">mathblogging.org</a> and <a href="http://mathblogging.wordpress.com/">our blog at wordpress.com</a>.</p>
<p>The last week I was able to spend at the <a href="http://www.math.uni-bonn.de/people/logic/events/young-set-theory-2011/">Young Set Theory Workshop</a> thanks to the generous DFG. This was my first time at the YST although I have followed its success story via friends since it began three years ago. The workshop is, well, a workshop so the focus was on tutorials and so-called discussion sessions which were open to all topics and were decided upon spontaneously.</p>
<h2>The tutorials</h2>
<p>The tutorials were all very good. Personally, I was particularly amazed by Joel David Hamkins and Juris Steprans. Joel gave the very first tutorial (each tutorial had 2 parts) and talked about Boolean ultrapowers which (at least when presented by him) seems an amazingly simple point of view to understand both forcing and large cardinals. I keep wondering if this non-technical approach to those set theoretically heavy-weight topics might be a way to finally bring these tools to a more general mathematical audience. I had never met Joel before but I knew him from afar as <a href="http://mathoverflow.net/users">THE mathoverflow user</a>; suffice it to say that he is just as friendly and helpful in meat space as he is on MO. The second tutorial on Monday and Tuesday was given by Slawomir Solecki who gave an introductory course on Borel equivalence relations. Though I enjoyed most of his tutorial, I did have trouble to follow the beginning of the second part. The problem for me was that he continued a technical proof that he had started at the end of the first part of his tutorial and I just couldn’t remember enough of the details and definitions from part 1 to follow. Since I have experienced this often when there’s a two part proof, it made me wonder what kind of strange tradition this is in mathematics. Why not just skip the rest of the proof? If you cannot expect your audience to actually follow, it should be better to skip it since there’s nothing to be gained (except the apparent tradition that every talk of sufficient length must contain a complicated proof). Of course, realistically Slawomir Solecki did everything right, I was just not fit enough to follow that proof — I didn’t have the impression that many shared my trouble. In any case, the rest of the lecture was luckily self-contained in the sense that the actual techniques in the proof were not important. It also left me with the goal to one day give lectures (and courses!) that are always perfectly self contained (one can dream, right?).</p>
<p>On Wednesday and Thursday Ali Enayat’s tutorial offered insight into models of arithmetic and models of set theory and their interactions. After some initial confusion on my part, I did enjoy this even though it was not a blackboard talk as the first two tutorials had been (and I’m always in favor of those if time permits). I can’t really say a lot else because the topic was rather far away from anything I know. Thursday and Friday also saw Juris Steprans’s tutorial on amenability. This was shockingly interesting for me. When I did my PhD in Berlin Sabine Koppelberg had a student who wrote a master’s thesis about shift invariant means. And even though I went to each of his many talks, I must admit that I had never understood what it was really all about. This probably only shows that not all talks I don’t understand are in vain in the long run, but on the other hand I am really annoyed with myself that I never took the time to understand this stuff back then. I’ll definitely have to look into at least one result (I think by <del>-Magidor</del>- Foreman): under MA every ultrafilter on \(\omega\) allows for the construction of a subgroup of the symmetric group \(S(\mathbb{N})\) with a unique translation invariant mean. This is exciting because I am always looking for ultrafilter related invariants that are finer than the Rudin-Keisler order (mostly because algebraic properties are not really invariant under RK-equivalence). Juris Steprans’s tutorial at times was a little strange for me. Whenever he talked to the audience freely, I was amazed at the clarity he communicated, but every so often he’d turn to his slides and suddenly that great clarity was gone until he started to speak freely again. In the second part of his tutorial he also gave a lot of technical details for a proof which I couldn’t really follow. But for me it was all good since the topic was so much fun. I must admit, I always favor the applications of set theory to the “purest of the pure” kind of stuff…</p>
<p>[[Note: <a href="http://www.math.uni-bonn.de/people/logic/events/young-set-theory-2011/programme.shtml">The slides of all tutorials are available online</a> ]]</p>
<h2>The discussion sessions</h2>
<p>Every day after lunch it was time for the so-called discussion sessions. These were rather informal and the ones I visited were very different from each other. On Monday, I joined a session led by Minami Hiroake about \(F_\sigma\) ideals and maximal almost disjoint families. This was in a way the best and the worst discussion session I joined. It was good because after a slow start four, five people really discussed a research problem. Unfortunately, the other ten people in the room did not seem to be able to join in. I guess people weren’t ready to walk out of the very first session just because it wasn’t perfect — the other sessions I went were much more relaxed in any case. On Tuesday, I joined a session by Luz Maria Garcia Avila (sorry for missing accents) who is at the University of Barcelona and presented a really nice proof of Ramsey’s Theorem using the <a href="https://secure.wikimedia.org/wikipedia/en/wiki/Rasiowa%E2%80%93Sikorski_lemma">Rasiowa-Sikorski Lemma</a> and the partial order used in Mathias forcing. I can’t shake the feeling that I have seen this argument before, but this does not make her proof less beautiful. I’m all in favor for giving credit for (re)discovering known results. In my experience we mathematicians are too often obsessed with originality and should give far more credit for independent rediscoveries and high quality presentations of known results. Anyways, after the proof of Ramsey’s Theorem, Luz went on to describe a similar approach to prove Hindman’s Finite Sums Theorem which she was working on. My immediate response was “that should work straight away” because Andreas Blass often talks about Baumgartner’s combinatorial proof of Hindman’s Theorem as a forcing argument. This led to a couple of good discussions with Luz later (with a lot of confusion because we thought we were talking about the same presentation of that proof) and I hope she’ll be able to make it work.</p>
<p>On Thursday and Friday I headed two discussion sessions myself. The first was a short one because of the excursion later that day and I mostly presented the basics of algebra in the Stone–Čech compactification (again sorry for the missing accent, I’m too lazy right now) and on some recent problems regarding union ultrafilters. I tried to focus on the general feel of the area rather than proofs because even the elegant Galvin-Glazer proof of Hindman’s Theorem has some subtleties that I feel are difficult to communicate in a short amount of time — and a senseless copying down of a proof seemed inappropriate in such a setting (well, actually, in any setting). The session on Friday was on Teh Internetz. I had hoped to get a discussion going regarding a possible meeting point for set theorists but I think I didn’t quite do that right. I started off with mathoverflow and thankfully Joel David Hamkins was there and gave us his view of the platform. I hope I can convince him to write a little about it some other time, especially an extended FAQ describing the shape of the community and what to expect when posting there. After MO, I talked about some of the tools I use online and offline. After almost an argument about hidden vs open meeting places (I’m in favor of visibililty and openness but others raised concerns that I couldn’t quite pin down) we finally arrived at my favorite hobby — recording and broadcasting seminar and other talks. There was very positive feedback from Joel David Hamkins and Juris Steprans, so I hope to get a small project via posterous, tumblr or wordpress going to collect talks where the “locals” would offer to record or broadcast.</p>
<h2>The postdoc talks</h2>
<p>The final research piece of the conference were the talks by some of the postdocs. Unfortunately, I missed Katie Thompson’s short talk on LOTS on Monday because I was caught up in a research discussion with David Chdounsky. On Tuesday, Assaf Rinot gave a great talk on “his” Ostaszewski square. Even though I have a hard time with these purest of the pure talks, Assaf is simply an awesome speaker. He relies little on slides and could really just give a talk — no blackboard or slide needed — amazing and extremely enjoyable (although with this kind of skill, he could put even less on the slides, real presentation zen). On Wednesday, there were two talks, Sam Coskey talked about applications of Borel equivalence relations to the conjugacy problem and Dilip Raghavan talked about the P-ideal dichotomy. I enjoyed both talks immensely not just because they were blackboard talks but because they both presented a well chosen amount of proof; and even better: those proofs were presented in a fashion which is suitable for talks, namely as sketches, hand-waving arguments and proof by picture with only little formal notation. On Thursday, David Schrittesser gave a very technical talk which I was unable to follow and on Friday Grigor Sargsyan gave a talk on inner model theory. Even though my own research is about as far away from inner model theory as is possible within logic, I always enjoy his talks because he really has a mouth-watering kind of way of telling you why people ended up doing what they are doing in that part of set theory.</p>
<p>I must nevertheless admit that I didn’t understand the motivation for this part of the workshop. Not that I think that postdoc talks are not interesting — quite the opposite, in fact. After all, a young postdoc can usually relate better to problems a grad student might have with a topic. What irritated me was the randomness. It didn’t feel that the speakers were chosen for specific reasons or talks but just for the usual kind of talk you’d give as at an arbitrary conference. I’d have preferred either discussion sessions guided by the postdocs or some kind of tutorial. This also connects to something I kept wondering about. The workshop has grown considerably. The first one had, I think, 30 participants, this year there were over 70. Even though I didn’t go to the earlier ones, I think it might be worthwhile to think about restricting access somewhat. Not by some random notion of ‘elite’ but simply by academic age, say people who are +-2 years from a PhD. Combine those with a select choice of great tutorial/discussion speakers (great speakers, not just great researchers), possibly increase discussions by hooking up some more postdocs via video broadcasting. I don’t know, just a thought.</p>
<h2>The social <del>-network</del>- experience</h2>
<p>Finally, all of the above experiences would be much less meaningful without the social aspect of (especially) this meeting. After all, the <strong>young</strong> set theorists are the focus. When I was on my way to the workshop, it dawned on me that, assuming I manage to stay in research, this would be a large part of my long-term peers. This gave the social component of the workshop a particular flavor and I often stopped to wonder how comfortable I’d be in this group. From the gender debate on quomodocumque a while ago, that one sentence stayed with me: “mathematics is often not worth the people you have to put up with”. My feelings in this respect were very mixed. I find it very difficult to introduce myself to mathematicians if I don’t have a meaningful question or comment. In a conference where there are relatively few speakers the easy way out for me (to pick something from the talk and start a conversation) wasn’t available. So I didn’t end up getting to know as many new people as I would have liked. Among those that I got to know for the first time where both very nice people and people that I could not connect with at all (or rather would prefer not to connect with), so I guess that part is absolutely normal. A few times though I was really disturbed by people, the most disgusting part probably was to overhear an extremely sexist comment. Unfortunately, I heard it from far away and couldn’t react at all, but such an open display shocked me. I guess you could say “well, quite normal in our society” but I do feel that such smart and highly educated people should be able to think beyond such discrimination (and certainly I cannot accept an excuse along the lines of “wasn’t meant that way” from somebody this educated).</p>
<p>I was nevertheless extremely happy to meet many old and new friends. To have a memorable conversation with Stefan Geschke, Gido Scharfenberger-Fabian (Berlin “siblings” of mine), David Chodounsky, Jonathan Verner, Marcin Sabok, Philipp Schlicht (head of the organizing comittee and master’s “sibling” ages ago in Munich), Thilo Weinert, Alexander Primavesi, Andrew Brooke-Taylor, Daniel Soukup, Sam Coskey, Wolfgang Wohowsky, Luz Avila, Dilip Raghavan — so many people, it was a pleasure.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[gender discussion at quomodocumque]]></title>
        <id>https://www.peterkrautzberger.org/0053/</id>
        <link href="https://www.peterkrautzberger.org/0053/">
        </link>
        <updated>2011-02-03T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Since I had promised, let me post <a href="http://quomodocumque.wordpress.com/2011/01/26/gendered-conference-campaign/#comment-5736">the comment I finally added</a> to the discussion at quomodocumque I had <a href="https://www.peterkrautzberger.org/0052/">mentioned before</a>. Also: note the link to Ivelisse Rubio’s talk in there — it’s finally online!</p>
<p>I had been following the discussion and I finally wanted to add my 2 cents. As much as I’m in favor of a gender conference campaign (let me see, my next conference has 52 men and 8 women participating, and that’s a conference exclusively for young researchers…) I think there’s need to think about the levels before that.</p>
<p>I wanted to stress <a href="http://quomodocumque.wordpress.com/2011/01/26/gendered-conference-campaign/#comment-5699">Pipers</a> sad but true point “i find that math is often not worth the people you have to deal with”. As a student, during my PhD and now as a postdoc I have seen how this and similar issues have driven women (and minorities) out of mathematics. Not only did we loose a diversity in mathematical culture, but we simply lost some of the most talented people I have met.</p>
<p>The dominant unconscious bias I encounter is ignorance. That is, many researchers seem unaware of the simple fact that people with different backgrounds require different measures to show them a way towards mathematical research. Yes, everybody has to work hard, but if nobody shows you what doing research is actually about, how can you consider investing your talent in research?</p>
<p>The most brilliant argument in favor of an initiative seems to be success. Ivelisse Rubio recently gave a <a href="http://www.math.lsa.umich.edu/mlk/index.html">talk at the UofM</a> about women and minorities in mathematics. She spend the second half of the talk to describe young researchers that were drawn into research through such initiatives and supervisors that were ready to think about the real problems that stand in the way of such a career.</p>
<p>I think that’s the crucial factor. We should do whatever it takes to get the smartest people to do research in mathematics. Not just those white males that get a lot of good feedback from themselves.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Punkmath, annotatr and gender discussions]]></title>
        <id>https://www.peterkrautzberger.org/0052/</id>
        <link href="https://www.peterkrautzberger.org/0052/">
        </link>
        <updated>2011-01-31T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>So last week was pretty abysmal as I spent most of the time in bed with a cold like I haven’t had in a while. Since this led to a major shutdown of my brain I failed to do anything useful. Whenever it didn’t burn a hole in my brain I did read a few interesting things.</p>
<h2>Punkmath</h2>
<p>I seem to be both late and early to the party. I cannot quite reconstruct how I ended up reading about Tom Henderson’s projects, so this is rather random. He co-hosts the frakkin’ cool podcast <a href="http://www.mathforprimates.com/">Math for Primates</a> together with <a href="http://www.sapiengames.com/">Nick Horton</a>, there’s <a href="http://www.mathpunk.net/">mathpunk.net</a> and <a href="http://punkmathematics.com/">punk mathematics</a> and finally he can be found <a href="http://twitter.com/mathpunk">on twitter</a>.</p>
<p>The sad thing is that all of Tom’s projects (apart from his twitter account) seem currently dormant while he writes a book — a book that <a href="http://www.kickstarter.com/projects/1541803748/punk-mathematics">he financed via kickstarter</a> with an incredible USD28.000+ raised after aiming for a goal of USD2.400! That’s just absolutely mind-boggling to me. You can read an interesting <a href="http://technoccult.net/archives/2010/02/25/the-punk-rock-philosophy-of-mathematics-technoccult-interviews-tom-henderson/">interview with him on technoccult</a> if you don’t have the time to listen to the podcasts (if you find the podcast’s topics all too familiar when it comes to topics for popularizing mathematics I would still argue you should check out their awesome style).</p>
<h2>annotatr</h2>
<p>So a while ago there was <a href="http://mathoverflow.net/questions/51056/are-there-any-good-websites-for-hosting-discussions-of-mathematical-papers">an interesting mathoverflow question on discussing mathematical papers online</a> that was (of course) closed immediately but Ben Webster managed to revive it and it actually got some fascinating answers.</p>
<p>Besides the trouble that mathoverflow still has when it comes to long term development of questions, there were not only the favoured power user answers describing a potential system — there were <a href="http://www.quora.com/What-are-some-websites-where-one-can-post-commentary-and-reviews-of-academic-papers">actual pointers to such projects</a>! What caught my eye immediately was, as you’ll understand, <a href="https://web.archive.org/web/20110301214716/http://annotatr.appspot.com/">annotatr [Wayback Machine]</a>.</p>
<p>Annotatr is a sleeping beauty of a project. Hosted on the Google App Engine with <a href="https://github.com/mreid/annotatr">open sourced code on github</a> it makes you heart delight. Also, the simplicity of the idea is wonderful — combine citeulike with disqus, done.</p>
<p>Alas, it’s not working well so far. On the one hand the code hasn’t seen an update in half a year, on the other, there’s lack of a community. If mathblogging allows for it, I’d love to get acquainted with the code. I think if someone <a href="https://github.com/mreid/annotatr/issues">solves issues 2 and 3</a> it would be easy to get more people engaged.</p>
<h2>Gender bias at mathematical conferences</h2>
<p>A discussion took place at <a href="http://quomodocumque.wordpress.com/2011/01/26/gendered-conference-campaign/">quomodocumque</a> the other day. I wish I could say I was surprised by the early comments but I was glad to read all the good counter arguments to the displayed ignorance. I haven’t got around posting my 2 cents. I’ll write more here once I get around posting there (which I plan after getting Ivelisse Rubio’s <span class="caps">MLK</span>-day talk online on the department’s website). But you should really read it and join the discussion.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Outage at mathblogging.org]]></title>
        <id>https://www.peterkrautzberger.org/0051/</id>
        <link href="https://www.peterkrautzberger.org/0051/">
        </link>
        <updated>2011-01-20T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Wow! Today we experienced our first outage at <a href="http://mathblogging.org/">mathblogging.org</a>.</p>
<p>Time to finally set up <a href="https://mathblogging.wordpress.com/">our developer blog</a> for future emergencies and better coverage of what we’re doing! Check it out for an explanation of today’s outage.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Eternal preliminaries part 3, the problem of extending partial semigroups]]></title>
        <id>https://www.peterkrautzberger.org/0050/</id>
        <link href="https://www.peterkrautzberger.org/0050/">
        </link>
        <updated>2011-01-18T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://www.peterkrautzberger.org/0047/">In the previous post</a> I have totally ignored my focus from the first post, namely that I want to focus on partial semigroups, not full semigroups. As <a href="https://www.peterkrautzberger.org/0042/">mentioned in the first part</a> this is not really a problem as any partial semigroup operation is in essence a restriction of a full semigroup operation. So the full semigroup is always a neat thing to fall back to when you’re in doubt. Nevertheless, if, as I claimed, it is an advantage to work with partial semigroups, can we not get around this problem?</p>
<h2>Extending a partial operation to \(\beta S\).</h2>
<p>Luckily, it is very much possible to do extend a partial operation. (Un)fortunately, <a href="https://www.youtube.com/watch?v=qWS2NVX6VP0">nobody’s perfect</a> that is I don’t know how to get all the theory to run smoothly so in what follows I might have to fall back for some things. We’ll see.</p>
<p>So how do you extend the operation? Easy! Use the brute force method!</p>
<p><strong>Extending the operation to \(\beta S\)</strong> For \(p,q \in \beta S\), consider those \(A\subseteq S\) with \(A^{-q} \in p\). These sets may or may not yield an ultrafilter. If they do, we call it \(p \cdot q\).</p>
<p>Ok, that’s a bit weird. The way I wrote it there is no reason to believe that such \(A\) will ever form a filter, let alone an ultrafilter! Now, since the operation is partial, we had to expect a little bit of weirdness. But accept (or ignore) the unreasonable definition at this point and I’ll try to explain why this could work.</p>
<p>First to note is: watch out! Maybe I’m trying to trick you with the definition, hiding behind the weirdness. As I wrote in the last post, the \(A^{-q}\)-notation is a “general nonsense” notation (even worse, I came up with it myself…), a simplified notation that hides complicated structures (though, hopefully, to a later advantage). So we better check it in detail.</p>
<ul>
<li>First, for semigroups we had defined \(A^{-q} = \\{ s \in S: s^{-1}A \in q\\}\) — this still seems to work fine, we’re just checking if some set is in \(q\).</li>
<li>But what kind of set are we checking? Going into detail, we find \(s^{-1}A = \\{ t \in S: s \cdot t \in A\\}\) — and this not clear at all! Remember, \(s\cdot t\) might not be defined. What do we do then? Do we want to include or exclude those incompatible \(t\)?</li>
</ul>
<p>But, assuming you’re a forgiving reader, I think it still makes sense: just make \(s\cdot t\) to mean “\(s \cdot t\) and it is defined”. In other words, the original definition should really read \[ s^{-1}A := \\{ t\in \sigma(s) : s \cdot t \in A\\}. \]<br>
This is fine from the point of view of a full semigroup (since always \(\sigma(s) =S\)) and it really captures what we want to capture: those \(t\) that \(s\) maps to \(A\). Of course, the convention that \(s\cdot t\) entails \(t\in \sigma(s)\) is really standard ever since the paper by Bergelson, Blass and Hindman. So I’m luckily in good company. To finish the introduction, we get the same phenomenon as we did before.</p>
<p>\(A \in p\cdot q\) if and only if there exists \(V \in p, {( {W_ v} )}_ {v \in V} \in q\) such that \(\bigcup_ {v\in V} v \cdot W_ v \subseteq A\).</p>
<p>Again, with the analogous convention that \(v\cdot W_ v = v \cdot (W_ v \cap \sigma(v))\).</p>
<h2>The most important observation</h2>
<p>So after this short delay, we can say we have defined a partial operation on \(\beta S\) where the product is \(p\cdot q\) as defined in the previous part but only if the definition yields an ultrafilter. One question is rather immediate.</p>
<ul>
<li>What can go wrong to prevent the multiplication from being defined?</li>
<li>That is, which \(p, q\) actually yield an ultrafilter \(p \cdot q\)?</li>
<li>In other words, how rich is the multiplication?</li>
</ul>
<p>Luckily, this question can be answered rather easily. But let me begin with the most crucial observation and the goal of the rest of this post.</p>
<p><strong>The semigroup \(\delta S\)</strong> Given an (adequate) partial semigroup \((S,\cdot)\) and the above extension of the operation to \(\beta S\), it turns out that \(\delta S\) is a full semigroup.</p>
<p>Kaboom! This is extremely nice. Even though our operation is partial, we get a relatively good piece of \(\beta S\) that is a full, compact, and (we’ll see later) right-topological semigroup — the three key properties for the next part of these preliminaries. This will be our motivation for the rest of this post. Luckily, the proof is essentially done by answering the above questions.</p>
<h2>The partial semigroup \(\beta S\).</h2>
<p>As the heading says, the nicest thing about this extension is that it yields a partial semigroup. This is positively surprising because strong associativity seems difficult to conserve. The key observation is the following.</p>
<p><strong>Proposition</strong> For \(p,q \in \beta S\), the product \(p \cdot q\) is defined if and only if $ \{ s\in S: \sigma(s) \in q \} \in p$.</p>
<p>This is a pretty natural observation. You’d expect the product to work out on the ultrafilters if they contain sets where the multiplication behaves nicely. This is, of course, a common phenomenon with ultrafilters: properties of an ultrafilter are often reflected by its elements and vice versa.</p>
<p><strong>Proof.</strong></p>
<ul>
<li>Like any good ultrafilter proof, we start with a partition: \(S= \\{ s\in S: \sigma(s) \in q\\} \cup \\{ s\in S: \sigma(s) \notin q\\} \in p\).</li>
<li>Since \(p\) is an ultrafilter, one part is in \(p\).</li>
<li>If the second part is in \(q\), then \(p \cdot q\) is not a filter, i.e., the forward direction of our equivalence holds by contraposition.
<ul>
<li>Assume \(A= \\{ s\in S: \sigma(s) \notin q\\} \in p\).</li>
<li>Since \(q\) is an ultrafilter, for any \(a\in A\) we get \(S \setminus \sigma(a) \in q\).</li>
<li>But then \(\bigcup_ {a\in A} a \cdot S\setminus \sigma(a) = \emptyset\), so \(p \cdot q\) is not a filter.</li>
</ul>
</li>
<li>If the first part, call it \(B\) is in \(p\), then \(p \cdot q\) is an ultrafilter.
<ul>
<li>The only problematic case (i.e., the one deviating from the proof of the brute definition for full semigroups) is that \(\emptyset \notin p \cdot q\).
<ul>
<li>To see this realise that \(\bigcup_ {v\in V} v \cdot W \supseteq \bigcup_ {v \in V \cap B} v \cdot (W \cap \sigma(v)) \neq \emptyset\) since \(V \cap B \in p\) and each \(W\cap \sigma(v) \in q\).</li>
</ul>
</li>
<li>The rest is straight forward and not really fulfilling.</li>
<li>Closure under taking supersets and finite intersection is just as easy to check.</li>
<li>\(p \cdot q\) is prime.
<ul>
<li>Let \(C_ 0 \dot\cup C_ 1 = C \in p\cdot q\).</li>
<li>Now easily \(s^{-1} C = s^{-1} (C_ 0 \dot\cup C_ 1) = s^{-1}C_ 0 \dot\cup s^{-1}C_ 1\).</li>
<li>Since \(q\) is prime, exactly one part is in \(q\).</li>
<li>In other words, \(C^{-q}= C_ 0^{-q} \dot\cup C_ 1^{-q} (\in p)\).</li>
<li>Since \(p\) is prime, exactly one part is in \(p\), say \(C_ i^{-q} \in p\).</li>
<li>But this means by definition that \(C_ i \in p \cdot q\), as desired.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>And once again, I have taken the liberty of skipping a little bit ahead. In fact, I will spend the bigger part of the next post talking about other tricks like \((C_ 0 \cup C_ 1)^{-q} = C_ 0^{-q} \cup C_ 1^{-q}\) that the notation has to offer.</p>
<p>But with this we can actually claim.</p>
<p><strong>Theorem</strong> \(\beta S\) is a partial semigroup.</p>
<p>The proof is long and rather boring. Using the previous proposition you can compare what it means for say \(p (q \cdot r)\) and \((p \cdot q) \cdot r\) to be defined. Unsurprisingly, this comparison boils down to a comparison of elements in \(S\) — where, of course, we have strong associatitivity. I’ll gladly update this post if there’s interest and you can find it as <a href="http://www.diss.fu-berlin.de/diss/receive/FUDISS_thesis_000000014327">Proposition B.3 in my thesis</a>.</p>
<p>It’s almost midnight and I’m getting tired so let’s wrap up the proof of the supposedly important observation.</p>
<p><strong>Proof that \(\delta S\) is a semigroup.</strong></p>
<ul>
<li>By the proposition, we know that the multiplication is defined for all \(p,q \in \delta S\) because \(q\) contains all \(\sigma(s)\). (yeah, only \(q\) – you can see some more general observations looming around, right?)</li>
<li>So the question is, whether the product is again in \(\delta S\).</li>
<li>But for that we just check that \(\left(\bigcup_ {t \in \sigma(s)} t \cdot \left(\sigma(t) \cap \sigma(s\cdot t) \right)\right) \subseteq \sigma(s)\) by strong associativity.</li>
<li>So \(\sigma(s) \in p\cdot q\) for all \(s\in S\), as desired.</li>
</ul>
<p>Ok, after this small detour, we’re ready for some ancient and brilliant theorems. Ellis’s Lemma and Hindman’s Theorem coming right up.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[In case you read this]]></title>
        <id>https://www.peterkrautzberger.org/0049/</id>
        <link href="https://www.peterkrautzberger.org/0049/">
        </link>
        <updated>2011-01-17T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Ever since we started working on <a href="http://www.mathblogging.org/">mathblogging.org</a> I have been reading far too many math blogs. At the beginning of the year many bloggers (of course, also in the scienceblogging community) have analyzed their page data and discussed trends and interests to readers. This made me think whether I should invest time in some technology to gather such data. Thankfully, I do not have to do this from a technical point of view since my webspace is provided for free thanks to a generous supporter. But somehow I do not feel inclined to do it anyways. It’s not that I don’t want to know people read my posts (although, realistically I would expect the number be significantly lower than 10). But when weighing the invasion of privacy of my (potential) readers against my own interest in them, I am convinced that it’s not worth it, a conviction which grew stronger this week.</p>
<p>Last week I stumbled upon a piece on <a href="http://www.ftrain.com/">ftrain</a> that I found amazing. Paul Ford writes about a concept he calls wwic or “Why wasn’t I consulted” and believes to be a integral property of the most successful internet projects. You should, really should, go over and read it. It made me think about why I keep this page. As you can check I have approximately zero comments and most communication I have about my posts happens in meatspace, not cyberspace. What I would love to have is, like most bloggers, a conversation about what I write. Most of the things I write are nevertheless not really designed to spawn a conversation. And that’s ok. I will nevertheless try to experiment more towards creating conversations and see how that goes.</p>
<p>Coming back to collecting data, this goal, having a conversation, strengthens my conviction that I do not want to have the necessary technology. I want to ‘consult’ (in the wwic sense) people, find out what they think about what I write. If somebody does not want to get involved with my posts (leave a comment, link me etc) then I really have no reason to track their behaviour either — it’s just not what I am interested in. If, on the other hand, you ever read my posts and want to react, I’d be very happy if you left a comment.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Saturday morning math blogs]]></title>
        <id>https://www.peterkrautzberger.org/0048/</id>
        <link href="https://www.peterkrautzberger.org/0048/">
        </link>
        <updated>2011-01-15T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Well, with <a href="http://www.mathblogging.org/">mathblogging.org</a> up and running in beta I have been reading far too many math blogs (and I love it). This morning there was a lot of interesting stuff out there and I thought it might be interesting to mention some, especially those that I actually left a comment on. After all, that’s what makes blogging come alive and I don’t comment often enough.</p>
<h2>researchblogging vs arxivblogging</h2>
<p><a href="http://www.stat.columbia.edu/~cook/movabletype/archives/2011/01/regression_disc.html" title="...">Andrew Gelman (sorry for the error earlier) of Statistical Modelling</a> posted what is essentially a short review of a paper. I was too lazy to check if the paper had been published, but I left a comment anyway (although now, a couple of hours later I can’t see it and I can’t remember if comments are creened or if I screwed up; oh well, I’ll risk a double post tomorrow). The post reminded me of one the things I miss in the mathematical blogosphere — using <a href="http://researchblogging.org/">researchblogging.org</a> to spread word about reviews. I mean, go there and check the mathematics tag. It could really use more posts to give the almighty mathscinet neutrality machine some competition… (and yes, that includes myself and I already have an idea).</p>
<p>The question is if arXiv papers are “allowed” there since researchblogging is all about peer-reviewed papers. Of course, <a href="http://mathoverflow.net/questions/51056/is-there-a-place-where-people-discuss-arxiv-org-papers">there was a discussion on mathoverflow</a> on discussing arxiv papers and there actually seems to be <a href="http://scirate.com/">a project for that called scirate</a> unfortunately with little traffic, the last development blog entry from 2008 and little moderation. Oh well.</p>
<h2>Pondering visitors</h2>
<p><a href="http://www.neverendingbooks.org/the-reddit-aftereffect">Lieven Le Bruyn of neverendingbooks</a> discusses his recent prominence on reddit/math which led him to review how his readers find him. It’s an interesting read and made me write a short post for myself answering his fundamental questions at the end for mysel (which I’ll post some other time).</p>
<h2>Writing experiments</h2>
<p><a href="http://aperiodical.com/2011/01/400-words-in-30-minutes-on-chaos-and-the-weather/">Peter Rowlett of Travels in mathematics</a> starts an experiment for writing more frequently. Great idea, he does a great job and makes me want to copy him. (but, boy, I had forgotten how complicated blogspot’s comment system is…)</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Eternal preliminaries part 2, filters and ultrafilters]]></title>
        <id>https://www.peterkrautzberger.org/0047/</id>
        <link href="https://www.peterkrautzberger.org/0047/">
        </link>
        <updated>2011-01-09T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://www.peterkrautzberger.org/0042/">Last time</a> I wrote about the basic structures, (partial) semigroups. But algebra in the Stone–Čech compactification deals, well, with the Stone–Čech compactification. I will try to ignore the general theory of compactifications because we only deal with a very simple case — discrete spaces. Suffice it to say that any elementary topology book should have a chapter on compactifications if you want to read more.</p>
<h2>Filters and ultrafilters</h2>
<p>Already at the <a href="https://www.peterkrautzberger.org/0042/">end of the first part</a>, I needed to refer to the notions of filters. I don’t want to talk too much about <a href="https://en.wikipedia.org/wiki/Filter_" title="mathematics">filters</a> or <a href="https://en.wikipedia.org/wiki/Ultrafilter">ultrafilters</a> formally because a) we’re going to talk about them all the time anyway and b) wikipedia (to which I link) is much better at giving you a concise but broad overview than I am. Let me give you a cheat sheet though.</p>
<ul>
<li>A family of subsets of \(S\) is a <strong>filter</strong> if it does not contain \(\emptyset\), is closed under taking finite intersections and supersets.</li>
<li>A family of subsets of \(S\) has the <strong>(strong or infinite) finite intersection property or (i)<span class="caps">FIP</span></strong> if the intersection of any finite subfamily is non-empty (infinite).</li>
<li>A family with (i)<span class="caps">FIP</span> generates a (free) filter by closing it under finite intersections and supersets.</li>
<li>A filter \(F\) is an ultrafilter iff it is a <strong>maximal</strong> filter (with respect to inclusion) iff it is <strong>prime</strong> \((A\cup B \in F \leftrightarrow A \in F \mbox{or} B\in F)\) iff \((\forall A\subseteq S) A\in F \mbox{or} S\setminus A \in F\).</li>
<li>We identify \(s\in S\) with the principal ultrafilter \(\\{ A\subseteq S : s\in A\\}\).</li>
</ul>
<p>Filters can be considered as 0-1-valued, finitely-additive measures (or rather the measure 1 sets of such a measure) in which case ultrafilters are complete measures which is an idea I might use in “prose” every once in a while. You can also consider them as a form of universal quantifiers which gives another intuition. A useful shorthand will be “almost all (with respect to some ultrafilter \(p\))” or “\(p\)-many” or “\(p\)-large” etc. instead of, say, “there exists a set in the filter such that for every element in that set…”.</p>
<p>We’ll get back to this later. One final note, \(F,G,H\) are usually denoting filters, \(p,q,u\) ultrafilters. We’ll discuss many filters explicitly later (and in part 1 we already considered the filter \(\sigma(S)\)) but the existence of ultrafilters is a tricky business that requires quite a bit of the axiom of choice.</p>
<p><strong>The Ultrafilter Lemma</strong> Every filter can be extended to an ultrafilter.</p>
<p><strong>Proof</strong>.</p>
<ul>
<li>The set of filters is partially ordered by inclusion.</li>
<li>The union of any chain of filters is a filter.</li>
<li>Apply Zorn’s Lemma to find a maximal element.</li>
</ul>
<p>[This theorem](<a href="https://secure.wikimedia.org/wikipedia/en/wiki/Boolean_">https://secure.wikimedia.org/wikipedia/en/wiki/Boolean_</a> prime_ ideal_ theorem) is weaker than the axiom of choice, but very strong already in itself (looking up that link I just learned that Tarski himself proved the existence of non-principal ultrafilters in 1930; wikipedia. awesome.). Of course, the real power lies in the three characterizations of ultrafilters in the cheat sheet, so let’s prove the difficult one</p>
<p>A filter \(F\) is maximal iff \(F\) is prime, i.e., \((\forall A\subseteq S) A\in F \mbox{ or } S\setminus A \in F\)<br>
<strong>Proof</strong>.</p>
<ul>
<li>If \(F\) is maximal, \(A\subseteq S\), then either \(A \in F\) or \(S\setminus A \in F\).
<ul>
<li>If there exists \(B\in F\) such that \(A \cap B = \emptyset\), then \(B \subseteq S\setminus A\), so \(S\setminus A \in F\) and we’re done.</li>
<li>Otherwise every \(B\in F\) has \(A \cap B \neq \emptyset\) in which case \(F\cup \\{A\\}\) has the <span class="caps">FIP</span>, hence generates a filter.</li>
<li>But \(F\) was maximal, so the generated filter cannot gain new elements.</li>
<li>In other words, \(A\in F\).</li>
</ul>
</li>
<li>If \(F\) is prime, then \(F\) is maximal.
<ul>
<li>Consider any family \(G\) such that \(F \subseteq G\), but there exists \(A \in G \setminus F\).</li>
<li>Since \(A \notin F\), then by primeness of \(F\), \(S \setminus A \in F\).</li>
<li>Therefore, \(A, S\setminus A\) are both in \(G\).</li>
<li>In other words, \(G\) is not a filter — in other words, \(F\) is maximal.</li>
</ul>
</li>
</ul>
<h2>The Stone–Čech compactification (apologies for missing haceks)</h2>
<p>The set of ultrafilters is often denoted by \(\beta S\) and it turns out to be the [Stone–Čech compactification](<a href="https://secure.wikimedia.org/wikipedia/en/wiki/Stone%E2%80%93%C4%8Cech_">https://secure.wikimedia.org/wikipedia/en/wiki/Stone–Čech_</a> compactification), i.e., the maximal compactification of \(S\), because \(S\) is discrete. There’s a gazillion things to be said about \(\beta S\). To get started, we should celebrate the most practical and in fact characterizing property of the Stone–Čech compactification.</p>
<p><strong>Universal Property of \(\beta S\)</strong> If \(X\) is compact and Hausdorff, \(f: S \rightarrow X\) continuous (in our case, any map is), then there exists a unique continuous map \(\beta f: \beta S \rightarrow X\) that extends \(f\). We usually identify \(\beta f\) with \(f\) for convenience.</p>
<p>The easiest way to do this in our setting, is to <a href="http://www.tricki.org/article/How_to_use_ultrafilters">take the limit along ultrafilters</a>. But for now we don’t need to.</p>
<p><strong>An interlude about extensions</strong> If \(f: S \rightarrow S\), then we can describe the image quite nicely, namely \[ f(p) = \\{ B : (\exists A \in p) f[A] \subseteq B \\}. \]</p>
<p>Often this definition is given by $ f(p)= \{ B: f^{-1}[B] \in p\}$ but I think this is a perfect example of the stupid tendency of mathematicians to write a definition as efficiently as possible even though the compression does more harm than good — as a student it always confused the hell out of me and I mixed it up with preimage filters (which are more difficult to define unless \(f\) is surjective). To remember: \(f(p)\) is the unique ultrafilter generated by the family $ (f[A])_ {A\in p}$, the filter generated by the images. Yes, it’s longer to write down, it’s not as self-contained a definition, but really: it does make more sense that way, no? And who’d think the self-contained definition in itself helps anyone understand anything anyway…</p>
<h2>Extending the semigroup operation</h2>
<p>We want to extend our (partial) semigroup operation to \(\beta S\). The trouble is that the extension won’t be unique and from a theoretical point of view each of those non-unique extensions can be defined using different techniques (resulting in the same kind of extension). The problem of uniqueness also leads to four different descriptions when it comes to the continuity of the operation, but let’s first get started.</p>
<p>I “grew up” with the book by Neil Hindman and Dona Strauss, so I tend to follow their set up (regarding which kind of extension we want).</p>
<h3><strong>Using the universal property of \(\beta S\)</strong></h3>
<ul>
<li>For each \(s\in S\), we can consider \(\lambda_ s: S \rightarrow S\subseteq \beta S, t\mapsto s \cdot t\), i.e., multiplication with a fixed left-hand side.</li>
<li>This is a continuous map (since any map on \(S\) is), so we can extend it to \(\beta \lambda_ s : \beta S \rightarrow \beta S\); we simply write \(s \cdot q\) for this.</li>
<li>Now switch it around and for \(q\in \beta S\) consider this extended multiplication with \(q\) fixed on the right hand side, i.e., the map \(\rho_ q: S \rightarrow \beta S, q \mapsto s \cdot q\).</li>
<li>Again this is a continuous map (since any map on \(S\) is), so we can extend it to \(\beta \rho_ q : \beta S \rightarrow \beta S\); and for this we write \(\rho_ q(p) = p \cdot q\).</li>
<li>Tada, we have our operation.</li>
</ul>
<p>Of course, this gives us no tangible clue as to what such a product of ultrafilters actually looks like. But at least one thing is easy — multiplication with a fixed right hand side is continuous! I call this <strong>right-topological</strong>. You can see that we might start symmetrically and then we end up with a different operation (though very similar to our own). Also, some people like to call the above continuity left-topological (because its continuous in the left hand argument). So, lots of confusion… we’ll stick to this one.</p>
<h3><strong>The brute force definition</strong></h3>
<p>There’s thankfully a way to give the same definition by brute force (which is my favourite way to write it down), but let’s think about it naively. We have two ultrafilters \(p,q\) and we have our operation \(\cdot\). So why not just take \(A \in p\) and \(B\in q\) and look at all possible products \(A \cdot B\)? Collect all these \(\\{ A \cdot B: A \in p, B \in q\\}\) and we get a nice little filter. Are we done? Well, the problem is that this will pretty much never give you an ultrafilter (if it does you either have a very simple operation or (say in \(\mathbb{N}\)) very, very special ultrafilters).</p>
<p>So what do we need to do? We need to complicate things (and if you try to write down to check where the above attempt of a definition fails, this complication comes naturally). Later I’ll introduce some notation to make nicer general nonsense, but let’s take a look first.</p>
<p><strong>Extending multiplication to \(\beta S\)</strong> For a semigroup $(S, \cdot) $ and \(p,q \in \beta S\) we define the product \(p \cdot q\) by \[ A \in p\cdot q \Leftrightarrow (\exists V\in p)(\exists {(W_ v)}_ {v\in V} \mbox{ in } q) \bigcup_ {v\in V} v \cdot W_ v \subseteq A. \]</p>
<p>Ok, quite a beast. Don’t despair! Remember what we tried first: sets of the form \(V \cdot W = \bigcup_ {v\in V} v \cdot W\). What the above definition tells us is that we need to allow the \(W\) to be more flexible — possibly different for each \(v\)!</p>
<p>There is a different angle to look at this: the tensor (or Fubini) product of ultrafilters.</p>
<p><strong>Tensor product of ultrafilters</strong> For \(p,q \in \beta S\) define \(p \otimes q \in \beta (S \times S)\) by \[ A\in p\otimes q \Leftrightarrow \\{ s: \\{ t : (s,t) \in A \\} \in p \\} \in q \]</p>
<p>Not much better, eh? Let’s take a look though: the tensor product is contains sets \(A\) such that the first projection of \(A\) lies in \(p\) and additionally almost all fibers (in the sense of \(p\)) of the first projection lie in \(q\). So you might say that the sets are \(p\)-large horizontally and \(q\)-large vertically.</p>
<p>What has this to do with the product we defined before? Well, the tensor product live on \(S \times S\) and the multiplication is a map from \(S \times S\) to \(S\). So looking at the continuous extension \(\beta \cdot\), i.e., the extension to \(\beta (S\times S)\) (which is different from \(\beta S \times \beta S\) btw) we can simply take the image, \(\beta \cdot(p \otimes q)\). If you look at the “interlude” earlier regarding such images, you’ll notice that we get exactly the ultrafilter described in the brute force definition.</p>
<p>Still not happy? Yeah, I know that feeling… Ok, let me offer my favourite general nonsense notation.</p>
<ul>
<li>For \(s \in S, A\subseteq S\) define \(s^{-1}A := \\{ t \in S: st \in A\\}\) (note: don’t have to be able to invert to define this…)</li>
<li>For \(A\subseteq S, q \in \beta S\) define \(A^{-q} := \\{ s \in S: s^{-1}A \in q \\}\)</li>
<li>Then \(A \in p \cdot q\) if and only if \(A^{-q} \in p\).</li>
</ul>
<p>Alright, much shorter now. But does it help? I don’t know. I certainly don’t claim to “really” understand this operation (but there’s a certain limit since, well, it’s on ultrafilters after all…). My notation for the set \(A^{-q}\) is not standard (but there’s no notation, so I made it up for my thesis). This set consists of those elements that (inverse-)shift \(A\) to make it an element of \(q\). If \(p\) contains it, we can expect elements in \(p\) to contain elements that shift elements of \(q\) into \(A\) — which is maybe an idea.</p>
<p>One advantage is that you can check a few things more easily with the brute force definition.</p>
<ul>
<li>The operation is right-continuous — \(A^{-q}\) is exactly the neighbourhood that shows the continuity of \(\rho_ q\) with respect to \(A\).</li>
<li>The operation is associative — just write it out.</li>
</ul>
<p>Phew, that was a lot. But we’re finally ready to get to some real theorems!</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The candy stores of academia]]></title>
        <id>https://www.peterkrautzberger.org/0046/</id>
        <link href="https://www.peterkrautzberger.org/0046/">
        </link>
        <updated>2011-01-06T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><strong>Over lunch</strong> I had one of those really excellent discussions you can enjoy with grad students at the University of Michigan. Among a thousand interesting topics we talked about the question of career options for grad students after graduation. Of course, we started debating the usual sad story: being academically brought up at a research university your supervisors will hardly ever discuss alternatives to a career in academia because, well, they obviously did not pursue alternative career paths and hence have little to share on the topic. Of course, most faculty will argue that they are in the education business (<a href="http://www.johndcook.com/blog/2011/01/03/educating-versus-credentialing/">not the certification business</a>) so they need to focus on educating you about (their) research topics. At this point it’s not difficult to start a rant for a day or two…</p>
<p><strong>Thankfully,</strong> the grad student gave it an interesting twist by mentioning the experience of a friend higher up in the academic food chain at a university in a city far far away. Said friend did, in fact, try hard to do just what we both complained about and invested a large amount of time in <a href="https://www.peterkrautzberger.org/0046/">pointing out the risks</a> of an academic career. Unfortunately, it turned out that the students could not be bothered to consider alternatives, would be annoyed and generally opposed to information on the subject.</p>
<p><strong>This is,</strong> unfortunately, not really surprising. Universities are, in essence, the candy stores of academia. The students are like small children in awe of people who seemingly live in the candy store. What child would believe them when they say that you shouldn’t eat candy all day long?</p>
<hr>
<p><em>Note 2015</em>: The link at &quot;pointing out the risks&quot; pointed to <code>http://blogs.iq.harvard.edu/sss/archives/2011/01/the_phd_craze.shtml</code><br>
which does not exist anymore, not even on the internet archive.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introducing mathblogging.org]]></title>
        <id>https://www.peterkrautzberger.org/0045/</id>
        <link href="https://www.peterkrautzberger.org/0045/">
        </link>
        <updated>2011-01-05T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I think I mentioned at some point that I had started a secret little project a few months ago. Well, <a href="http://www.felixbreuer.net/">Felix</a>, <a href="http://ta.twi.tudelft.nl/wst/users/heymann/">Fred</a> and I have decided that the new year should be plenty of reason to put some more hours into its development and make it more public.</p>
<h2><a href="http://www.mathblogging.org/">mathblogging.org</a> — the idea</h2>
<p>As we say on the main page (<a href="http://www.mathblogging.org/">click it now!</a>), ‘’<a href="http://mathblogging.org/">Mathblogging.org</a> is your one-stop shop for mathematical blogs’‘. Why on earth, you might say, do we need such a thing? Well, I have been following mathematical blogs for quite some time now but I am frequently amazed how unaware of the rich mathematical blogosphere many people are. Maybe some people became more aware over last years <a href="http://www.scottaaronson.com/blog/?p=458">PvNP-proof-debate</a> or the fantastic <a href="http://polymathprojects.org/">polymath projects</a>. But too many people I talked to, whether academically young or old, although interested in blogs often complained to me how complicated it is to find out what’s happening in the mathematical blogosphere.</p>
<p>So one day, when Felix, Fred and I talked about this, I suggested that we could really use a mathematical copy of the extremely cool project over at <a href="https://web.archive.org/web/20110108131826/http://scienceblogging.org/">scienceblogging.org [wayback machine]</a>. Of course, the science bloggers have not just the advantage of numbers and public interest. They also have <a href="http://scientopia.org/blogs">strong</a> <a href="http://blogs.plos.org/">blogging</a> <a href="http://www.labspaces.net/view_blogs.php">networks</a> which already guarantee a high degree of connectivity within the scientific blogosphere. Since the ideal solution of starting a blogging network can not happen by wishful thinking we thought we could at least help to raise the visibility of the mathematical blogosphere. So we started to design a clone of <a href="http://scienceblogging.org/">scienceblogging.org</a> while tyring to accomodate the shape of the mathematical blogging community. And thus <a href="http://mathblogging.org/">mathblogging.org</a> was born…</p>
<h2><a href="http://www.mathblogging.org/">mathblogging.org</a> — what it does</h2>
<p>If you <a href="http://www.mathblogging.org/">still haven’t clicked on the link</a> to see what <a href="http://www.mathblogging.org/">the website</a> actually <a href="http://www.mathblogging.org/">does</a>, let me fill you in. As you’ll see we try to keep everything very simple. So far, we have created three views of what’s going on in the blogosphere:</p>
<ul>
<li>The page with <strong><a href="https://web.archive.org/web/20110129211715/http://www.mathblogging.org/bydate">latest posts [wayback machine]</a></strong> gives you a quick fix, just check what’s fresh out of the typewriters so to speak.</li>
<li>The page with <strong><a href="https://web.archive.org/web/20110123013111/http://www.mathblogging.org/bytype">posts by category [wayback machine]</a></strong> gives you an overview of the different kinds of blogs (group blogs, single researcher blogs, institutional feeds etc) with the latest entries organised by blog.</li>
<li>The page with <strong><a href="https://web.archive.org/web/20110113121453/http://www.mathblogging.org/bychoice">our favourites [wayback machine]</a></strong> (well, favorites — BE vs AE, not easy for three Germans…) is for those who feel overwhelmed by the amount of posts and blogs and just want to read something interesting. The page contains a couple of blogs which either we like or we think are interesting in general.</li>
</ul>
<p>Other than that, there’s the obligatory <a href="https://web.archive.org/web/20110114174017/http://www.mathblogging.org/about">about-page [wayback machine]</a> and some <a href="https://web.archive.org/web/20110114174100/http://www.mathblogging.org/feeds">elementary feeds [wayback machine]</a>. That’s it. Of course, we don’t yet have every blog in there — that’s why there’s a nice “send us your blog” icon on the front page as well.</p>
<h2><a href="http://www.mathblogging.org/">mathblogging.org</a> — the technology</h2>
<p><a href="http://mathblogging.org/">mathblogging.org</a> is beta and still in development. We have many ideas to make it better but we’re all working in research so forgive the slow development. Every page (except the start page) has a comments section thanks to <a href="http://www.disqus.com/">disqus</a> so feel free to comment on anything and everything. In the scientific spirit, the whole project is free as in freedom: the code is GPL’ed and on github, the content is licensed under creative commons and we will dump the database on github after we do some cleaning up. So you are free to give us some competition or help us make it better. Finally, we host everything on Google’s app engine which is nice and affordable. To give credit where credit is due, we generated the initial database by going through our own feed readers and, most importantly, the <a href="http://academicblogs.org/index.php?title=Mathematics/Statistics">mathematics section of academicblogs.org</a> discarding dead blogs and those without a (mathematics related) post in the last 9 months (for the record, we did this in November 2010 so feel free to let us know what we missed since then).</p>
<h2><a href="http://www.mathblogging.org/">mathblogging.org</a> — the future</h2>
<p>As mentioned, we have many ideas. The views are very basic right now and especially the category-view is a bit cluttered due to the amount of blogs (which will only increase…). So check out our development over time and feel free to give us a hand. My personal hope is that the increased visibility will lead to some mathematical blogging networks eventually, making discussions even richer.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Preprint 'On union ultrafilters']]></title>
        <id>https://www.peterkrautzberger.org/0044/</id>
        <link href="https://www.peterkrautzberger.org/0044/">
        </link>
        <updated>2010-12-21T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Remember back in summer when I was at <span class="caps">BLAST</span>? I promised that I’d upload that paper to the arXiv soon. Well, it took me a while longer, but it finally is uploaded to the <a href="http://arxiv.org/pdf/1012.4532">arXiv</a> (after submitting it to the <span class="caps">BLAST</span> proceedings in November).</p>
<h3>What it’s about</h3>
<p>The paper is a sibling to <a href="https://www.peterkrautzberger.org/0026/">the one already mentioned</a>. This time, instead of the strongly summable ultrafilter world, I focused on the union ultrafilter world.</p>
<ul>
<li>An ultrafilter on \(\mathbb{F}\), the non-empty subsets of \(\omega\), is a <strong>union ultrafilter</strong> if it has a base of FU-set, i.e., sets of the form $FU ( \mathbf{s} ) $ where \(\mathbf{s}= (s_i)_{i \in \omega}\) is a sequence of pairwise disjoint elements.</li>
<li>A union ultrafilter is <strong>ordered</strong> if there is a base of FU-sets such that the sequences are <strong>ordered</strong>, i.e., \(\max(s_i) &lt; \min(s_{i+1})\).</li>
<li>A union ultrafilter is stable if for a sequence of elements $FU ( \mathbf{s}^\alpha ) $ (where \(\alpha &lt; \omega\)) it contains an element $FU ( \mathbf{t} ) $ such that $\{ t_i : i&lt; \omega \} \subseteq^* FU ( \mathbf{s}^\alpha ) $ for all \(\alpha\). Such a $ \mathbf{t} $ is a <strong>pseudo condensation</strong>.</li>
</ul>
<p><a href="http://www.math.lsa.umich.edu/~ablass/uf-hindman.pdf">Back when Andreas Blass introduced union ultrafilter</a> (<a href="http://www.ams.org/mathscinet-getitem?mr=891244">MR</a>) he studied mostly ordered union ultrafilters. The results in my preprint try to make some progress as how to differentiate the different notions. The terminology for stability is akin to P-points and their pseudo intersections, in fact the name is borrowed from the french term for P-points — \(\delta\)-stable.</p>
<h3>Stability for union ultrafilters</h3>
<p>Andreas ended his incredibly rich paper introducing union ultrafilters with a huge theorem which characterizes stability for ordered union ultrafilters in 6 different ways. The first part of the preprint analyses whether the orderedness can be dropped. Orderedness is a very strong condition to add to union ultrafilters and it is similar to the difference between P-points and Ramsey/selective ultrafilters.</p>
<p>Even though <a href="http://dx.doi.org/10.1090/S0002-9947-1987-0906807-4">Andreas Blass and Neil Hindman later constructed a union ultrafilter that is not ordered</a>, the nature of ‘unorderedness’ remained unclear. So I wanted to check if stability might actually imply orderedness. Unfortunately, not a lot can be said. Some of Andreas’s stability characterizations hold for unordered union ultafilters in a similar way, some others imply stability, but whether one of those properties can imply orderedness is still open. The key result in this regard is the following.</p>
<p><strong>Theorem</strong> A union ultrafilter is stable iff whenever the ordered pairs \(\mathbb{F}^2_&lt; = \\{ (s,t) : \max(s) &lt; \min(t) \\}\) are finitely coloured, there exists a homogeneous set in the ultrafilter.</p>
<p>This characterization (which works for any other power up to and including \(\omega\)) is very surprising if you like the analogy to P-points and Ramsey ultrafilters. Indeed, back when Andreas proved it he used it to imply that the image of a stable ordered union ultrafilter under the minimum and maximum functions are Ramsey ultrafilter (he had shown that they are Q-points and the stability easily shows that the images are P-points) which was really surprising at the time — you took a P-point like property and out came that min and max are Ramsey ultrafilters! However, shortly thereafter (in the above paper of Andreas Blass and Neil Hindman), it turned out that union ultrafilters always have min and max as P-points ultrafilters. This leads back to the true mystery: how does stability have such a Miliken-Taylor-Theorem like Ramsey property?</p>
<h3>Unordered, but almost as good as ordered.</h3>
<p>The other half of the paper contains a construction that settles another question related to orderedness. As I mentioned, Andreas and Neil had constructed a union ultrafilter that is not ordered. The way they did it was by preventing min and max to map it to a Q-point — since Andreas had shown that ordered union ultrafilters map to Q-points that way, this meant a fortiori that the union ultrafilter is not ordered. When I first studied that construction, the trouble was (for me) that this construction does not really tell you what ‘unorderedness’ look like. In the spirit of the first part, trying to check the differneces between ordered and unordered union ultrafilters, I wanted to settle the question whether the properties of the images und min and max can have an influence on the orderedness. Namely, it was open whether a union ultrafilter that maps to Ramsey ultrafilters must be ordered. This turned out not to be the case.</p>
<p><strong>Theorem</strong> There consistently exists union ultrafilters that are not ordered union ultrafilters but their min and max are Ramsey ultrafilter.</p>
<p>It looks like a silly theorem, doesn’t it? So technical, just a slight difference to what was known etc etc. For me the interesting part was what happened in the proof. One key was to consider what I call the meshing graph.</p>
<p>Fix some pairwise disjoint sequence \(\mathbf{s}\). If $\mathbf{t} \subseteq FU(\mathbf{s}) $, then <strong>the meshing graph</strong> on the vertices \(\mathbf{t}\) is defined by edges between some \(t_i,t_j\) if there exist \(s_k \subseteq t_i, s_l \subseteq t_j\) such that neither \(\min( s_k ) &lt; \max( s_l )\) nor $\min ( s_l ) &lt; \max ( s_k ) $.</p>
<p>In other words an edge represents that two elements are not ordered, they mesh. But it’s actually important that they do not just mesh, but they mesh because they contain elements in \(\mathbf{s}\) mesh. The reason is that for a union ultrafilter not to be ordered requires some special FU-set (in this case $FU ( \mathbf{s} ) $) that is never refined to an <strong>ordered</strong> FU-set.</p>
<p>For that it’s not enough to look at the meshing graph with edges when the \(t_i\) mesh; it could be that they mesh but in such a way that we are later forced to condense \(\mathbf{s}\) to something ordered. To put it differently, it’s not difficult to take an ordered union ultrafilter and write down a base of not-ordered FU-sets (just merge every second element of a sequence). The difficulty is to guarantee that no ordered base exists.</p>
<p>The idea of the construction (which is done assuming CH, but essentially just requires iterated Cohen forcing, so MA-variants suffice) is to string together big batches of finite sequences with a complete meshing graph (in respect to some nicely behaving special sequence \(\mathbf{s})\). So the meshing appears in big blobs of larger and larger cliques — which then turn out to be strung together in an ordered fashion (the blobs that is). For details, check the preprint.</p>
<p>Why do try to describe this? Well, it seems to give a good idea of what meshing in an unordered union ultrafilter should look like — each sequence for an FU-set should have larger and larger segments that mesh perfectly, but those segments come up in an ordered fashion. Now if only somebody could prove that meshing always looks like that — it would simplify many proofs and open up new approaches…</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Small update]]></title>
        <id>https://www.peterkrautzberger.org/0043/</id>
        <link href="https://www.peterkrautzberger.org/0043/">
        </link>
        <updated>2010-12-13T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I just did a couple of small updates, finally!</p>
<ul>
<li>MathJax is working properly again (although the firefox bug regarding mathbf-fonts persists…)</li>
<li>I finally changed my license to cc-nc-sa 3.0-licencsing as can be seen by the footer.</li>
<li>The css is now valid although the html is still a mess (e.g., the cutting of the posts on the front page often leads to missing closing tags).</li>
</ul>
<p>Ah well, you can’t have everything…</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Eternal preliminaries part 1, semigroups and such]]></title>
        <id>https://www.peterkrautzberger.org/0042/</id>
        <link href="https://www.peterkrautzberger.org/0042/">
        </link>
        <updated>2010-12-12T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>My thesis was a (somewhat) coherent structure and hence had one big chapter of preliminaries. It was rather painful (and in retrospect stupid) to create preliminaries for each paper based on the results from the thesis by taking that chapter and reducing it to only those terms necessary in each respective paper. To (over)compensate, I have been thinking for a while to write down some ‘eternal preliminaries’ here.</p>
<h2>Semigroups and such</h2>
<p>In the field that is often called ‘algebra in the Stone–Čech (sorry about the missing hacek) compactification’ (or ‘Hindman stuff’ for short), the structures of interest are infinite <a href="http://en.wikipedia.org/wiki/Semigroup">semigroups</a> \((S,\cdot)\), i.e., \(\cdot: S\times S \rightarrow S\) is associative.</p>
<p>However, ever since the amazingly rich <a href="http://www.math.lsa.umich.edu/~ablass/bbh.pdf">paper by Vitaly Bergelson, Andreas Blass, and Neil Hindman on located words</a> (<a href="http://doi.org/10.1112/plms/s3-68.3.449">doi</a>) we have the notion of a partial semigroup. I like this more general notion for several reason which is why I will formulate everything in terms of partial semigroups here.</p>
<p><strong>Definition</strong> Following the above paper, I’ll call \((S,\cdot)\) a <strong>partial semigroup</strong> if the map \(\cdot\) is a partial binary operation for which equations of the type \((s \cdot t) \cdot u = s \cdot (t \cdot u)\) hold in the sense that whenever one side is defined, so is the other and they are equal.<br>
This is often called strong associativity.</p>
<p>The most important example of a partial semigroup consists of the finite, non-empty subsets of \(\omega\),<br>
\[ \mathbb{F} := \\{ s \subseteq \omega : 0 &lt; |s| &lt; \omega \\} \]<br>
with the partial operation<br>
\[ s \cdot t = s \cup t \mbox{ iff } \max(s) &lt; \min(t),\]<br>
in other words restricting the union operation to so called <strong>ordered unions</strong>. Sometimes, another operation is interesting, the more general restriction to disjoint unions, but most of the time the difference between the two restriction won’t matter much to us so we’ll stick to the ordered unions for now. This example is useful right here because it shows two important properties that are typical for partial semigroups, the first resulting in the following observation.</p>
<p><strong>Proposition</strong> Every partial semigroup can be extended to a full semigroup: For every partial semigroup \((S,\cdot)\) there is a full semigroup \((T,\star)\) such that \(S\subseteq T, \cdot \subseteq \star\).</p>
<p><strong>Proof.</strong></p>
<ul>
<li>Given a partial semigroup \((S,\cdot)\), simply adjoin a new zero element.</li>
<li>I.e., let \(T: = S \dot\cup \\{ 0 \\}\) (wherer \(0\) is a new element) and define \(v \star w = v\cdot w\) if defined in \(S\) and \(v \star w = 0\) otherwise.</li>
<li>It’s easy to check that the operation is associative (thanks to strong associativity).</li>
</ul>
<p>Even though partial subsemigroups are much more abundant than subsemigroups (which is why I like them so much), the above fact is extremely useful when it comes to the background theory of partial semigroups (especially, ultrafilters on them which will be our main goal for the next section): we can simply pretend that we have a full semigroup and use that well-developed theory to help us along, after which we can restrict our interests again to the partial subsemigroup.</p>
<p>Actually, most of the time we really are in a situation like \((\mathbb{F},\cdot)\) — we mostly start with a full operation which we reduce to a partial semigroup operation so as to simplify the algebra (as in the case of \(\mathbb{F}\)). Before I get to the first important property of partial semigroups that must be assumed for all that follows, let me give you the most important class of examples of partial subsemigroups — FP-sets.</p>
<p><strong>Examples</strong> Given any (partial) semigroup \((S,\cdot)\) and a sequence \(\mathbf{x}\) in \(S\) the <strong>FP-set</strong> of \(\mathbf{s}\), \(FP := \\{ \prod_ {i \in s} x_ i : s \in \mathbb{F} \\}\) (where products are always in increasing order of indices) has a partial semigroup structure induced by \((\mathbb{F},\cdot)\):<br>
\[ \prod_ {i \in s} x_ i \cdot \prod_ {i\in t} x_ i = \prod_ {i \in s\cup t} x_ i \mbox{ iff } \max(s) &lt; \min(t).\]<br>
In case our (partial) semigroup is written additively, we write FS-set etc.<br>
Note that for commutative (partial) semigroups we can also consider the partial semigroup structure induced by disjoint unions rather than ordered unions since the products/sums still make sense in the commutative world.</p>
<p>These examples are essentially my favorite reason for thinking primarily in partial semigroups — FP-sets with this partial semigroup structure are such a critical component of algebra in the Stone–Čech compactification that we might as well make this explicit. It also has a certain slickness to it — Hindman’s Theorem (one of our main goals here) could be formulated very nicely with this terminology — but that slickness is somewhat misleading; let’s discuss that when we get there (when I would love to weaken the notion further…)</p>
<p>The main problem with partial semigroups is, of course, their partiality; they could be so partial that they are meaningless, i.e., the operation could have empty domain or a very small domain. Thankfully, the examples above have a very rich partial structure: for any finite number of elements we find (many) elements that are compatible with all those finitely many. That’s why I usually assume the following property for partial semigroups.</p>
<p><strong>Definition and convention</strong> Consider a partial semigroup \((S,\cdot)\).<br>
For each \(s \in S\) we denote the set of (right-)compatible elements by \(\sigma(s) := \\{ t \in S: s\cdot t \mbox{ is defined} \\}\).<br>
We say that \(S\) is <strong>adequate</strong> if \({(\sigma(s))}_ {s\in S}\) has the [infinite (or strong) finite intersection property](<a href="http://en.wikipedia.org/wiki/Finite_">http://en.wikipedia.org/wiki/Finite_</a> intersection_ property) and we denote the generated [filter](<a href="http://en.wikipedia.org/wiki/Filter_">http://en.wikipedia.org/wiki/Filter_</a> %28mathematics%29) by \(\sigma(S)\). Unless specifically stated otherwise partial semigroups are adequate.</p>
<p>For most theoretical things it’s not really important that the filter contains only infinite sets, but that’s what we’re really interested in in our applications, so we might as well assume it. On a side note, it is useful <strong>not</strong> to assume that the filter \(\sigma(S)\) is [free](<a href="http://en.wikipedia.org/wiki/Filter_">http://en.wikipedia.org/wiki/Filter_</a> %28mathematics%29), for example when we have an identity in the partial semigroup. The name adequate (without the infinity assumption) is again taken from the paper by Bergelson, Blass and Hindman.</p>
<p>And that’s about all you need to know about partial semigroups for now. In the next post of this series-to-be I will continue with ultrafilters on (partial) semigroups.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The single most important subject]]></title>
        <id>https://www.peterkrautzberger.org/0041/</id>
        <link href="https://www.peterkrautzberger.org/0041/">
        </link>
        <updated>2010-11-28T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Recently, I had a few conversations about teaching mathematics varying from elementary school to undergraduate level. These are not refined, in depth analyses, just some quick thoughts that I think worthwhile to ponder every once in a while.</p>
<h2>The single, most important subject in school is language</h2>
<p>The single, most important subject in school is the native/primary language — especially, for mathematics. This seems to strike people as odd. But I find this statement trivial. Too many people seem to think that everybody understands language anyway and that’s that. As a mathematician and science fan I often found that the lack of proficiency in languages compromises people’s abilities to deal with everyday concepts in our scientific world. The complexity of language is a challenge not to be taken lightly. Even professional journalists are frequently overwhelmed by the complexity of scientific writing — over at <a href="https://web.archive.org/web/20110108131826/http://scienceblogging.org/">scienceblogging.org [Wayback Machine]</a> you will probably find some science blogger crying out against a piece of misunderstood and/or abused science everyday.</p>
<p>In mathematics, it is however even more vital than in the sciences and the humanities. The sciences have empirical facts and the humanities have both emotional and factual aspects that allow us to understand their concepts with information outside of the language being used. If you don’t know what I mean, just look up to the stars, look at some original historical documents or listen to a poem read aloud.</p>
<p>In mathematics the situation is different, language is both alpha and omega. The initial step in understanding a new concept in mathematics is alike to Galileo’s problem: his first telescope was of such primitive nature that if you didn’t not know what you were looking at, you could easily get confused and not see what’s there. Written mathematics is often the only way to make a first step, maybe blindly following the formalism, maybe trying to find understanding by meditating over prose. Once this initial step has been taken we have diagrams, we have computer animation and most of all fruitful discussions; we have all sorts of helpful tricks to add to this initial understanding. But that is not enough, one cannot stop there. In the end, when push comes to shove, we only trust a detailed proof in written or spoken language (and if Doron Zeilberger ever reads this: code is valid for me). There are no other facts, no independent empirical facts, no historical facts that can significantly support a mathematical thought. The abstract thought that gives rise to mathematics can, it seems, only be exchanged neutrally using language.</p>
<p>At school level, it might seem that language is only needed for word problems. But these are often the worst examples — <a href="http://blog.mrmeyer.com/">head over to Dy/dan</a> to understand that. Language is used uselessly; lots of words for no mathematical content. At university on the other hand you often find only our highly specialized language without any supposedly superfluous understandable language. For example, you will encounter the tradition that <a href="http://abstrusegoose.com/230">refuses to find a way to write proofs as they are discovered</a> (which actually often makes them more accessible); the university variant of dy/dan’s pseudocontext are epsilon-delta arguments written the ‘flawless’ but inaccessible way: let \(\epsilon > 0\); set \(\delta\) to \(\frac{ 2 \sqrt{ln(\epsilon) – 5.2346}}{3\pi}\).</p>
<p>So, teach language more! It’s the one and only subject that guarantees a) life long, self-governed education, b) citizens that can understand complicated (political) issues and c) students that have a better chance of excelling at mathematics (and in the long run produces better mathematicians, hooray)!</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tiddlywiki or the end of my LaTeX notes]]></title>
        <id>https://www.peterkrautzberger.org/0040/</id>
        <link href="https://www.peterkrautzberger.org/0040/">
        </link>
        <updated>2010-11-10T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>How can I not even have mentioned this? The single greatest tool of the last three month is… <a href="http://tiddlywiki.com/">Tiddlywiki</a></p>
<h3>What is Tiddlywiki?</h3>
<p><a href="http://tiddlywiki.com/">Tiddlywiki</a> is a wiki in a single html file. It can be full fledged wiki by lots and lots of fantastic javascript fancy. Hackers love it because, well, they can hack it. For me there are <a href="http://customize.tiddlyspace.com/">tons of plugins</a> around (and of course <a href="http://customize.tiddlyspace.com/">also lots of themes</a>). It’s bit weird getting used to the whole thing since the single-file technology works a little differently (plugin installation especially), but it’s so worth it!</p>
<h3>How can it replace your LaTeX notes?</h3>
<p>For mathematicians (and scientists) the coolest thing about tiddlywiki is that you can write <a href="http://en.wikipedia.org/wiki/LaTeX">LaTeX-code</a> in it! There is a jsmath plugin but I prefer the <a href="https://web.archive.org/web/20130707161357/http://www.math.ist.utl.pt/~psoares/MathSVG.html">mathsvg [Wayback Machine]</a> plugin (based on asciimath) since it does not require any additional files (just fonts in the browser, like the styx fonts with firefox). So nowadays I write in a simple markup <a href="https://en.wikipedia.org/wiki/Textile_(markup_language)">much like textile</a> (which this blog is written in). There are <a href="https://web.archive.org/web/20110128204422/http://svn.tiddlywiki.org/Trunk/contributors/MartinBudden/formatters/">plugins for almost any text markup [Wayback Machine]</a>, so if you prefer something else, knock yourself out. I don’t need much myself, to be honest, and unfortunately, the textile plugin I found deactivates mathsvg. Thankfully, tiddlywiki’s own markup and textile overlap a lot and I don’t do much fancy stuff anymore anyway.</p>
<h3>But I like to write in my fancy LaTeX style!</h3>
<p>Oh, I do love fancy TeX styles! But after developing a lot of TeX extravaganza for my thesis, my LaTeX notebook and papers (just ask all those pissed off referees I’ve had) I have gone back to TeX’s roots: separate content from layout. I do believe there is desperate need for the development of better and creative mathematical writing (as in structuring mathematical thoughts in an better understandable way) as well as layout design — mathematical writing is in a bad state and my best guess is that this is thanks to the publish-or-perish pressure (the motto seems: just get the referee to ok it and don’t waste time on quality writing) as well as the journal system failing as a gatekeeper in that respect.</p>
<p>I nevertheless believe that it is not the mathematicians who should develop suitable layout and typesetting style, but typographic professionals (where’s the <a href="http://www.edwardtufte.com/">Edward Tufte</a> of mathematical typesetting!?). With this in mind, my TeX has reverted back to the essentials: simple layout using elementary structures (lots of lists) that can easily manipulated by whoever actually wants to look at my stuff. The ‘restricted’ TeX available in tiddlywiki is more than enough for this (and really, I have not encountered a missing functionality so far).</p>
<p>Essentially, I want to write mathematical content in markup — and whoever wants to view it can generate the layout from the source, whichever way fits best, be it on a projector or a smartphone. Of course, this does not mean to stop thinking about good layout and good writing, it just means that I prefer to mark it up in a way that can be altered easily, preferably automatically.</p>
<h4>But LaTeX is so much easier and flexible!</h4>
<p>Well, not really. Sure, I still pride myself of the fact that my thesis’s source could easily fit on a floppy disc. But that’s really kidding myself — after all, I always need a LaTeX installation to make it work. I have fiddled with a gazillion ways of making TeX portable; virtual machines, live install, online editors, remote access, nothing really works. But a browser, well, a browser is something I will find at any computer with an internet connection; there’s even an android app for tiddlywiki.</p>
<p>And even if I eventually find a good portable LaTeX (though I doubt the need will arise again since there’s a textile to latex converter), I still have to compile stuff. To be honest, after using tiddlywiki for a while compiling LaTeX feels sooooo slow. Anybody who’s seen MathJax in action over at mathoverflow probably knows what I’m talking about. Sure, in the end, a real <span class="caps">PDF</span> would need to be typeset properly (if you really want to print something that is). But anytime before that, I just need a fast conversion and flexible, accessible raw data. So tiddlywiki is actually much nicer for writing TeX. Especially since I “combine” it with <a href="http://www.dropbox.com/">dropbox</a> — it is the perfect way to have my single file accessible anywhere (and share a secret tiddlywiki with Francois and Andreas).</p>
<p>So <a href="http://blogs.plos.org/mfenner/2010/11/06/beyond-the-pdf-it-is-time-for-a-workshop/">unless there’s finally a professional markup developed for scientific and mathematical writing</a>, I will keep my notes in tiddlywiki and make it LaTeX when something goes on the arXiv.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GAIN another retrospective]]></title>
        <id>https://www.peterkrautzberger.org/0039/</id>
        <link href="https://www.peterkrautzberger.org/0039/">
        </link>
        <updated>2010-11-09T00:00:00Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>The people over at <a href="http://www.gain-network.org/"><span class="caps">GAIN</span> headquarters</a> asked me if I could write a short piece about the conference for their newsletter. Even though I have been swamped with work (perfect proof being the lack of updates around here), I could not say no to them. If you have <a href="https://www.peterkrautzberger.org/0033/">read</a> <a href="https://www.peterkrautzberger.org/0034/">my</a> <a href="https://www.peterkrautzberger.org/0035/">previous</a> <a href="https://www.peterkrautzberger.org/0036/">posts</a> <a href="https://www.peterkrautzberger.org/0037/">on the conference</a> you’ll be aware of how much I enjoyed it and especially how much I appreciate the work of the organizers. However, writing such a special post for the GAIN newsletter proved difficult. It was a different beast and, as you know, I am barely capable of writing a blog post. Anyway, I also include that 500-800 words piece here; a bit milder thanks to their editing (and finally a reason to choose a creative commons license for my stuff; watch out for updates in that respect).</p>
</blockquote>
<p>I was looking for a catchy first line, you know, that perfect line that captures the whole piece? Something with ‘Cambridge’, ‘<span class="caps">GAIN</span> conference’, preferably ‘September morning’ and maybe even ‘pondering’ and ‘merrily’ in it. Well, that experiment failed and I only have 800 words, so let’s just jump right in (remind you of anything, dear postdoc?). Just to get it out of the way, the conference was excellent. The participating audience was amazing, the schedule was well balanced and the organization appeared flawless. However, it was a conference for Germans and <a href="http://www.spiegel.de/international/0,1518,417958,00.html">Germans always complain</a>, right? Take me for example. As a mathematician I clearly belonged to the exotic researchers at a conference which, by the looks of it, focused on the life sciences (hardly surprising since <a href="http://www.dfg.de/download/pdf/dfg_magazin/wissenschaftliche_karriere/heisenberg_treffen_2010/erc_foerderung.pdf">40% of all grant money goes that way</a>). So could I really expect anything? Well, I certainly gained a lot.</p>
<h3>The Good</h3>
<p>The first key was the smooth run right down to the details (like catering, the design of the career fair etc.). It created a relaxed and productive atmosphere which turned an audience into participants. This worked extremely well with the balanced mix of sessions, certainly at its best in the Q&amp;A breakout sessions. No lengthy, prepared statements, just jumping right in — and an audience that was not taken aback but ready to debate. It was, simply put, exciting to be at those sessions.</p>
<p>The lecture-like sessions were fortunately both of high quality and actual interest. For example, you got a solid introduction to the complicated grant structures for the next step as well as the academic system in general — and some of them even tried to ‘just’ extend everybody’s horizon. But the very best thing was that I met a lot of interesting people, so interesting in fact, I do not remember a single boring conversation.</p>
<h3>the Bad,</h3>
<p>Now that we have the good stuff out of the way, let’s do some German complaining. Even though the breakout sessions with their panels were very good, this sometimes seemed to be despite the panelists not because of them. Even though it was flattering that all the big research organizations sent their presidents who participated in workshops, panels, and were approachable during coffee breaks and socials, they sometimes fell back on evasive ‘politician speak’ during the q&amp;a sessions. In stark contrast to this was the very best session of the conference, the session on “Nachwuchsgruppen” (the unfortunate term). That session was the perfect combination of what made the conference so enjoyable; excellent information on the grant system and peers that have taken the next step but could still relate to their audience. These PIs were open to questions, did not mind thinking on their feet, did not even mind to stand corrected (how shocking!) after arguments were debated; in short, their invaluable insight gave the participants what they were looking for both intellectually and emotionally. If I had one wish, I’d suggest that there should be more sessions like that one.</p>
<h3>and the Ugly</h3>
<p>There was nothing ugly, of course. But there were some little disappointments, like old-fashioned responses to gender and childcare questions or the lack of foreign researchers from within the German system (only the brilliant lecture by Philip Altbach offered an outsider’s view but stayed outside). Above all, I missed a European perspective. The fact that German funding agencies are restricted to Germany cannot explain the profound lack of a European perspective. This could have been given by the federal politicians (who often seemed in the wrong place) or by German researchers in the EU. With all the talk about brain drain, gain and circulation the one advantage the North-American market will always have over Germany is its size. ‘Getting them home’ should mean Europe, not just Germany. Finally, the recent positive developments in academic funding were excessively stressed by some panelists, once even to deny a discussion of persisting issues. Maybe this short period of improvement solved all problems but it might have been worthwhile to discuss why people nevertheless left Germany.</p>
<h3>Coda</h3>
<p>Juergen Mlynek’s remark during the ‘presidential’ panel was spot on: the biggest problem might be psychological. There are many opportunities to continue a career in or close to academia, more than there ever were, both in number and variety. But reliable information about the actual experience needs to get out there. This sharing of information and personal experience is the main achievement of the conference (with much more beyond that). I’m looking forward to a chance to go again next year.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Live broadcast on the web or why you should never have to miss a talk again]]></title>
        <id>https://www.peterkrautzberger.org/0038/</id>
        <link href="https://www.peterkrautzberger.org/0038/">
        </link>
        <updated>2010-11-06T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I haven’t written anything in ages but so many posts are almost finished and then there’s my secret new project that I can get all excited about but it’s not yet time… Anyway, I just read <a href="http://mathoverflow.net/questions/45037/should-there-be-a-true-model-of-set-theory">this question on mathoverflow</a> and it finally triggered this post. You see, if you read that post, you will stumble upon <a href="http://www.phil.upenn.edu/Workshop+on+Set+Theory+and+the+Philosophy+of+Mathematics">this workshop</a> and, if you’re me, you’ll wonder why you cannot watch a recording of those lectures and, hopefully, the debates that came with it. Now, as puny a set theorist as I might be, I have strong feelings about this — and with Hugh Woodin’s visit to the UofM I was thinking about this stuff a lot all week anyway. So why did I have to miss those talks?</p>
<p>What is so annoying is, that it is soooooo easy to not just record a lecture, but broadcast it live these days. All you need is a decent internet connection and some free tools. Everybody can do it and any larger university should feel obliged to do this. For example, there aren’t many departments in the world that can compete with the math department at the University of Michigan. As I have come to understand our seminar culture is renowned — you can almost double book your entire afternoon everyday with seminars here. But there are a lot of places who cannot offer this for many different reasons. As a public institution (but really, as center of education) we should feel obligated to make this available to anyone. Up until recently, this was not feasible. Today, it is almost trivial. With ability, I believe, comes obligation. (Yes, I almost wrote “with great power comes great responsibility”, fanboys)</p>
<h3>Broadcasting live — the tools.</h3>
<p>So what do you need?</p>
<ul>
<li>1 decent internet connection (good starts at cable/DSL level, any ‘western’ university connection should do)</li>
<li>1 computer (possibly laptop for flexibility)</li>
<li>1 camcorder (a webcam might do, but picture and audio quality is usually higher with a proper camcorder; don’t forget a tripod…)</li>
</ul>
<p>You probably have access to the first two things if you’re in academia. A decent camcorder is expensive but you can look for older models that are affordable. You don’t have to be super picky about the camcorder since only a limited amount of quality will survive the compression of the broadcast anyway. The only thing that’s <strong>important</strong> is that you can hook it up to your computer as an external camera.</p>
<h2>The free (not libre) software</h2>
<p>I have been trying out several things over the last couple of months and the following set up is what I use at the moment.</p>
<ul>
<li><a href="http://www.justin.tv/">justin.tv</a></li>
<li><a href="http://www.adobe.com/products/flashmediaserver/flashmediaencoder/">flash media live encoder</a></li>
<li>windows or mac os (ok, not so free)</li>
</ul>
<p>Before I get to the how…</p>
<h3>What’s the deal?</h3>
<p>You will usually not have a connection good enough to be your own streaming server. That’s where <a href="http://justin.tv/">justin.tv</a> comes in (of course, there are competitors like ustream, but I ended up using that one). They give you the webserver for free (with ads you can pay to get rid of). If you have friends in the IT department, you could try installing the free developer version of <a href="http://www.adobe.com/products/flashmediaserver/">Adobe’s streaming server</a> for up to 10 viewers — and if you’re rich you can buy a full licence… That’s the thing about the free live encoder from Adobe — it’s free, but it needs their media server (which <a href="http://justin.tv/">justin.tv</a> gives you); if you’re like me, you’ll like that <a href="http://justin.tv/">justin.tv</a> also supports vlc (see below).</p>
<h3>How to</h3>
<p>The main initial “effort” is to get your <a href="http://justin.tv/">justin.tv</a> account going — any search engine will help you find info on that but it’s just your average web service. I just want to point out that you should check out the privacy controls as well as <a href="https://web.archive.org/web/20130316081119/http://de.justin.tv/p/fme">their fme guide [Wayback Machine]</a> to, once and for all, find the basic settings that work for your connection.</p>
<p>Once you have made yourself acquainted with a <a href="http://justin.tv/">justin.tv</a> account, you only need to do the following for your regular broadcast.</p>
<ul>
<li>Hook up your camcorder</li>
<li>Launch the live media encoder and press start</li>
</ul>
<h3>The somewhat libre variant</h3>
<p>If you’re a little bit more engaged (and, like me, an <span class="caps">OSS</span> fan), you can replace the proprietary Adobe Flash Media Encoder with the fantastic <a href="http://www.videolan.org/vlc/">VLC</a> following the <a href="https://web.archive.org/web/20130704032729/http://apiwiki.justin.tv/mediawiki/index.php/Linux_Broadcasting_API">justin.tv api vlc guide [Wayback Machine]</a>. I don’t yet know a good libre media streaming server that could replace <a href="http://justin.tv/">justin.tv</a> though. Vlc’s own server creates a huge lag for me.</p>
<h3>What to do during the broadcast or does the lag allow for live questions?</h3>
<p>The whole point of a broadcast is not to just record a video but to allow interaction. I am usually experiencing a three second lag (at home or the department). That’s usually ok for questions and interaction in general. <a href="http://justin.tv/">Justin.tv</a> offers chat on the broadcasting site and you can choose to use facebook or twitter as required authentication. Of course, nothing stops you from using any other system on the side. Questions are fastest by chat, but I usually run skype or similar things, so that a short audio or video question is possible as well. Finally, when it comes to mathematics, I have noticed that audio is more important than video (you can hear what is written down) — and used blackboards have <a href="http://vimeo.com/15475347">very bad contrast</a>…</p>
<h3>Recap — how much time does it really cost?</h3>
<p>Of course, to find this solution is the biggest issue and I spent quite some time to arrive at this solution. But once you get going, all you need is someone to lead the camera — setting things up usually takes 5 minutes (unless you run into technical problems of course…).</p>
<p>So go forth and spread your scientific knowledge!!! And afterwards publish the recording on vimeo or youtube or whatever for all digital eternity. And then nobody has to ever miss a talk again.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GAIN conference retrospectively conclusion]]></title>
        <id>https://www.peterkrautzberger.org/0037/</id>
        <link href="https://www.peterkrautzberger.org/0037/">
        </link>
        <updated>2010-10-07T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Well, this has been going on for too long… This final post should have concluded the mini-series weeks ago. Instead, it has prevented me from writing about anything else. So let me conclude with some late notes and my answers to the feedback questionnaire. I will not go back to the individual posts to refresh my memory, instead, I will write simply what I remember now which is probably more important since it will dominate my long time memory of the whole event (but I will use my notes for this post which sort of developed while writing the rest).</p>
<h3>pros and cons</h3>
<p>Let’s just quickly go through the pros and cons of the whole shebang. First and foremost, the biggest pro was certainly my extremely low expectations. And in a way I am more neutral about the positive aspects of the conference now. After all, it did reinforce the feeling that my field (pure mathematics in general) is quite generally an exotic subject and hence in danger of falling of the funding wagon in the long run. Nevertheless, here is a list of neutral pros.</p>
<p><strong>pros</strong></p>
<ul>
<li>very good information on grant opportunities in Germany
<ul>
<li>This is especially true for but not restricted to post-post-doc funding, i.e., things that might get you on track for a permanent position. So if you want to get info on that, you should come to the conference next time!</li>
</ul>
</li>
<li>Meeting interesting people.
<ul>
<li>This is a soft factor, but one to reckon with. These truly are your peers — and it’s very easy to strike up a conversation. This made the atmosphere (for me) much more relaxed and opened up more aspects that I would have missed on my own. Talk about networking…</li>
</ul>
</li>
<li>Light at the end of short-term contract tunnel
<ul>
<li>It seems that finally the many, many calls are being heard. Many small signs showed that long-term, non-tenure positions might be possible in the future. That would be incredibly appealing to almost anyone I talked to. As was said, it’s all all about psychology. Permanent positions will lower the all-or-nothing pressure which will never lead to less dynamical researchers, but to more productive work environments.</li>
</ul>
</li>
</ul>
<p>Let’s hit the cons. I admit I am probably overly critical, but hey, it’s my post. Go and comment if you disagree!</p>
<p><strong>cons</strong></p>
<ul>
<li>social networks, social media, internet based cooperations FAIL
<ul>
<li>For a networking conference the lack of considerations of internet based networking was pretty shocking. Every (young) researchers knows that digital communication is the key for a productive future. The total lack of talking about this did not mean that this is a triviality and does not need to be repeated. It unfortunately meant that the funding organisations are still in tight control of non-digital natives who don’t understand what potential is already there and how much more is yet to be achieved through online collaborations. Of course, the funding landscape does not accommodate such collaborations for the very same reason, so there was no need for this if you focus on available tools. But the vision was clearly lacking.</li>
</ul>
</li>
<li>Deutsch, Deutsch, Deutsch
<ul>
<li>The whole conference was too German-centric. I grew up in Schengen-country, I don’t know borders in Europe. Europe is my home, Germany my local variant to Europe. Of course, I’m exaggerating. Nevertheless, the funding agencies need to think European. And we’re not doing that. The shameful number is (I believe but find no links) 8<span>%</span> non-German professors which (I believe) gets cut to 3<span>%</span> if you exclude Austrian and Swiss professors. All the talk about brain drain vs brain gain vs brain circulation. What’s the point if this is only focused on German researchers? The one thing that makes the American system fascinating is its openness towards foreigners. And if the German system cannot even open up to the rest of Europe than it’s never going to become as interesting a system. Similarly, if you want those well-educated people back from North-America then you should be happy if you can get them back to the EU. Obviously, that might not be possible with your money (although, why not for neighboring countries?), but this kind of conference needs to get a European equivalent. Maybe there we could at least get the <a href="http://www.dfg.de/download/pdf/dfg_magazin/wissenschaftliche_karriere/heisenberg_treffen_2010/erc_foerderung.pdf">information that is already available</a> (cf. the post on the field-specific breakout session).</li>
</ul>
</li>
<li>Federal politicians can do more
<ul>
<li>As mentioned in the posts, the federal politicians felt that they were the wrong people to talk to since universities are outside federal control. That might be, but funding is not. And most definitely European initiatives are not. Also, remember the talk about the American system? That it’s bad for American researchers to spend time outside of the US-system? Hello federal politicians? International relations are your thing, are they not? Get in there, turn the tables, get the smartest American researchers to Europe and Germany, try initiatives that break up this crust! Really, if politicians think there’s nothing that needs to be done on an international level, we probably shouldn’t vote for them next time.</li>
</ul>
</li>
<li>State politicians were missing
<ul>
<li>Nuff said. But don’t just replace federal with state. We need both.</li>
</ul>
</li>
<li>More women, more foreigners
<ul>
<li>Yes, there were plenty of women. But not only the reactions to gender related questions were alarmingly old-fashioned. And there were hardly any foreigners that have positions in Germany and could open up the conversation, could give a different perspective. A good example was the Nachwuchsgruppen-breakout — one foreigner and one woman, combined in one person. Sad.</li>
</ul>
</li>
</ul>
<p>So let’s turn to things that were good, but</p>
<p><strong>not good enough</strong></p>
<ul>
<li>More ‘next gen’ peers
<ul>
<li>The best session was the session on Nachwuchsgruppen. It was the only session designed to interact with the people that have taken the next step. This should have been a much bigger part of the conference. Even though it’s nice to hear about tenure-track and similar things (and it’s important, I know) those are in the far future. The next step needs to be the focus. And it needs to include those that have failed, too!</li>
</ul>
</li>
<li>Bosses, open up!
<ul>
<li>The big heads need to open up. They should come to listen, not just talk. Yes, most post-docs don’t know much about funding opportunities or politics, they don’t know how much has been accomplished or how bad it used to be. But really, it’s still pretty bad after decades of cuts. So listen to the worries, listen to what we see that is important, what is good, what is bad (here and there). Give us your perspective, but please don’t ignore any question that you don’t understand, especially when it’s repeated again and again. It might be worth to find out what’s behind it even if you think it’s bogus — hell, especially, if you think it’s bogus!</li>
</ul>
</li>
</ul>
<p>So that’s it. Enough now.</p>
<h3>Auszug aus Feedback-Umfrage</h3>
<p>Let me, to finally finish this series, disclose my answers to the feedback questionaire — albeit in German.</p>
<ul>
<li>
<p>Veranstaltung</p>
<ul>
<li>Plus:
<ul>
<li>Die direkten Erfahrungen der Teilnehmer und vor allem der Wissenschaftler ‘danach’, d.h. die Wissenschaftler, die den naechsten Schritt auf der Karriereleiter getan haben (eine eigenstaendige Gruppe fuehren). Einerseits, weil sie “Vorbilder” sind, andererseits weil die Gespraeche am ergiebigsten waren, da diese Vorbilder am naechsten dran sind, an der Situation der PostDocs.</li>
</ul>
</li>
<li>Minus:
<ul>
<li>Die hochkaraetigen Teilnehmer (all die Praesident_innen) waren haeufig zu professionell. D.h. wenn eine unbequeme oder unerwartete Frage kam, wurde politisch professionell ausgewichen (durch Floskeln, Themenwechsel etc.). Es waere wichtig, dass (insbesondere in den Gespraechsrunden) auch eine Atmosphaere des (durchaus kritischen) Zuhoerens von Seiten der Fuehrungspersoenlichkeiten herrschen wuerde.</li>
<li>Es fehlte durchweg die internationale Ausrichtung. D.h. einerseits herrschte eine Fixierung auf Deutschland, als ob Deutsche nur nach Deutschland wollten; stattdessen waere doch eine europaeische Perspektive viel wichtiger. Andererseits fehlten Nicht-Deutsche Kollegen; wenn schon brain circulation, dann sollte diese dringend auch Nicht-Deutsche einbeziehen. Siehe die Statistik der 9<span>%</span> nicht-deutscher Professoren in Deutschland, von denen weitere 5<span>%</span> aus der Schweiz und Oesterreich stammen.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Talent Fair</p>
<ul>
<li>Plus
<ul>
<li>Die Gespraeche mit BCG, GSO und dem Dual Career Office der TUM waren sehr interessant. Die drei hatten die einzigen Leute, die auch mit “Exoten” ein Gespraech fuehren koennen.</li>
</ul>
</li>
<li>Minus
<ul>
<li>Als “Exot” (Reine Mathematik) war der Fair ziemlich irrelevant. Ausseruniversitaere Forschung faellt weg, die Hochschulen boten kaum passende Gespraechsmoeglichkeiten, da sie sich (verstaendlicherweise) auf den Mainstream der Forschung (sprich: life sciences) konzentrierten. Stattdessen konnte ich das traurige Spiel spielen “Googlen, wie viel Stellen meines Faches an ihrer Hochschule dennaechst wegfallen”.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Tagungsmappe</p>
<ul>
<li>Es braucht keine Tagungsmappe. Eine gute Website, eine paar Displays im Konferenzbereich mit interaktiver Funktion waere besser — dank all der Laptops und Smartphones braucht es nicht mehr.</li>
</ul>
</li>
<li>
<ol>
<li>Breakout</li>
</ol>
<ul>
<li>Gefallen hat sie mir, nicht wegen den “Rednern” (da wurde ich eher enttaeuscht), sondern wegen der guten und kritischen Fragen. Gut war, dass es direkt mit Fragen losging, ohne Statements etc.<br>
(siehe auch <a href="https://www.peterkrautzberger.org/0033/">Teil 1</a>)</li>
</ul>
</li>
<li>
<ol start="2">
<li>Breakout</li>
</ol>
<ul>
<li>Wiederum waren es die Teilnehmer, die das ganze interessant machten. Die Fragen wurden aber auch meist recht gut beantwortet, wobei Karin Zach deutlich sinnvollere Antworten gab. Wiederum Lob fuer das offene Konzept, kein Lob fuer ausweichende Antworten. (siehe auch <a href="https://www.peterkrautzberger.org/0034/">Teil 2</a>)</li>
</ul>
</li>
<li>
<ol start="3">
<li>Breakout</li>
</ol>
<ul>
<li>Siehe <a href="https://www.peterkrautzberger.org/0035/">Teil 3</a></li>
</ul>
</li>
<li>
<ol start="4">
<li>Breakout</li>
</ol>
<ul>
<li>Siehe <a href="https://www.peterkrautzberger.org/0035/">Teil 3</a>. Definitv das Highlight der Konferenz!</li>
</ul>
</li>
<li>
<ol start="5">
<li>Breakout</li>
</ol>
<ul>
<li>Siehe <a href="https://www.peterkrautzberger.org/0036/">Teil 4</a></li>
</ul>
</li>
<li>
<p>Orga</p>
<ul>
<li>Die Organisation war besonders gut. Der Tagungsort war sehr angenehm und machte es einfach, sich auf die Konferenz zu konzentrieren. Die Kaffeepausen in den Career Fair zu integrieren war perfekt. Die Organisation der Sessions war sehr gut. Mir ist nie etwas Organisatorisches negativ aufgefallen.</li>
</ul>
</li>
<li>
<p>Karriere</p>
<ul>
<li>Einerseits, dass mein Exotenfach evtl. keine Zukunft hat. Andererseits, dass es einige wenige Alternativen im wissenschaftsnahen Bereich gibt, in denen ich evtl. meine Begeisterung an Wissenschaft an sich gut einbringen kann. Das war’s leider auch schon.</li>
</ul>
</li>
</ul>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GAIN conference retrospectively Day 3]]></title>
        <id>https://www.peterkrautzberger.org/0036/</id>
        <link href="https://www.peterkrautzberger.org/0036/">
        </link>
        <updated>2010-09-22T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>The last day of the conference was only half a day and the only one without pure Q&amp;A sessions but more traditional panel discussions.</p>
<h3>First session</h3>
<p>The first session was another workshop with three parallel instances. I chose to go to the first (‘New oppucations for scientists’) although I later realized that I probably declared interest in the third one on co-operation and interdisciplinary reserach when I registered. Nevertheless, I think it was a very good choice.</p>
<p>As mentioned, this session was a classical discussion panel. The five participants (Susanne Dyrchs, Boston Consulting, Hellmut Meinhof, Bundesagentur, Heide Naderer, RWTG Aachen, Stefanie Seltmann, DKFZ, and Isolde von Bülow, LMU) started with short talks followed by some q&amp;a. As a completely irrelevant remark, the only male participant actually apologized for getting up when it was not his turn. It struck me as odd; was he worried to be considered sexist (for ignoring the woman whose turn it was)? Since this did not happen at the beginning the thought never crossed my mind. Why would he have to apologize for an honest mistake? Weird.</p>
<p>Anyway, back to the talks. They were extremely interesting (except Hellmut Meinhof’s talk which was very vague compared to the others). Stefanie Seltmann hit it off with a brilliant first talk, starting from her own early career decisions to becoming the press officer of the <a href="http://www.dkfz.de/">DKFZ</a>. She outlined what steps in her career seemed important and gave some advice for those considering similar careers. In a way, it was very interesting to hear about her unconventional career path. And yet I could not fully relate. She was, in a way, too far ahead in her career, where my questions lay in more immediate concerns (how do I get started etc). Again, this is was not an uncommon theme that the speakers were too advanced. One more nerdy thing: using a strip from <a href="http://www.smbc-comics.com/">smbc</a> without crediting, not good…</p>
<p>Next came Heide Naderer, director of the international office at the RWTH. She highlighted the pros and cons of working in a German university’s administration. I enjoyed her balanced and realistic talk; it seems like administrations at German universities are finally waking up. If only they had some real power in a system where every committee by law has a majority of tenured professors. Nevertheless, she left me with the impression that this is actually an interesting job.</p>
<p>Isolde von Bülow left a similar impression as Heide Naderer. She is the head of the Graduate Center at the LMU and had a similarly straight career path as Heide Naderer, in her case this involved a lot of experience in administrating Graduiertenkollegs. I also had a good conversation with her at the career fair afterwards. She gave very open advice on how to get into her line of work. The only disappointment for me was that in my field most of her descriptions seemed not to fit. In pure mathematics there is not a lot of daily administration for even a large grant, no equipment to buy, no budget to keep an eye on daily. So as much as I enjoyed talking to her, it left me wondering if her proposed way into this line of work actually works outside experimentally rich research.</p>
<p>With Susanne Dyrch the first ‘outsider’ (truly outside academia) gave the fourth introduction. Her talk was just as lively my own conversation with her at the career fair the day before. She definitely got her own enthusiasm for the work at the Boston Consulting Group across. However, given the strong natural science bias of the participants (and given my own interests) I would have enjoyed the talk even more if she could have told us more about opportunities in science related projects the BCG has to offer (say technology or even academia related). I think this would be very attractive for researchers – if you leave your field your interest stay the same nevertheless, so anything science related would be more attractive. But still I liked her talk most because she was another example of ‘the next step’, this was still her first job after leaving academia which made her information more valuable.</p>
<p>Finally, Hellmut Meinhof gave a introduction jobs at international organisations (though he never said it I’m guessing as the representative for the German government) such as UN- and EU-organisations. His talk was a bit difficult to follow and the many restrictions did not make it look very appealing to me. But maybe I just didn’t get the point. My notes on it prominently mention that the salaries are tax free — go figure…</p>
<p>Strangely enough I have no notes about the questions from the audience. I know there were some (though only a few), but I can only vaguely remember one. I think somebody asked about the kind of contracts that the first three speaker had at their various career steps. They all had many short-term contracts and I think it was Stefanie Seltmann who even switched from a position for life to a short-term contract while changing jobs. In a way, however, I thought this was not the right questions. Short-term contracts have a different meaning outside of research. In research everybody is supposed to aim for tenure, if you have it, you made it, if you change jobs before that it is often considered a failure. Also, having different, slightly different occupations at different jobs is something positive, whereas in research this is very difficult and often dangerous – you might end up not producing results which will hurt you later no matter what experience you gained with new techniques you learned.</p>
<h3>The final panel</h3>
<p>After the coffee break and career fair the closing panel offered the politicians a chance to tell the participants their impression. So the panel consisted of the five members of the Bundestag, more precisely the committee for education and research, Thomas Feist, Anette Hübinger, Patrick Meinhardt, Martin Neumann and Krista Sager. Interestingly enough this was the first time (in ten years of GAIN conferences) that the committee had sent an official delegation – which will ensure that these impressions will find their way back to the committee and therefore maybe even to the more general public (or at least policy makers). But this is essentially where the good news ended. Mostly, the five were repeating that due to the federal structure they themselves, as members of the federal parliament, could not really influence the policies anymore and that the conference was missing representatives from the federal states. There was also a lot of banter about current political issues which did not touch the subject of the conference at all. In short, the panel’s debate suffered from the fact that I described before – the politicians were too professional. Nevertheless, they seemed to be taking with them one important impression: the assembled postdocs were in fact the right people to ask if one tries to find out what the problem and the lack of appeal of the German academic system is. The following questions were a bit weird. Not only were they cut short for no apparent reason other than the official time limit. But they started out with some weird old professor who just happened to be in town, had not attended the conference but went on some fundamental rant on the more basic funding problems of universities in Germany. Not that he was not right, but not only in retrospect did he waste everybody’s time. This topic, ongoing cuts on the state level, had been discussed numerous times in many sessions. That he seemed to not even consider that this topic had been discussed made his rant all the more distracting. Another question was about daycare – the situation is still abysmal, there is essentially no sensible affordable daycare in West Germany (and of course almost all of the best universities and research center are in the south and west where the federal states are simply richer). Another one was aimed at the problem that short-term positions with independent grant money do not lead to more researchers or lecturers but are countered by the state cutting regular positions – this was an easy deflection for the (federal) politicians. The only upside was that Krista Sager had another chance to re-enforce my impression of her being the most capable (or simply most experienced?) politician at the conference – she simply said that the situation is everybody’s fault and that the key is to end the blame game and start cooperating for real change. For comparison, Patrick Meinhardt at some point answered (I think it was a question on gender politics) that most problems were simply a generational problem, that the next generation will automatically fix. Wishful thinking if there ever was… So in a way, this was a disappointing end of the conference, but hey, somebody has to be the bottom feeder…</p>
<p>Well, my final thoughts on the conference will have to wait.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GAIN conference retrospectively Day 2]]></title>
        <id>https://www.peterkrautzberger.org/0035/</id>
        <link href="https://www.peterkrautzberger.org/0035/">
        </link>
        <updated>2010-09-17T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>The second day at the GAIN conference was obviously the most intense day simply because it was the only full day. However, the program was well designed which minimised stress and maximised my attention span.</p>
<h3>First session</h3>
<p>The first session consisted of three parallel workshops. Since some were repeated in the afternoon it was not too hard to decide on two out of <del>three</del> five. In the morning I arrived a little late (thanks to a flate bike tire) at the workshop on “Alternative ways for a successful re-entrance in the German research system”. The session consisted of five short talks and questions. The talks were excellent. The DAAD, DFG and MPG talks were really informative showing all the tools and grants available. Even more interesting were the two other talks. The Potsdam university’s vice-president talked about their strategy for postdocs. He made quite an impression with honest answers and good comparative data. The fact that the university has a specific guide for postdocs was actually impressive (though this is kind of a sad thing to say). His talk was also interesting because some of his comments on the lack of long-term positions got a strong reaction from Krista Sager, MdB. Although the ‘politicality’ of their argument was a bit annoying, the facts were interesting. Apparently, there is a slight chance that finally we could have open ended contracts that can be terminated for economic reasons. This is something that is amazingly complicated in Germany. Since almost all universities are public institutions, their employees have very strong unions and therefore extemely good contracts (also, professor are always <a href="http://en.wikipedia.org/wiki/Beamter">Beamte</a>) and every open-ended position is essentially tenure.</p>
<p>This is a problem for two reasons. One, universities are unwilling to give open-ended contracts since they cannot get rid of people if money is tight later. Two, researchers have either too much security or none at all. I did mention the interesting comments by Helmut Schwarz years ago at a Bundestag committee meeting. One thing he said there was that he does not understand, why German universities do not offer jobs via the overhead they acquire from the funding agencies. After all, the total overhead for the university fluctuates much less than on a departmental or personal level. So this extra money should give us extra positions (and investments). He argued that these could easily be open-ended since universities have enough experience to judge how the overhead will develop over the years. If its researchers acquire less and less grants (and hence overhead) then it should be possible to let people go for economic reasons (<a href="http://dict.leo.org/">leo</a> tells me the correct term is “redundancy due to business operations”).</p>
<p>Generally speaking, I don’t understand why <del>everybody</del> the majority in the academic system should get tenure. If the price for tenure is as in Germany – ca. 10<span>%</span> (the professors) have an immense security whereas 50<span>%</span> are researchers with short-term contracts – then it’s not worth it. But open-ended contracts are necessary to give especially young researchers a greater security – just like everywhere else. My impression of my peers at the conference was: we’re not afraid of the competition but short-term contracts discourage immensely. Also, we don’t intend to get stuck on a low-level open-ended position. We want career options because we are ready to make a career.</p>
<p>Anyway, the last talk was by Kerstin Dübner-Gee of the dual career office at the TUM. I had already talked to her at the career fair the day before and her talk included a lot of interesting facts. I really hope more universities will introduce such tools. I think this will easily be the ‘killer application’/service to attract young researchers. Just connecting the partners, arranging informal (job) interviews and supporting the process as a whole; that’s very attractive for a lot of people I know.</p>
<h3>talk talk talk</h3>
<p>After the obligatory coffee break and another opportunity to stroll through the career fair it was time for talks. The first talk by Anke Burkhardt offered insight into (her) research in the development of academia in Germany. The talk gave a very good overview of the general structure of the system, the amount of money, how few tenured positions we have (as mentioned), the difficult legal situation since the most recent reform has had the federal administration give up almost all ways to do anything about the development of the academic system. Interesting as it was, I would have preferred a shorter talk on the issue. After all, postdocs are a long way from influencing policies, we’d rather hope for more information on how to get to a stable position where we can even think about that. Nevertheless, the talk was very good, albeit (again) Germany-centric. And a very frustrating note: almost all new tools in the system (tenure-track, negotiable salary, lecturer positions) are only ever optional, i.e., those federal states that have made them possible in their system made sure not to require them but only ‘allow’ them. And the (aging?) professorate controlling the universities seems quite unwilling to actually introduce them.</p>
<p>After lunch, it was time for the second talk of the day. Philip Altbach of Boston College gave the only English talk of the conference. His was an amazing talk. A gifted (and I assume well trained) speaker he gave an introduction into the American system as whole. I learned a lot, finally understanding a little how community colleges, public and private universities interact in the States. To pick out one particular topic, I think I was most surprised by his answer to the question why American students/researchers do not often consider going abroad. In his humble opinion the reason for this is that the American market mostly discourages this. That is, except for the top universities an institution will usually fail to acknowledge the quality of such an experience, both personally as well as academically. It really just makes your chances worse; poor Americans, I thought.</p>
<p>The last ‘talk’ wasn’t so much a talk as a panel. Marion Schmidt of the FTD moderated a discussion between the presidents of DFG, DAAD, Helmholtz Society, Humboldt Foundation and Hochschulrektorenkonferenz as well as Thomas Rachel (Ministry of education and research) and Andreas Busch (head of Bayer Schering research). It was probably the most uninteresting part of the conference. On second thought, due to the high quality of the rest this wouldn’t say much, but this was actually a little uninteresting. The discussion was too professional, nobody was ready to discuss their positions openly instead hiding behind durable political phrases. Only the Helmholtz-president tried to break out of that habit, challenging the complacency but even his comments pearled off. It probably did not help that the only head of an industrial research department was only asked very, very few questions. Maybe he could have said more if the moderation had permitted. The questions from the audience were very limited but at least two topics made it into my own notes. One question asked the lonely politician how he assessed the quality of science lobbying which yielded a very diplomatic answer (essentially, it has improved in the last few years but the starting point was non-existentence). Another question regarding lack of long-term contracts led to an almost emootional comment by Jürgen Mlynek (Helmholtz president). He pointed out that the biggest problem was ignored by the panel – the psychological problem, that young researcher do not expect to have it easy but they need to see that the hard work they are putting in will enable them to have a life. That seems to be exactly to the point.</p>
<h3>last session</h3>
<p>After another coffee and career break the last session repeated the morning workshops. This time I went to the workshop on ‘Nachwuchsgruppen’. The term itself deserves some criticism. It seems to be a German (perhaps European) phenomenon to call everyone who isn’t a tenured professor <a href="http://dict.leo.org/ende?lp=ende&amp;lang=de&amp;searchLoc=0&amp;cmpType=relaxed&amp;sectHdr=on&amp;spellToler=&amp;search=nachwuchs">Nachwuchs</a> – that’s offspring, new blood, younglings, kids, whatever. This enables an attitude of looking down on anybody who isn’t a tenured professor. It’s annoying, it’s disrespectful (think of a non-tenured PI here) and in stark contrast to the Anglo-Saxon culture where (grad) students are already treated with almost the same respect as everybody else. Ok, enough ranting.</p>
<p>Getting back on the topic, this session was perhaps the best session (and it’s a shame that there were not more of this kind). The main reason was that it gave the next step (in this session, grants for PI positions) a face. This was perfect timing after the aforementioned comment by Jürgen Mlynek on the psychology of things. To meet four researchers that have taken the next step and become PIs with 5-7 years (extendable) contracts was, I think, for most people in the room a very welcomed experience. The talks by Tilman Brummer, Zuzana Storchova, Christoph Eberl and Kristian Kersting were also among the best when it came to quality. They introduced the application process and added the personal experiences of both the procedure and the actual beginning of this next career step. I am wondering if the parallel session (on careers outside of academia) was equally interesting. Judging from the program it was senior executives instead of people closer to the situation of the postdocs present. It was unfortunate that not all of these sessions were accessible. I hope they’ll do it differently next time since I felt that this session was ‘what it’s all about’.</p>
<p>The session concluded the day for me since I did not join the dinner at the German consulate – I met some old friends from Berlin who came to visit Boston that day so I did the other part of networking, instead of new ties I strengthened old ones.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GAIN conference retrospectively end of Day 1]]></title>
        <id>https://www.peterkrautzberger.org/0034/</id>
        <link href="https://www.peterkrautzberger.org/0034/">
        </link>
        <updated>2010-09-14T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Continuing my posts on the GAIN conference, let me jump right back in.</p>
<h3>The second break-out session</h3>
<p>The second and final break-out of the day was field specific. So as usual for a mathematician, I ended up in the ‘natural but not life sciences’ session. Again, this was one big Q&amp;A, this time with Karin Zach (of the physics/mathematics/geo sciences office at the DFG) as well as a physics prof from Heidelberg (I forgot the name and he’s not in the program, my apologies). I don’t remember all the questions I must admit. One interesting one was how to get Karin Zach’s job. Interestingly enough she told us that most people get to her/a similar DFG-position after their first postdoc and that there’s a high fluctuation especially now that science management is becoming a topic and more jobs appear outside the funding agencies. I asked if the DFG offered any assistance on accessing the funding opportunities within and through the EU which she had to decline. This was one example for a recurring theme that bugged me during the conference.</p>
<p>It was extremely Germany-centric, all about ‘getting us home’ instead of ‘getting us back to Europe’ (let alone ‘getting the best minds in the world’). As much as I understand that circumstances do not allow for an absolutely open approach (e.g. the regulations for the funding agencies prohibit a more open, European point of view) I think it is the biggest mistake and very unfortunate for us, the researchers, wanting to return. One huge advantage of the American system is its size; Europe could compete if only it would want to. This reminded me of the response by Helmut Schwarz to the ‘80%’-question in the preceding session. He replied (referring to the larger (albeit shrinking) tenure track market in the US) along the lines of “Well, but if you get a position in the US you don’t want any kind of position – you want one at a great university”. As true as that may be, it was absolutely not the point. The point is that in the American system, if after all the postdocs at fancy institutions you find that, after all, you won’t be in the top league of researchers in your field then you still have a much better chance of getting a life time position here, say at a small college. Sure, there won’t be ivy on the wall, but it’s a job and you might still be able to do some research, get some funding and above all stay close to your great love, you field of research. At least you have something.</p>
<p>For another topic in the session that I could relate to, let me take you back to the beginning. In the big opening speeches it was repeated again and again that German academic teaching was obviously excellent since there were 400 people in the room witnessing that the American system wants German graduates. Even ignoring the fact that most institutions will welcome you when you bring your own grant money, this is one classical logical fallacy that I would expect every scientist to know – coincidence does not imply causality. In the break-out session I found one possible cause. A lot of the questions began “I also survived the German academic system, …”. And this is a feeling that was (and is) easily confirmed in conversations – people who graduate in Germany do so more often in spite of the quality of teaching. If you survive the system in Germany, chances are that you must be very well trained (and probably auto-didactically).</p>
<h3>NERDs</h3>
<p>To end the evening everybody was invited to a buffet at MS’s New England Research and Development center across the street. I had not planned to attend but luckily I had met somebody who was kind enough to force me. The food was surprisingly good and the company more than enjoyable. I ran into some people from Ann Arbor and my lunch companion. All in all, I was very surprised how easy it was to have conversations with these people. I guess we had not only a common situation, but a common mindset.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GAIN conference retrospectively Day 1]]></title>
        <id>https://www.peterkrautzberger.org/0033/</id>
        <link href="https://www.peterkrautzberger.org/0033/">
        </link>
        <updated>2010-09-13T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Yesterday, the 10th GAIN conference in Boston ended and, since I attended it, I thought I should try to do some classical, journal-like blogging (at least retrospectively) and report a little on what that was all about (don’t expect me to be <a href="http://gowers.wordpress.com/2010/09/02/icm2010-final-post/">Gowers</a> though).</p>
<p><a href="http://www.gain-network.org/">GAIN</a> stands for ‘German academic international network’, strangely enough this is restricted to North America (well, at least they include Canada…). The network is essentially run by three big German research funding agencies DAAD, DFG and Alexander-von-Humboldt Foundation, but check out the website for details. The conference is designed to improve networking among German researchers in North America, and almost all attending had a grant of either of the three agencies (in my case, the DFG Forschungsstipendium). Instead of giving you more background (of which I learned during the conference) let me jump right in. As I’m writing retrospectively just following my notes and thoughts, this will not be meticulous.</p>
<h2>Day 1</h2>
<h3>First impressions</h3>
<p>I must say, having looked at the conference schedule online on Thursday evening, I had extremely low expectations. This was mostly due to the exotic nature of mathematics in this kind of environment – the schedule included lots of interesting topics for people in the life sciences plus some ‘general info’. So walking to the Cambridge Marriott Friday morning, I was pondering how much work I could get done while sitting in endless talks about (for me) irrelevant information. The first impression was then also quite unsurprisingly negative (you get what you expect); in the relatively crowded floor outside the conference rooms, which people shared with a ‘career fair’ of sorts, I maneuvered around many small groups of people from the different life sciences who were busy reconnecting and networking. When I finally found the registration desk (I blindly followed the concierge’s description and had stumbled through the fair instead of right into the registration desk) and got my badge and booklet, I took some time to read through the list of participants. And behold, including me, three mathematicians were on the list (and some computer scientists, to be fair) who I unfortunately failed to meet in person (and the liberal arts had even fewer). Since I had arrived early enough, I went on my first stroll through the career fair. On the one hand, it was an interesting experience since ‘the industry’ was not as present as usual – which made sense since the conference is for PostDocs (and beyond), so only a few big pharmaceutical companies were present and, of course, one consulting company (you can find a complete list at the GAIN homepage, they are transparent as they should). Otherwise, German universities and the big research societies/institutes (MPG, Fraunhofer, Helmholtz) were present. A curious fact was that my two former universities, LMU and FU had teamed up which, I felt, was somewhat funny for completely personal reasons. Additionally, only the TUM was present with their dual career office (of which, more later).</p>
<h3>The beginning</h3>
<p>Fascinatingly, the first official get together was lunch. And really, lunch, at tables, with waiters. Which was somewhat awkward since I didn’t know anyone. But it was really a good idea since, well, when you sit with a lot of PostDocs at a table it’s not actually hard to strike up a conversation, in my case a very interesting one. So not only well fed, but also more at ease socially (I’m no <a href="https://web.archive.org/web/20101016160444/http://trainingprofessor.blogspot.com/2008/11/some-questions-answered.html">PiT [Wayback Machine]</a> but…) I left the lunch table for the-impossible-to-leave out (that’s conferences, not me…) speeches of by ‘politicians’. I can’t reconstruct from my notes what the speeches were about, but they were relatively short and painless – what else can you want? Well, actually, I know remember that one theme bugged me as it often does. All speakers focused on terms like ‘excellence’, ‘leaders in their field’, ‘best of the best’. This bugs me because in all the debates of recent years in Germany, it was all about elitism. What is missing is the large base of very good scientists that have no future and little standing in the academic (and certainly no positions). That base upon is missing from the conversation. And if their is no room for ‘good’ how can we still check that somebody is excellent?</p>
<p>An elegant solution was to have the career fair be within coffee breaks (quite literally) so after all the speeches, not only did I get coffee (hooray), but I had an interesting conversation with the head of the TUM’s dual career office. This is definitely something on my mind and although I’m not yet the correct ‘target’ for them it was interesting to hear that dual career offices are finally establishing themselves as a professional (and impartial) service to attract researchers. I hope I could convey that this is just in time as most academic couples I personally know worry about the lack of such services.</p>
<h3>The first break-out session</h3>
<p>On the first actual breakout session I cheated myself into the ‘wrong’ conference room – the split was organised by name but I wanted to listen to people that I found more interesting. In Berlin I had once attended a public hearing of the science-committee of the German Bundestag (the federal parliament). The session was a discussion of the experts response on a study on ‘science as a career’ in the German academic system. Mostly, it was about the lack of it, but I had a very positive impression of Helmut Schwarz, the head of the Alexander von Humboldt Foundation. So I went to the session where he was on the panel. There were no statements, just questions from the audience, which was the general theme of the conference. It was strange however, that the official, lofty topics from the program never came up. Instead, people started right away with quite down-to-earth questions which was much more interesting, but are more difficult to reconstruct now. I do vividly remember one person asking follow up questions quite rigorously and making a beautiful point. He pointed out that the statements essentially told him the following: If you get the prestigious Emmy Noether grant you will, at the end of that funding, be in the following position: you will have been the top of your class at university level to become a PhD candidate, the top of your ‘class’ at PhD level to get a grant to go abroad (which is required for Emmy Noether grants), at the top of your PostDoc ‘class’ when you get the Emmy Noether grant and after that you have a 80% chance of getting some kind of permanent position in the German academic system. Which led to the question: are you really trying to sell that to the smartest students that you want to keep in you research instead of ‘loosing’ them to the industry? They have to be the very best for 15 years just to get a puny permanent position for themselves? The replies to this were unfortunately simple – we should be bloody grateful that we get any grants at all, period.</p>
<p>Btw, my own question in that session was about future plans to improve teaching structurally – I was wondering if there were initiatives (or plans thereof) so that researchers waste less energy (in my experience the larger part of German teaching workload is wasted efforts that could be prevented with a little more structural thinking) while students get better guidance to us researchers, i.e., students have a higher chance to end up in fields they have talent for and we have a better chance of finding those talents. This question also didn’t get an answer (which might have been due to me very nervously blurting it out), but rather bounced off the political professionalism of the panel – it felt a lot like ‘I never cared about that, so why would I think about it?’. This sums up my memory of the session actually, the questions were excellent (in that I could absolutely see where they were coming from) but answered honestly only if the panel members felt their own position were flawless. I had hoped that in such a conference, the big heads were more open to listening and being self critical.</p>
<p>To be continued.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A comment at Gobbledygook on evaluating science]]></title>
        <id>https://www.peterkrautzberger.org/0032/</id>
        <link href="https://www.peterkrautzberger.org/0032/">
        </link>
        <updated>2010-09-04T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p><em>This morning I commented <a href="http://blogs.plos.org/mfenner/2010/09/04/unmeasurable-science/">on a post at one of the PLoS-blogs, Gobbledygook</a>. Since it got rather lenghty, I thought its worth posting here as well. You should go and read the originalpost. Martin Fenner makes some interesting points on the problem of evaluating research output. He makes some suggestions on how to change the system so that less time is spent writing grant applications and reports, to which I commented the following.</em></p>
<p>These ideas sound very good and I agree with them, but I think this is only half the problem. The change has to got both ways. Researchers and their institutions have to become much more professional when it comes to acquiring grants and evaluating projects. We need better standards, but they will be wasted if we, the researchers (and our institutions), do not invest in efficiently using them — which includes money and time for training.</p>
<p>Research institutions often do not offer any kind of support or training for their own researchers when it comes to grant writing — on any level. Neither do they offer support for a later evaluation. Why is that so? Why don’t we require a certain amount of overhead to be spent on developing such support? Why don’t we have people employed that specialize in giving this kind of support? After all, even standards should be revised regularly — and as a researcher I don’t want to be the one who has to keep track all the time.</p>
<p>As an example, I could imagine that continuous reporting/evaluating could be less draining than the big reports that nobody reads. It should be possible to require researchers to keep a blog-like log for a project. After all, your lab notes are already there, why not keep them digitally and with some additional reflection once in a while? Writing a ‘report’ the length of a blog post or just a good long email at the end of the week seems much less work than a huge report at the end of 6 months or a year.</p>
<p>But again, this would have to be developed professionally — just as writing in general is a skill that requires training, so would such a kind of reporting/evaluating. Do we have/develop tools for that? Do we share the tools that we have? Do we train our students to use them? Do we have methods to allow trusted outsiders to evaluate such ‘status updates’? While the project is running?</p>
<p>Such transparency could even shift the focus back to “successfully failing” instead of blowing up every single small result to reach the smallest publishable unit. After all, science is about failing, again and again, until we have revised our ideas enough to make progress in understanding. Imagine, our failures would become our successes again.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Supervisor Precognition]]></title>
        <id>https://www.peterkrautzberger.org/0031/</id>
        <link href="https://www.peterkrautzberger.org/0031/">
        </link>
        <updated>2010-08-27T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I am currently working on a nice little proof. I was initially very confident that I could find the proof — mostly because I already gave a different proof for the same observation, albeit with completely different tools.</p>
<p>This time around the proof will probably end up as a series of stronger and stronger lemmas. Already 3 weeks ago I thought I had shown the strongest intermediary lemma I have formulated so far. Unfortunately, <a href="http://www.math.lsa.umich.edu/~ablass/">Andreas</a> shot it down, then I found a different proof, and <a href="http://www.math.lsa.umich.edu/~ablass/">Andreas</a> shot it down again, then I found another proof, and <a href="http://dorais.org/">Francois</a> shot it down. As painful as this sounds (and really, really is), I am so lucky to have such colleagues.</p>
<p>Finally, I think I have a found a proof for the intermediary lemma that will live (well, maybe I should wait until Francois sees it later today…). The creepiest thing about this proof, however, is <a href="http://www.math.lsa.umich.edu/~ablass/">Andreas’s</a> precognition.</p>
<p>When I showed him the failed second attempt (which failed pretty much at line 1…), we discussed the phenomena involved and Andreas made two comments about the problem itself. The first was that due to the setting, an indirect proof seemed to him to be the way to go; second, he gave a very simple example, a special case of the problem that should turn up in some general form. And as you might expect, these two predictions came true — in almost every respect.</p>
<p>The first time I ever heard of such precognition was from a student of Stevo Todorcevic when I was just starting out on my PhD — and it scared the hell out of me to hear that he predicted a complication that the student only found after 3 months of work on that problem. I call this phenomenon ‘supervisor precognition’. It’s not like supervisors in mathematics always have an idea for an actual proof of a problem, usually not even for a strategy. However, supervisors often have a small but brilliant insight into the situation as such and might spot some critical properties far ahead, long before the student actually gets there.</p>
<p>I know that this strength has as much to do with experience as it does with mathematical talent, but it is both annoying and wonderful. Annoying, since I would like to pretend that I could be as productive without these amazing insights from other people. For <a href="http://senseis.xmp.net/?HikaruNoGo">Hikaru no Go</a> fans, it feels like Akira playing Sai in the first game — it’s a move from far above, so to speak. To use a metaphor that I don’t really like, if we fight through a jungle to get on a mountain top, this precognition maybe is the equivalent of a greater height, allowing to see not the exact path ahead, but a few major obstacles ahead.</p>
<p>I think this precognition is perhaps the most important strength of a good supervisor. On some level, this precognition needs to be present to guide students to their own, independent research. Students should look out for signs of it (and ask around who’s got it) and researchers should try to develop it (if anyone can tell me how, please tell!). Now if only my proof was finished…</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Now why did I throw this away?]]></title>
        <id>https://www.peterkrautzberger.org/0030/</id>
        <link href="https://www.peterkrautzberger.org/0030/">
        </link>
        <updated>2010-08-20T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I once read the following anecdote about John von Neumann’s housekeeper (the only reference I found was, of course, on <a href="http://mathoverflow.net/questions/7155/famous-mathematical-quotes/7207#7207">mathoverflow</a>). Being asked what her impression of him was she is said to have replied that he is quite a nice man and all, but that she did not understand how he could get any work done; after a long day sitting at the desk writing he would just throw everything he’d done in the garbage. I thought Doron Zeilberger (unfortunately, I cannot find the opinion I was looking for — any help appreciated!) in one of his wonderful opinions pointed out that nothing would be greater bliss than to get our hands on all the failed attempts that von Neumann made. What we could learn from his mistakes!</p>
<p>I spent last weekend in Boston and for a bare half an hour worked on a proof that has consumed most of the last 3 weeks. The proof for the little piece I was wokring on didn’t seem to go anywhere, so I threw it away. Now, having written up what I can prove so far I yearn to read what I read back then — the modifications I made TeXing my progress just now remind me an awful lot of what I wrote on that piece of paper. Now why did I throw that away? Or better yet, why on earth did I write on a piece of paper instead of my moleskine? Damn.</p>
<p><strong>Update</strong> Fred was kind enough to <a href="http://www.math.rutgers.edu/~zeilberg/Opinion39.html">find the correct Zeilberger post</a> for me:</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Return to bloglife]]></title>
        <id>https://www.peterkrautzberger.org/0029/</id>
        <link href="https://www.peterkrautzberger.org/0029/">
        </link>
        <updated>2010-08-01T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Maybe it was the summer heat, maybe the summer break at the UofM or something else. In any case, I did not feel like blogging the last couple of weeks. But this must change! So to get me back to writing I’ll start with something <del>small</del> tiny.</p>
<h2>Unforeseen</h2>
<p>I have the great pleasure of spending my PostDoc at the University of Michigan. After spending a winter here 2/3 years ago, I knew a lot of things I could look forwards to — like the amazing grad students.</p>
<p>One of the unforeseen pleasures so far has been to meet <a href="http://dorais.org/">Francois Dorais</a> of <a href="http://mathoverflow.net/users/2000/francois-g-dorais">MathOverflow-Admin</a> fame. Last Friday <del>we talked</del> he told me about <a href="http://doi.org/10.2307/2047620">a proof by Michael Canjar</a> (sorry for linking to a paywall) on Mathias forcing and there is this small observation that I think is really cool.</p>
<h2>(non) P-points</h2>
<p>I mentioned them before, but repetition is never a bad thing.</p>
<p>An ultrafilter \(p\) on \(\omega\) is called a <strong>P-point</strong> if for every \(f: \omega \rightarrow \omega\) there is \(A\in p\) such that \(f\) restricted to \(A\) is either finite-to-one or constant.</p>
<p>P-points are truly classical ultrafilters having been studied since the dawn of <del>time</del> ultrafilters. They carry interesting properties and Shelah proved that they might not exist (though they do under reasonably weak assumptions like very weak versions of <a href="http://en.wikipedia.org/wiki/Martin%27s_axiom">Martin’s Axiom</a>).</p>
<p>The property of P-points somehow tells us that functions drastically ‘changes speed’ on a set in the ultrafilter. If you take a function which is ‘nowhere’ finite-to-one, i.e., every point has an infinite preimage, then a P-point either slows it down completely (by making it constant on a set) or speeds it up extremely (by making it finite-to-one).</p>
<p>But the cool thing Francois showed me (from Canjar’s proof) is what non P-points (so possibly all ultrafilters) can do. They can force any function to slow down in a weird fashion.</p>
<h2>Slowing to identity.</h2>
<p>Even though the argument I want to mention holds for arbitrary functions, you should think of quickly growing functions, i.e., strictly increasing functions. So let us pick some \(g: \omega \rightarrow \omega\).</p>
<p>Now if \(p \in \beta \mathbb{N}\) is not a P-point, then there exists a function \(f: \omega \rightarrow \omega\) which is not constant or finite-to-one on any set \(A \in p\).</p>
<p>So what about \(I_g := \\{ n \in \mathbb{N} \ \vert \ g(f(n)) &lt; n \\}\)?</p>
<p>On this set, \(g \circ f\) is dominated by the identity. That’s slow!!! Just imagine \(g\) was the <a href="http://en.wikipedia.org/wiki/Ackermann_function">Ackermann function</a> or faster thatn all recursive functions! Suddenly, its only as fast as the identity? Wow…</p>
<p>And now the crazy part.</p>
<p>\(I_g \in p\).</p>
<p>That’s right! On a set in \(p\), \(g\circ f\) slows down like that. That’s crazy!</p>
<p><strong>Proof</strong>.</p>
<ul>
<li>\(f\) is finite-to-one on \(\omega \setminus I_g\).
<ul>
<li>For \(k\in \omega\), \(f^{-1}(k) \cap (\omega \setminus I_k) = \\{ i \in \omega \ \vert \ g(k)= g(f(i)) \geq i \\}\)</li>
<li>But this is a finite set for any \(k\).</li>
<li>In other words, \(f\) is finite-to-one.</li>
</ul>
</li>
<li>Therefore \(\omega \setminus I_g \notin p\).</li>
<li>Since \(p\) is a maximal filter, \(I_g \in p\).</li>
</ul>
<p>That’s all.</p>
<h3>What you can do with this.</h3>
<p><a href="http://doi.org/10.2307/2047620">Michael Canjar used this fact</a> to show that Mathias forcing with a non P-point adjoins a dominating real. This is not too difficult now since it is easy to see that a Mathias real will dominate all sets in the ultrafilter. But that’s all for today.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A small website update]]></title>
        <id>https://www.peterkrautzberger.org/0028/</id>
        <link href="https://www.peterkrautzberger.org/0028/">
        </link>
        <updated>2010-07-01T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>You probably wouldn’t have noticed, but I worked on the website a little. The only visible change is that I have added some more permanent content. You can find <a href="https://www.peterkrautzberger.org/0028/">the about page</a> page as well as a page called <a href="https://www.peterkrautzberger.org/0028/">resources, links and friends</a> in the top right column.</p>
<p>(<strong>Note from 2015:</strong> I retired those pages at some point and cannot reconstruct the respective content.)</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A virtual visit to Prague]]></title>
        <id>https://www.peterkrautzberger.org/0027/</id>
        <link href="https://www.peterkrautzberger.org/0027/">
        </link>
        <updated>2010-06-28T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Tomorrow, I will be visiting Prague! Well, only virtually, but for the second time in 8 days — yay!</p>
<p>Back at <a href="https://www.peterkrautzberger.org/0024">BLAST 2010</a> I had a chance to meet up with David Chodounsky — he is one of the PhD students in the group around Professors Blacar and Simon and David also helped organize the <a href="http://www.winterschool.eu/">Winterschool</a> in Hejnice. He gave a nice talk about one of <a href="http://atlas-conferences.com/cgi-bin/abstract/cbap-25">his current projects</a> so I asked him if he could tell me a little more about it via Skype.</p>
<p>Last week he simply invited me to join the set theory seminar at Charles University. What amazed me was the simplicty of the tools used compared to the quality. David used his laptop with Skype to show me the blackboard (and himself) as well as being able to keep an eye on me if I had any questions or problems. Additionally, Jonathan Verner (PhD student, also involved in the winterschool) used his webcam and vlc to broadcast a live feed of the audience. They used an external mic to get very good audio quality through skype.</p>
<p>It was really amazing, I could read the blackboard and listen to the conversation — with just a bunch of freeware and open-source software (and on top of that I understood his proofs!).</p>
<p>So not only can I look forward to joining them tomorrow but additionally I think the technology is there to do this spontaneously whenever there’s interest. Now all we need is a good technology to exchange and collect seminar information so that anyone can join any seminar he’s interested in around the world.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Preprint 'On strongly summable ultrafilters']]></title>
        <id>https://www.peterkrautzberger.org/0026/</id>
        <link href="https://www.peterkrautzberger.org/0026/">
        </link>
        <updated>2010-06-18T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I have just uploaded a preprint titled <a href="http://arxiv.org/abs/1006.3816">On strongly summable ultrafilters</a> to the <a href="http://arxiv.org/">arXiv</a>. Let me give a short account of what it’s about.</p>
<p>In the preprint I extend a theorem orginally due to <a href="http://nhindman.us/">Neil Hindman</a> and <a href="http://www.genealogy.math.ndsu.nodak.edu/id.php?id=38708">Dona Strauss</a>. The theorem shows that certain ultrafilters can only be written as sums in the (so-called) trivial fashion. On the one hand, this property is quite unique and I find it algebraically fascinating. On the other, the existence of the ultrafilters in question is independent of ZFC, so set theoretic interests are immediate. Let’s start with the ultrafilters.</p>
<h2>Strongly summable ultrafilters</h2>
<p>Among the idempotent ultrafilters on \(\mathbb{N}\) a certain type is quite special. To define it, we only need to know what an <em>FS-set</em> is.</p>
<p>For a sequence \(\mathbf{x}\) in \(\mathbb{N}\), the set of all (distinct) finite sums is</p>
<p>\[{FS}( \mathbf{x}) = \left\{ \sum_{i \in s} x_i : \emptyset \neq s \subseteq_f \omega \right\} \]</p>
<p>Then \(p\in \beta \mathbb{N}\) is called <strong>strongly summable</strong> if it has a base of FS-sets.</p>
<p>By the Galvin-Glazer Theorem, any set in an idempotent ultrafilter contains an FS-set. The difference to arbitrary idempotent ultrafilters is that strongly summables have such a set in the ultrafilter itself! So in measure theoretic terms, not only does every measure 1 set contain an FS-set, but one of measure 1. As a comparison, the very important <em>minimal</em> idempotents can never be strongly summable; in fact strongly summable ultrafilters are at the other end of the spectrum — they are what is called strongly right maximal idempotents.</p>
<p>In other words, what selective ultrafilters are for Ramsey’s Theorem, strongly summable ultrafilters are for Hindman’s Theorem. Unlike idempotent ultrafilters strongly summable ultrafilters might not exist, since their existence implies the existence of P-points in \(\beta \mathbb{N}\). But under rather weak assumptions (like CH or weak forms of Martin’s Axiom) they do exist.</p>
<h2>Union Ultrafilters</h2>
<p>There is an equivalent notion, union ultrafilters, see <a href="https://www.peterkrautzberger.org/0025/">here</a>. In the preprint, as always, it’s hard to speak about the one without the other.</p>
<p>Denote the non-empty, finite subsets of \(\omega\) by \(\mathbb{F}\) (with semigroup operation \(\cup\)). In what follows a sequence \(\mathbf{s}\) in \(\mathbb{F}\) is always assumed to have pairwise disjoint elements.<br>
The <strong>FU-set (generated by \(\mathbf{s}\))</strong> is the set of all finite unions, i.e.,</p>
<p>\[ {FU(} \mathbf{s} ) := \left\{ \bigcup_{ i \in v} s_i : v \in \mathbb{F} \right\}.  \]</p>
<p>A <strong>union ultrafilter</strong> on \(\mathbb{F}\) is an ultrafilter with a base of FU-sets.</p>
<h3>Trivial sums</h3>
<p>As mentioned, the main result in the preprint is about writing ultrafilters as sums. Any idempotent ultrafilter can be written as a sum in many ways, most trivially as \(p+ p = p\). However, since \(\beta \mathbb{N}\) is a left ideal in \(\beta \mathbb{Z}\), there is another way by means of integers.</p>
<p>If \(p \in \beta \mathbb{N}\) is idempotent and \(z \in \mathbb{Z}\), then</p>
<p>\[(p+z) + (p-z) = p + p + z – z = p.\]</p>
<p>This is simply due to the fact that the integers still commute with everything in \(\beta \mathbb{Z}\).</p>
<p>Let’s say that an (idempotent) ultrafilter \(p\) has <strong>the trivial sums property</strong> if this is the only way to write is as a sum, i.e.,</p>
<p>\[ (\forall q,r\in \beta \mathbb{N}) q+r = p \Rightarrow (\exists z \in \mathbb{Z}) q= p+z, r = p -z.  \]</p>
<p>This property fascinates me for many reasons. One easy but equally fascinating consequence is that the maximal group of such an idempotent \(p\), i.e., the maximal subgroup of \(\beta \mathbb{N}\) with identity \(p\) (which is the same as the union of all such subgroups), is just \(p + \mathbb{Z}\). This is fascinating since it is the minimal case — the famous Theorem by Yevhen Zelenyuk showed that there are no finite subgroups in \(\beta \mathbb{N}\).</p>
<p>In contrast, minimal idempotent ultrafilters have huge maximal groups. In fact, those always include a copy of the free group on \(2^{2^\omega}\)-many generators! That is mind-bogglingly big, so in comparison the integers are really very minimal. And on top of everything it is also open whether any ultrafilters with a maximal group isomorphic to \(\mathbb{Z}\) exist in ZFC…</p>
<h3>Using union ultrafilters</h3>
<p>I gave a simplified version of the main theorem <a href="https://www.peterkrautzberger.org/0025/">here</a>. For this consider the very natural map \(f: \mathbb{F} \rightarrow \mathbb{N}, s \mapsto \sum_{i \in s} 2^i\).</p>
<p><strong>Theorem</strong> If \(u\) is a union ultrafilter, then \(f(u)\) has the trivial sums property.</p>
<p>In fact, the theorem in the preprint does a bit more. You see, such an \(f(u)\) contains $ FS ( \mathbf{x} ) $ for a sequence \(\mathbf{x}\) with <strong>disjoint binary support</strong> — simply because that’s what happens to pairwise disjoint sets under \(f\).</p>
<p>Now if you take any other divisible sequence \(\mathbf{a}\), i.e., with \(a_n \vert a_{n+1}\) for all \(n\) (and assume for convenience that \(a_0 = 1\)), then just as in the binary situation, we have a unique representation for every natural number by means of \(\mathbf{a}\).</p>
<p>Then we can formulate the full theorem from the preprint.</p>
<p><strong>Theorem</strong> If \(p\) is strongly summable and contains an FS-set for a sequence with disjoint support in the \(\mathbf{a}\)-representation, then \(p\) has the trivial sums property.</p>
<h2>About the result</h2>
<p><a href="http://nhindman.us/research/primes.pdf">The original theorem by Neil Hindman and Dona Strauss</a> [<a href="http://doi.org/10.1007/BF02573639">doi</a>] (also to be found in their book, chapter 12) showed that the trivial sums property holds for strongly summable ultrafilters with special properties. These included the restriction that the strongly summable ultrafilters must have a base of FS-sets coming from divisible sequences. In particular, these strongly summables will contain the FS-set for a sequence with disjoint support for a divisible sequence (just for the sequence itself), i.e., the result in the preprint entails the original result.</p>
<p>To see that it is a little bit more general, you need to know another concept, <em>additive isomorphism</em>. To keep it short, let’s just state it for strongly summable ultrafilters.</p>
<p>Two strongly summable ultrafilters \(p_0, p_1\) are <strong>additively isomorphic</strong> if there are $ {FS(} \mathbf{x} ) \in p_ 0$, $ {FS(} \mathbf{y} ) \in p_ 1$, such that the map $ \sum_ {i\in s} x_ i \mapsto \sum_ {i \in s} y_ i$ is well defined and maps \(p_0\) to \(p_1\) (so in particular, \(p_ 0 \cong p_ 1\) in the usual sense).</p>
<p>In <a href="http://nhindman.us/research/primes.pdf">their original paper</a> [<a href="http://doi.org/10.1007/BF02573639">doi</a>], Neil Hindman and Dona Strauss give a beautiful example of a strongly summable ultrafilter that does not concentrate on FS-sets from divisible sequences (this is done using unordered union ultrafilters) — and no additively isomorphic copy does. However, every strongly summable is additively isomorphic to one as in the result from the preprint. Hence the result is a little bit stronger.</p>
<p>(Un)fortunately, the trivial sums property is not transferred via an additive isomorphism, so one open question is whether all strongly summable ultrafilters have it. Although I included some evidence in the preprint towards believing that all strongly summables have it, I hope that it is not the case, simply because I hope that a counterexample would be a new kind of strongly summable ultrafilter. Of course, the big question is whether any other idempotents have this property! In particular, if there might exist such examples in ZFC.</p>
<h2>About the proof</h2>
<p>The proof in the preprint follows the same strategy as the proof of the original theorem by Neil Hindman and Dona Strauss. So the main task (or rather the initial observation that got me thinking about their proof again) was to overcome some of the restrictions on the strongly summable ultrafilters. Besides the ones already mentioned, there was another technical condition in the original result, a strange combinatorial property which I prefer to think about in terms of union ultrafilters.</p>
<p>An ultrafilter \(u\) on \(\mathbb{F}\) is <strong>special</strong> if for every infinite \(L\subseteq \omega\) there exists \(X \in u\) such that \(L \setminus \bigcup X\) is infinite.</p>
<p>In other words, \(u\) is able to ‘miss’ any infinite set by a large amount. The counterpart for strongly summable ultrafilters (which was already considered by Hindman and Strauss) is more complicated to write down, but suffice it to say that the two are equivalent. The key is that for union ultrafilters this property is not special at all.</p>
<p><strong>Theorem</strong> Every union ultrafilter is special.</p>
<p>The proof is not very complicated, it involves a standard parity argument that often appears when arguing with union ultrafilters (and then you just have to look carefully to see that you’re done).</p>
<p>But now this strange and difficult extra condition from the original result by Neil Hindman and Dona Strauss is suddenly available for free.</p>
<p>The final result is derived in essentially two steps. There is a bit of technicality involved, but I think nothing really complicated (to read).</p>
<p>Fixing some divisible sequence \(\mathbf{a}\), let’s call the support of a number in the representation via \(\mathbf{a}\) the <strong>\(\mathbf{a}\)-support</strong>. Then it roughly proceeds as follows.</p>
<ul>
<li>Show trivial sums for the ultrafilters that contain the set of multiples for each member of \(\mathbf{a}\).
<ul>
<li>This essentially reflects from a simple observation: if two elements with \(\mathbf{a}\)-support sufficiently far apart have their sum in an FS-set with disjoint \(\mathbf{a}\)-support, then they must both be in the FS-set already.</li>
</ul>
</li>
<li>Finally show that any sum equal to the strongly summable is essentially only possible by integer translates of ultrafilters that contain these sets of multiples.</li>
</ul>
<p>In this tricky final part the specialness condition comes into play. It is used to create an FS-set that has a lot of ‘holes’ in the \(\mathbf{a}\)-support. This makes it impossible for a single number to translate infinitely many numbers into that FS-set (as happens in a sum of ultrafilters all the time) simply because you would need too much ‘carrying over’ when translating/adding.</p>
<p>Well, of course that’s only a vague description of the proof, but the preprint should have enough details.</p>
<h2>Questions</h2>
<p>The most important questions I have already asked. Does every strongly summable have the trivial sums property and are their other ultrafilters with it, maybe even in ZFC? A result by Neil Hindman and Dona Strauss shows that all strongly summable ultrafilters have a maximal group isomorphic to the integers. It is still unkown if any other ultrafilters carry this property. So I think there is still a lot to be learned about this property.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BLAST 2010 chalk slides]]></title>
        <id>https://www.peterkrautzberger.org/0025/</id>
        <link href="https://www.peterkrautzberger.org/0025/">
        </link>
        <updated>2010-06-11T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>The organizers of <a href="https://web.archive.org/web/20100612014546/http://euclid.colorado.edu/~kasterma/blast/">BLAST 2010 [Wayback Machine]</a> asked the speakers to upload or give a link to the slides of their talk. Since I gave a chalk talk at the blackboard I had no slides. So instead of slides let me give a short recollection of my talk here.</p>
<h2>The semigroup \(\mathbb{F}\).</h2>
<p>Like any bad math talk, let’s start with a definition…</p>
<p><strong>Definition</strong> Denote the non-empty, finite subsets of \(\mathbb{N}\) by \(\mathbb{F}\) with semigroup operation \(\cup\) (or if you prefer, \(\Delta\)).</p>
<p>To offer different choices for the operation may seem odd, but as mentioned in <a href="https://www.peterkrautzberger.org/0016/">this post</a> the real concern is with the restriction to disjoint sets, i.e., where both operations coincide.</p>
<p><strong>FU-set</strong> Accordingly, in what follows, every sequence \(\mathbf{s} = (s_ i)_ {i \in \omega}\) in \(\mathbb{F}\) is supposed to be pairwise disjoint. Then the <em>FU-set (generated by</em> \(\mathbf{s}\)<em>)</em> is the set of all finite unions, i.e.,</p>
<p>\[ {FU(} \mathbf{s} ) := \left\{ \bigcup_{ i \in v} s_i : v \in \mathbb{F} \right\}.  \]</p>
<p>An FU-set is <em>ordered</em> if the generating sequence is, i.e., $\max(s_i) &lt; \max(s_{i+1} ) $.</p>
<h2>Union Ultrafilters</h2>
<p>One of the most important examples of idempotent ultrafilters are union ultrafilters on \(\mathbb{F}\).</p>
<p><strong>Union Ultrafilters</strong><br>
a) \(u \in \beta \mathbb{F}\) is called <em>union ultrafilter</em> if it has a base of <em>FU-sets</em>.<br>
b) \(u\) is an <em>ordered union</em> ultrafilter if it has a base of ordered FU-sets.<br>
c) \(u\) is a stable union ultrafilter if it is a union ultrafilter and for every choice of countably many \(FU ( \mathbf{s}^k ) \in u\) (\(k \in \omega\)) there exists $ {FU(} \mathbf{t} ) \in u $ such that for all $ k \in \omega $</p>
<p>\[ { \mathbf{t} } {\subseteq^*} {FU(} \mathbf{s}^k ).  \]</p>
<p>Here \(\subseteq^*\) is the usual almost inclusion, i.e., up to a finite set; in other words, \(\mathbf{t}\) is a pseudointersection of the \({FU(} \mathbf{s}^k )\). Note that \({FU(} \mathbf{t} )\) is not a pseudointersection — idempotents (in fact, products) can never be P-points.</p>
<p>These notions were <a href="http://www.math.lsa.umich.edu/~ablass/uf-hindman.pdf">introduced by Andreas Blass</a> (<a href="http://www.ams.org/mathscinet-getitem?mr=891244">MR</a>). Union ultrafilters are idempotent since \({\bigcup_{v \in {FU(} \mathbf{s}) } } v \cdot {FU(} \mathbf{s}) \subseteq {FU(} \mathbf{s})\). To digress.</p>
<p><strong>Question</strong> Do union ultrafilters have a base of FU-sets generated by unnested sequences? (where unnested means \(\min(s_i) &lt; \min(s_j) \rightarrow \max(s_i) &lt; \max( s_j)\))</p>
<p>This small question came up while preparing the talk; it has no ulterior motive (that I know of) and I never really thought about it.</p>
<h2>Differences — orderedness.</h2>
<p>As Andreas Blass said at the beginning of his <span class="caps">BLAST</span> 2010 tutorials, the very first question when it comes to ultrafilters is, how ultrafilters can be different from each other. In this case, the question becomes: are the three notions any different? Some results about ordered union ultrafilters are as follows.</p>
<ul>
<li><a href="http://www.math.lsa.umich.edu/~ablass/uf-hindman.pdf">Blass</a> (<a href="http://www.ams.org/mathscinet-getitem?mr=891244">MR</a>) If \(u\) is ordered union, then the images \(\max(u)\), \(\min(u)\) are non-isomorphic Q-points.</li>
<li><a href="http://dx.doi.org/10.1090/S0002-9947-1987-0906807-4">Blass, Hindman</a> If \(u\) is union, then the images \(\max(u)\), \(\min(u)\) are P-points.</li>
<li><a href="http://dx.doi.org/10.1090/S0002-9947-1987-0906807-4">Blass, Hindman</a> There consistently exist \(u\) union, such that \(\max(u)\), \(\min(u)\) are not Q-points. (in particular, such \(u\) is not ordered union).</li>
<li>There consistenly exists \(u\) union with \(\max(u)\), \(\min(u)\) both Q-points, but \(u\) is not ordered. (hopefully on the arXiv soon…)</li>
</ul>
<p>The actual results are usually a bit stronger, but that’s not important right now.</p>
<p>So on the one hand, ordered unions are really stronger than unions; on the other it is not enough for a union ultrafilter to map to Q-points to imply that it is ordered union. So it stays difficult to differentiate the two notions.</p>
<p>As a typical example of clever arguments with union ultrafilters, let’s prove something. This is from <a href="http://dx.doi.org/10.1090/S0002-9947-1987-0906807-4">Blass, Hindman</a>.</p>
<p><strong>Theorem</strong>(<a href="http://dx.doi.org/10.1090/S0002-9947-1987-0906807-4">Blass, Hindman</a>) If \(u\) is a union ultrafilter, then \(\max(u)\) is a P-point.</p>
<p><strong>Proof</strong>.</p>
<ol>
<li>Fix \(f \in \omega^\omega\).</li>
<li>Consider \(A = \left\\{ s \in \mathbb{F}: \min\left(s\right) &lt; f\left(\max(s)\right) \right\\}\).</li>
<li>If \(A \notin u\), then \(f \circ \max\) is bounded (hence constant) on a set in \(u\).
<ol>
<li>Take \({FU(} \mathbf{t}) \in u\) disjoint from \(A\).</li>
<li>It’s a nice exercise to show that if \({FU(} \mathbf{t}) \in u\) then so are all the FU-sets generated by the \(t_i\) with \(i>k\) (for each \(k\)).</li>
<li>Fix \(t_0\). For all but finitely many \(i\) we have \(\max(t_0) &lt; \min(t_i)\) (say from index \(k\) onwards).</li>
<li>Hence we calculate \(v \in FU( \mathbf{t}_{>k})\)<br>
\[   \min(t_0) = \min(t_0 \cup v) \geq f(\max(t_0 \cup v)) = f(\max( v)).  \]<br>
In other words, \(f \circ \max\) is bounded by \(\min(t_0)\).</li>
</ol>
</li>
<li>If \(A \in u\), then \(f\) is finite-to-one on a set in \(\max(u)\).
<ol>
<li>Take $ {FU(} \mathbf{t} {) \in u} $ included in A.</li>
<li>We calculate \(k = f(\max(v)) > \min(v)\).</li>
<li>But \(\max( FU(\mathbf{t} ))= \max(\mathbf{t})\) and only finitely many \(t_i\) have \(\min(t_ i) &lt; k\).</li>
</ol>
</li>
</ol>
<p>If you look closely, the last line shows that \(\max(u)\) is a rapid P-point; rapidity is attributed to Pierre Matet. The argument for \(\min\) is a bit more complicated (and longer).</p>
<h2>Stability.</h2>
<p>So it is difficult to differentiate ordered from unordered — maybe the third notion helps? For this, Andreas Blass proved the following amazing theorem.</p>
<p><strong>Theorem</strong> (<a href="http://www.math.lsa.umich.edu/~ablass/uf-hindman.pdf">Blass</a>, <a href="http://www.ams.org/mathscinet-getitem?mr=891244">MR</a>) If \(u\) is a ordered union ultrafilter, then the following are equivalent.</p>
<ol>
<li>Stability</li>
<li>Whenever \(\mathbb{F}^2_ &lt; = \left\\{ (s,t) \in \mathbb{F}^2 : \max(s) &lt; \min(t) \right\\}\) is partitioned into two pieces, there exists \(A\in u\) such that \(A^2_ &lt;\) is homogeneous.</li>
<li>The analogue for \(\mathbb{F}^k_ &lt;\) (and even \(\mathbb{F}^\omega_ &lt;\) if one part of the partition is analytic).</li>
<li>The ultrapower \(u\operatorname{-prod}\omega\) has exactly 5 constellations generated by \(id\), \(\max\), \((\min,\max)\), \(\min\) and \(0\).</li>
<li>\(\min\) generates an initial segment of \(u\operatorname{-prod}\omega\).</li>
</ol>
<p>This result is just amazing. It connects a P-point-like property to a Ramsey property — quite unlike the classical situation. At the time it was not yet known that union ultrafilters give P-points as \(\min\) and \(\max\) (which follows easily from stability), so it was even more surprising.</p>
<p>Now, you’d think there must be a difference if you drop the orderedness of the union ultrafilter, right? Unfortunately, this is not really the case.</p>
<p><strong>Theorem</strong> If \(u\) is a union ultrafilter, then 1-4 are equivalent and implied by 5. (again, arXiv, hopefully, soon…)</p>
<p>The proof follows Andreas Blass’s proof. He needed orderedness only in ‘1 implies 2’ and ‘5 implies 1’ so this where one has to work a little.</p>
<p>This part 5) is a bit of a rogue since I hadn’t thought about that part until recently and so it is a ‘new’ observation. I do not know if it is strictly stronger and there is evidence that it might not be. But again there seems little hope to differentiate ordered from unordered by means other than the definition.</p>
<p>Regarding the restriction to ordered pairs: this cannot be weakened to disjoint pairs, since any FU-set (ordered or not) will contain ordered and unordered disjoint elements (if ordered, compare \(s_1 \cup s_3\) to \(s_2 \cup s_4\)).</p>
<p>Now, all constructions in the literature yield stable union ultrafilters, hence the big open question for me is:</p>
<p><strong>Question</strong> Does there consistently exist an unstable union ultrafilter, i.e. a union ultrafilter that is not stable?</p>
<p>I have worked on this for a while now and even though I hope these exist (say under CH or MA) I think at the moment it is wide open.</p>
<h2>The other world.</h2>
<p>My own interest lies more in the world of \((\mathbb{N},+)\).</p>
<p><strong>Strongly Summable Ultrafilters</strong> An ultrafilter on \(\mathbb{N}\) is called <em>strongly summable</em> if it has a base of FS-sets.</p>
<p>FS-sets stand for the analogue of FU-set, i.e., for ‘finite sums set’ — but here with no extra conditions on the sequence in \(\mathbb{N}\).</p>
<p>If \(u\) is a union ultrafilter, \(f: \mathbb{F} \rightarrow \mathbb{N}, s \mapsto \sum_{i\in s} 2^i\), then \(f(u)\) is a strongly summable ultrafilter.</p>
<p>This is easy since disjoint unions map to correct sums (there is no carrying over after all). There is also a way back, i.e., for every strongly summable there is a similar looking function that maps it to a union ultrafilter, see <a href="http://dx.doi.org/10.1090/S0002-9947-1987-0906807-4">Blass, Hindman</a>, however</p>
<p><strong>Question</strong> If \(p\) is strongly summable, is \(f^{-1} (p)\) a union ultrafilter?</p>
<p>I hope this is not true, since it would simplify too many interesting questions, but it seems possible.</p>
<p>As an example why the other world is interesting, let me give (a special case of a) theorem (going back to a theorem by Neil Hindman and Dona Strauss).</p>
<p><strong>Theorem</strong> If \(u\) is a union ultrafilter, \(q,r \in \beta \mathbb{N}\) with \(q+r = f(u)\), then \(q,r \in \mathbb{Z} + f(u)\) (arXiv, soon…).</p>
<p>What does this mean? The only way to write these kinds of strongly summable ultrafilters as a sum is the trivial way via integers. Ah, I should mention: it is an exercise to show that \(\beta \mathbb{N}\) is a left ideal in \(\beta \mathbb{Z}\) (so this actually makes sense…) and then that the integers commute (so this trivial way is always possible).</p>
<p>This is a fascinating property and these (and some more) strongly summables are the only known examples with this property (unlike nearly all other results for idempotents which are in <span class="caps">ZFC</span>). I hope to blog more about more special properties sometime soon but this is all I covered in my talk, so enough for today.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BLAST 2010, post scriptum]]></title>
        <id>https://www.peterkrautzberger.org/0024/</id>
        <link href="https://www.peterkrautzberger.org/0024/">
        </link>
        <updated>2010-06-07T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Darn, being delayed for 5 hours at the airport on Sunday still only got me started (not finished) on this retrospective on the BLAST 2010. I guess since it was a delay from 11pm to 4.30am my brain stopped working after the long, final day in Boulder (which included my very own first conference chalk talk!).</p>
<p>In short, it was a very, very good conference, one of the best that I have been to (which arguably aren’t that many). The tutorials were either very good or just short of amazing, the short talks were good and the atmosphere extremely friendly. The only, very slight criticism would be the predominance of set theoretic talks. This may sound strange from somebody closer to set theory than most other things, but I would have enjoyed having the opportunity to learn even more about the other fields present (at least the tutorials did not have to be 3-1). Especially, to hear about the connections between universal algebra and theoretical computer science was extremely interesting.</p>
<p>On top of that I met a great number of interesting and genuinely nice people (almost everyone I had mnore than 5 minutes to talk to, in fact) and also reconnected with many others. This is certainly the most exhilarating part, finally without restrictions — no PhD thesis (or supervisors) to keep in mind, just being a researcher, as much or as little as I can. Frequently, that is a frustrating thing, at the BLAST it was genuine fun. Who’d have thunk?</p>
<p>Of course, it helps to come back with at least one interesting new observation that really questions my intuition about my favourite objects, idempotent ultrafilters. And then there are all those interesting open questions that I collected…</p>
<p>I hope I get a chance to return to Boulder sometime soon. If only to go on another hike in those incredible mountains.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BLAST 2010, first impressions]]></title>
        <id>https://www.peterkrautzberger.org/0023/</id>
        <link href="https://www.peterkrautzberger.org/0023/">
        </link>
        <updated>2010-06-02T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I am spending this week in Boulder, Colorado, at the <a href="https://web.archive.org/web/20100612014546/http://euclid.colorado.edu/~kasterma/blast/">BLAST 2010 [Wayback Machine]</a> and it’s off to a great start.</p>
<p>There are many reasons I am enjoying myself. The city’s location is naturally amazing and I look forward to the conference hike on Friday. The town seems very nice as far as I got around and the campus is beautiful. Socially speaking, I thoroughly enjoy meeting familiar faces and friends in numbers I never experienced before. Scientifically speaking, the tutorials are excellent, both Matti Rubin and Andreas Blass are amazing teachers. Also, some personal conversations already led to new (and surprising) results, so that’s quite cool. I keep wondering a little if there could be a better format for talks in mathematics. The usual setup I have encountered so far seems consisting of invited speakers getting around 45 mins, others 30 mins. This mostly leads to invited speakers giving much too broad talks whereas the other speakers start to rush a lot. As much as I love LaTeXs Beamer class, the power point problem of too many and too easily forgotten slides hurts mathematical talks badly since there are no best practices, there is no power point zen for mathematics.</p>
<p>And there is this thought that always overcomes me at some point during conferences. After listening to fascinating and intricate new and old results, after getting a glimpse at so many concepts and techologies that I barely follow, I eventually start to worry about the future of <del>pure mathematics</del> mathematical logic. Why do we do it? Of course, a conference is not the ideal place for this question (but where is it?). Pure mathematicians might agree that mathematics is ‘mostly useless’ — just as art and literature and staring into the sky is mostly useless. Useless in that there are rarely immediate ‘real world’ applications in sight. Of course, history is on our side and there are many examples of extremely pure, mathematical results that <a href="http://mathoverflow.net/questions/2556/real-world-applications-of-mathematics-by-arxiv-subject-area">came to be applied</a> decades or centuries later.</p>
<p>For day to day lives, teaching seems the natural answer. Any student that is taught a class in a field of mathematical logic has gained an education in abstract thinking on a level that no other field of mathematics offers. But in the current scientific climate, teaching is not an accceptable justification, only research is (or really, publishablity and impact factor, sadly enough). But if reasearch is ‘mostly useless’, where does this leave us?</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why there is need to train bad mathematicians]]></title>
        <id>https://www.peterkrautzberger.org/0022/</id>
        <link href="https://www.peterkrautzberger.org/0022/">
        </link>
        <updated>2010-05-24T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Felix Breuer has asked me to repost <del>an old</del> my very first public blog post <del>from way back when</del> originally posted on 2008-08-06 over at <a href="http://web.archive.org/web/20151016002857/http://www.scivee.tv/">scivee [Wayback Machine]</a>. Felix wanted to link to it in <a href="http://blog.felixbreuer.net/2010/05/12/excellence-and-creativity.html">his interesting post on excellence and creativity</a> which I want you to read right away (albeit, only if you read German…).</p>
<h3>Why there is need to train bad mathematicians</h3>
<p>Recently, the Olympic games are the hottest topic on the news. I don’t want to talk about the games as such, rather I want to start my blog by talking about a parallel I noticed yesterday while listening to the German public radio station Deutschlandfunk (<a href="http://www.dradio.de/">www.dradio.de</a>).</p>
<p>They aired a feature on financial support for German athletes. Apparently, one major factor is the support offered by the German Olympic sports union (DOSB). The feature criticized that the DOSB’s support focuses too much on high level athletes and too little on low-level sports, i.e. local clubs, regional networks etc. Even without an understanding of the latter, special part of German culture I think the problem is easy to understand: The lack of support for everyday, John Doe kind of sports clubs of all inclinations (think kayaking, gymnastics, archery, curling) can reduce the amount of highly talented people that get in touch with such activities. A probable consequence is that in the long run, less people will have a chance to discover their talents in these not very popular sports, which in turn will naturally decrease the amount of high level athletes that could have a chance to compete on an international level.</p>
<p>So what does this have to do with bad mathematicians? Well, obviously I think that something similar is true when it comes to training mathematicians. The mathematics community (in Germany) seems to be so focused on producing the highest level of researchers (even when they are not), that they completely forget to train “bad” mathematicians, that is “low level” mathematicians. So what could “bad” mathematicians be good for? In a negative description, a bad mathematician is a mathematician that never added “significantly” to the field, never published in great and important journals, never impressed the greatest minds of the field. Indeed, a bad mathematician might not even know all that much about any current hype in research, might not even know the whole of mathematics all that well, might in fact never have published at all, never proven a publishable result, never even considered trying. So what good could a bad mathematician possibly be?</p>
<p>Positively described a bad mathematician has studied mathematics, yet a degree has nothing to do with it. Instead a bad mathematician learned what practicing mathematics is like, learned the difficulties of the mind that delves into a mathematical problem without yet knowing what a solution could even be like, learned to overcome these difficulties (though maybe “only” at a basic level), practiced enough mathematics to comprehend the depth and artistic worth of this truest art of the mind and has glimpsed at a universe unkown to most. Above all, a bad mathematician shares an enthusiastic interested in mathematics, maybe because it is beautiful, maybe because it is challenging, maybe because it is ancient and intricate. And I believe to be a bad mathematician you don’t even have to know very much about mathematics — at least not in the way this is statement is commonly understood today.</p>
<p>I have often encountered that many find the following idea to be a cardinal sin: to train people consciously in such a way that they will not know enough about “real” mathematics, not know enough to understand the complex development of modern results, not have the technical expertise to follow a complex proof, not have the experience of trying to create unique, independent results, in short not to train them towards an academic career. But let me abuse the image of sports once more. It is not important to be even close to performing a sport on the highest level to develop a deep love and fascination for it (though let me remind you that I am talking about active amateur sport here, not pure fandom). I think one relevant aspect is the ability to recognize, understand and relate to what high level sportspeople actually accomplish — and as anyone watching some unfamiliar sport during the Olympic games will easily remember: this is quite a feat on its own.</p>
<p>So what does that mean for “bad” mathematicians? I am not saying they should only know lots of calculations or lots of logic puzzles or lots of fun applications (this won’t hurt — it’s just not that interesting, really). No, “bad” mathematicians need to know what the work of a mathematician is like — they do need to know some real, modern mathematics. But they do not need to know a lot of areas of mathematics in great detail — since frankly neither does the greater part of the scientific community. Instead bad mathematicians have learned to appreciate mathematics for what it really is — neither blindly loving it nor excessively criticizing the often either arrogant or mothering presentation of mathematics by mathematicians.</p>
<p>Now a lot of people I have met claim that the German (and maybe European) academic system is actually really good at the general level of education, e.g. french Bac compared to a US high school degree, a German Diplom with an anglo-saxon master etc. However, I think this is off the point. The fact is, that when it comes to mathematics, only a few people study it, even fewer get to appreciate it, hardly anyone falls in love with it, so that we are in danger of loosing have lost the large base of people generally interested in mathematics, people who know that mathematics is not just numbers, people that can appreciate the complex work (of art) that mathematicians try to accomplish everyday, people, in short, that have a clue about mathematics.</p>
<p>These are the only people that could make mathematics really popular — well, maybe not actually popular, but they certainly would turn it into a subject like any other, a subject “of the people”, a subject that will seem sensible to most people, even though they don’t know it themselves, a subject that everybody finds plausible to study, a subject to be interested in just as it is interesting to play a game of football with a couple of friends in a public park — it’s not high level, but it certainly is fun to do every now and then (and really, couldn’t we use the exercise more often?) — and then, if you really want to, just go ahead and try to go pro! If you’re lucky there might be a “bad” mathematician in your neighbourhood and somebody’s able to tell you: “I know just the guy you need to talk to”.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Beautiful Prezi and more]]></title>
        <id>https://www.peterkrautzberger.org/0021/</id>
        <link href="https://www.peterkrautzberger.org/0021/">
        </link>
        <updated>2010-05-23T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>There is a lot of catching up to do… Let’s get started.</p>
<p>As I mentioned Tim Gowers’s use of Prezi <del><a href="https://www.peterkrautzberger.org/0020/">the other day</a></del> a while ago, I found <a href="http://prezi.com/aww2hjfyil0u/math-is-not-linear/">this incredible example of prezi</a> <del>today</del> shortly thereafter but never got around posting it. In the mean time I stumbled upon more things worth (re)posting all over the intertubes.</p>
<p>As always, I’m amazed when somebody can explain probability to me — this time over at <a href="http://blogs.discovermagazine.com/cosmicvariance/2010/05/17/non-normalizable-probability-measures-for-fun-and-profit/">cosmic variance on normalizability</a>. Also, I cannot not mention <a href="http://www.scienceblogs.de/mathlog/2010/05/illusion-des-jahres-3.php" title="via Thilo Kuessner's mathlog">this years best optical illusion</a>.</p>
<p>Slightly related, there has been an <a href="http://blogs.discovermagazine.com/80beats/2010/05/21/refuting-einstein-in-4-easy-steps-physicists-measure-brownian-motion/">amazing experiment at the University of Texas, Austin, mentioned on 80beats</a>. Fortunately, just because real Brownian Motion becomes predictable the mathematical notion remains the same — but I wonder if this will lead to confusion in the far future…</p>
<p>Last but not least, <a href="http://scienceblogs.com/bioephemera/2010/05/fixing_our_impatience_with_irr.php">bioephemera lead me to Dan Meyer’s TED talk</a>, which is cool and insightful.</p>
<p>The slightly worrying thing is that the best place to find good mathematics blogging (at least the science journalism kind) is on non-mathematical blogs…</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mathematics in Newspapers (Germany vs USA)]]></title>
        <id>https://www.peterkrautzberger.org/0020/</id>
        <link href="https://www.peterkrautzberger.org/0020/">
        </link>
        <updated>2010-05-09T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I meant to write about this for a while now but everytime I began the post became either too boring or too much of a rant.</p>
<p>It fascinates me (in a horrible kind of way) how the quality of popular mathematical writing (be it blogs or newspaper columns) in German is so much lower than in English. Granted, many more people write in English. But it is not the language that seems to matter, it is the style of writing.</p>
<h3>Newspapers</h3>
<p>Recently, I read the following.</p>
<p><a href="https://en.wikipedia.org/wiki/G%C3%BCnter_M._Ziegler">Günther Ziegler</a> at <a href="http://www.zeit.de/2010/16/Mathe-Buch">Die Zeit</a></p>
<p>compared to</p>
<p><a href="http://www.stevenstrogatz.com/">Steven Strogatz</a> at <a href="http://opinionator.blogs.nytimes.com/2010/04/18/it-slices-it-dices/">The New York Times</a></p>
<p>Ziegler’s article is quite nice but Strogatz’s column is so much more. Both articles contain easy to read anecdotes (always great so that readers can relate). But that’s where Ziegler essentially stops (or rather, repeats) whereas Strogatz just gets started and continues with actual mathematics, not afraid to throw in equations (shocking!) and actually explaining an important tool of mathematics — just like any other science journalist.</p>
<p>Now, don’t get me wrong. I admire Günther Ziegler (how could I not after doing my PhD in Berlin where the mathematical community profits so much from his numerous endeavours) and I know he is a great communicator (even though I don’t like ‘Proofs from the Book’ but that’s another post). So I cannot help but wonder if it is somebody else’s fault, namely the editor’s, that there is no actual mathematics in that article.</p>
<h3>Blogs</h3>
<p>The situation is rather the same when it comes to blogs. I admit I only read one mathblog that's in German — <a href="http://www.scienceblogs.de/mathlog/">mathlog</a> which is very good. But last week I noticed <a href="http://www.scilogs.de/mathe-sprache">a series of blog posts at scilogs</a> and I found it extremely boring. I am always interested in external opinions on mathematics (pure mathematics is extremely self-centered) but I found no interesting opinions (or anything else) in those posts. It felt, all in all, very artificial compared to other posts of these bloggers. So again, maybe there is an editor to blame, I don’t know.</p>
<p>I don’t want to write about all the English math blogs I read. But I wanted to mention it for a different reason anyway, so <a href="http://gowers.wordpress.com/2010/05/08/a-little-experiment-iv">Timothy Gowers’s</a> is as good a representative as you’ll find — this time not just by subject but by technology. For his ongoing series of experiments on mathematical thinking he uses a <a href="http://prezi.com/">Prezi Presentation</a>. I wish I found the time to learn prezi…</p>
<h3>So?</h3>
<p>So I keep asking myself: Is this a misconception due to my narrow minded blogroll? Where are all these great examples of German math writing that I miss?</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[YSTN first look]]></title>
        <id>https://www.peterkrautzberger.org/0019/</id>
        <link href="https://www.peterkrautzberger.org/0019/">
        </link>
        <updated>2010-05-08T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>The last week was rather busy and I did not find time to blog. The good news is that I will be attending <a href="https://web.archive.org/web/20100612014546/http://euclid.colorado.edu/~kasterma/blast/">BLAST 2010 [Wayback Machine]</a> in Boulder come June and they are very kind to support me.</p>
<p>After having been very excited last week with the start of the <a href="https://web.archive.org/web/20110711064402/http://young-set-theory.net/wiki/Main_Page">Young Set Theory Network [Wayback Machine]</a> I wanted write a follow up on the project that hopefully helps people who want to become active in it. The text was supposed to help me identify how I would want to contribute. But it became a bit more so I decided to post it.</p>
<h3>Technology</h3>
<p>Well, that’s easy enough. The <a href="https://web.archive.org/web/20110711064402/http://young-set-theory.net/wiki/Main_Page">YSTN [Wayback Machine]</a> uses a wiki, more specifically wikimedia’s MediaWiki used by <a href="http://www.wikipedia.org/">Wikipedia</a> itself. That is one reliable and flexible piece of software. The <a href="https://web.archive.org/web/20110711064402/http://young-set-theory.net/wiki/Main_Page">YSTN [Wayback Machine]</a> does not allow for editing without registration since it is too small a project to battle spam. But I hope they will change that in the future — after all, MediaWiki does allow for other measures such as <a href="http://en.wikipedia.org/wiki/CAPTCHA">captcha</a>.</p>
<p>At the moment I would say the biggest drawback is that registration does not allow for free editing. For this you have to wait until a user with “Set Theorist” status upgrades you to that status. This probably hinders the development of the network in the beginning. But I don’t think it will stay that way, rather it will speed up the development once critical mass is reached. So if you want to be upgraded to Set Theorist status just contact me via the comments.</p>
<p>I think in the long run it might turn out that the project needs a more dynamic technology such as specialised social networks via e.g. <a href="http://www.mixxt.net/">mixxt</a>. But even in that case an open and established platform such as MediaWiki is a good start. Now if only MathML was used instead of these ugly PNGs…</p>
<h3>Concept</h3>
<p>The <a href="https://web.archive.org/web/20110711064402/http://young-set-theory.net/wiki/Main_Page">YSTN's [Wayback Machine]</a> concept is explained at its <a href="https://web.archive.org/web/20110709063115/http://young-set-theory.net/wiki/Young_Set_Theory_Network:Community_Portal">Community Portal [Wayback Machine]</a>. In my humble opinion the concept is too complex, it is trying too much at once. Reading it for the first time left me with the impression that the <a href="https://web.archive.org/web/20110711064402/http://young-set-theory.net/wiki/Main_Page">YSTN [Wayback Machine]</a> wants to be a simultaneous (albeit set-theoretically specialised) copy of a ton of other projects that have been around for a while. Following <a href="http://www.buzzmachine.com/2007/02/22/new-rule-cover-what-you-do-best-link-to-the-rest/">Jeff Jarvis’s Rule</a> I don’t think this is a good idea.</p>
<p>Don’t get me wrong everything on that list would be really good to have. But most points are already covered — and extremely well at that! So I think it might be a better idea for the <a href="https://web.archive.org/web/20110711064402/http://young-set-theory.net/wiki/Main_Page">YSTN’s [Wayback Machine]</a> development to follow Jarvis: do what you can do best and link to the rest. In other words, add and aggregate to other projects and only do what is not already done better elsewhere. This is also important so as not to isolate the content from a more general (mathematical) audience.</p>
<p>Let me comment on the list from the <a href="https://web.archive.org/web/20110709063115/http://young-set-theory.net/wiki/Young_Set_Theory_Network:Community_Portal">Community Portal [Wayback Machine]</a> to show you what I mean.</p>
<ul>
<li><em>Notes etc.</em> Talks are usually stored by authors or conference websites, it is the right place logically (and legally). Everything else should be on the author’s homepage or the <a href="http://arxiv.org/">arXiv</a>. Everything book-like should be linked on <a href="https://web.archive.org/web/20120512220416/http://mathonline.andreaferretti.it/pages/home">MathOnline [Wayback Machine]</a> (which has an empty set theory section last time I checked).</li>
<li><em>Theses</em> should be on the Author’s site or the <a href="http://arxiv.org/">arXiv</a></li>
<li><em>Unpublishable original research</em>
<ul>
<li><em>Paper annotations</em> That’s a cool idea, especially when annotations are joined work</li>
<li><em>proofs of known results</em> again: Author’s site or <a href="http://arxiv.org/">arXiv</a></li>
<li><em>observations</em> Blogs</li>
</ul>
</li>
<li><em>General articles</em> <a href="http://www.wikipedia.org/">Wikipedia</a>, <a href="http://www.tricki.org/">Tricki</a></li>
<li><em>Young Set Theory activities</em> the list of conferences is a good feature</li>
<li><em>Possibilities for discussion pages</em> social networks, blogs, <a href="https://en.wikipedia.org/wiki/Apache_Wave">Google wave</a> are better suited for discussions than a wiki.
<ul>
<li><em>Open questions</em> <a href="http://garden.irmacs.sfu.ca/">Open Problem Garden</a></li>
<li><em>Research discussions</em> <a href="http://mathoverflow.net/">mathoverflow</a> , <a href="http://polymathprojects.org/">polymath</a>, social networks, blogs, <a href="https://en.wikipedia.org/wiki/Apache_Wave">waves</a></li>
<li><em>Working groups</em> social network, <a href="https://en.wikipedia.org/wiki/Apache_Wave">waves</a> , blogs, <a href="http://polymathprojects.org/">polymath</a></li>
<li><em>Technology group</em> Good idea, will repost my Winterschool post there</li>
</ul>
</li>
<li><em>Job application documents</em> That would be one cool feature</li>
<li>Other set-theory related writing
<ul>
<li><em>Book reviews</em> <a href="https://web.archive.org/web/20120512220416/http://mathonline.andreaferretti.it/pages/home">MathOnline [Wayback Machine]</a></li>
<li><em>Essays</em> Blogs, <a href="http://arxiv.org/">arXiv</a></li>
</ul>
</li>
</ul>
<p>This may seem very negative, but I believe it can prove to be a strength. With a better focus on areas that are not covered anywhere and a high level of transparency and connectivity towards other projects it will be much easier for the network to create momentum.</p>
<h3>Content</h3>
<p>Ok, so this is a bit of problem and the reason why I think the <a href="https://web.archive.org/web/20110711064402/http://young-set-theory.net/wiki/Main_Page">YSTN [Wayback Machine]</a> needs focus. There is no content as far as I can see. The wiki claims to have four articles, three of them help pages (which is quite ok, help pages are extremely important). So the <a href="https://web.archive.org/web/20110711064402/http://young-set-theory.net/wiki/Main_Page">YSTN [Wayback Machine]</a> needs to gather a few people that will actively contribute. Content that either gives people something to read or something to do. If this is not possible a later relaunch could be an option.</p>
<h3>Conclusion</h3>
<p>The main conclusion is that the <a href="https://web.archive.org/web/20110711064402/http://young-set-theory.net/wiki/Main_Page">YSTN [Wayback Machine]</a> uses solid technology and has many ideas on what it wants to become. So I think I will invest time into contributing. However, it is not without alternatives so for most people it will have to prove that it can be a good addition to the status quo — wikipedia, tricki, mathoverflow, arXiv, email, social networks, blogs, twitter cannot be ignored but easily embraced. In particular, I think there is need to give those visitors that want to help more concrete tasks, tell them how they can contribute, be it small or large.</p>
<p>Above all the <a href="https://web.archive.org/web/20110711064402/http://young-set-theory.net/wiki/Main_Page">YSTN [Wayback Machine]</a> needs a small group of engaged people with focus to start breathing life into it. It need not be perfect, it just needs to grow.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Young Set Theorists Network starting]]></title>
        <id>https://www.peterkrautzberger.org/0018/</id>
        <link href="https://www.peterkrautzberger.org/0018/">
        </link>
        <updated>2010-04-30T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>The <a href="https://web.archive.org/web/20110711064402/http://young-set-theory.net/wiki/Main_Page">Young set theorist network [Wayback Machine]</a> has been opened to the public! Although I have yet to make it to a Young Set Theorist Meeting (I always failed for some technical reasons) I feel it is important to get involved in the network and make it a success.</p>
<p>The YSTN is not just an important tool for the people already involved in the YST, but it is a step to reach out and gain momentun and I believe it offers a chance for a lot of <a href="http://en.wikipedia.org/wiki/Emergence">emergence</a> in logic and set theory inside and outside of Europe.</p>
<p>As I see it, it is also a big step forward for the whole project. My only criticism so far was that the activity till now was too narrow and too “old school”. Don’t get me wrong, from what I have heard the meetings were very good and really did focus on the younger generation. But they were just that, once a year meetings. That’s a limitation on communication of the past. With the internet <a href="https://www.peterkrautzberger.org/0010/">and its countless possibilites</a> to connect we could have virtual meetings whenever and wherever we want.</p>
<p>Meetings are important (especially when they are as good as the YSTs) but we need to be more flexible in ways to “congregate” — in the pure sciences in general and especially in set theory, a subject where positions get fewer and fewer and workgroups get smaller and smaller.</p>
<p>This is why the network is an important step forward, let’s fill it with life!</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New "What is…?" Videos]]></title>
        <id>https://www.peterkrautzberger.org/0017/</id>
        <link href="https://www.peterkrautzberger.org/0017/">
        </link>
        <updated>2010-04-28T00:00:00Z</updated>
        <summary type="html"><![CDATA[<h3>Backlog</h3>
<p>Last week I finally begun catching up on uploading videos of the <a href="http://www.math.fu-berlin.de/w/Math/WhatIsSeminar">‘What is …?’ seminar</a> in Berlin. Even though I’m now in Ann Arbor I am still happy to help out by uploading the video recordings. For now I’m only catching up on videos I recorded at the beginning of the year, but there’s something to look forward to: the new video camera the <a href="http://www.math-berlin.de/">BMS</a> sponsored offers HD resolution! So look forward to more fantastic mathematical footage coming soon.</p>
<h3>Rough paths, Geodesics and more</h3>
<p>For now, I’m happy to say that two new videos are up. First there is Joscha Diehl’s talk on <a href="http://vimeo.com/11097173">‘What is … a rough path?’</a> .</p>
<p>Second there is the first ‘tag team’ talk by <a href="https://twitter.com/drorata">Dror Atariah</a> and <a href="http://www.mi.fu-berlin.de/en/math/groups/ag-geom/people/former-members/pfeiffer.html">Tobias Pfeiffer</a> on <a href="http://vimeo.com/11253670">‘What is … a geodesic on a Riemannian Manifold’</a> .</p>
<p>I also must say I love <a href="http://www.felixbreuer.net/">Felix Breuer’s</a> beautiful video <a href="http://vimeo.com/10014698">Der Kleine Gauß</a> which was made for a general (German speaking) audience explaining the equation</p>
<p>\[ \sum_{i \leq n} i = \frac{n\cdot (n+1)}{2}\]</p>
<p>not by stupid calculations but with real mathematical thought. (Disclaimer: I was involved in its production)</p>
<h3>Ramblings</h3>
<p>I am a huge fan of free online publication of video recordings of all kinds of lectures. Since a large part of university level teaching involves not-too-interactive lectures I think not only the <a href="https://www.youtube.com/user/MIT">MIT</a> has shown what an asset it is to have these video available both for their students and the general (academic) public.</p>
<p>There are just too many things great about this! The lecturer can evaluate him/herself, the students can use it to revise (and discuss), people all over the world gain access to top level teaching and on top of that you offer transparency to whoever funds research and teaching. It’s a win for everyone.</p>
<p>But I also think that teaching should only be the beginning. The <a href="https://www.youtube.com/user/JournalNumberTheory">Journal of Number Theory</a> has begun offering (and suggesting to) their authors to record video abstracts. Of course, <a href="http://www.scivee.tv/">Scivee.tv</a> has been doing this and much more, albeit with a heavy focus on the sciences, not so much mathematics.</p>
<p>But besides the high level math videos I think there is much need for lower level lectures, maybe even unsophisticated talks. This is not meant to be negative — for how else could I distinguish the top level if there was nothing else to compare it to? Everybody has to start somewhere and get experience to grow. This is why we always encouraged the speakers at the “What is …?” seminar to make their talks available — even with the worst talks (like a couple of my own) everybody gains, especially the speaker.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Van Douwen spaces]]></title>
        <id>https://www.peterkrautzberger.org/0016/</id>
        <link href="https://www.peterkrautzberger.org/0016/">
        </link>
        <updated>2010-04-25T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>At the <a href="http://www.winterschool.eu/">winterschool</a> <a href="http://math.uncc.edu/~adow/">Alan Dow</a> gave quite challenging tutorials. He also mentioned something about van Douwen spaces.</p>
<h3>Van Douwen Spaces</h3>
<p>As formulated <a href="http://math.uncc.edu/~adow/vDspace.pdf">here</a></p>
<p><strong>van Douwen space</strong> A countable \(S\) is a <em>van Douwen space</em> if it is crowded (i.e. has no isolated points) and there is a 1-to-1 function from \(\mathbb{N}\) to \(S\) that extends to a $\leq$2-to-1 function from \(\beta \mathbb{N}\) to \(\beta S\).</p>
<p>What caught my interest was that there is an example that has something to do with <a href="http://en.wikipedia.org/wiki/Idempotency">idempotent</a> <a href="http://en.wikipedia.org/wiki/Ultrafilter">ultrafilters</a>. Let me introduce something first.</p>
<p><strong>A partial order</strong> On the idempotent ultrafilters (on \(\mathbb{N}\)) define a partial ordering by</p>
<p>\[ p \leq_r q \Leftrightarrow q + p =p. \]</p>
<h3>Digressing</h3>
<p>This partial order (as well as its left counterpart and their intersection) is quite important in the algebra in the Stone–Čech-compactification. Mostly because this order has minimal idempotents which are central to the field. <s>(pardon the pun)</s> Oops, after ignoring its definition <a href="https://www.peterkrautzberger.org/0015/">in my last post</a> this is not a pun. So let me add: a set is in fact central if it is an element of a minimal idempotent. Central, get it? Ah, well…</p>
<h3>Strongly right maximal</h3>
<p>For van Douwen spaces it is useful to go in the other direction. There exist many right-maximal elements in this order, but even more can be said.</p>
<p><strong>Strongly right maximal idempotents</strong> An idempotent ultrafilters \(p \in \beta \mathbb{N}\) is <em>strongly right maximal</em> if</p>
<p>\[ q+ p =p \Rightarrow q= p. \]</p>
<p>Yevhen Zelenyuk once gave an example of a right-maximal that is not strongly right maximal assuming CH or MA (and even less). In any case these idempotents are very nice and thanks to Igor Protasov exist under ZFC alone. Nevertheless it is an open question whether consistenly all right-maximal idempotents are strongly right-maximal, i.e., if non-strongly but right-maximal idempotents exist under ZFC alone.</p>
<h3>Back to van Douwen spaces</h3>
<p>Anyhow, the main point is that strongly right maximal idempotents have an orbit that is a van Douwen space!</p>
<p>Let \(p\) be strongly right maximal. Then \(\mathbb{N} + p\) is a van Douwen space.</p>
<p>And this is what Alan Dow mentioned. Ignoring the crowdedness, this is really easy for in fact more holds in this case.</p>
<p>If \(p\) is strongly right maximal, then</p>
<p>\[ \rho_p: \mathbb{N} \rightarrow \beta \mathbb{N}, n \mapsto n+ p \]</p>
<p>is injective, hence also its continuous extension to \(\beta \mathbb{N}\) (which is naturally onto the orbit \(\mathbb{N} +p\)).</p>
<p>So in fact, it is not just a $\leq$2-to-one function, but an injective function. Strange, isn’t it? Strongly right maximality really only speaks of injectivity at \(p\), but this is already enough.</p>
<h4>Proof</h4>
<p>The proof needs some basic stuff such as ‘multiplication with fixed right hand side is continuous’. Oh, and you need to know that natural numbers are cancelative…</p>
<ul>
<li>Since $ ( \mathbb{N} , + ) $ is cancelative, the maps $ \lambda_{n} = n + \cdot$ are injective for all \(n\).</li>
<li>Since \(\lambda_n\) is continuous (on a discrete space), its extension to \(\beta \mathbb{N}\) is injective as well.</li>
<li>Then \(\rho_p\) is injective on \(\mathbb{N}\).
<ul>
<li>If \(n &lt; k \in \mathbb{N}\) had \(n+ p = k + p\), then by the above steps \(k-n + p = p\).</li>
<li>Since \(p\) is strongly right maximal, this would imply \(n-k = p\) — which is absurd since \(p\) is idempotent, hence free.</li>
</ul>
</li>
<li>But then by continuity the whole of \(\rho_p\) is injective.</li>
</ul>
<p>I like that. Now, my favourite kind of idempotent ultrafilters are strongly summable ultrafilters. Those were the first examples of strongly right maximal idempotents, however their existence is independent of ZFC. On the other hand, they have much stronger properties and I would not be surprised if this affected their orbit, i.e., if that van Douwen space is not special somehow.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding the Central Sets Theorem]]></title>
        <id>https://www.peterkrautzberger.org/0015/</id>
        <link href="https://www.peterkrautzberger.org/0015/">
        </link>
        <updated>2010-04-18T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>To write the first post on the new domain I thought I might just write a little about what I’ve been studying recently — the Central Sets Theorem.</p>
<p>This theorem dates back to the 70s and the original formulation and proof are due to <a href="http://en.wikipedia.org/wiki/Hillel_Furstenberg">Hillel Furstenberg</a>. In its current form as found say in <a href="http://nhindman.us/research/newcentral.pdf">De, Hindman, Strauss</a> (<a href="http://doi.org/10.4064/fm199-2-5">DOI</a>) it is probably the strongest algebraic partition theorem around. I had encountered the theorem many times before, in books, lectures, papers and talks but I never truly developed an understanding for it. Since I recently felt it might give me an edge in a problem I’m working on I decided to take a better look.</p>
<h3>Detour 1 — metamathematics</h3>
<p>How do you achieve an understanding of a theorem? In an incomplete list I would include the following</p>
<ul>
<li>Understand its most important application or corollary</li>
<li>Understand its statement</li>
<li>Understand its proof</li>
<li>Improve its proof</li>
<li>Understand how to come up with the proof</li>
<li>Give a different proof</li>
<li>Improve the theorem</li>
</ul>
<p>I would say this list is in increasing order of understanding but that’s open for discussion.</p>
<p>I might write about the history (and applications) of the Central Sets Theorem some other time, but here I want to focus on its formulation; in fact, I don’t even want to write about what it means to be <a href="http://en.wikipedia.org/wiki/Partition_regularity">central</a> (sorry) except that it is a <a href="http://en.wikipedia.org/wiki/Partition_regularity">partition regular</a> notion.</p>
<h3>Formulation</h3>
<p>So, what does the usual formulation look like?</p>
<p><strong>Central Sets Theorem</strong><br>
Imagine you are given finitely many sequences in a commutative semigroup \((S,+)\), say \(\mathbf{y^0}, \ldots, \mathbf{y^\alpha}\) as well as a central set \(C \subseteq S\).<br>
Then you can find a sequence \(\mathbf{a}\) in \(S\) as well as a sequence \(\mathbf{h}\) of non-empty, disjoint and finite subsets of \(\mathbb{N}\) such that for \(\beta \leq \alpha\)</p>
<p>\[ FS ( {a_n} + {\sum_{i \in h_n} y_i^\beta} ) \subseteq C. \]</p>
<p>Complicated, no? I mean, a random bunch of sequences, some strange set and you find some other sequence and some weird subsets of of the natural numbers and then the <a href="http://en.wikipedia.org/wiki/IP_set">IP-set</a> of some strange sums are in that strange set — <strong>ye what?</strong></p>
<p>Let’s cut it down a little and just consider the case \(\alpha = 0\).</p>
<p><strong>simple Central Sets Theorem</strong><br>
Imagine you are given a sequence \(\mathbf{y}\) in a commutative semigroup \((S,+)\) as well as a central set \(C \subseteq S\).<br>
Then you can find a sequence \(\mathbf{a}\) in \(S\) as well as a sequence \(\mathbf{h}\) of non-empty, disjoint and finite subsets of \(\mathbb{N}\) such that</p>
<p>\[ FS ( {a_n} + {\sum_{i \in h_n} y_i} ) \subseteq C. \]</p>
<h3>Detour 2 — oversimplification</h3>
<p>Even this special case of the standard formulation somehow focuses on aspects that get me sidetracked. So I attempted to formulate it in a way that gives (me) better focus.</p>
<p>Now, the theorem says all kinds of complicated things about the existence of a sequence of disjoint finite subsets of \(\mathbb{N}\). Can I get around this? I thought I should be able to. Let’s start with a much weaker version of the theorem.</p>
<p><strong>A weak simple Central Sets Theorem</strong><br>
Imagine you are given a subsemigroup \(T \subseteq \mathbb{N}\) as well as a central set \(C \subseteq \mathbb{N}\).<br>
Then you can find a sequence \(\mathbf{a}\) in \(\mathbb{N}\) as well as a sequence \(\mathbf{b}\) in \(T\) so that</p>
<p>\[ FS ( {a_n} + {b_n} ) \subseteq C. \]</p>
<p>I find this weaker version much easier to understand. It just says that I can always translate infinitely many elements from a given subsemigroup into the central set; additionally the finite sums stay within the set.</p>
<p>This is much weaker than the statement before. Of course, given a sequence \(\mathbf{y}\) we could consider the generated subsemigroup and use the weaker version. But this would not guarantee the result of applying the Central Sets Theorem — Furstenberg’s theorem gives much more control over which elements are picked since there are no repititions in the sums of the generators.</p>
<h3>Partial Semigroups</h3>
<p>So where does this leave us? Well, when I hear finite subsets of \(\mathbb{N}\) I think of my favourite structure — in fact the favourite structure for a lot of algebra in the <a href="http://en.wikipedia.org/wiki/Stone%E2%80%93%C4%8Cech_compactification#Addition_on_the_Stone.E2.80.93.C4.8Cech_compactification_of_the_naturals">Stone–Čech compactification</a> on \(\mathbb{N}\), the semigroup \(\delta \mathbb{F}\). But let’s step back a little. The best way to think about \(\delta \mathbb{F}\) is in terms of partial semigroups.</p>
<p><strong>(Adequate) Partial Semigroups</strong><br>
A <em>partial semigroup</em> operation on a set \(S\) is a map \(\cdot: S \times S \rightarrow S\) such that associativity \(s \cdot (t \cdot u) = (s \cdot t) \cdot u\) holds in the sense that if one side is defined so is the other and they are equal. A partial semigroup is <em>adequate</em> if the sets</p>
<p>\[
 \sigma(s) := \left\\{ t\in S : {s \cdot t} \mbox{ is defined} \right\\}
 \]   generate a filter, i.e., finitely many elements have a common compatible element.</p>
<p>This notion was introduced by <a href="http://www.math.lsa.umich.edu/~ablass/bbh.pdf">Bergelson, Blass and Hindman</a> (<a href="http://doi.org/10.1112/plms/s3-68.3.449">DOI</a>) in the 90s. It tells us that the operation, although partial, is associative in a strong way. Additionally, it makes sure the operation is not just empty but defined for many elements (well, ok it could be just one for all, but that’s not the point).</p>
<p>For ultrafilters the critical point is the following.</p>
<p><strong>The semigroup \(\delta S\)</strong><br>
Given an adequate partial semigroup and \(p,q\) ultrafilters containing all \(\sigma(s)\). Then the operation</p>
<p>\[
 p \cdot q = \left\\{ A \subseteq S : \left\\{ s : \left\\{ t : s \cdot t \in A \right\\} \in q \right\\} \in p \right\\}
 \]</p>
<p>is well-defined and associative and semi-continuous. In other words, \(\delta S\) is a closed semi-continuous semigroup.</p>
<p>Now this is somewhat surprising. Even though our operation is partial, these ultrafilters are a full semigroup! With all the bells and whistles it takes to do algebra in the Stone–Čech compactification.</p>
<p>What does this have to do with the Central Sets Theorem?</p>
<p>Denote the non-empty, finite subsets of \(\mathbb{N}\) by \(\mathbb{F}\). Consider the restriction of \(\cup\) on \(\mathbb{F}\) defined by</p>
<p>\[
 s + t \mbox{ defined } \Longleftrightarrow \max(s) \cap \min(t) = \emptyset.
 \]</p>
<p>Then in fact this constitutes a partial semigroup, adequate at that.</p>
<p>This partial semigroup structure could be called the free partial semigroup in the following sense: given any sequence \(\mathbf{s}\) in any semigroup \(S\) we can consider the induced partial semigroup on the set of finite sums \({FS( \mathbf{s} ) }\): we only allow sums where the index sets are disjoint (so that we are closed under our partial operation). Then all \(FS\)-sets are naturally isomorphic (in the appropriate sense of partial semigroups).</p>
<h3>The weak version revisited</h3>
<p>To come back to the weak version of the Central sets theorem — partial semigroups are exactly what it talks about. So let us reformulate,</p>
<p><strong>simple Central Sets Theorem</strong><br>
Imagine we are given a partial subsemigroup \(T\) of \((S,+)\) as well as a central set \(C \subseteq \mathbb{N}\). Then we find sequences \(\mathbf{a}\) in \(\mathbb{N}\) and \(\mathbf{t} \in T\) such that \(FS ( {t_n} ) \subseteq T\) and</p>
<p>\[
  {FS( a_ {n} + t_{n}) \in C.}
 \]</p>
<p>Now this sounds much closer to the original theorem. Since any sequence generates a partial semigroup on its \(FS\)-set (isomorphic to \(\mathbb{F}\)), this is in fact the Central Sets Theorem for just one sequence.</p>
<h3>Leaving the simplification</h3>
<p>However, the actual theorem is more than just some kind of induction on the above version. It is considerably stronger and here it is time to let go of the simplifications of partial semigroups again. For the theorem really does talk about \(FS\)-sets, i.e., partial semigroups isomorphic to \(\mathbb{F}\). The strength lies in the fact that the infinite sequences can be chosen uniformly in the sense that we pick from the different partial semigroups in the same prescribed way.</p>
<p><strong>Central Sets Theorem</strong><br>
Imagine you are given finitely many \(FS\)-sets in a commutative semigroup \((S,+)\), say \({FS( {\mathbf{y^0}} )}, {\ldots}, {FS( {\mathbf{y^\alpha}} )}\) as well as a central set \(C \subseteq S\).<br>
Then you can find a sequence \(\mathbf{a}\) in \(S\) as well as one disjoint sequence \(\mathbf{h}\) in \(\mathbb{F}\) such that for all \(\beta \leq \alpha\)</p>
<p>\[ FS ( {a_n} + {\sum_{i \in h_n} y_i^\beta} ) \subseteq C. \]</p>
<p>To see this strength at work it is time to look at the classical application.</p>
<p><strong>Central sets in \(( \mathbb{N},+)\) contain arbitrarily long arithmetic progressions</strong><br>
Take \(\mathbf{y^\beta}\) to be the multiples of \(\beta\) (for \(\beta \leq \alpha\)). Then the central set theorem guarantees we find \(a_1, h_1\) such that for all \(\beta \leq \alpha\)</p>
<p>\[ (a_1 + \beta \cdot \sum_{i\in h_1} i) \in C.\]</p>
<p>For this application is obviously critical that the to-be-translated elements can be chosen uniformly. That’s all for now but I hope I can write a follow up some other time.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Welcome! (again)]]></title>
        <id>https://www.peterkrautzberger.org/0014/</id>
        <link href="https://www.peterkrautzberger.org/0014/">
        </link>
        <updated>2010-04-15T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Welcome to the new home of thelazyscience. I hope the new setup makes everything better.</p>
<p>For myself, writing and posting has been simplified considerably by the use of <a href="http://wiki.github.com/mojombo/jekyll/">Jekyll</a> with <a href="https://en.wikipedia.org/wiki/Textile_(markup_language)">Textile</a> as markup. The mathematics is simply <a href="http://en.wikipedia.org/wiki/LaTeX">\(\LaTeX\)</a> code which gets ignored by textile and converted by <a href="http://www.mathjax.org/">MathJax</a>. In fact, textile markup is so <a href="http://en.wikipedia.org/wiki/Human-readable_medium">human-readable</a> that I can see myself eventually writing exclusely in textile. Instead of explaining how this workflow works I invite you to read <a href="http://blog.felixbreuer.net/2010/03/19/writing-math.html">Felix Breuer’s explanation</a>.</p>
<p>Additionally, the only dynamic part left is now organized by <a href="http://disqus.com/">Disqus</a>. Their tool makes commenting easy and hopefully reduces spam even further.</p>
<p>So, I hope you’ll enjoy the new lazy science. If you do, let me know.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The end is near]]></title>
        <id>https://www.peterkrautzberger.org/0013/</id>
        <link href="https://www.peterkrautzberger.org/0013/">
        </link>
        <updated>2010-04-14T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Well, as promised, the end is near.</p>
<p>I have begun moving thelazyscience. The future location will be at [<a href="http://peter.krautzberger.info/">peter.krautzberger.info</a>](<a href="http://peter.krautzberger.info/">http://peter.krautzberger.info/</a>. It’ll probably take me a few more days to (manually…) move the old posts over to the new site. However, the next post is almost finished. I still have to see if I can find a mechanism to automagically put a short post up here for each new one there, but we’ll see.</p>
<p>It was good to have started the blog at blogspot but hopefully the new workflow (and more time) will lead to more frequent posts.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Research notes — Welcome to Ann Arbor]]></title>
        <id>https://www.peterkrautzberger.org/0012/</id>
        <link href="https://www.peterkrautzberger.org/0012/">
        </link>
        <updated>2010-03-18T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>After too many weeks of silence and almost two weeks in the States it is definitely time for an update.<br>
The first 10 days at the <a href="http://www.math.lsa.umich.edu/">University of Michigan</a> were taken up mostly by bureaucracy but some old and some new ideas have evolved out of my first two meetings with <a href="http://www.math.lsa.umich.edu/~ablass/">Andreas Blass</a>.</p>
<p>On the one hand he has renewed his interest in the forcing construction of a non-Ramsey ultrafilter that <a href="http://math.ucalgary.ca/profiles/claude-laflamme">Claude Laflamme</a> did under his supervision back in the 80s. In fact (spoiler alert) Andreas will talk about such things at the <a href="http://www.aslonline.org/Meetings.htm">ASL Meeting in Washington</a> this week.</p>
<p>On my related part I have resumed work on constructing an unstable union ultrafilter which Andreas and I once had hoped to relate to the Laflamme forcings but later turned out not to. Mostly I spent time recovering my old strategies and had lots of them shot down by Andreas. Nevertheless I see progress there and look forward to spending more time on the issue (and hopefully blog about it, too).</p>
<p>Blog related the great change is finally coming up. I will switch to <a href="http://www.blogofile.com/">blogofile</a>, a blog compiler for static blogging, after I find a good place to host the new blog. I plan to switch to <a href="http://www.mathjax.org/">MathJax</a> for better MathML support and use <a href="http://disqus.com/">Disqus</a> for comments. This will simplify my publishing process and I hope it will lead to more frequent posts. After all I have not done enough writing so that it comes naturally to me.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Other lazy people]]></title>
        <id>https://www.peterkrautzberger.org/0011/</id>
        <link href="https://www.peterkrautzberger.org/0011/">
        </link>
        <updated>2010-02-15T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I frequently wind up with a list of interesting blog posts — so why not include this here, too? As long as I cannot convince myself to use google reader or buzz, I’ll do this the classical way (especially since I just read a complaint that less and less blogers use backlinks).</p>
<p>An old but very nice post on Graeme Taylor’s Modulo Errors — with beautiful linkage. I just spent 10 minutes cheering the algorithm for vehicles to succeed…</p>
<p><a href="http://maths.straylight.co.uk/archives/125">http://maths.straylight.co.uk/archives/125</a></p>
<p>Gil Kallai continues his series of posts on the concept of probability  with a wonderful video by Itamar Pitowski</p>
<p><a href="http://gilkalai.wordpress.com/2010/02/15/itamar-pitowski-probability-in-physics-where-does-it-come-from/">http://gilkalai.wordpress.com/2010/02/15/itamar-pitowski-probability-in-physics-where-does-it-come-from/</a></p>
<p>For the German speaking people — via <a href="http://www.scienceblogs.de/frischer-wind/2010/02/schones-video-faszination-der-mathematik.php">Christian Reinboth</a> a nice (I’m guessing Austrian science department) video promoting mathematics.</p>
<iframe width="100%" height="510" src="https://www.youtube.com/embed/NdL5vN65U_8" frameborder="0" allowfullscreen=""></iframe>
<p>Enjoy.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tools for your online collaboration]]></title>
        <id>https://www.peterkrautzberger.org/0010/</id>
        <link href="https://www.peterkrautzberger.org/0010/">
        </link>
        <updated>2010-02-14T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>So the <a href="http://www.winterschool.eu/">winter school in Hejnice</a> <del>ended two weeks ago</del> is long past — and despite my intentions I did not find the time to blog. This is primarily a sign of the quality of the winter school, both scientifically and socially. I do admit I spent the lunch breaks walking in the beautiful surrounding mountains instead of blogging…</p>
<p>Anyway, on the last evening of the winter school a couple of people gathered together to exchange tools for collaborating via the <a href="http://en.wiktionary.org/wiki/Intertubes">intertubes</a>. I volunteered — also with the upcoming third <a href="http://www.math.uni-bonn.de/ag/logik/events/young-set-theory-2010/">Young Set Theorists</a> meeting in mind — to make the discussion available online. Of course, the title refers to <a href="http://info.tuwien.ac.at/goldstern/papers/tools.ps">this</a> wonderful paper by Goldstern and Judah which taught me the little bit of iterated forcing that I know.</p>
<p>For now I will restrict myself to <a href="http://en.wikipedia.org/wiki/Freemium">freemium</a> services. Of course, this is an open list — drop me a comment to add to this list (hm, a google wave would be better, right?).</p>
<p><strong>Phones</strong></p>
<p>A much better tool than a phone is? A videophone! (especially for handwaving arguments). Namely, <a href="http://skype.com/">skype</a> comes to mind, but there are alternatives like <a href="http://en.wikipedia.org/wiki/Tokbox">tokbox</a> or <a href="http://en.wikipedia.org/wiki/Google_Talk">google talk</a> which are web based. With possibly lower video quality they offer other useful things like actual video conferences (whereas skype restricts you afaik to 1-1 video calls) and invitation by link. There are also numerous true VoIP/SIP clients like <a href="http://en.wikipedia.org/wiki/Ekiga">Ekiga</a>. But they may have the need for some firewall configuring. For more general information, check out <a href="http://en.wikipedia.org/wiki/List_of_video_telecommunication_services_and_product_brands">wikipedia</a>.</p>
<p><strong>Whiteboards</strong></p>
<p>But what good is a (video)phone if you cannot write on a blackboard together? In any serious mathematical discussion, notation will become an issue sooner or later. A simple, but bandwidth friendly and flash based whiteboard is <a href="http://en.wikipedia.org/wiki/Paint_chat#Scriblink">scriblink</a> — just go to the site and give your partner the invitation link. An alternative is <a href="https://web.archive.org/web/20100208022739/http://www.dabbleboard.com/">dabbleboard</a> which offers some shape recognition and also allows multiple pages in the free version and — most importantly — PDFs as background images. However, it is a little heavy on the bandwidth, especially latency which often annoys my voip connection.</p>
<p>Of course, if you want to use an online whiteboard efficiently you need some kind of <a href="http://en.wikipedia.org/wiki/Tablet_%28disambiguation%29">tablet</a> to write with. I personally have been very happy with a <a href="http://en.wikipedia.org/wiki/Graphics_tablet">graphics tablet</a>, a Wacom Bamboo to be exact. You can get tablets for 40€ and lower in Germany, but prices will differ regionally. Of course, I also use my Gigabyte M1028T <a href="http://en.wikipedia.org/wiki/Tablet_PC">tablet pc</a> — although its tablet functionality is basic (no pressure sensitivity, only moving by clicking) making writing with it less suitable for real note taking — see the PDF section below.</p>
<p><del><a href="http://de.wikipedia.org/wiki/Eierlegende_Wollmilchsau">Eierlegende Wollmilchsau</a></del> <a href="http://en.wikipedia.org/wiki/Swiss_Army_Knife"><strong>Swiss Army Knives</strong></a></p>
<p>There are of course those services which offer all of the above at once. A prime example would be <a href="http://en.wikipedia.org/wiki/Dimdim">dimdim</a> which offers a nice, unified service including video conferencing, instant messaging, whiteboard, pdf viewing and collaborative websurfing — all of this available with a free account which is limited only in the number of participants (and there are premium services available, of course).  Additionally dimdim’s server technology is mostly open source, so you can set up your own server if you have the means. Unfortunately, I never got the video conference system to work correctly under linux. Although not quite with collaboration in mind there is also the awesome <a href="http://en.wikipedia.org/wiki/Teamviewer">TeamViewer</a>. It is a great remote assistance tool designed for efficient access to another computer screen. In that sense you could use it to access your home or office machine from anywhere — if your department allows that. But in the latest version (although windows only) Teamviewer also offers Video chat and a whiteboard to communicate. For further tools look <a href="http://en.wikipedia.org/wiki/Comparison_of_web_conferencing_software">here</a>.</p>
<p><strong>Instant Chat, Online Docs and Google Wave</strong></p>
<p>Personally, I have not used instant messaging for mathematics so far — video phones seem better. However, <a href="http://en.wikipedia.org/wiki/Pidgin_%28software%29">Pidgin</a> has a <a href="http://en.wikipedia.org/wiki/LaTeX">LaTeX</a> <a href="http://sourceforge.net/projects/pidgin-latex/">plugin</a> to display basic TeX code. This is of course a useful feature. I’ll come back to the general problem of displaying mathematics on the web later.</p>
<p>I feel I must also mention <a href="http://en.wikipedia.org/wiki/Google_wave">Google Wave</a> and <a href="http://en.wikipedia.org/wiki/List_of_collaborative_software">its competitors</a>. These are powerful tool mixing mail, chat, wikis and collaborative document editing. I have not tried any of these yet but if there’s someone to collaborate with it’s worth a try.</p>
<p><strong>PDFs I — what you can do with them</strong></p>
<p>PDFs is the somewhat dominant standard for (compiled) TeX documents (sorry, dvi and ps fans). Besides the next section there is another aspect which makes them worthwhile — <a href="http://en.wikipedia.org/wiki/PDF_annotation#Annotating_PDFs">PDF annotation</a>. If you are like me and like to take your notes with you (for all those typos and indices that drive you mad in some papers) there is nothing better than annotating a PDF directly — especially if you invested in a (graphics) tablet.</p>
<p>My favourite is the open source <a href="http://en.wikipedia.org/wiki/Xournal">Xournal</a> with excellent tablet support on both linux and windows. Alternatives are <a href="http://en.wikipedia.org/wiki/Jarnal">Jarnal</a> (which also works as real time whiteboard) and (for Mac users) <a href="http://en.wikipedia.org/wiki/Skim_%28software%29">Skim</a>.</p>
<p>Although it does not quite fit in here (or anywhere): if you feel that PDFs are inadequate to present mathematics, why don’t you take a look at <a href="http://en.wikipedia.org/wiki/Prezi">prezi</a>? It offers a different angle on presentations altogether. I sometimes dream of having a prezi like ability to zoom into papers or rather proofs giving me details where I want them and letting me quickly browse through the main ideas dynamically whenever I choose to…</p>
<p><strong>PDFs II — Personal online libraries</strong></p>
<p>It is convenient to store papers and other materials online. If you cannot set up a decent <a href="http://en.wikipedia.org/wiki/File_Transfer_Protocol#FTP_over_SSH_.28not_SFTP.29">sftp</a> or <a href="http://en.wikipedia.org/wiki/Comparison_of_open_source_software_hosting_facilities">a version control system</a> on your university’s server, you might want to try <a href="http://en.wikipedia.org/wiki/Dropbox_%28storage_provider%29">dropbox</a> <a href="http://en.wikipedia.org/wiki/File_synchronization">or</a> <a href="http://de.wikipedia.org/wiki/TeamDrive">teamdrive</a>. If you frequently use public computers you might want to use something more web based like <a href="http://en.wikipedia.org/wiki/Google_Documents">google documents</a> or the very pretty <a href="http://en.wikipedia.org/wiki/Issuu">isssu</a> that I use from time to time on this blog.</p>
<p><strong>Community Sites</strong></p>
<p>Of course, all science is community driven but I think (pure) mathematics could profit more from an online community than any other science or (liberal) art. The biggest player is certainly <a href="http://en.wikipedia.org/wiki/Facebook">facebook</a> — which already has a group for, of course, the <a href="http://www.facebook.com/group.php?gid=150548369161">winterschool</a> itself. Facebook <a href="http://www.danah.org/papers/essays/ClassDivisions.html">attracts academia</a> (as opposed to myspace), hence it is the more obvious place to connect — this does not mean that you shouldn’t worry about its privacy settings or rather the partial lack thereof.</p>
<p>On the other hand, there are a couple of science focused <a href="http://en.wikipedia.org/wiki/List_of_social_networking_websites">community sites</a>, among them <a href="http://en.wikipedia.org/wiki/Researchgate">researchgate</a> which offer science specific tools like (p)reprint lists, online references, database searches etc. This might be better for purely professional intent but I have no experience using it.</p>
<p>A young and incredibly successful new site is <a href="http://mathoverflow.net/">mathoverflow</a> — a mathematical version of the great <a href="http://en.wikipedia.org/wiki/Stackoverflow">stackoverflow</a>. You can ask and answer questions of all sorts in a very efficient manner — just don’t get lost in all the fun.</p>
<p><strong>Databases</strong></p>
<p>Of course the mother of all things is the <a href="http://arxiv.org/">arXiv</a> — do I need to explain it? And then there are Google’s products <a href="http://en.wikipedia.org/wiki/Google_scholar">scholar</a> and <a href="http://en.wikipedia.org/wiki/Google_book_search">book search</a>. A somewhat different database is <a href="http://gigapedia.com/">gigapedia</a> where you can easily search for books and find free ones. In all things beware of legal issues though.</p>
<p><strong>LaTeX or displaying mathematics on the web</strong></p>
<p>Of course mathematicians are used to LaTeX. On the web the best way for displaying mathematics is (from a web standards point of view) <a href="http://en.wikipedia.org/wiki/Mathml">mathml</a>. The problem is that mathml is <strong>a)</strong> too difficult to write as code directly, <strong>b)</strong> difficult to view since not all browsers view them correctly and from a visually impaired point of view it seems to be a disaster, too (see the <a href="http://terrytao.wordpress.com/2009/10/29/displaying-mathematics-on-the-web/">discussion</a> on Terry Tao’s blog) and <strong>c)</strong> it is difficult to convert back to LaTeX.</p>
<p>There are numerous workarounds. On the one hand you can (as I do) use <a href="http://en.wikipedia.org/wiki/TeX4ht">tex4ht</a> to convert LaTeX to mathml. Of course, as my blog shows this is a rather tedious thing if you do not have (or want to have) control over the webserver. Alternatives are <a href="http://www.math.union.edu/~dpvc/jsMath/">jsMath</a> which might be superseded by <a href="http://en.wikipedia.org/wiki/Mathjax">mathjax</a>. If you have a <a href="http://en.wikipedia.org/wiki/Wordpress">wordpress</a> blog you can (even on your free account on <a href="http://en.wikipedia.org/wiki/Wordpress.com">wordpress.com</a>) use <a href="http://wordpress.org/extend/plugins/wp-latex/">this plugin</a> — which converts basic LaTeX commands into (rather ugly) PNGs.</p>
<p>The winner for best practices with mathml, I think, is the <a href="http://golem.ph.utexas.edu/category/">n-Category Cafe</a>. Besides being a very active group blog they have developed impressive technologies such as mathml inclusion, the LaTeX dialect itex, the itex capable <a href="http://golem.ph.utexas.edu/wiki/instiki/show/HomePage">instiki</a> with <a href="http://golem.ph.utexas.edu/~distler/blog/itex2MMLcommands.html">itex2mml</a> to convert tex to mathml on the fly and all of this available in the comments, too.</p>
<p><strong>Blogs, blogs, blogs</strong></p>
<p>Almost last but in no way least, there are blogs.  This would be worth an independent post and there are plenty of examples for this, but here we go.</p>
<p>They come in all colours, for an impressive list go <a href="http://web.archive.org/web/20100120025343/http://wiki.henryfarrell.net/wiki/index.php/Mathematics/Statistics">here [Wayback Machine]</a>. Also, go to any of those blogs and check their blogroll to find many more mathematics blogs. If you don’t understand what blogs are good for you might read <a href="http://golem.ph.utexas.edu/category/2009/09/what_do_mathematicians_need_to_1.html">John Baez’s article</a>. To name a few contenders for ‘most influential mathematical blogs’: <a href="http://terrytao.wordpress.com/">What’s new with Terence Tao</a>, the most active single user blog I know, <a href="http://gowers.wordpress.com/">Timothy Gowers’s Weblog</a> and Gil Kallai’s <a href="http://gilkalai.wordpress.com/">Combinatorics and more</a>.</p>
<p>Of course, they are the ones that got me started with reading math blogs, but it’s the small blogs that got me hooked. The diversity is a challenge (I don’t understand half of what I read) but blogs form the best mathematics newspaper out there.</p>
<p><strong>Polymath</strong></p>
<p>At the moment the most hardcore project when it comes to online collaboration is clearly <a href="http://en.wikipedia.org/wiki/Polymath_project#Polymath_project">Polymath</a>. With <a href="http://arxiv.org/abs/1002.0374">one paper</a> on the arxiv, two projects finished and three projects going it is the perfect show case. Driven by the “big three” — Tao, Gowers, Kallai — one may argue that their power makes sure that it works (and is protected from theft). Polymath is an exemplary web project. It follows <a href="http://www.buzzmachine.com/2007/02/22/new-rule-cover-what-you-do-best-link-to-the-rest/">Jeff Jarvis’s rule</a> and shows the synergetic behaviour of web projects — using multiple technologies at once: there’s the <a href="http://polymathprojects.org/">blog</a> for the main discussion, but also the authors individual blogs used partly to organize. Finally there’s the <a href="http://michaelnielsen.org/polymath1/index.php?title=Main_Page">wiki</a> for fixing proper definitions and notational issues and finally they frequenly use mathoverflow to recruit new people by e.g. singling out distinct partial or dervitative questions.</p>
<p>But I believe it shows a glimpse of the future of mathematics. On the one hand, many problems have become too complex to be tackled by a single person or research group. On the other hand, although the techology might change considerably in the future, the idea of having researchers on all levels collaborate — with every contribution being valued — could be a prototype that values many soft skills, be it good writing, accessible presentation, social skills for bringing conversations to converge productively, taking a bird’s view of the process to assist or acquiring empirical experimentation and implementation. It is also a very flexible approach where people can help as much or as little as they find the time for while (with proper support like Gower’s current EDP posts) still being able to follow the flow and ideally being able to change their level of involvement as they please.\</p>
<p>That’s all for now. Let me know what I forgot.</p>
<p><em><strong>Addenda</strong></em></p>
<p><strong>2010-02-15</strong></p>
<p><strong>Unicode characters</strong></p>
<p>There was also a question regarding unicode characters and the like (instead of mathml). I just found <a href="http://web.archive.org/web/20080703175126/http://tlt.psu.edu/suggestions/international/bylanguage/mathchart.html">this chart [Wayback Machine]</a> via <a href="http://mathoverflow.net/faq#latex">mathoverflow</a> — maybe it helps.</p>
<p><strong>2010-02-17</strong></p>
<p><strong>Feeds and feed readers</strong></p>
<p>Feeds in either <a href="http://en.wikipedia.org/wiki/RSS">Real simple syndication (RSS)</a> or <a href="http://en.wikipedia.org/wiki/Atom_%28standard%29">Atom</a> from are worth mentioning on its own. As a tool for 1-to-infinity communication it’s an important technology for collaboration. You’ll find feeds for all kinds of newssites and blogs, but also <a href="http://arxiv.org/help/rss">for each section of the arxiv</a>. To read feeds you can use <a href="http://en.wikipedia.org/wiki/Comparison_of_feed_aggregators">lots of different programs</a> and <a href="http://en.wikipedia.org/wiki/Aggregator">web based services</a>.</p>
<p><strong>Video sites</strong></p>
<p>Videos of research level mathematics are pretty rare. There is the <a href="http://www.msri.org/communications/vmath/index_html">archive of the MSRI</a> and singular popular mathematics gems like <a href="http://www.gresham.ac.uk/event.asp?PageId=45&amp;EventId=607">Gowers’s talk on multiplication</a>. Also, you should check out <a href="http://www.youtube.com/user/MIT">MIT’s impressive youtube channel</a>.</p>
<p>To put up a video you don’t need much these days, so it’s strange that there’s not more around — especially since (pure) mathematics seems easier to share than, say, complicated science experiments. There are <a href="http://en.wikipedia.org/wiki/Video_sharing_website">too many free video sites</a> out there. Next to the already mentioned youtube I would point out the science video site <a href="http://en.wikipedia.org/wiki/SciVee">SciVee</a> (with its strong, yet somewhat expensive premium service) and <a href="http://en.wikipedia.org/wiki/Vimeo">Vimeo</a> with its focus on original content.</p>
<p><strong>Reference management</strong></p>
<p>Thanks to David for reminding me that I forgot one aspect of pdf management — <a href="http://en.wikipedia.org/wiki/Comparison_of_reference_management_software">reference management (see the list on wikipedia)</a>. Now there are many programs out there to get your citations, i.e., your BibTeX files organized. But there are also programs that connect the citations with the pdf, offer online database searches, tags, pdf annotation and social networking ideas.</p>
<p>A big list can (once again) be <a href="http://en.wikipedia.org/wiki/Comparison_of_reference_management_software">found on wikipedia</a>. To present a few. I personally use <a href="http://en.wikipedia.org/wiki/Referencer">referencer</a> but David also mentioned <a href="http://en.wikipedia.org/wiki/Mendeley">Mendeley</a> in his comment which has an impressive list of features including online access and social network aspects and I’ll probably try it out. To give credit where it is due a few of these programs name <a href="http://www.papersapp.com/">Papers</a> as inspiration which unfortunately is Mac only. With a different flavour there are the web-only <a href="http://en.wikipedia.org/wiki/Zotero">Zotero</a>, a powerful Firefox addon, and <a href="https://en.wikipedia.org/wiki/Ilibrarian">I, Librarian</a>, a groupware tool.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is…? Seminar new videos]]></title>
        <id>https://www.peterkrautzberger.org/0009/</id>
        <link href="https://www.peterkrautzberger.org/0009/">
        </link>
        <updated>2010-01-28T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>One of the most valuable experiences during my time as a PhD student lay in helping to establish a <a href="http://www.math.fu-berlin.de/w/Math/WhatIsSeminar">‘What is…?’ seminar</a> at the <a href="http://www.math.fu-berlin.de/index.html">Freie Universität Berlin</a> and later/now at the <a href="http://www.math-berlin.de/">Berlin Mathematical School</a> .</p>
<p>I originally came into contact with the concept while visiting the <a href="http://www.math.lsa.umich.edu/%7Elji/what-is.html">University of Michigan</a> in the winter 2007/2008. However, back in Berlin I wanted to use the theme for a different purpose. In conversations with a <a href="http://boolesrings.org/vonheymann/">couple</a> <a href="http://www.sfu.ca/~nilten/index.html">of</a> <a href="http://www.felixbreuer.net/">friends</a> we developed the idea to create a seminar by PhD students for PhD students.</p>
<p>This idea became central since the regular colloquium never attracted PhD students nor did the PhD students ever gather together (which thankfully now changes with the BMS). In particular, we were looking for something with a more open atmosphere.</p>
<p>Looking at Harvard University’s experience with (from what I have been told) first having a <a href="http://www.math.harvard.edu/fc/index.html">‘Basic Notions’ seminar</a> the non-trivial nature of which lead the students to compensate with a <a href="http://www.math.harvard.edu/trivial/">‘Trivial Notions’ seminar</a> , we decided to exclude professors at first. This in fact got us some really negative responses when we sent out emails looking for all the PhD students hidden in workgroups outside our own fields (one professor in particular simply could not fathom that the presence of your “boss” might hinder a free discussion). It was rather shocking that even professors actively popularizing mathematics simply reacted with “these things only last as long as a single person is behind them” (and this was before we even started — talk about support…).</p>
<p>Nevertheless, the seminar got on its way. The first semester was tough, with lots of, shall we say, “experiments”, trying to find our way (and above all speakers from other fields). In the second semester a <a href="http://didaktik1.mathematik.hu-berlin.de/index.php?article_id=181">PhD student</a> from the BMS joined us with the idea of making the seminar as part of the biweekly <a href="http://www.math-berlin.de/academics/bms-fridays/">BMS Friday</a> . This semester has seen yet another expansion with some talks taking place at the BMS lounge at the <a href="https://www.forschung.tu-berlin.de/netz_der_promotionsprogramme/menue/programme/berlin_mathematical_school/">Technische Universität Berlin</a>.</p>
<p>Since I’m now leaving Berlin it has been a pleasure to see the next generation take over. However — and this was the whole point of the post before this melancholic rambling took over — I still am involved in making video recordings of the talks available whenever possible. I want to stress how much I am indebted to the speaker for allowing the publication of their talks. This is especially important since the videos are sometimes not very good (see my own soon to be put up and very bad talk about topological dynamics). The point is that the seminar is a platform to experiment and test oneself which is something that students of mathematics do not get to do a lot. Therefore I think we can be very happy that so many speakers are ready to put themselves out there and learn from the experience.</p>
<p>Anyway, yesterday I published two more videos, <a href="http://carsten.codimi.de/">Carsten Schultz’s</a> &quot;What is Morse theory?&quot; [permantently dead link: <a href="http://www.scivee.tv/node/15455">http://www.scivee.tv/node/15455</a>] and <a href="http://web.archive.org/web/20150311034722/http://maths.uq.edu.au/cmp/webpage_inna/inna.html">Inna Lukyanenko’s [Wayback Machine]</a> <a href="http://vimeo.com/8796425">‘What is a quantum group?’</a> . The good user experience of vimeo might lead to all of the videos eventually appearing there, but so far Inna’s video is the first on vimeo and the rest is on SciVee (but another one might end up on vimeo next week, we’ll see…).</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Good news, bad news]]></title>
        <id>https://www.peterkrautzberger.org/0008/</id>
        <link href="https://www.peterkrautzberger.org/0008/">
        </link>
        <updated>2010-01-21T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Just so that not another week ends without me writing a post. The bad news is that my departure for <a href="http://www.math.lsa.umich.edu/">Michigan</a> gets closer and the technicalities take up more and more time. Therefore I’m not sure I’ll have much time to post in the next couple of weeks. Additionally, I’ll be attending a <a href="http://www.winterschool.eu/">winter school</a> in Hejnice in the first week of February so I also need to <del>prepare</del> finish preparing my talk.</p>
<p>So what’s the good news? Well, I have been busy on the blog but nothing has come of it yet. On the one hand I have been studying the <a href="https://en.wikipedia.org/wiki/Google_App_Engine">Google App Engine</a> so as to move the blog there — which should make the work flow much more efficient (and the code better). On the other hand that there are three blog posts I have not finished — so there’s a chance the dry spell will be over sooner than I think. Finally, I hope to write posts during the winter school reflecting on the (possibly daily) experience.</p>
<p>Well, let me at least throw in some nice links worth a read. Gil Kallai turned a mathoverflow question into <a href="http://gilkalai.wordpress.com/2010/01/20/randomness-in-nature-ii/">the kind of blog posts I really like</a> . Over at the n-Category Cafe David Corfield <del>explains</del> <a href="http://golem.ph.utexas.edu/category/2010/01/the_sacred_and_the_profane.html">muses</a> over the “sacred” and the “profane” in mathematics (or rather for mathematicians) which made me ponder what my own “bottom line” is.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Matrices vs. idempotent ultrafilters part 2.5]]></title>
        <id>https://www.peterkrautzberger.org/0007/</id>
        <link href="https://www.peterkrautzberger.org/0007/">
        </link>
        <updated>2010-01-11T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Note: there seems to be some problematic interaction between the javascripts I use and blogspot’s javascripts which prevents longer posts from being displayed correctly. As long as I don’t understand how to fix this, I will simply split the posts.</p>
<p>We can also describe size and the algebraic structure.</p>
<ol>
<li>\(A\) with \(F_1\) (\(F_2\)) generates a <a href="http://en.wikipedia.org/wiki/Null_semigroup">right (left) zero semigroup</a> (hence of size \(2\), except for \(x=0\)).</li>
<li>\(A\) with \(F_3\) or \(F_4\) generates a semigroup with \(AB\) <a href="http://en.wikipedia.org/wiki/Nilpotent_matrix">nilpotent</a> (of size \(4\), except for \(x=0\), where we have the null semigroup of size \(3\)).</li>
<li>\(A\) with \(G_i\) generate (isomorphic) semigroups of size \(8\). These contain two disjoint right ideals, two disjoint left ideals generated by \(A\) and \(B\) respectively.</li>
</ol>
<p>Luckily enough, we get something very similar from our alternative for \(A\).</p>
<p><strong>Proposition</strong> In case \(A = \begin{pmatrix} 1 &amp; 1 \\\ 0 &amp; 0 \end{pmatrix}\) the solutions for \(B\) being of rank one consist of five one – dimensional families namely (for \(x\in \mathbb{Q}\))<br>
\[
 H_1(x) = \begin{pmatrix} 1 &amp; x \\ 0 &amp; 0 \end{pmatrix},  \\
 H_2(x) = \begin{pmatrix} x+1 &amp; x \\ ( – x – 1) &amp; – x \end{pmatrix},  \\
 H_3(x) = \begin{pmatrix} 0 &amp; x \\ 0 &amp; 1 \end{pmatrix},  \\
 H_4(x) = \begin{pmatrix} ( – x+1) &amp; ( – x+1) \\ x &amp; x \end{pmatrix},  \\
 H_5(x) = \begin{pmatrix} ( – x+1) &amp; ( – x – 1 – \frac{2}{x – 2}) \\ x – 2 &amp; x \end{pmatrix} , x \neq 2.
 \]</p>
<p>As before we can describe size and structure.</p>
<ol>
<li>\(A\) with \(H_1\) (\(H_2\)) generates a right (left) zero semigroup (as before).</li>
<li>\(A\) with \(H_3\) or \(H_4\) generates a semigroup with \(AB\) nilpotent (as before).</li>
<li>\(A\) with \(H_5\) generates the same \(8\) element semigroup (as before).</li>
</ol>
<p>Finally, it might be worthwhile to mention that the seemingly missing copies of the \(8\) element semigroup are also dealt with; e.g. $ – G_i$ generates the same semigroup as \(G_i\) etc.</p>
<p>It is striking to see that the orders of all finite semigroups generated by rational idempotent two by two matrices are either \(2^k,2^k + 1\) or \(2^k + 2\).</p>
<p>At first sight it seems strange that we cannot find other semigroups with two generators like this. As another friend commented, there’s just not enough space in the plane. I would love to get some geometric idea of what’s happening since my intuition is very poor. But that’s all for today. <a href="https://www.peterkrautzberger.org/assets/2010/matrices2.pdf">pdf</a></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Matrices vs. idempotent ultrafilters part 2]]></title>
        <id>https://www.peterkrautzberger.org/0006/</id>
        <link href="https://www.peterkrautzberger.org/0006/">
        </link>
        <updated>2010-01-07T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>In <a href="https://www.peterkrautzberger.org/0004/">an earlier post</a> I gave a short introduction to an interesting finite semigroup. This semigroup could be found in the \(2\times 2\) matrices over \(\mathbb{Q}\).</p>
<p>When I met with said friend, one natural question came up: what other semigroups can we find this way?</p>
<p>The first few simple observations we made were</p>
<ul>
<li>If either \(A\) or \(B\) is the identity matrix \(I_2\) or the zero matrix \(0_2\) the resulting semigroup will contain two elements with an identity or a zero element respectively.</li>
<li>In general, we can always add \(I_2\) or \(0_2\) to the semigroup generated by \(A\) and \(B\) and obtain a possibly larger one.</li>
<li>\(A,B\) generate a finite semigroup iff \(AB\) is of finite order (in the sense that the set of its powers is finite).</li>
<li>\(AB\) has finite order iff its (nonvanishing) eigenvalue is \(\pm 1\).</li>
<li>For \(A\) of rank \(1\) we may assume (by base change) that \(A\) is one of the two matrices \[\begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 0\end{pmatrix}, \begin{pmatrix} 1 &amp; 1 \\ 0 &amp; 0 \end{pmatrix}\,.\]</li>
</ul>
<p>So, as a first approach we thought about the following question.</p>
<p><strong>Question</strong> If we take \(A\) to be one of the above, what kind of options do we have for \(B\), i.e., if \(B\) is idempotent and \(A,B\) to generate a finite semigroup?</p>
<p>Thinking about the problem a little and experimenting with <a href="http://en.wikipedia.org/wiki/Macaulay2">Macaulay 2</a> we ended up with the following classification</p>
<p><strong>Proposition</strong> For \[A = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 0\end{pmatrix}\] the solutions for \(B\) being of rank one consist of four one – dimensional families, namely (for \(x\in \mathbb{Q}\))<br>
\[
 F_1(x) = \begin{pmatrix} 1 &amp; x \\ 0 &amp; 0 \end{pmatrix},
 F_2(x) = \begin{pmatrix} 1 &amp; 0 \\ x &amp; 0 \end{pmatrix},
 F_3(x) = \begin{pmatrix} 0 &amp; x \\ 0 &amp; 1 \end{pmatrix},
 F_4(x) = \begin{pmatrix} 0 &amp; 0 \\ x &amp; 1 \end{pmatrix}.
 \]<br>
Additionally, we have four special solutions<br>
\[
 G_1 = \begin{pmatrix} – 1 &amp; 1 \\ – 2 &amp; 2 \end{pmatrix},
 G_2 = \begin{pmatrix} – 1 &amp; – 1 \\ 2 &amp; 2 \end{pmatrix},
 G_3 = \begin{pmatrix} – 1 &amp; 2 \\ – 1 &amp; 2 \end{pmatrix},
 G_4 = \begin{pmatrix} – 1 &amp; – 2 \\ 1 &amp; 2 \end{pmatrix}.
 \]</p>
<p>Note: due to technical problems, this post continues <a href="http://thelazyscience.blogspot.com/2010/01/testing.html">here</a> .</p>
<p>We can also describe size and the algebraic structure.</p>
<ol>
<li>\(A\) with \(F_1\) (\(F_2\)) generates a <a href="http://en.wikipedia.org/wiki/Null_semigroup">right (left) zero semigroup</a> (hence of size \(2\), except for \(x=0\)).</li>
<li>\(A\) with \(F_3\) or \(F_4\) generates a semigroup with \(AB\) <a href="http://en.wikipedia.org/wiki/Nilpotent_matrix">nilpotent</a> (of size \(4\), except for \(x=0\), where we have the null semigroup of size \(3\)).</li>
<li>\(A\) with \(G_i\) generate (isomorphic) semigroups of size \(8\). These contain two disjoint right ideals, two disjoint left ideals generated by \(A\) and \(B\) respectively.</li>
</ol>
<p>Luckily enough, we get something very similar from our alternative for \(A\).</p>
<p><strong>Proposition</strong> In case\[
A = \begin{pmatrix} 1 &amp; 1
 \\ 0 &amp; 0
 \end{pmatrix}\] the solutions for \(B\) being of rank one consist of five one – dimensional families namely (for \(x\in \mathbb{Q}\))<br>
\[
 H_1(x) = \begin{pmatrix} 1 &amp; x \\ 0 &amp; 0 \end{pmatrix},
 H_2(x) = \begin{pmatrix} x+1 &amp; x \\ ( – x – 1) &amp; – x \end{pmatrix},
 H_3(x) = \begin{pmatrix} 0 &amp; x \\ 0 &amp; 1 \end{pmatrix},
 H_4(x) = \begin{pmatrix} ( – x+1) &amp; ( – x+1) \\ x &amp; x \end{pmatrix},
 \]<br>
\[
 H_5(x) = \begin{pmatrix} ( – x+1) &amp; ( – x – 1 – \frac{2}{x – 2}) \\ x – 2 &amp; x \end{pmatrix} , x \neq 2.
 \]</p>
<p>As before we can describe size and structure.</p>
<ol>
<li>\(A\) with \(H_1\) (\(H_2\)) generates a right (left) zero semigroup (as before).</li>
<li>\(A\) with \(H_3\) or \(H_4\) generates a semigroup with \(AB\) nilpotent (as before).</li>
<li>\(A\) with \(H_5\) generates the same \(8\) element semigroup (as before).</li>
</ol>
<p>Finally, it might be worthwhile to mention that the seemingly missing copies of the \(8\) element semigroup are also dealt with; e.g. $ – G_i$ generates the same semigroup as \(G_i\) etc.</p>
<p>It is striking to see that the orders of all finite semigroups generated by rational idempotent two by two matrices are either \(2^k,2^k + 1\) or \(2^k + 2\).</p>
<p>At first sight it seems strange that we cannot find other semigroups with two generators like this. As another friend commented, there’s just not enough space in the plane. I would love to get some geometric idea of what’s happening since my intuition is very poor. But that’s all for today. <a href="https://www.peterkrautzberger.org/assets/2010/matrices2.pdf">pdf</a></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Working on the workflow]]></title>
        <id>https://www.peterkrautzberger.org/0005/</id>
        <link href="https://www.peterkrautzberger.org/0005/">
        </link>
        <updated>2009-12-22T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Since I do want to try to post something once a week, I’ll recap my work towards a reasonable workflow. As I hinted at <a href="https://www.peterkrautzberger.org/0002/">before</a>, I’m currently aiming at a workflow of <a href="http://en.wikipedia.org/wiki/LaTeX">LaTeX</a> via <a href="http://en.wikipedia.org/wiki/TeX4ht">tex4ht</a> to <a href="http://en.wikipedia.org/wiki/Mathematical_Markup_Language">mathml</a> to blogspot. I have encountered a couple of problems, some of which I could overcome, some of which I could not and some of them turned out to be bugs or missing features.</p>
<p>The main problem is that my LaTeX style is too complicated for tex4ht. Now obviously this is somewhat my fault and I should (and will) simplify and update my current style of typesetting. But I intend to experiment here and it would be much easier (and possible in a more consistent fashion) if I could “just” convert my LaTeX experiments to blog experiments. In any case, it bugs me whenever I cannot find the reason why some things fail but not others, so let me recount what I could figure out.</p>
<p>One problem that I could find an explanation for is the <a href="http://en.wikipedia.org/wiki/Svg"><span class="caps">SVG</span></a> generation of <a href="http://en.wikipedia.org/wiki/PGF/TikZ">TikZ</a> code via tex4ht. In particular this combination cannot handle more complex text (mathematics or not) inside an svg, e.g., minipages within tikZ pictures are simply ignored entirely. Admittedly, this is documented in a short paragraph in the TikZ manual but it took me a while to find that…</p>
<p>Speaking of manuals. I finally stumbled upon this <a href="http://tug.org/applications/tex4ht/mml.html#mml-prob">part of the tex4ht manual</a> where some of the common problems and restrictions of tex4ht are described. This helped a lot with a couple of small errors like the missing \bigcap in the <a href="https://www.peterkrautzberger.org/0004/">Matrices vs Idempotents</a> post. Most importantly, I now know where to look these things up, so maybe there’s hope for me after all.</p>
<p>To make up for this and as a generally easy part of the workflow I added the first <span class="caps">PDF</span> via the very nice <a href="http://issuu.com/">issuu</a> . This is really no extra effort since issuu offers the code for embedding in blogspot — and I really like the viewer (as opposed to scribd).</p>
<p>For the future I like the idea to include audio and video as well, especially after the accessibility discussion on What’s new. It seems simple enough these days to upload some flash based or html5 based audio and video based on a post and I hope to find time to experiment with such media. Up until now I used SciVee a bit for a seminar. But since they went commercial a while ago I have to see if scivee’s plans are reasonable given the competition — they seem to focus more on large entities like universities and buying bulk accounts (open access like).</p>
<p>All in all, it’s going alright, even though the flow is far from what I want it to be. Let’s see what the holidays will lead to.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Matrices vs. idempotent ultrafilters]]></title>
        <id>https://www.peterkrautzberger.org/0004/</id>
        <link href="https://www.peterkrautzberger.org/0004/">
        </link>
        <updated>2009-12-15T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Note: as you can see I am not yet in control of how to convert LaTeX to mathml — bear with me, but I thought I should kick myself and start posting…</p>
<p>The other day I was looking for someone to chat about an interesting example of ﬁnite <a href="http://en.wikipedia.org/wiki/Semigroup">semigroups</a> . So <del>yesterday</del> last week I finally met up with a friend who offered to do just that. The ‘results’ of the morning we spent chatting are perfect blogging material: quite simple, mostly elementary, easily open for discussion and still carry some interest. However, it is much too long, so I’ll split it into a series of posts.</p>
<p>So to start: what’s the example?</p>
<p><strong>Example</strong> The <a href="http://en.wikipedia.org/wiki/Matrix_(mathematics)">matrices</a><br>
\[
 A= \begin{pmatrix} 1&amp;0\\ 0&amp;0 \end{pmatrix}, B=\begin{pmatrix} -1&amp;-2\\ 1&amp;2 \end{pmatrix}
\]<br>
generate an 8-element (multiplicative) subsemigroup. Its elements are \(A,B,AB, BA, ABA, BAB, ABAB, BABA\).</p>
<p>So what? Well, what is interesting is that although both \(A\) and \(B\) are <a href="http://en.wikipedia.org/wiki/Idempotence">idempotent</a> (i.e. \(A\cdot A=A, B\cdot B = B\)), their product is not, since</p>
<p>\[
 AB = \begin{pmatrix} {-1} &amp; {-2} \\ 0&amp;0 \end{pmatrix}, AB\cdot AB = \begin{pmatrix} 1&amp;2\\ 0&amp;0 \end{pmatrix} = -AB
\]</p>
<p>Still, why is it interesting? Well, this example is of interest for people working with <a href="http://en.wikipedia.org/wiki/Ultrafilter">ultrafilters</a> on semigroups, in particular on \(\mathbb{N}\) — one reason following from the following lemma.</p>
<p><strong>Lemma</strong> Every finite (discrete) semigroup is the image of the closed subsemigroup \(\mathbb{H} := \bigcap_{n \in \mathbb{N}} cl({2^n\mathbb{N}})\) under a continuous homomorphism.</p>
<p>This can be found as Corollary 6.5 in the book ’Algebra in the <a href="http://en.wikipedia.org/wiki/Stone%E2%80%93%C4%8Cech_compactification">Stone–Čech compactification</a>’ by <a href="http://nhindman.us/">Neil Hindman</a> and <a href="http://www.genealogy.math.ndsu.nodak.edu/id.php?id=38708">Dona Strauss</a>. What can we do with this?</p>
<p><strong>Corollary</strong> There are idempotent elements in \(\beta \mathbb{N}\) whose sum is not idempotent.</p>
<p><strong>Proof</strong></p>
<ul>
<li>Step 1 Consider the (discrete) finite semigroup generated by \(A\) and \(B\).</li>
<li>Step 2 By the previous lemma, it is a continuous, homomorphic image of \(\mathbb{H}\).</li>
<li>Step 3 The preimage of both \(A\) and \(B\) is a closed (by continuity) semigroup (by homomorphy) of \(\beta \mathbb{N}\).</li>
<li>Step 4 Conversely, the preimage of \(AB\) cannot contain an idempotent (or else the image of that idempotent, \(AB\), would be idempotent by homomorphy).</li>
<li>Step 5 In particular, by the Ellis-Numakura Lemma, both preimages contain idempotents \(a,b \in \beta \mathbb{N}\).</li>
<li>Step 6 But \(ab\) is in the preimage of \(AB\), hence not idempotent.</li>
</ul>
<p>One can easily show more, i.e., \(a,b\) can even be minimal idempotents and their product is not even in the closure of idempotents, but let’s leave it at that.</p>
<p>Now of course one can look at finite semigroups abstractly. But the advantage of matrix representations is that it puts some flesh to the bones of abstraction.</p>
<p>Update: since fighting with mathml is tough for the time being, here is something to make up for that.  <a href="https://www.peterkrautzberger.org/assets/2009/matrices1.pdf">pdf</a></p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gedankenfetzen nach einer Diskussion zum Lehramtsstudium]]></title>
        <id>https://www.peterkrautzberger.org/0003/</id>
        <link href="https://www.peterkrautzberger.org/0003/">
        </link>
        <updated>2009-12-14T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>I had originally planned to open this blog with a scientific post — but what can you do. Since this post is about universities in Germany this’ll be in German.</p>
<p>Ein paar Gedankenfetzen nach einer Diskussionsveranstaltung zum Lehramtsstudium Mathematik an der FU Berlin. Die einladende Email:</p>
<blockquote>
<p>Liebe Studierende mit dem Ziel “Schule”,<br>
haben Sie manchmal das Gefühl, dass zu viel in Ihren Studiengang gepackt ist, dass Sie nicht unbedingt die richtigen Sachen für Ihren späteren Beruf lernen, dass Sie sich das Studium überhaupt irgendwie anders gedacht haben?<br>
Wirklich ist auch unter Hochschullehrern die Meinung verbreitet, dass in der Lehrerausbildung manches verbesserungsbedürftig ist. Um einen Meinungsaustausch in Gang zu bringen und – vielleicht – Änderungen zum Positiven zu erreichen, soll es<br>
am 14. 12. 2009 (Montag)<br>
ab 16.15 Uhr<br>
im großen Hörsaal der Informatik<br>
eine Diskussionsveranstaltung<br>
“Mathematikausbildung für angehende Lehrerinnen und Lehrer” geben.<br>
Als Fachleute werden dabei sein: Dr. Deiser, Prof. Lutz-Westphal, Prof. Schulz.<br>
Alle Fachbereichsangehörigen sind herzlich eingeladen.<br>
Mit freundlichen Grüßen<br>
E. Behrends</p>
</blockquote>
<p>Anwesend waren, na vielleicht 40 Studenten und eine handvoll Dozenten. Vermutlich litt die Veranstaltung also daran, dass nur die Studenten mit den größten Problemen sowie die Dozenten, die zufällig gerade Anfängervorlesungen halten, anwesend waren, aber genauer erschloss es sich nicht. Aber zu meinen Eindrücken.</p>
<p>Die anwesenden Dozenten/Professoren konnten bei den Studenten mit Einzelinitiativen punkten; seien es ergänzende Verstanstaltungen, um Lehramststudenten zusätzlich zu helfen, seien es didaktische Experimente. Trotzdem klang das nach dem sprichwörtlichen Tropfen auf den heißen Stein. Gerade die Unterschiede zum Engagement viele anderer Dozenten und die Willkür der vermeintlichen Freiheit der Forschung führen in der Lehre wohl eher dazu, dass solche engagierten Dozenten viel zu viel Kraft verschwenden, dieselben Widerstände jedesmal aufs Neue zu überwinden.</p>
<p>Dabei stieß eine Bemerkung des gastgebenden Prof. Behrends kaum auf Reaktionen. Auf die scheinbar erfolgreichen Versuch seiner Kollegin Lutz-Westphal, mehr didaktische Inhalte für Lehramtsstudenten in die Veranstaltungen einzubringen, reagierte er mit der Feststellung, dass dies ja fachlich für andere Dozenten nicht machbar wäre. Warum eigentlich? Ist es zuviel verlangt, dass sich Dozenten eine hohschuldidaktische Bildung aneignen? Es scheint jedenfalls so; Professionalisierung ist ein Fremdwort an deutschen Hochschulen. Sogar eine Vereinbarung unter den Dozenten, “best practices” o.ä. auszutauschen und gar durch persönliche Absprache innerhalb des Fachbereichs (Kollaboration!) verpflichtend zu machen, scheint undenkbar — vor allem wohl, weil ein solches Engagement in der deutschen Wissenschaftslandschaft in keiner Weise honoriert wird; nur die Publikationsliste bringt Geld ein, sonst nichts.</p>
<p>Zur Diskussion um die Vorlesungsgestaltung stellte sich mir nachträglich eine grundlegende Frage. Es wurde breit diskutiert, ob und wie die “normalen” Veranstaltungen für überlastete Lehramtsstudenten ergänzt werden können, durch z.B. didaktische Übungsaufgaben oder einfach leichtere Prüfungsbedingungen. Dabei stellt sich doch eigentlich die umgekehrte Frage: Warum richtet man das Niveau der Veranstaltungen nicht an den Lehramtsstudenten aus und bietet Ergänzungen für Mono-bachelor an? Dies könnten zusätzliche Veranstaltungen mit zusätzlichem Stoff sein, dies könnte Projektarbeit bedeuten, oder es könnten mehr und schwerere Aufgaben in extra Schwerpunktvorlesungen sein. Ich vermute, dass die meisten deutschen Hochschuldozenten viel eher dafür zu begeistern wären, schwereren Stoff gesondert zu vermitteln als leichteren (oder gar “Nachhilfe” zu geben).</p>
<p>Der Großteil der Diskussionsbeiträge durch Studenten (die viel sagten und sogar widersprachen) wirkte jedoch gefangen im Netz der schlechten Umsetzung des Bolognaprozesses. Verzweifelt wehren sie sich, versuchen, hier und da kleine Verbesserungen vorzuschlagen, drehen sich um sich selbst, ohne zu bemerken, dass es kein Herauswinden gibt. Die Probleme bilden eher den Gordischen Knoten, der durchschlagen werden muss. In fast jedem Beitrag zur Sinnhaftigkeit des Studienstoffs wurde klar, was eigentlich jeder weiß: das eigentliche Ziel der Bachelor- und Masterumstellung wurde regelrecht boykottiert — die Einrichtung eines originär neuen Studiengang der den rein äußeren Bedingungen des Bolognaprozess mit inhaltlicher Erneuerung begegnet, der etwas neues, etwas qualitativ anderes, aber vielleicht sogar besseres schafft.</p>
<p>Im Grunde bestand die Einführung des Bachelor/Master darin, dass man Vordiplom und Zwischenprüfung einfach neu deklariert hat (plus Bachelorarbeit und ein Seminarlein). Es scheint, als wollte sich bei der Einführung niemand darüber Gedanken machen, dass ein 6-semestriger Studiengang inhaltlich grundlegend anders strukturiert sein muss als ein Vordiplom. Es braucht andere Vorlesungsformen, andere Seminarformen, andere Medien und andere Curricula — es braucht neue Ideen. Stattdessen haben wir ein umdeklariertes Vordiplom. Aber das Vordiplom war zu unstrukturiert, um den organisatorischen Ansprüchen des Bolognaprozesses zu entsprechen. Wiederum liegt ein wesentlicher Grund der mangelhaften Umsetzung sicherlich darin, dass solch eine Arbeit keinen Wert für die Dozenten bzw. die Professoren hat, das sie nicht vergolten wird. Zudem wurde durch Professor Schulz darauf hingewiesen, dass gerade beim Lehramt in den zuständigen Kommissionen Lehrer saßen und damit für das Lehramtsstudium wohl auch eine Schuld an dem heutigen Elend haben. Die Entwicklung neuer Vorlesungen wäre vielleicht ein mittelfristiges Ziel, dass durch einige wenige, bemühte Dozenten erarbeitet werden könnte, aber wie gesagt, es zählt nichts — wer sollte sich da auch engagieren.</p>
<p>Ein gänzlich verkorkster Diskussionspunkt lag in der Frage nach “Anwendungen”, insbesondere in der Schule. Wie passend, dass kein angewandter Mathematikdozent anwesend war. Von Seiten der Studenten schien es vor allem ein verzweifelter Ruf nach motivierenderen Vorlesungen zu sein. Jedoch trifft es für mich ein tieferes Problem: Der Lehrplan an deutschen Gymnasien ist langweilig und veraltet. Er besteht eigentlich nur aus Rechnen, das auch noch höchst langweilig gelehrt wird. Es ist wie Sportunterricht, bei dem man die ganze Zeit Zirkeltraining macht, aber behauptet, man würde Fussballspielen. Kurz gesagt, alles nach der Bruchrechnung ist eigentlich irrelevant, vor allem auf die Art und Weise, wie es gelehrt wird — und irrelevant heißt hier sowohl für die Bildung der Schüler ganz allgemein als auch als wissenschaftlicher Inhalt. Damit stellt sich aber die Frage, wie man einem Lehramtsstudenten erklären soll, warum er sich mit (Hochschul)Mathematik auseinandersetzen soll. Und ehrlich gesagt, kann ich keinen Grund finden, solange die Lehrpläne an den Schulen nicht modernisiert werden.</p>
<p>Das Problem, dass aber bei all dem Zappeln im Bolognanetz am stärksten auffiel ist die Unsinnigkeit der deutschen Lehrerausbildung. Hochspezialisiert, fast ohne Wechselmöglichkeiten, viel zu lange, ohne Praxiserfahrungen und auch personell weder von den Fachbereichen noch den Studierenden zu meistern. Warum braucht es überhaupt auf universitärer Seite ein spezialisiertes Studium? Warum braucht es einen Master? Warum so komplizierte, inkompatible Studienpläne? So unmöglich es ist, dies praktisch zu fordern: das Lehramtsstudium gehört eigentlich abgeschafft. An dessen Stelle könnte auf der wissenschaftlichen Seite ein BSc oder BA treten und auf pädagogischer Seite eine professionelle Facharbeiterausbildung an den Schulen, die auf einem Bachelor aufbaut. Wäre das so fachlich so unsinnig?</p>
<p>Und dann war da noch Peter Monnerjahn, einsamer Rufer im Walde, der als Einziger wiederholt feststellte, dass es in der gesamten Lehre grundlegende Probleme gibt. Einerseits stieß er sogar bei den Studenten auf großes Unverständnis (was vielleicht zeigt, dass man von Studenten, die drei Jahre an der Uni verbringen, kaum erwarten kann, eine korrekte Analyse der Situation vorzunehmen), andererseits wurden seine Anmerkungen in den Abschlussworten auch noch elegant-arrogant als schlicht “nicht originell” weggewischt. Das war dann der traurige Höhepunkt, an dem ich die Veranstaltung verlassen musste.</p>
<p>Mein persönliches Fazit ist dreigeteilt. Auf der untersten Ebene stehen Lösungen der konkreten Probleme der besorgten Studenten. Auch wenn ich oben vom Zappeln im Netz sprach, so wenig hilft es, deswegen gar nichts zu tun. Die gerne (auch von Studenten) gestellte Frage, ob Lehramtsstudenten “dümmer” sind oder nicht, ist völlig irrelevant. Alle Dozenten haben die Verantwortung, ihre Studenten so zu unterrichten, wie es am besten für die Student ist (lesenswert: <a href="http://www.math.rutgers.edu/%7Ezeilberg/Opinion73.html">Zeilberger</a>). Dazu gehört aber auch die ehrliche Wahrheit, dass Regeln nie für Härtefälle gemacht werden dürfen (Härtefälle, wie alleinerziehende Eltern oder sich ihr Studium selbst finanzierende Studenten) — keine Regel kann sich daran orientieren, aber Ausnahmen müssen dem trotzdem Sorge tragen.</p>
<p>Auf der mittleren Ebene sehe ich die mittelfristigen Möglichkeiten. Solange die schwerwiegenden Defizite — Mängel in der Verwaltung, Kürzungen von studentischen Tutoren, Vernachlässigung der und Mangel an Räumlichkeiten und auch der Mangel an (gut ausgebildeten, langfristig angestellten) Dozenten, vor allem im Mittelbau — solange diese Defizite bestehen, wird es fast unmöglich, Veränderungen in der Lehre grundsätzlich anzugehen. Dies kann solange also nur durch Zusammenarbeit unter den Dozenten gelingen. Dabei haben die Professoren die größte Verantwortung und Verpflichtung, gerade weil Kooperation selten ist unter Professoren, die oft an mittelalterliche Kleinstfürsten erinnern. Anstatt Entscheidungen zu blockieren, müssen Sie dafür sorgen, dass die Erkenntnisse der engagierten Kollegen nicht sinnlose Einzelaktionen bleiben, sondern als “best practice” Kodex zumindest innerhalb der Universitäten Geltung erlangen.</p>
<p>Auf der obersten Ebene sehe ich, dass weiterhin eine langfristige Vision fehlt, wie sich die Lehre und damit die Universität als Institution entwickeln soll. So wenig eine solche Vision praktisch orientiert sein kann, kann ich niemandem trauen, dem eine solche Vision fehlt — nur mit einer klaren Vision lassen sich gut strukturierte Vorschläge für Veränderungen machen, die mit Weitsicht sinnvolle Kompromisse ermöglichen.I had originally planned to open this blog with a scientific post — but what can you do. Since this post is about universities in Germany this’ll be in German.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Testing MathML]]></title>
        <id>https://www.peterkrautzberger.org/0002/</id>
        <link href="https://www.peterkrautzberger.org/0002/">
        </link>
        <updated>2009-12-09T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>One of the tools I want to use in this blog will be MathML. I think MathML is so far the best solution to present mathematical content on the web even though the <a href="http://terrytao.wordpress.com/2009/10/29/displaying-mathematics-on-the-web/">discussion</a> on Terence Tao’s blog shows that MathML has its own deficits, especially when it comes to accessibility.</p>
<p>Nevertheless, tex4ht allows me to wait for a good standard to develop while working with one “generator”, namely LaTeX, to produce multiple outputs.</p>
<p>I chose blogger especially because I wanted to use MathML, e.g.</p>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <semantics>
    <mrow>
      <mi>x</mi>
      <mo>=</mo>
      <mfrac>
        <mrow>
          <mo>&#x2212;<!-- − --></mo>
          <mi>b</mi>
          <mo>&#x00B1;<!-- ± --></mo>
          <msqrt>
            <msup>
              <mi>b</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>2</mn>
              </mrow>
            </msup>
            <mo>&#x2212;<!-- − --></mo>
            <mn>4</mn>
            <mi>a</mi>
            <mi>c</mi>
          </msqrt>
        </mrow>
        <mrow>
          <mn>2</mn>
          <mi>a</mi>
        </mrow>
      </mfrac>
    </mrow>
    <annotation encoding="application/x-tex">x=\frac{-b \pm \sqrt{b^{2}-4ac}}{2a}</annotation>
  </semantics>
</math>
<p>Of course, blogger does not make it easy, but thanks to <a href="http://dpcarlisle.blogspot.com/2007/04/as-mentioned-in-earlier-post-im.html">David Carlisle</a> a good friend of mine was able to hack enough for me to work on for now. Unfortunately, I will now have to add to the header that you really need firefox with javascript, but is that too much to ask these days?</p>
<p>By the way, this tag will hopefully lead to more techological experiments in the future.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Welcome]]></title>
        <id>https://www.peterkrautzberger.org/0001/</id>
        <link href="https://www.peterkrautzberger.org/0001/">
        </link>
        <updated>2009-12-07T00:00:00Z</updated>
        <summary type="html"><![CDATA[<p>After more and more intense blog reading over the last couple of months it felt right to try to start my own blog for the <del>first</del> second time.</p>
<p>For the moment everything in this blog will be experimental which seems appropriate given that I am not PhD student any more but have not officially started my PostDoc yet.</p>
<p>The main purpose of this blog (in the long run) will be to document my own research activities (in the broadest of senses, although usually just mathematics). Of course, due to the nature of the web this blog is bound to include random bits of other things, hopefully including experimental use of the web as a medium, in particular for presenting mathematics.</p>
<p>Enjoy, Peter.</p>]]></summary>
        <author>
            <name>Peter Krautzberger</name>
        </author>
    </entry>
</feed>